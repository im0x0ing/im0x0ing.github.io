{"index":{"slug":"index","filePath":"index.md","title":"🏠 首页","links":["about"],"tags":[],"content":"欢迎来到 ING wiki！\n本质自用, 持续建设中…\n📂 导航\n\n关于我\n\n📝 最近更新\n\n这里可以写一些最近的想法或者置顶的内容。\n"},"工具使用/Obsidian插件":{"slug":"工具使用/Obsidian插件","filePath":"工具使用/Obsidian插件.md","title":"Obsidian插件","links":[],"tags":[],"content":"templater\n可以把Templates文件夹下的笔记作为模板,左侧功能栏点击即可套用到其他笔记上.不会影响已写的内容.\nConsistent Attachments and Links\n右键某个文件夹,可以从整个仓库收集属于该文件夹下笔记的图片,并放到该文件夹下的attachments文件夹中.\n\n首先要在obsidian设置-文件与链接-附件默认存放路径,确定好附件存放方式是在文件夹下的attachments文件夹.\n使用时,比如先移动了一个笔记,然后右键笔记所属文件夹即可选择collect attachments.[注意不要对附件文件夹做任何删除操作,这个移动是附件本体进行移动,不是副本移动]\n\nclear unused images\n就是删除未被引用的附件图片\nGit\n好用,可以把整个obsidian仓库托管到git然后设置每两小时提交一次(如果有修改的话).我之前琢磨附件插件的时候把附件删没了全靠git找回来(当然也可以去回收站找)\nShell Commands\n可以编写终端指令.使用例:\n\n编写了一个指令,每次Obsidian打开的时候会自动进入我的博客本地仓库进行一次发布.\n"},"工具使用/博客搭建":{"slug":"工具使用/博客搭建","filePath":"工具使用/博客搭建.md","title":"博客搭建","links":[],"tags":[],"content":"基于Obsidian和Quartz4.流程:\n\n将quartz4仓库克隆到本地.然后将content文件夹重定向到本地obsidian仓库的public文件夹.这样两边的内容会进行一个同步.\n为本地quartz仓库配置私钥和公钥.私钥链接到github私有仓库.公钥连接到github公有仓库.这样只有静态产物会deploy到公有仓库,将公有仓库名字设置为username.github.io即可.\n在obsidian中的Public文件夹下书写笔记,然后在quartz4本地仓库进行提交.这样之后私有仓库[博客源码]会更新.公有仓库[静态产物]也会更新,最终体现在博客网页上.\n\n评论\ngiscus 基于github仓库discussion\ntips\n\nquartz.config.ts-&gt;plugins -&gt; transformers\n加上一行Plugin.HardLineBreaks(),,就会调用remark-breaks 这个库,将所有换行强制渲染成&lt;br&gt;,否则笔记里面的本来的换行选然后会变成空格.[只有两次回车/两个空格一次回车会被渲染成换行但是太麻烦了所以]\n"},"工具使用/未命名":{"slug":"工具使用/未命名","filePath":"工具使用/未命名.md","title":"未命名","links":[],"tags":[],"content":"gitingest.com/ 可以将github仓库的内容整理成一个txt文件."},"技术积累/Golang/库/Golang标准库":{"slug":"技术积累/Golang/库/Golang标准库","filePath":"技术积累/Golang/库/Golang标准库.md","title":"Golang标准库","links":[],"tags":[],"content":"j := sort.SearchInts(g, x) go标准库的二分查找,在g中查找第一个&gt;=x的位置,如果g中所有数都&lt;x,就会返回len(g)//这里是比最大下标还大1"},"技术积累/Golang/库/fmt":{"slug":"技术积累/Golang/库/fmt","filePath":"技术积累/Golang/库/fmt.md","title":"fmt","links":[],"tags":[],"content":"fmt.Print(&quot;Hello&quot;)//不换行原样输出\nfmt.Println(&quot;a&quot;,&quot;b&quot;)//自动换行且参数之间自动加空格\nfmt.Printf(&quot;我是%s,%d岁&quot;, name, age )//格式化输出,不换行\n \nfmt.Scanln(&amp;n)//读取到的数据放入到这个地址中"},"技术积累/Golang/库/slices":{"slug":"技术积累/Golang/库/slices","filePath":"技术积累/Golang/库/slices.md","title":"slices","links":[],"tags":[],"content":"slices.Sort(x):针对有序类型,默认升序排序,使用默认比较.可以对整数\\浮点数和字符串进行排序\nnums := []int{3, 1, 2}\nslices.Sort(nums) // nums 变为 [1, 2, 3]\nslices.SortFunc(x, cmp):针对任何类型,适用于结构体\\二维数组\\自定义类型\n排序使用自定义排序,必须提供func(a,b,E)int\n// 比较函数：如果 p &lt; q 返回负数，如果 p &gt; q 返回正数，相等返回 0。\ncmp := func(p, q []int) int { return p[0] - q[0] }\nslices.SortFunc(intervals, cmp)\n只要func(p, q T) int返回值&gt;0 就认为p&gt;q,p应该排在q的后面.以此类推.\nleftSize := slices.Index(inorder, preorder[0]) 返回在第一个数组中对应数据第一次出现的下标位置"},"技术积累/Golang/库/strings":{"slug":"技术积累/Golang/库/strings","filePath":"技术积累/Golang/库/strings.md","title":"strings","links":[],"tags":[],"content":"strings.Builder\n常用于在循环中对字符串进行增加的操作.builder就相当于一个缓冲区,在最后才生成最终的字符串.\nimport &quot;strings&quot;\n \nvar sb strings.Builder\nsb.Grow(100)//预分配内存,可以避免中途多次扩容,提高性能\n \nsb.WriteString(&quot;Hello&quot;) // 写入字符串\nsb.WriteByte(&#039; &#039;) // 写入单个字节 (比如空格)\n \nresult := sb.String()//最终生成结果字符串"},"技术积累/Golang/库/轮子":{"slug":"技术积累/Golang/库/轮子","filePath":"技术积累/Golang/库/轮子.md","title":"轮子","links":[],"tags":[],"content":"github.com/go-ini/ini\n读取ini文件\n标准库\n”path/filepath”\nJoin 把多个字符串拼接起来,组成一个合法的路径.最重要的是可以自动识别操作系统,选用不同的路径分隔符.而不是硬编码连接,更加健壮"},"技术积累/Golang/核心知识/01-slice切片动态数组类型":{"slug":"技术积累/Golang/核心知识/01-slice切片动态数组类型","filePath":"技术积累/Golang/核心知识/01 slice切片动态数组类型.md","title":"04 slice切片动态数组类型","links":[],"tags":[],"content":"tips\n\n\nvar s []byte 得到的是nil切片,但是可以照常append go自己会处理.适用于不知道长度的情况下\n\n\ns:=make([]int,0,k) 知道长度的情况下,这种做法更优.\n\n\n注意切片是左闭右开,\n\n\n固定长度数组array\n但是在go中不等同于其他语言数组的地位,可以说slice才是go语言的数组.\n\n根据索引初始化 注意默认值是0\n查看数组的数据类型：长度变成了类型的一部分,因此存在两个问题\n\n因此传参的时候也要区分不同长度的数组了\n而且仍然是一个值传递（把本来的数组拷贝给形参，所以还是会有之前那个内存和地址的问题，所以不能进行改动）\n\n\n所以说要传参的话最好还是写动态数组,也可以使用切片操作符 [:] 你可以把数组“切”一下,这里是创建一个引用 不是copy,相当于传了地址\n\nrange关键字\n根据遍历不同集合返回不同值。\n\n数组或切片\n\n返回两个值  当前元素所在索引和当前元素值本身如果不关心某个返回值的话可以把它设置成匿名\n\n\n\n动态数组:切片 slice\n数据结构\n连续的内存,本身只包含三个信息(可以在runtime包下查询)\ntype slice struct {\n    // 指向起点的地址\n    array unsafe.Pointer\n    // 切片长度\n    len   int\n    // 切片容量\n    cap   int\n}\n\n指针 第一个元素的内存地址\n长度 当前存放的元素个数  访问切片是否合法\n容量 总共能装多少个元素(提前分配的空间元素个数),cap永远大于等于len 考虑性能优化\n\n\n索引时只需要计算目标地址 = 起始地址 + ( 索引 x 每个元素的大小 ),因此时间复杂度是O(1)\n\n特征\n\n传递时表面上是进行slice header的值传递,但因为内部存放的是unsafe.Pointer地址,因此实际上相当于引用传递,可以直接进行传递并在函数中进行值修改.[go语言中没有真正的引用传递,基本都是这样的伪引用传递].\n\n因此len和cap在函数中被修改是不会反映到底层数据结构的\n\n\n括号里面是空的，表示动态。可以看到类型也是动态数组类型\n\nslice切片的四种声明方式/初始化\n\n声明但不进行初始化\n\n判断一个slice是否为空nil [没有空间,而全0不算空]\n空slice不能够进行赋值,但是可以进行append(相当于一个一个开辟空间)\n\n\n\nvar s []init\n \n//判断一个slice是否为0\nif  slice1 == nil{\n\tfmt.println(&quot;是一个空切片&quot;)\n\t}else{\n\tfmt.println(&quot;不是一个空切片&quot;)}\nelse和前后两个括号需要在同一行否则会报语法错\n\n基于make进行初始化\n\n只初始化len而不初始化cap.\n\n此时会将len和cap同时默认设置为len的值.因为如果len&gt;cap会初始化失败.\n切片的长度一旦被指定了，就代表对应位置已经被分配了元素，设置的会是对应元素类型下的零值.\n\n\n分别指定len和cap\n\n在index【len,cap)的区域无法被访问,因为逻辑上不存在元素,访问会被报错.\n\n\n\n\n\ns := make([]int,8)\ns := make([]int,8,16)\n\n%v 可以打印数组内详细数据\n\n\n初始化连带赋值\n\n会将len和cap同时设为3并且完成赋值\n\n\n\n  s := []int{2,3,4}\n初始化源码\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n    // 根据 cap 结合每个元素的大小，计算出消耗的总容量\n    mem, overflow := math.MulUintptr(et.size, uintptr(cap))\n    if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {\n        // 倘若容量超限，len 取负值或者 len 超过 cap，直接 panic\n        mem, overflow := math.MulUintptr(et.size, uintptr(len))\n        if overflow || mem &gt; maxAlloc || len &lt; 0 {\n            panicmakeslicelen()\n        }\n        panicmakeslicecap()\n    }\n    // 走 mallocgc 进行内存分配以及切片初始化,以及回收\n    return mallocgc(mem, et, true)\n}\n追加与截取\n切片的追加\n通过 append 操作，可以在 slice 的末尾，额外新增一个元素.\n\n这里的末尾指的是针对 slice 的长度 len 而言.实际上截取的话,从起点开始的容量会保留,详见辨析5\n这个过程中倘若发现 slice 的剩余cap已经不足了，则会对 slice 进行扩容.动态开辟相当于本来cap的容量\n\n\n在创建 slice 时，如果能够预估到其未来所需的容量空间,应该提前分配好对应容量，避免在运行过程中频繁触发扩容操作，这样会对性能产生不利的影响.\n\n\n实例1\n倘若希望使用 append 操作完成 slice 赋值，则应该在初始化 slice 时，给其设置不同的长度 len 和容量 cap 值，cap 和 len 之间的差值就是预留出来用于 append 操作的空间. 具体代码如下：\nfunc Test_slice(t *testing.T){\n    s := make([]int,0,5)\n    for i := 0; i &lt; 5; i++{\n       s = append(s, i)//追加的对象数组,以及追加的数据\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n实例2\n我们将 slice 的长度和容量都设置为 5,然后通过遍历 slice 的方式进行执行位置元素的赋值（不使用 append 操作）：\nfunc Test_slice(t *testing.T){\n    s := make([]int,5)\n    for i := 0; i &lt; 5; i++{\n       s[i] = i\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n扩容\n当len与cap相等时,下一次append操作就会进行一次扩容\n    // len:4, cap: 4\n    s := []int{2,3,4,5}\n    // len:5, cap: 8    len=原来的长度+1,cap=原来的cap*2\n    s = append(s,6)\n\n\n\n预期容量:\n\n如果只追加一个元素,预期容量就是原本的容量+1,\n如果预期元素是比如一个切片,那么预期容量就可能会超出原容量的两倍.\n\n\n\n如果预期容量小于原切片容量,panic\n\n\n倘若切片元素大小为 0（元素类型为 struct{}），则直接复用一个全局的 zerobase 实例，直接返回\n\n\n倘若预期的新容量超过老容量的两倍，则直接采用预期的新容量\n\n\n倘若老容量小于 256，则直接采用老容量的2倍作为新容量\n\n\n倘若老容量已经大于等于 256，则在老容量的基础上扩容 1/4 的比例并且累加上 192 的数值，持续这样处理，直到得到的新容量已经大于等于预期的新容量为止..如果在这个循环中数值太大了以至于越界,那么就直接取预期新容量为最终值\n\n这样做,可以使得随着容量增长,增长因子从2.0平滑过度到1.25\n1.18之前是直接*1.25,内存分配行为发生剧烈变化不够优雅\nnewcap += (newcap + 3*threshold) / 4。\n\n\n\n根据数据类型推算出实际需要的内存大小,然后mallocgc中还要对内存分配单元mspan的等级制度,推算得到实际需要申请的内存空间大小(向上取整)\n\nmheap是go管理的所有内存之和\nmspan就是标准大小地块,有不同大小等级共程序申请使用.\n\n\n\n调用 mallocgc，对新切片进行内存初始化\n\n\n调用 memmove 方法，将老切片中的内容拷贝到新切片中\n\n\n返回扩容后的新切片【扩容后会变成新的地址】\n源码:\n\n\nfunc growslice(et *_type, old slice, cap int) slice {\n    //... \n    if cap &lt; old.cap {\n        panic(errorString(&quot;growslice: cap out of range&quot;))\n    }\n \n \n    if et.size == 0 {\n        // 倘若元素大小为 0，则无需分配空间直接返回\n        return slice{unsafe.Pointer(&amp;zerobase), old.len, cap}\n    }\n \n \n    // 计算扩容后数组的容量\n    newcap := old.cap\n    // 取原容量两倍的容量数值\n    doublecap := newcap + newcap\n    // 倘若新的容量大于原容量的两倍，直接取新容量作为数组扩容后的容量\n    if cap &gt; doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256\n        // 倘若原容量小于 256，则扩容后新容量为原容量的两倍\n        if old.cap &lt; threshold {\n            newcap = doublecap\n        } else {\n            // 在原容量的基础上，对原容量 * 5/4 并且加上 192\n            // 循环执行上述操作，直到扩容后的容量已经大于等于预期的新容量为止\n            for 0 &lt; newcap &amp;&amp; newcap &lt; cap {             \n                newcap += (newcap + 3*threshold) / 4\n            }\n            // 倘若数值越界了，则取预期的新容量 cap 封顶\n            if newcap &lt;= 0 {\n                newcap = cap\n            }\n        }\n    }\n \n \n    var overflow bool\n    var lenmem, newlenmem, capmem uintptr\n    // 基于容量，确定新数组容器所需要的内存空间大小 capmem\n    switch {\n    // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap.\n    // 同时会针对 span class 进行取整\n    case et.size == 1:\n        lenmem = uintptr(old.len)\n        newlenmem = uintptr(cap)\n        capmem = roundupsize(uintptr(newcap))\n        overflow = uintptr(newcap) &gt; maxAlloc\n        newcap = int(capmem)\n    // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小\n    // 并会针对 span class 进行取整\n    case et.size == goarch.PtrSize:\n        lenmem = uintptr(old.len) * goarch.PtrSize\n        newlenmem = uintptr(cap) * goarch.PtrSize\n        capmem = roundupsize(uintptr(newcap) * goarch.PtrSize)\n        overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize\n        newcap = int(capmem / goarch.PtrSize)\n    // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算   \n    case isPowerOfTwo(et.size):\n        var shift uintptr\n        if goarch.PtrSize == 8 {\n            // Mask shift for better code generation.\n            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63\n        } else {\n            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31\n        }\n        lenmem = uintptr(old.len) &lt;&lt; shift\n        newlenmem = uintptr(cap) &lt;&lt; shift\n        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)\n        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)\n        newcap = int(capmem &gt;&gt; shift)\n    // 兜底分支：根据元素大小乘以元素个数\n    // 再针对 span class 进行取整     \n    default:\n        lenmem = uintptr(old.len) * et.size\n        newlenmem = uintptr(cap) * et.size\n        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n        capmem = roundupsize(capmem)\n        newcap = int(capmem / et.size)\n    }\n \n \n \n \n    // 进行实际的切片初始化操作\n    var p unsafe.Pointer\n    // 非指针类型\n    if et.ptrdata == 0 {\n        p = mallocgc(capmem, nil, false)\n        // ...\n    } else {\n        // 指针类型\n        p = mallocgc(capmem, et, true)\n        // ...\n    }\n    // 将切片的内容拷贝到扩容后的位置 p \n    memmove(p, old.array, lenmem)\n    return slice{p, old.len, newcap}\n}\n切片的截取\n\n要注意这里是左闭右开,因此[0:2]取的是第0.1位,2并没有算进来\n\n\n[:]=[0:len(s)]\n\n\n[:3]=[0:3]\n\n\n[4:]=[4:len(s)]\n\n\n本质上是引用传递操作,因此无论截取多少次,底层都是同一块内存空间数据.不过截取会创建出新的slice header实例\n\n\n因为实际上指向的是同一个地址区间,因此修改其中一个元素会影响到另外一个数组的\n\n\n如果要分开截取的话就使用copy函数,相当于拷贝一个副本,这样修改的话不会影响到本来的slice\n\n\n\n元素删除\n从切片中删除元素(只对len做修改)的实现思路，本质上和切片内容截取的思路是一致的.\n\n删除 slice 中的首个元素，在操作上等同于从切片 index = 1 开始向后进行内容截取\n删除 slice 的尾部元素，则操作等价于截取切片内容，并将终点设置在 len(s) - 1 的位置\n删除 slice 中间的某个元素，操作思路则是采用内容截取加上元素追加的复合操作，可以先截取待删除元素的左侧部分内容，然后在此基础上追加上待删除元素后侧部分的内容\n最后，当我们需要删除 slice 中的所有元素时，也可以采用切片内容截取的操作方式：s[:0]. 这样操作后，slice header 中的指针 array 仍指向原处，但是逻辑意义上其长度 len 已经等于 0，而容量 cap 则仍保留为原值.\n\nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [1,2,3,4]\n    s = s[1:]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [0,1,2,3]\n    s = s[0:len(s)-1]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // 删除 index = 2 的元素\n    s = append(s[:2],s[3:]...)//\n    // s: [0,1,3,4], len: 4, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = s[:0]\n    // s: [], len: 0, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n…:\n\n在函数定义中,func myFunc(args ...int)，这里 ... 意味着 myFunc 是一个可变参数函数。它可以接受任意数量的 int 作为参数（0个、1个或多个）。\n在函数调用中 ：append(s1, s2...)，这里的 ... 意思是“将这个切片 (slice) 拆包/解开 (unpack/expand)”。\n\n因为append并不接受一个slice作为第二个参数,于是我们用…将slice拆分为单独元素\n\n\n\n切片拷贝\n包括简单拷贝和完整拷贝两种\n\n简单拷贝\n\n只要对切片的字面量进行赋值传递.这样相当于创建出了一个新的 slice header 实例，但是其中的指针 array、容量 cap 和长度 len 仍和老的 slice header 实例相同..\n对切片进行%p打印地址,打印出来的不是slice header的地址,而是内部array字段指向的数组地址\n切片的截取操作也属于是简单拷贝，s 和 s1 会使用同一片内存空间，只不过地址起点位置偏移了一个元素的长度. s1 和 s 的地址，刚好相差 8 个 byte.\n\n\n完整拷贝\n\n指的是会创建出一个和 slice 容量大小相等的独立的内存区域，并将原 slice 中的元素一一拷贝到新空间中.在实现上，slice 的完整复制可以调用系统方法 copy，通过日志打印的方式可以看到，s 和 s1 的地址是相互独立的.因此对应的数组地址也是全新的\n\n\n\n问题辨析\nfunc Test_slice(t *testing.T){\n    s := make([]int,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 20\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,0,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [10], len of s: 1, cap of s: 10\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,11)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 11\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0 0] len=2 cap=4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:9]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0] len:1 cap:4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1[0] = -1\n    t.Logf(&quot;s: %v&quot;,s)\n}\n//结果:s: [0 0 0 0 0 0 0 0 -1 0]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    v := s[10]\n    // 求问，此时数组访问是否会越界\n}\n//会越界,因为len=10 是0-9的索引上有值\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1 = append(s1,[]int{10,11,12}...)\n    v := s[10]\n    // ...\n    // 求问，此时数组访问是否会越界\n}\n//由于 s 预留的空间不足，s1 会发生扩容,扩容后会返回拷贝后的新切片,这里的拷贝是完整拷贝,意味着修改 s1 不再会影响到 s\n// s 继续维持原本的长度值 10 和容量值 12，因此访问 s[10] 会panic\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v&quot;,s)\n}\n \n \nfunc changeSlice(s1 []int){\n  s1[0] = -1\n}\n//结果:s=[00000000-10  ]s1=[-10  ]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s, len(s), cap(s))\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1, len(s1), cap(s1))\n}\n \n \nfunc changeSlice(s1 []int){\n  s1 = append(s1, 10)\n}\n//结果:s=[0000000000  ]不变 s1也不变\n//在局部方法 changeSlice 中，虽然对 s1 进行了 append 操作，但这这会在局部方法中这个独立的 slice header 中生效，不会影响到原方法 Test_slice 当中的 s 和 s1 的**长度和容量**.    \n \n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = append(s[:2],s[3:]...)\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n    v := s[4] \n    // 是否会数组访问越界\n}\n//[0,1,3,4] 会.\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,512)  \n    s = append(s,1)\n    t.Logf(&quot;len of s: %d, cap of s: %d&quot;,len(s),cap(s))\n}\n//结果:len=513 cap: 根据不到两倍且&gt;256的计算方式(n += (n+3*256)/4) 可以计算到832, 然后根据mspan向上补齐的法则,得到848\n其他\nslice 不是并发安全的数据结构,没有对并发读写的保护机制.\n参考资料\n你真的了解go语言中的切片吗？—小徐先生的编程世界"},"技术积累/Golang/核心知识/02-map-实现原理":{"slug":"技术积累/Golang/核心知识/02-map-实现原理","filePath":"技术积累/Golang/核心知识/02 map 实现原理.md","title":"02 map 实现原理","links":["tags/待解决"],"tags":["待解决"],"content":"（1）存储基于 key-value 对映射的模式；\n（2）基于 key 维度实现存储数据的去重；\n（3）读、写、删操作控制，时间复杂度 O(1).\n定义\n声明\n\n\n\n\n如果满了的话再添加就会再加一个10(当前容量)\nmap里面感觉长度和容量变成一个东西了\n然后实际上存入的内容并非按存入顺序,而是采用基本的哈希方式来存的,可以认为是随机的.并且go会随机化起始点,所以哪怕两次遍历一个数组,得到的结果是不同的.因此如果要按照key的字母顺序来处理map数据,需要有一个有序索引slice然后用这个slice去map里面一个个查询\n\n\n\nmake是必须的,要有一个开辟空间的这么一个声明,才会有空间(虽然不设定容量的话空间为0)\n\n没有空间时赋值:越界报错\n有空间为0,赋值:会一个一个开辟的所以没事\n\n\n\n\n就是在声明的时候直接初始化,一般用这个\n\n\nkey的类型要求\n必须为可比较的类型，slice、map、func不可比较\n使用方式\n读\nv1 :=myMap[10]\n//倘若key存在,则获取到对应的val\n//倘若key不存在或者map未初始化,则会返回val类型的零值\n \nv2,ok := myMap[10]\n//添加一个bool类型的flag标识,读取成功则为true,读取失败为false[读取失败,key不存在/map未初始化]\n同一种语法能够实现不同返回值类型的适配，是由于代码在汇编时，会根据返回参数类型的区别，映射到不同的实现方法\n写\nmyMap[5] = 6\n//如果map未初始化,直接执行写操作会导致panic报错\n删\ndelete(myMap,5)\n//key存在:删除对应整个键值对\n//key不存在或map未初始化,方法会直接结束,不会产生显式提示\n遍历\nfor k,v := range myMap{\n  // ...\n}\n \nfor k := range myMap{\n  // ...\n}\n//获取key,不关注val的取值\n两次遍历一个数组,得到的结果是不同的.因此如果要按照key的字母顺序来处理map数据,需要有一个有序索引slice然后用这个slice去map里面一个个查询\n并发冲突\nmap 不是并发安全的数据结构，倘若存在并发读写行为，会抛出 fatal error.\n具体规则是：\n（1）并发读没有问题；\n（2）并发读写中的“写”是广义上的，包含写入、更新、删除等操作；\n（3）读的时候发现其他 goroutine 在并发写，抛出 fatal error；\n（4）写的时候发现其他 goroutine 在并发写，抛出 fatal error.\n需要关注，此处并发读写会引发 fatal error，是一种比 panic 更严重的错误，无法使用 recover 操作捕获. 待解决\n核心原理\nmap 又称为 hash map，在算法上基于 hash 实现 key 的映射和寻址；在数据结构上基于桶数组实现 key-value 对的存储.\n以一组 key-value 对写入 map 的流程为例进行简述：\n（1）通过哈希方法取得 key 的 hash 值；\n（2）hash 值对桶数组长度取模，确定其所属的桶；\n（3）在桶中插入 key-value 对.\n\nhash 的性质，保证了相同的 key 必然产生相同的 hash 值，因此能映射到相同的桶中，通过桶内遍历的方式锁定对应的 key-value 对.\n因此，只要在宏观流程上，控制每个桶中 key-value 对的数量，就能保证 map 的几项操作都限制为常数级别的时间复杂度.\n\nhash\nhash 译作散列，是一种将任意长度的输入压缩到某一固定长度的输出摘要的过程，由于这种转换属于压缩映射，输入空间远大于输出空间，因此不同输入可能会映射成相同的输出结果. 此外，hash在压缩过程中会存在部分信息的遗失，因此这种映射关系具有不可逆的特质.\n（1）hash 的可重入性：相同的 key，必然产生相同的 hash 值；\n（2）hash 的离散性：只要两个 key 不相同，不论其相似度的高低，产生的 hash 值会在整个输出域内均匀地离散化；\n（3）hash 的单向性：企图通过 hash 值反向映射回 key 是无迹可寻的.\n（4）hash 冲突：由于输入域（key）无穷大，输出域（hash 值）有限，因此必然存在不同 key 映射到相同 hash 值的情况，称之为 hash 冲突.\nbucket\nmap 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储：\n（1）每个桶固定可以存放 8 个 key-value 对；\n（2）倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.\nhash冲突\n\n首先，由于 hash 冲突的存在，不同 key 可能存在相同的 hash 值；\n再者，hash 值会对桶数组长度取模，因此不同 hash 值可能被打到同一个桶中.\n综上，不同的 key-value 可能被映射到 map 的同一个桶当中.\n\n此时最经典的解决手段分为两种：拉链法和开放寻址法.\n\n拉链法，将命中同一个桶的元素通过链表的形式进行链接，因此很便于动态扩展\n开放寻址法, 在插入新条目时，会基于一定的探测策略持续寻找，直到找到一个可用于存放数据的空位为止.\n\n\nmap的解决\n在 map 解决 hash /分桶 冲突问题时，实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述：\n（1）桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；\n（2）每个桶固定可以存放 8 个 key-value 对；\n（3）当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；\n（4）倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第（3）步；\n（5）倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.\n就是先用开放寻址,后用拉链法,对每个桶通过开放寻址保证填满\n扩容优化性能\nmap 的桶数组长度固定不变，那么随着 key-value 对数量的增长，当一个桶下挂载的 key-value 达到一定的量级，此时操作的时间复杂度会趋于线性，无法满足诉求.\n\n因此在实现上，map 桶数组的长度会随着 key-value 对数量的变化而实时调整，以保证每个桶内的 key-value 对数量始终控制在常量级别，满足各项操作为 O(1) 时间复杂度的要求.\nmap 扩容机制的核心点包括：\n（1）扩容分为增量扩容和等量扩容；\n（2）当桶内 key-value 总数/桶数组长度 &gt; 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；\n（3）当桶内溢出桶(从第二个开始到结束)数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶数组的长度保持为原值；[考虑到kv对不多,但是溢出桶很多的情况(可能本来很多后来慢慢删掉了,会有很多空洞)]\n（4）采用渐进扩容的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动.就是说分摊到后续的每一笔写操作中去这样,比较温和.\n\nkey属于哪个桶是有映射关系的,哈希不变,但是对桶数组取模有影响,就是加上一倍老数组个数.\n\n对4取模,得到的结果是0 那么桶0里面的kv对 key取哈希后得到最低两位都是00(对4取模等价于对3按位与)桶1 最低位01.\n那扩容后对8取模,等价于对7按位与.那么最第三位都要是0 按位与出来=0的才能放在8桶数组的0号位.最低位是100的会放在4号位,和本来的0号位差4\n所以说0号桶里的数,在扩容后,要么在0要么在4,差的就是一倍的老数组个数.就是大致被拆成两份,因此每个桶中的数据规模也大致变成原来的一半.\n\n数据结构\n源码位置在runtime/map.go\nhmap =map\n\ncount 总kv对数量\nB unit8 标注出桶数组的长度是2的B次方(1&lt;&lt;B)\nbuckets unsafe.pointer 指向桶数组起点位置\nextra 预先申请好的溢出桶节点\n对每个kv 还会存一个top值对应key的哈希值高八位来标识一些额外含义\n\n\ntype hmap struct {\n    count     int \n    flags     uint8//map状态标识,标识map是否被goroutine并发读写\n    B         uint8  \n    noverflow uint16 //溢出桶的数量\n    hash0     uint32 //hash随机因子,生成key的hash值得时候会用到\n    buckets    unsafe.Pointer //桶数组\n    oldbuckets unsafe.Pointer //扩容过程中老得同数组\n    nevacuate  uintptr//扩容进度标识,因为扩容是渐进的       \n    extra *mapextra \n}\nmapextra 溢出桶\n\ntype mapextra struct {\n    overflow    *[]*bmap//供桶数组buckets使用的溢出桶\n    oldoverflow *[]*bmap//扩容流程中,老桶数组使用的溢出桶\n \n \n    nextOverflow *bmap//下一个可用的溢出桶\n}\n在 map 初始化时，倘若容量过大，会提前申请好一批溢出桶，以供后续使用，这部分溢出桶存放在 hmap.mapextra 当中：\nbmap =map中的桶\n\n可以存储8组kv对,以及一个指向下一个桶的指针\n每组kv对包括 key的高八位哈希值tophash,key,val 三个部分.每组kv对可以直接通过内存地址偏移的方式去找.所以下面三个值都不是太有用\nconst bucketCnt = 8\ntype bmap struct {\n    tophash [bucketCnt]uint8\n    //keys [bucketCnt]T\n    //values [bucketCnt]T\n    //overflow uint8\n}\n这里key和value分开存,是为了内存对齐.因为k一般是int8(一字节),v是int64(8字节),9字节一组不好存,kkkkvvvv比较好存.\n构造方法/初始化"},"技术积累/Golang/核心知识/03-GMP-原理":{"slug":"技术积累/Golang/核心知识/03-GMP-原理","filePath":"技术积累/Golang/核心知识/03 GMP 原理.md","title":"03 GMP 原理","links":[],"tags":[],"content":"概念梳理\n\n\n                  \n                  tips \n                  \n                \n\n为什么要引入P: 加入了一个本地队列,基本实现了无锁化.并且尽量让相关的g在同一个m上跑,利用了cpu多级缓存性质.\n\n\n线程\n通常语义中的线程，指的是内核级线程，核心点如下：\n（1）是操作系统最小调度单元；\n（2）创建、销毁、调度交由内核完成，cpu 需完成用户态与内核态间的切换；\n（3）可充分利用多核，实现并行.\n协程\n协程，又称为用户级线程，核心点如下：\n（1）与线程存在映射关系，为 M：1；\n（2）创建、销毁、调度在用户态完成.实际上是Go代码指针的修改,切换不同协程结构体而已,对CPU来说一直是在跑同一个线程\n（3）从属同一个内核级线程，无法并行；一个协程阻塞会导致从属同一线程的所有协程无法执行.\nGoroutine\nGoroutine，经 Golang 优化后的特殊“协程”，核心点如下：\n（1）与线程存在映射关系，为 M：N；\n（2）创建、销毁、调度在用户态完成，对内核透明，足够轻便；\n（3）可利用多个线程，实现并行；\n（4）通过调度器的斡旋，实现和线程间的动态绑定和灵活调度；\n（5）栈空间大小可动态扩缩，因地制宜.\nGMP模型\ngmp = goroutine + machine + processor （+ 一套有机组合的机制），下面先单独拆出每个组件进行介绍，最后再总览全局，对 gmp 进行总述\ng\n（1）g 即goroutine，是 golang 中对协程的抽象；\n（2）g 有自己的运行栈、状态、以及执行的任务函数（用户通过 go func 指定）；\n（3）g 需要绑定到 p 才能执行，在 g 的视角中，p 就是它的 cpu.\np\n（1）p 即 processor，是 golang 中的调度器；\n（2）p 是 gmp 的中枢，借由 p 承上启下，实现 g 和 m 之间的动态有机结合；\n（3）对 g 而言，p 是其 cpu，g 只有被 p 调度，才得以执行；\n（4）对 m 而言，p 是其执行代理，为其提供必要信息的同时（可执行的 g、内存分配情况等），并隐藏了繁杂的调度细节；\n（5）p 的数量决定了 g 最大并行数量，可由用户通过 GOMAXPROCS 进行设定（超过 CPU 核数时无意义）.\nm\n（1）m 即 machine，是 golang 中对线程的抽象；\n（2）m 不直接执行 g，而是先和 p 绑定，由其实现代理；\n（3）借由 p 的存在，m 无需和 g 绑死，也无需记录 g 的状态信息，因此 g 在全生命周期中可以实现跨 m 执行.\ngmp\n\nGMP 宏观模型如上图所示，下面对其要点和细节进行逐一介绍：\n（1）M 是线程的抽象；G 是 goroutine；P 是承上启下的调度器；\n（2）M调度G前，需要和P绑定；一个m绑定一个g\n（3）全局有多个M和多个P，但同时并行的G的最大数量等于P的数量；\n（4）G的存放队列有三类\n\nP的本地队列\n全局队列\nwait队列（图中未展示，为io阻塞就绪态goroutine队列）\n\n（5）M调度G时，优先取P本地队列，其次取全局队列，最后取wait队列；这样的好处是，取本地队列时，可以接近于无锁化，减少全局锁竞争；\n（6）为防止不同P的闲忙差异过大，设立work-stealing机制，本地队列为空的P可以尝试从其他P本地队列偷取一半的G补充到自身队列.\n全局队列:不能满,必须要能够扩容,但是扩容会锁死所有p,所以用链表可以直接挂到末尾.并且如果有移动的话不需要内存拷贝,只需要指针操作.\n本地队列:固定长度数组256,因为p访问本地队列非常频繁,一口气加载连续内存的空间局部性比较友好,也没有gc开销\n核心数据结构\ng\ntype g struct {\n    // ...\n    m         *m    //负责执行当前g的m\n    // ...\n    sched     gobuf//gobuffer 存档\n    // ...\n}\n \n \ntype gobuf struct {\n    sp   uintptr //保存 CPU 的 rsp 寄存器的值，指向函数调用栈栈顶\n    pc   uintptr //保存 CPU 的 rip 寄存器的值，指向程序下一条执行指令的地址\n    ret  uintptr //保存系统调用的返回值\n    bp   uintptr // 保存 CPU 的 rbp 寄存器的值，存储函数栈帧的起始位置.\n}\n \n \nconst(\n  _Gidle = itoa // 0 为协程开始创建时的状态，此时尚未初始化完成\n  _Grunnable // 1 协程在待执行队列中，等待被执行\n  _Grunning // 2 协程在待执行队列中，等待被执行\n  _Gsyscall // 3 协程正在执行系统调用\n  _Gwaiting // 4 协程处于挂起态，需要等待被唤醒. gc、channel 通信或者锁操作时经常会进入这种状态\n  _Gdead // 6 协程刚初始化完成或者已经被销毁，会处于此状态\n  _Gcopystack // 8 协程正在栈扩容流程中\n  _Gpreempted // 9 协程被抢占后的状态\n)\nm\ntype m struct {\n    g0      *g     // goroutine with scheduling stack一类特殊的调度协程,不用于执行用户函数,负责执行g之间的切换调度,与m的关系为1:1,也不需要排队,就是m的一部分\n    // ...\n    tls           [tlsSlots]uintptr // thread-local storage (for x86 extern register)线程本地存储,存储内容只对当前线程可见,线程本地存储的是m.tls 的地址，m.tls[0] 存储的是当前运行的 g，因此线程可以通过 g 找到当前的 m、p、g0 等信息.\n    //其实代码执行的时候,cpu也不知道自己在哪个m里面,所以要用m.tls[0].m去找,这么做主要是因为需要更快速的访问g所以牺牲了访问m的所需时间\n    // ...\n}\np\ntype p struct {\n    // ...\n    runqhead uint32  //队列头\n    runqtail uint32   //队列尾\n    runq     [256]guintptr   //本地g队列,最大长度256\n    \n    runnext guintptr  //下一个可以执行的g  比如一些插队的,比如两个协程之间有一些亲缘关系,那么大概率会共享数据,这样就优先运行亲缘近的,可以更好的利用cpu缓存不用洗掉本来的数据\n    // ...\n}\nschedt\n全局g队列的封装\ntype schedt struct {\n    // ...\n    lock mutex   //全局g队列的锁\n    // ...\n    runq     gQueue   //全局g队列\n    runqsize int32 //全局g队列的容量\n    // ...\n}\n调度流程\n两种g的转换\ng可以分为两类\n\n普通g\n调度普通g的g0 执行固定的调度流程,与m的关系是1: 1\n\nm 通过 p 调度执行的 goroutine 永远在普通 g 和 g0 之间进行切换\n\n当 g0 找到可执行的 g 时，会调用 gogo 方法，调度 g 执行用户定义的任务\n当 g 需要主动让渡或被动调度时，会触发 mcall 方法，将执行权重新交还给 g0.\n\nfunc gogo(buf *gobuf)//根据缓存内容恢复普通g\n// ...\nfunc mcall(fn func(*g)) //fn是一个处理函数,在彻底切换到g0之后会被执行,一般是一些调度器逻辑,把放弃了cpu的这个g放到队列尾之类的\n调度类型\n主动调度\n\n一种用户主动执行让渡的方式，主要方式是，用户在执行代码中调用了runtime.Gosched 方法，此时当前 g 会当让出执行权，主动回到全局队列, 等待下次被调度执行.\n保证了当前 P 的本地任务能得到执行，也让其他 P 有机会分担这个 G\n\nfunc Gosched() {\n    checkTimeouts()\n    mcall(gosched_m)//让g0把g放到全局队列\n    }\n被动调度\n常见的被动调度触发方式\n\n因 channel 操作或互斥锁操作陷入阻塞等操作，g会调用 gopark 方法.这里的阻塞是用户态阻塞,不需要占用m,g进行mcall,让g0把自己放进等待队列.\n\nfunc gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {\n    // ...\n    mcall(park_m)\n}\n\ngoready 方法通常与 gopark 方法成对出现，当满足唤醒条件后就会被调用.能够将 g 从阻塞态中恢复，重新进入等待执行的状态.优先进入本地队列,如果本地队列满了,就会进入全局队列\n\nfunc goready(gp *g, traceskip int) {\n    systemstack(func() {\n        ready(gp, traceskip, true)\n    })\n}\n\n\n                  \n                  用户态阻塞与线程态阻塞 \n                  \n                \n\n用户态阻塞:只需要进行逻辑等待,只要信号来了立马就能恢复，并不占用m\n\nchannel,等待有人往里面塞数据\nmutex,等待锁被释放的信号\nsleep,等待闹钟响了的信号\n\n线程阻塞(m阻塞),总之会让内核卡住干不了别的事情\n\n磁盘io\n系统调用\n\n\n\n正常调度\ng 中的执行任务已完成，g0 会将当前 g 置为死亡状态，发起新一轮调度.\n抢占调度\n\n\n倘若 g 执行系统调用[m阻塞]超过指定的时长，且全局的 p 资源比较紧缺，此时将 p 和 g 解绑，把p抢占出来用于其他 g 的调度.\n\n\n等 g 完成系统调用后，会重新进入全局队列中等待被调度.[这时候m已经没有p了,所以也就意味着没有本地队列,g就回到全局队列,而m会试着去寻找空闲的p]\n\n\n值得一提的是，前 3 种调度方式都由 m 下的 g0 完成，唯独抢占调度不同.\n\n\n因为发起系统调用时需要打破用户态的边界进入内核态，此时 m 也会因系统调用而陷入僵直，无法主动完成抢占调度的行为.\n\n\n因此，在 Golang 进程会有一个全局监控协程 monitor g 的存在，这个 g 会越过 p 直接与一个 m [专用的,独立的m]进行绑定，不断轮询对所有 p 的执行状况进行监控. 倘若发现满足抢占调度的条件，则会从第三方的角度出手干预，主动发起该动作.\n\n在 Go 的内存里，有一个全局数组叫 allp，里面记录了所有 P（独轮车） 的实时状态。\n\n\n\n\n\n                  \n                  抢占 \n                  \n                \n\n1.14之前,协作式强占.编译器会在函数调用入口插入检查代码,如果写了死循环且没有函数调用,就永远不会被抢占,m直接被占死.\n1.14之后,变成了基于信号的抢占/异步抢占,sysmon(就是全局g)会给m发送一个操作系统信号,不管g在干嘛,操作系统会中断他并强制插入调度逻辑,所以现在死循环也能被抢下来了\n\n\n宏观调度流程\n（1）以 g0 → g → g0 的一轮循环为例进行串联；\n（2）g0 执行 schedule() 函数，寻找到用于执行的 g；\n（3）g0 执行 execute() 方法，更新当前 g、p 的状态信息，并调用 gogo() 方法，将执行权交给 g；\n（4）g 因主动让渡( gosche_m() )、被动调度( park_m() )、正常结束( goexit0() )等原因，调用 m_call 函数，执行权重新回到 g0 手中；\n（5）g0 执行 schedule() 函数，开启新一轮循环.\nfunc schedule() {\n    // ...\n    gp, inheritTime, tryWakeP := findRunnable() // blocks until work is available//寻找到下一个执行的goroutine\n \n \n    // ...\n    execute(gp, inheritTime)//执行该goroutine:更新状态信息,并且调用gogo方法加载gobuf\n}\nfindRunnable\n如何找到下一个要执行的g.\n是 M（在 g0 栈上）运行调度程序，操作 P 的本地队列或全局队列来获取 G\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) {\n    _g_ := getg()\n \n \ntop:\n    _p_ := _g_.m.p.ptr()\n    // ...\n    // 1. p每执行61次调度,会从全局队列中获取一个 goroutine 进行执行\n    if _p_.schedtick%61 == 0 &amp;&amp; sched.runqsize &gt; 0 {\n        lock(&amp;sched.lock)\n        gp = globrunqget(_p_, 1)\n        unlock(&amp;sched.lock)\n        if gp != nil {\n            return gp, false, false\n        }\n    }\n    \n    // ...\n    //2. 尝试从p本地队列中获取一个可执行的goroutine:runqget方法\n    if gp, inheritTime := runqget(_p_); gp != nil {\n        return gp, inheritTime, false\n    }\n    \n    // ...\n    //3. 倘若本地队列没有可执行的g,会从全局队列中获取\n    if sched.runqsize != 0 {\n        lock(&amp;sched.lock)//加锁\n        gp := globrunqget(_p_, 0)\n        unlock(&amp;sched.lock)\n        if gp != nil {\n            return gp, false, false\n        }\n    }\n    \n\t//4. 倘若本地队列和全局队列都没有g,则会获取准备就绪的网络协程\n    if netpollinited() &amp;&amp; atomic.Load(&amp;netpollWaiters) &gt; 0 &amp;&amp; atomic.Load64(&amp;sched.lastpoll) != 0 {\n        if list := netpoll(0); !list.empty() { // non-blocking\n            gp := list.pop()\n            injectglist(&amp;list)\n            casgstatus(gp, _Gwaiting, _Grunnable)//刚获取网络协程时，g 的状态是处于 waiting 的，因此需要先更新为 runnable 状态.\n            return gp, false, false\n        }\n    }\n \n    // ...\n    //5. work-stealing:从其他 p 中偷取 g\n    procs := uint32(gomaxprocs)\n    if _g_.m.spinning || 2*atomic.Load(&amp;sched.nmspinning) &lt; procs-atomic.Load(&amp;sched.npidle) {\n        if !_g_.m.spinning {\n            _g_.m.spinning = true\n            atomic.Xadd(&amp;sched.nmspinning, 1)\n        }\n \n        gp, inheritTime, tnow, w, newWork := stealWork(now)\n        now = tnow\n        if gp != nil {\n            // Successfully stole.\n            return gp, inheritTime, false\n        }\n        if newWork {\n            // There may be new timer or GC work; restart to\n            // discover.\n            goto top\n        }\n        if w != 0 &amp;&amp; (pollUntil == 0 || w &lt; pollUntil) {\n            // Earlier timer to wait for.\n            pollUntil = w\n        }\n    }\n具体函数\n1. 防饿死\n\np每执行61次调度,会从全局队列中获取一个 goroutine 进行执行\n\n通过globrunqget,传入max=1(最多只拿一个)\n\n\n\nfunc globrunqget(_p_ *p, max int32) *g {\n//全局队列为空\n    if sched.runqsize == 0 {\n        return nil\n    }\n//要获取的goroutine数为,全局g总数/p总数+1 比如11个g2个p,每个p分到6个\n    n := sched.runqsize/gomaxprocs + 1\n    if n &gt; sched.runqsize {\n        n = sched.runqsize\n    }//不超过全局g数\n    //如果是防饿死机制,max=1,这是调用者指定的\n    if max &gt; 0 &amp;&amp; n &gt; max {\n        n = max\n    }\n    //不超过本地队列容量的一半(别塞太满)\n    if n &gt; int32(len(_p_.runq))/2 {\n        n = int32(len(_p_.runq)) / 2\n    }\n\t//开始搬运\n    sched.runqsize -= n\n    gp := sched.runq.pop()//弹出一个是马上要执行的g\n    n--\n    //剩下的g, 循环塞进p的本地队列\n    for ; n &gt; 0; n-- {\n        gp1 := sched.runq.pop()\n        runqput(_p_, gp1, false)\n    }\n    return gp//返回要跑的那个g\n}\n将一个 g 由全局队列转移到 p 本地队列的执行逻辑:\nfunc runqput(_p_ *p, gp *g, next bool) {\n    // ...\n \nretry:\n    h := atomic.LoadAcq(&amp;_p_.runqhead) // 原子加载头节点索引\n    t := _p_.runqtail//加载尾节点索引\n    //环形队列还没满的时候 //go语言中环形队列的t和h不会归零会一直向上增长,计算当前环形队列中元素个数只需要相减就好了\n    if t-h &lt; uint32(len(_p_.runq)) {\n        _p_.runq[t%uint32(len(_p_.runq))].set(gp)//计算放入的位置:环形队列需要对长度取模,并放入数据\n        atomic.StoreRel(&amp;_p_.runqtail, t+1) //更新尾指针并解锁,StoreRel叫做释放写\n        return\n    }\n    //队列满了就执行runqputslow把一半g放到全局队列\n    if runqputslow(_p_, gp, h, t) {\n        return\n    }\n    // 如果slow过程失败了,比如被别人偷了导致 head 变了,就retry重试\n    goto retry\n原子操作:\n对于p的本地队列来说,生产者只有一个就是p自己,只有p能往自己的本地队列里面加东西.而消费者包括p自己从本地队列拿g去执行,也包括其他p通过work stealing机制来偷取p.\n\n因为偷取都是从队头偷取,放东西从队尾放.因此队头指针需要用原子操作,为了获取到确定是最新的head.\n因为是先写入数据,后移动尾指针.移动尾指针之前,这块数据对其他人来说并不可见,因此也不用担心竞争,所以不用原子写入操作.而移动尾指针需要是原子操作StoreRel,这个函数可以确保必须要先写入数据,再更新尾指针,防止cpu进行指令重排.\nLoadAcq:确保获取到最新的\nStoreRel:确保前面的修改已完成并写入内存\nCasRel:会检查当前值是否还是刚才读到的值\n\n\n\n                  \n                  Title \n                  \n                \n\n本地队列采用了单生产者-多消费者的无锁环形队列设计.\n为了性能,利用了原子操作的内存屏障语义来替代互斥锁\n\n移动tail指针,使用store-release语义.\n读取head指针,使用load-acquire语义.\n\n\n\n\n\n                  \n                  互斥锁与原子操作 \n                  \n                \n\n全局队列采用互斥锁,因为逻辑太复杂,原子操作搞不定.而且平摊成本,虽然锁比较慢,但是要操作全局队列的情况也比较少.\n本地队列一般用原子操作,主要是锁太慢了,而访问本地队列很频繁,由于窃取动作发生的频率不会太高，因此当前 p 拿到数据的成功率是很高的，因此可以说p 的本地队列是接近于无锁化，但没有达到真正意义的无锁.\n\n\n倘若发现本地队列 runq 已经满了，则会返回来将本地队列中一半的 g 放回全局队列中，帮助当前 p 缓解执行压力.\nfunc runqputslow(_p_ *p, gp *g, h, t uint32) bool {\n    var batch [len(_p_.runq)/2 + 1]*g //大小是队列容量的一半+新来的那个\n    n := t - h\n    n = n / 2\n    \n    // ...\n    //从队头开始复制到全局队列\n    for i := uint32(0); i &lt; n; i++ {\n        batch[i] = _p_.runq[(h+i)%uint32(len(_p_.runq))].ptr()\n    }\n    if !atomic.CasRel(&amp;_p_.runqhead, h, h+n) { // cas-release, commits consume\n        return false\n    }//更新队头指针\n    \n    batch[n] = gp//把新来的这个放到最后\n \n \n    // Link the goroutines.本地队列是数组结构,全局队列是链表结构,因此需要转换成链表\n    for i := uint32(0); i &lt; n; i++ {\n        batch[i].schedlink.set(batch[i+1])\n    }\n    //组装成一个临时的队列对象q\n    var q gQueue\n    q.head.set(batch[0])\n    q.tail.set(batch[n])\n \n \n    // Now put the batch on global queue.\n    //操作全局队列,必须加锁\n    lock(&amp;sched.lock)\n    globrunqputbatch(&amp;q, int32(n+1))\n    unlock(&amp;sched.lock)\n    return true\n为什么从队头开始搬:\n\n等了很久了,如果是阻塞的话可能还要接着等,不如放到全局让其他的p接走.\n队尾的g很可能跟当前的g有亲缘关系\n\n2. 从本地队列获取\n尝试从 p 本地队列中获取一个可执行的 goroutine\n if gp, inheritTime := runqget(_p_); gp != nil {\n        return gp, inheritTime, false\n    }\n    \nfunc runqget(_p_ *p) (gp *g, inheritTime bool) {\n//这是那个vip通道\n    if next != 0 &amp;&amp; _p_.runnext.cas(next, 0) {\n        return next.ptr(), true\n    }//这里的true指的是是否继承旧的g的时间片.因为一般vip通道的g和旧g有亲缘关系,为了避免无限继承所以共用同一个时间片.\n \n//到256格子环形队列里面拿\n    for {\n        h := atomic.LoadAcq(&amp;_p_.runqhead) // load-acquire, synchronize with other consumers\n        t := _p_.runqtail\n        //本地队列为空\n        if t == h {\n            return nil, false\n        }\n        //不为空,获取队首的g解锁并返回.\n        gp := _p_.runq[h%uint32(len(_p_.runq))].ptr()\n        if atomic.CasRel(&amp;_p_.runqhead, h, h+1) { // cas-release, commits consume\n            return gp, false\n        }\n    }\n3. 从全局队列获取\n倘若本地队列没有可执行的g,会从全局队列中获取\n   if sched.runqsize != 0 {\n        lock(&amp;sched.lock)\n        gp := globrunqget(_p_, 0)//这里的0就是无限制\n        unlock(&amp;sched.lock)\n        if gp != nil {\n            return gp, false, false\n        }\n    }\n4. 获取准备就绪的网络协程\n倘若本地队列和全局队列都没有g,则会获取准备就绪的网络协程[因为发起网络 I/O 请求（比如读写 TCP/UDP 连接）而被阻塞、暂时挂起的普通 Goroutine]\nif netpollinited() &amp;&amp; atomic.Load(&amp;netpollWaiters) &gt; 0 &amp;&amp; atomic.Load64(&amp;sched.lastpoll) != 0 {\n        if list := netpoll(0); !list.empty() { // non-blocking\n            gp := list.pop()//准备自己跑\n            injectglist(&amp;list)//其他已经准备就绪的网络协程放到全局队列\n            casgstatus(gp, _Gwaiting, _Grunnable)//改自己要跑的这个g的状态\n            return gp, false, false\n        }\n  }\n5.work-stealing偷取机制\n从其他 p 中偷取 g. 有时候也会偷全局队列和网络协程\n战略部分:\nfunc stealWork(now int64) (gp *g, inheritTime bool, rnow, pollUntil int64, newWork bool) {\n    pp := getg().m.p.ptr()\n    ranTimer := false\n \n    const stealTries = 4  //至多遍历所有p四次\n    for i := 0; i &lt; stealTries; i++ {\n        stealTimersOrRunNextG :=  i == stealTries-1 \n        //看i是不是=3,如果是最后一次遍历的话才允许偷vip g(runnext)\n\t\t\n\t\t//stealOrder 随机找一个p队列开始遍历,避免多个p去偷同一个p的队列\n        for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() {\n            // ...在这里调用runqgrab\n        }\n    }\n \n    return nil, false, now, pollUntil, ranTime\nfunc runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 {\n    for {\n        h := atomic.LoadAcq(&amp;_p_.runqhead) // load-acquire, synchronize with other consumers\n        t := atomic.LoadAcq(&amp;_p_.runqtail) // load-acquire, synchronize with the producer 这里就需要原子读了\n        \n        //偷一半\n        n := t - h\n        n = n - n/2\n        if n == 0 {\n\t        //没有能偷的,那就看看是不是能偷vip g的轮次(最后一次遍历才被允许)\n            if stealRunNextG {\n                // Try to steal from _p_.runnext.\n                if next := _p_.runnext; next != 0 {\n                //如果受害者p正在运行,那我就等一等避免激烈竞争\n                    if _p_.status == _Prunning {\n                        \n                        if GOOS != &quot;windows&quot; &amp;&amp; GOOS != &quot;openbsd&quot; &amp;&amp; GOOS != &quot;netbsd&quot; {\n                            usleep(3)\n                        } else {\n                            osyield()\n                        }\n                    }\n                    //偷取\n                    if !_p_.runnext.cas(next, 0) {\n                        continue\n                    }\n                    batch[batchHead%uint32(len(batch))] = next\n                    return 1\n                }\n            }\n            return 0\n        }\n        \n        \n        //如果普通队列有g,那就先偷普通队列的\n        //一致性检查\n        if n &gt; uint32(len(_p_.runq)/2) { // read inconsistent h and t\n            continue\n        }\n        //搬运一半复制到自己的batch数组里\n        for i := uint32(0); i &lt; n; i++ {\n            g := _p_.runq[(h+i)%uint32(len(_p_.runq))]\n            batch[(batchHead+i)%uint32(len(batch))] = g\n        }\n        \n        //修改受害者的队列头\n        if atomic.CasRel(&amp;_p_.runqhead, h, h+n) { // cas-release, commits consume\n            return n//返回实际偷取的数量\n        }\n    }\n}\nexecute\n当 g0 为 m 寻找到可执行的 g 之后. 接下来就开始执行 g\nfunc execute(gp *g, inheritTime bool) {\n    _g_ := getg() //现在应该是g0\n \n\t//绑定\n    _g_.m.curg = gp //m 现在跑的是刚才获取的g\n    gp.m = _g_.m  //刚才获取的g的m也设置为当前m\n    \n    casgstatus(gp, _Grunnable, _Grunning)//修改状态,把runnable,真正的改为running\n    //清理与准备 等待计时器为0\n    gp.waitsince = 0\n    gp.preempt = false  //清除强占标记\n    gp.stackguard0 = gp.stack.lo + _StackGuard  //栈溢出检测线\n    if !inheritTime {\n        _g_.m.p.ptr().schedtick++ //调度计数器加一\n    }\n \n \n    gogo(&amp;gp.sched)\ngosched_m\ng执行主动让渡时,会调用mcall方法将执行权归还给g0,并由g0调用gosched_m方法\nmcall方法:将当前用户g的pc和sp保存到g.sched里面,然后从用户栈切换到系统栈,在g0栈上执行gosched_m函数.\nfunc Gosched() {\n    // ...\n    mcall(gosched_m)\n}\n \nfunc gosched_m(gp *g) {\n    goschedImpl(gp)\n}\n \nfunc goschedImpl(gp *g) {\n    status := readgstatus(gp)\n    if status&amp;^_Gscan != _Grunning {\n        dumpgstatus(gp)\n        throw(&quot;bad g status&quot;)\n    }\n    casgstatus(gp, _Grunning, _Grunnable)//切换状态.就绪状态:随时可以跑,但是不想现在跑.\n    dropg()//解除绑定\n    lock(&amp;sched.lock)\n    globrunqput(gp)//扔进全局队列,让出当前cpu给别人\n    unlock(&amp;sched.lock)\n \n \n    schedule()//重新进行调度\n    \nfunc dropg() {\n    _g_ := getg()\n \n \n    setMNoWB(&amp;_g_.m.curg.m, nil)\n    setGNoWB(&amp;_g_.m.curg, nil)\n}\npark_m 与 ready\ng 需要被动调度时，会调用 mcall 方法切换至 g0，并调用 park_m 方法将 g 置为阻塞态\nfunc gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {\n    // ...\n    mcall(park_m)\n}\n \nfunc park_m(gp *g) {\n    _g_ := getg()\n \n    casgstatus(gp, _Grunning, _Gwaiting)\n    dropg()\n \n    // ...\n    schedule()\n当因被动调度陷入阻塞态的 g 需要被唤醒时，会由其他协程执行 goready 方法将 g 重新置为可执行的状态. 然后会将其添加到唤醒者的 p 的本地队列中：\nfunc goready(gp *g, traceskip int) {\n    systemstack(func() {\n        ready(gp, traceskip, true)\n    })\n}\n \nfunc ready(gp *g, traceskip int, next bool) {\n    // ...\n    _g_ := getg()\n    // ...\n    casgstatus(gp, _Gwaiting, _Grunnable)\n    runqput(_g_.m.p.ptr(), gp, next)//调用 runqput 将当前 g 添加到唤醒者 p 的本地队列中，如果队列满了，会连带 g 一起将一半的元素转移到全局队列.(runqput内部逻辑)\n    // ...\n}\ngoexit0\n当 g 执行完成时，会先执行 mcall 方法切换至 g0，然后调用 goexit0 方法\n// Finishes execution of the current goroutine.\nfunc goexit1() {\n    // ...\n    mcall(goexit0)\n} \n \n//g0调用这个函数,g是将死的那个协程\nfunc goexit0(gp *g) {\n    _g_ := getg()//这里获取了g0\n    _p_ := _g_.m.p.ptr()\n \n    casgstatus(gp, _Grunning, _Gdead)//g状态置为dead\n    // ...\n    gp.m = nil//清理gp的状态\n    // ...\n \n    dropg()//实际上是清理m的状态\n \n    // ...\n    schedule()\nretake夺回\n抢占调度的执行者不是 g0，而是一个全局的 monitor g.这个g会轮询所有的p,看哪个p对应的m陷在系统调用里面太久了,就把这个p抢过来分给别的m用.\nfunc retake(now int64) uint32 {\n    n := 0\n    \n    lock(&amp;allpLock)//加锁\n    //遍历全局p队列,寻找需要被强占的目标\n    for i := 0; i &lt; len(allp); i++ {\n        _p_ := allp[i]\n        if _p_ == nil {\n            // This can happen if procresize has grown\n            // allp but not yet created new Ps.\n            continue\n        }\n        pd := &amp;_p_.sysmontick\n        // ...\n        //当前处在系统调用状态的p\n        if s == _Psyscall {            \n            // ...\n            //以下三种情况会continue(不抢占)\n            //本地队列为空,那m阻塞也没事\n            //系统里还有别的空闲p那没必要非得抢这个\n            //进入系统调用的时间比较短(小于10ms)\n            if runqempty(_p_) &amp;&amp; atomic.Load(&amp;sched.nmspinning)+atomic.Load(&amp;sched.npidle) &gt; 0 &amp;&amp; pd.syscallwhen+10*1000*1000 &gt; now {\n                continue\n            }\n            unlock(&amp;allpLock)\n            \n            //动手抢,把p设置为闲置,如果cs成功就彻底解除绑定了\n            if atomic.Cas(&amp;_p_.status, s, _Pidle) {\n                n++\n                _p_.syscalltick++//记录一下p的状态变化\n                handoffp(_p_)//把这个p分配给别人!\n            }\n            incidlelocked(1)\n            lock(&amp;allpLock)\n        }\n    }\n    unlock(&amp;allpLock)\n    return uint32(n)\n}\n需要为p获取新的m的情况如下: 不满足则把p丢进空闲队列.\nfunc handoffp(_p_ *p) {\n//如果p的本地队列里面还有待执行的g或者全局列表里面有g,则需要找一个m来执行.\n    if !runqempty(_p_) || sched.runqsize != 0 {\n        startm(_p_, false)\n        return\n    }\n \n//go希望有一定的m处于spinning自旋状态,就是让他空转,而不是直接沉睡等待别人唤醒.如果没有自旋的m也没有空闲的p,说明大家都很忙,就启动一个m\n去绑定这个p,但是不一定为了跑具体的g,只是为了维持自旋.\n    if atomic.Load(&amp;sched.nmspinning)+atomic.Load(&amp;sched.npidle) == 0 &amp;&amp; atomic.Cas(&amp;sched.nmspinning, 0, 1) {\n        startm(_p_, true)\n        return\n    }\n    \n    lock(&amp;sched.lock)\n    // ...\n    if sched.runqsize != 0 {\n        unlock(&amp;sched.lock)\n        startm(_p_, false)\n        return\n    }\n    // If this is the last running P and nobody is polling network,\n    // need to wakeup another M to poll network.\n    //如果这是最后一个正在跑的p,如果睡了那就没人去问网络协程了,所以给这个p配个m去跑网络轮询.\n    if sched.npidle == uint32(gomaxprocs-1) &amp;&amp; atomic.Load64(&amp;sched.lastpoll) != 0 {\n        unlock(&amp;sched.lock)\n        startm(_p_, false)\n        return\n    }\n \n//如果真的啥都没得干,旧丢进空闲列表.\n    // ...\n获取m时会尝试获取已有的空闲m,否则创建新的m\nfunc startm(_p_ *p, spinning bool) {\n    \n    mp := acquirem()\n    lock(&amp;sched.lock)\n    // ...\n    \n    nmp := mget()\n    if nmp == nil {\n        id := mReserveID()\n        unlock(&amp;sched.lock)\n \n \n        var fn func()\n        // ...\n        newm(fn, _p_, id)\n        // ...\n        return\n    }\n    unlock(&amp;sched.lock)\n    // ...\n}\nreentersyscall 和 exitsyscall\n发生系统调用前，与 g 绑定的原 m 当中.在 m 需要执行系统调用前,会先执行下述方法.[M（线程）带着 G（协程）去内核办事（Syscall）之前怎么请假，办完回来怎么销假]\nfunc reentersyscall(pc, sp uintptr) {\n    _g_ := getg()//当前在跑的g\n \n \n    // ...\n    //保存进度\n    save(pc, sp)\n    _g_.syscallsp = sp\n    _g_.syscallpc = pc\n    casgstatus(_g_, _Grunning, _Gsyscall)//变更状态\n    // ...\n \n\t//腾出工位:找到我的p,解除绑定:p解除m\n    pp := _g_.m.p.ptr()\n    pp.m = 0\n    _g_.m.oldp.set(pp)//m记住旧的p,后续 m 恢复后，会优先寻找旧的 p 重新建立绑定关系.\n    _g_.m.p = 0//解除对p的绑定,带着g去内核流浪了\n    atomic.Store(&amp;pp.status, _Psyscall)//给p加一个状态 说m去系统调用了\n    // ...\nfunc exitsyscall() {\n    _g_ := getg()//普通g\n    \n    // ...尝试和旧的p进行绑定\n    if exitsyscallfast(oldp) {\n        // ...\n        casgstatus(_g_, _Gsyscall, _Grunning)\n        // ...\n        return\n    }\n \n \n    // ...//和旧的p绑定失败,则用mcall方法切换到m的g0 执行exitsyscall0方法\n    mcall(exitsyscall0)\n    // ...\n}\n \n \nfunc exitsyscall0(gp *g) {\n    casgstatus(gp, _Gsyscall, _Grunnable)//切换为可执行状态\n    dropg()//m解绑g,因为这里是m去找p 如果找到了才运行g,如果找不到的话,m是会休息的,所以要提前解绑.\n    \n    //从全局p队列获取可用的p\n    lock(&amp;sched.lock)\n    var _p_ *p\n    if schedEnabled(gp) {\n        _p_, _ = pidleget(0)\n    }\n    \n    //没有p可以用,就把g添加到全局队列\n    var locked bool\n    if _p_ == nil {\n        globrunqput(gp)\n    } \n    \n    //如果获取到p就执行g\n    unlock(&amp;sched.lock)\n    if _p_ != nil {\n        acquirep(_p_)\n        execute(gp, false) // 不返回...一旦执行，程序计数器（PC）就被改写了，CPU 直接去跑别的指令了，之前的函数栈帧对它来说已经是“过去式”了。\n    }\n    \n    // ...\n    //在没找到p的分支的末尾.m陷入沉睡\n    stopm()\n    schedule() // Never returns.\n}\n关于阻塞\n\n\n由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine；\n\n\n由于网络请求和 IO 操作导致 Goroutine 阻塞。Go 程序提供了网络轮询器（NetPoller）来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。执行网络系统调用不需要额外的 M，网络轮询器使用系统线程，它时刻处理一个有效的事件循环，有助于减少操作系统上的调度负载。用户层眼中看到的 Goroutine 中的“block socket”，实现了 goroutine-per-connection 简单的网络编程模式。实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket + I/O 多路复用机制“模拟”出来的。\n\n\n当调用一些系统方法的时候（如文件 I/O），如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 G1 将阻塞当前 M1。调度器引入 其它M 来服务 M1 的P。\n\n\n如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了。Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。\n\n"},"技术积累/Golang/核心知识/04-内存模型与分配机制":{"slug":"技术积累/Golang/核心知识/04-内存模型与分配机制","filePath":"技术积累/Golang/核心知识/04 内存模型与分配机制.md","title":"04 内存模型与分配机制","links":[],"tags":[],"content":"\nmcache: 每个p自己的缓存,各种规格的mspan都缓存一份.不需要锁\nmcentral: 某种特定规格的mspan的集合,如果p自己的缓存使用完了,就到mcentral里获取.需要锁.\nmheap: 如果mcentral也没有了,就要到mheap申请,这里必须严格加锁,性能最慢.管理的是堆和页,而不是mspan.\n如果mheap也没有了,就得向操作系统申请虚拟内存\n\n内存模型\n回顾操作系统\n\n操作系统中经典的多级存储模型设计.\n\n多级模型:根据读取速度\\空间大小\\价格的不同\n\n寄存器\n高速缓存\n内存\n磁盘\n\n\n动态切换\n\n\n虚拟内存与物理内存:\n\n在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）\n优化用户体验（进程感知到获得的内存空间是“连续”的）\n“放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）\n\n\n分页管理:\n\n操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作“页”，于物理内存而言叫作“帧”，原因及要点如下：\n\n提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）\n提高内外存交换效率（更细的粒度带来了更高的灵活度）\n与虚拟内存机制呼应，便于建立虚拟地址→物理地址的映射关系（聚合映射关系的数据结构，称为页表）\nlinux 页/帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）\n\n\n\n\n\ngo内存模型\n核心要点:\n\n空间换时间,一次缓存,多次复用.\n因为申请内存的操作很重,那么一次多申请一些.\nGolang中的堆mheap:\n\n\n对操作系统而言,这是用户进程中缓存的内存\n对于go进程内部,堆是所有对象的内存起源\n\n\n多级缓存,实现无/细锁化\n堆是Go运行时最大的临界共享资源,这意味着每次存取都要加锁.\nGolang在堆之上依次细化力度:\n\n\nmheap:全局内存起源,访问要加全局锁\nmcentral:每种对象大小规格(全局共划分为68种)对应的缓存,锁的粒度也仅限于同一种规格以内.mcentral是同种规格的mspan连接而成的一个链表\nmcache:每个P持有一份的内存缓存,访问时无锁.\n\n\n多级规格,提高利用率\n\n\npage 最小的存储单元.类似于操作系统的分页,但是大小是8kb\nmspan 最小的管理单元 大小为page的整数倍,被划分为从8b到80kb67种不同的规格[一个mspanl里面只有一种规格].[是再划分,和页的大小无关了.划分后的小块叫做object,object的数量叫nelems] 分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间.\n\n多规格 mspan 下产生的特点：\n\n根据规格大小，产生了等级的制度\n消除了外部碎片，但不可避免会有内部碎片.宏观上能提高整体空间利用率\n正是因为有了规格等级的概念，才支持 mcentral 实现细锁化,因为申请的是不同规格的mspan,不需要去全局争夺锁.\n\n\n\n\n\n核心概念梳理\n内存单元mspan\n\nmspan 是 Golang 内存管理的最小单元\nmspan 大小是 page 的整数倍（Go 中的 page 大小为 8KB），且内部的页是连续的（至少在虚拟内存的视角中是这样）\n每个 mspan 根据空间大小以及面向分配对象的大小，会被划分为不同的等级\n同等级的 mspan 会从属同一个 mcentral，最终会被组织成链表，因此带有前后指针（prev、next）\n由于同等级的 mspan 内聚于同一个 mcentral，所以会基于同一把互斥锁管理\nmspan 会基于 bitMap 辅助快速找到空闲内存块（块大小为对应等级下的 object 大小）此时需要使用到 Ctz64 算法.\n\n\ntype mspan struct {\n    // 标识前后节点的指针 \n    next *mspan     \n    prev *mspan    \n    // ...\n    // 起始地址\n    startAddr uintptr \n    // 包含几页，页是连续的\n    npages    uintptr \n \n \n    // 标识此前的位置都已被占用 \n    freeindex uintptr\n    // 最多可以存放多少个 object\n    nelems uintptr // number of object in the span.\n \n    // bitmap 每个 bit 对应一个 object 块，标识该块是否已被占用\n    allocCache uint64//64位,每一位代表一个格子的状态0为占用1为空.cpu有一条特殊指令可以对二进制进行O(1)的查询找到二进制中的1的位置\n    //如果这 64 位都用完了（全是 0），再从大位图中加载下 64 位进来补充\n    \n    \n    // ...\n    // 标识 mspan 等级，包含 class 和 noscan 两部分信息\n    //size class 前7位 可以查询这里面划分的object大小\n    //noscan 最后一位 是免扫描标记,gc看到这个标记,就知道里面存的对象不包含指针,不需要沿着指针打开往下扫描.\n    spanclass    spanClass    \n    // ...\n}\n内存单元等级spanClass\nmspan 根据空间大小和面向分配对象的大小，被划分为 67 种等级（1-67，实际上还有一种隐藏的 0 级，用于处理更大的对象，上不封顶）\n\n\nclass: mspan等级标识\nbytes/obj：该大小规格的对象会从这一 mspan 中获取空间. 创建对象过程中，大小会向上取整为 8B 的整数倍，因此该表可以直接实现 object 到 mspan 等级 的映射\nbytes/span：该等级的 mspan 的总空间大小\nobject：该等级的 mspan 最多可以 new 多少个对象，结果等于 （3）/（2）\ntail waste：（ 3）/（2）可能除不尽，于是该项值为（3）%（2）\nmax waste：通过下面示例解释：\n\n\n以 class 3 的 mspan 为例，class 分配的 object 大小统一为 24B，由于 object 大小 ⇐ 16B 的会被分配到 class 2 及之前的 class 中，因此只有 17B-24B 大小的 object 会被分配到 class 3.\n\n最不利的情况是，当 object 大小为 17B，会产生浪费空间比例如下：\n ((24-17)*341 + 8)/8192 = 0.292358 ≈ 29.24%\n\n除了上面谈及的根据大小确定的 mspan 等级外，每个 object 还有一个重要的属性叫做 nocan，标识了 object 是否包含指针，在 gc 时是否需要展开标记.\n在 Golang 中，会将 span class + nocan 两部分信息组装成一个 uint8，形成完整的 spanClass 标识. 8 个 bit 中，高 7 位表示了上表的 span 等级（总共 67 + 1 个等级，8 个 bit 足够用了），最低位表示 nocan 信息.\n线程缓存mcache\n（1）mcache 是每个 P 独有的缓存，因此交互无锁\n（2）mcache 将每种 spanClass 等级(是否scan算作同一个等级的两种mspan)的 mspan 各缓存了一个，总数为 2（nocan 维度） * 68（大小维度）= 136\n（3）mcache 中还有一个为对象分配器 tiny allocator，用于处理小于 16B 对象的内存分配\nconst numSpanClasses = 136\ntype mcache struct {\n    // 微对象分配器相关\n    tiny       uintptr\n    tinyoffset uintptr\n    tinyAllocs uintptr\n    \n    // mcache 中缓存的 mspan，每种 spanClass 各一个\n    alloc [numSpanClasses]*mspan \n    // ...\n}\n中心缓存mcentral\n（1）每个 mcentral 对应一种 spanClass\n（2）每个 mcentral 下聚合了该 spanClass 下的 mspan\n（3）mcentral 下的 mspan 分为两个链表，分别为有空间 mspan 链表 partial 和满空间 mspan 链表 full\n（4）每个 mcentral 一把锁\ntype mcentral struct {\n    // 对应的 spanClass\n    spanclass spanClass\n    // 有空位的 mspan 集合，数组长度为 2 是用于抗一轮 GC\n    partial [2]spanSet \n    // 无空位的 mspan 集合\n    full    [2]spanSet \n}\n全局堆缓存mheap\n• 对于 Golang 上层应用而言，堆是操作系统虚拟内存的抽象\n• 以页（8KB）为单位，作为最小内存存储单元\n• 负责将连续页组装成 mspan\n• 全局内存基于 bitMap 标识其使用情况，每个 bit 对应一页，为 0 则自由，为 1 则已被 mspan 组装\n• 通过 heapArena 聚合页，记录了页到 mspan 的映射信息（2.7小节展开）\n• 建立空闲页基数树索引 radix tree index，辅助快速寻找空闲页（2.6小节展开）\n• 是 mcentral 的持有者，持有所有 spanClass 下的 mcentral，作为自身的缓存\n• 内存不够时，向操作系统申请，申请单位为 heapArena（64M）\ntype mheap struct {\n    // 堆的全局锁\n    lock mutex\n \n \n    // 空闲页分配器，底层是多棵基数树组成的索引，每棵树对应 16 GB 内存空间\n    pages pageAlloc \n \n \n    // 记录了所有的 mspan. 需要知道，所有 mspan 都是经由 mheap，使用连续空闲页组装生成的\n    allspans []*mspan\n \n \n    // heapAreana 数组，64 位系统下，二维数组容量为 [1][2^22]\n    // 每个 heapArena 大小 64M，因此理论上，Golang 堆上限为 2^22*64M = 256T\n    arenas [1 &lt;&lt; arenaL1Bits]*[1 &lt;&lt; arenaL2Bits]*heapArena\n \n \n    // ...\n    // 多个 mcentral，总个数为 spanClass 的个数\n    central [numSpanClasses]struct {\n        mcentral mcentral\n        // 用于内存地址对齐\n        pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte\n    }\n \n \n    // ...\n}\n空闲页索引 pageAlloc\n\n数据结构背后的含义\n\nmheap会基于bitMap标识内存中各页的使用情况,bit位为0代表该页空闲,为1代表该页已被mspan占用\n每棵基数树聚合了16GB内存空间中各页使用情况的索引信息,用于帮助mheap快速找到指定长度的连续空闲页的所在位置\nmheap持有2的14次方棵基数树,因此索引全面覆盖到2的114次方*16gb=256T的内存空间\n\n\n基数树设定\n\n\n基数树中，每个节点称之为 PallocSum，是一个 uint64 类型，体现了索引的聚合信息，包含以下四部分：\n\nstart：最右侧 21 个 bit，标识了当前节点映射的 bitMap 范围中首端有多少个连续的 0 bit（空闲页）称之为 start；\n- max：中间 21 个 bit，标识了当前节点映射的 bitMap 范围中最多有多少个连续的 0 bit（空闲页）称之为 max；\nend：左侧 21 个 bit，标识了当前节点映射的 bitMap 范围中最末端有多少个连续的 0 bit（空闲页）称之为 end.\n最左侧一个 bit，弃置不用\n总之就是利用基数树快速查找空闲页\n\n\n\nheapArena\n\n每个 heapArena 包含 8192 个页，大小为 8192 * 8KB = 64 MB\nheapArena 记录了页到 mspan 的映射. 因为 GC 时，通过地址偏移找到页很方便，但找到其所属的 mspan 不容易. 因此需要通过这个映射信息进行辅助.\nheapArena 是 mheap 向操作系统申请内存的单位（64MB）\n\n对象分配流程\n下面来串联 Golang 中分配对象的流程，不论是以下哪种方式，最终都会殊途同归步入 mallocgc 方法中，并且根据 3.1 小节中的策略执行分配流程：\n\nnew(T)\n- &amp;T{}\nmake(xxxx)\n\n流程总览\n在golang中,依据object的大小,将其分为三类\n\ntiny 微对象(0,16B)\nsmall 小对象[16B,32KB]\nlarge 大对象(32KB,∞)\n\n不同类型的对象，会有着不同的分配策略，这些内容在 mallocgc 方法中都有体现.\n核心流程类似于读多级缓存的过程，由上而下，每一步只要成功则直接返回. 若失败，则由下层方法兜底.\n\n\n对于微对象的分配流程：\n（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）\n（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）\n（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）\n（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）\n（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.\n\n\n对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；\n\n\n对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步.[mspan最大的规格只有32KB]\n\n\n主干方法mallocgc\nfunc mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer {\n    // ...    \n    // 获取 m\n    mp := acquirem()\n    // 获取当前 p 对应的 mcache\n    c := getMCache(mp)\n    var span *mspan\n    var x unsafe.Pointer\n    // 根据当前对象是否包含指针，标识 gc 时是否需要展开扫描\n    noscan := typ == nil || typ.ptrdata == 0\n    // 是否是小于 32KB 的微、小对象\n    if size &lt;= maxSmallSize {\n    // 小于 16 B 且无指针，则视为微对象\n        if noscan &amp;&amp; size &lt; maxTinySize {\n        // tiny 内存块中，从 offset 往后有空闲位置\n          off := c.tinyoffset\n          // 如果大小为 5 ~ 8 B，size 会被调整为 8 B，此时 8 &amp; 7 == 0，会走进此分支\n          if size&amp;7 == 0 {\n                // 将 offset 补齐到 8 B 倍数的位置\n                off = alignUp(off, 8)\n                // 如果大小为 3 ~ 4 B，size 会被调整为 4 B，此时 4 &amp; 3 == 0，会走进此分支  \n           } else if size&amp;3 == 0 {\n           // 将 offset 补齐到 4 B 倍数的位置\n                off = alignUp(off, 4)\n                // 如果大小为 1 ~ 2 B，size 会被调整为 2 B，此时 2 &amp; 1 == 0，会走进此分支  \n           } else if size&amp;1 == 0 {\n            // 将 offset 补齐到 2 B 倍数的位置\n                off = alignUp(off, 2)\n           }\n// 如果当前 tiny 内存块空间还够用，则直接分配并返回\n            if off+size &lt;= maxTinySize &amp;&amp; c.tiny != 0 {\n            // 分配空间\n                x = unsafe.Pointer(c.tiny + off)\n                c.tinyoffset = off + size\n                c.tinyAllocs++\n                mp.mallocing = 0\n                releasem(mp)  \n                return x\n            } \n            // 分配一个新的 tiny 内存块\n            span = c.alloc[tinySpanClass]    \n            // 从 mCache 中获取\n            v := nextFreeFast(span)        \n            if v == 0 {\n            // 从 mCache 中获取失败，则从 mCentral 或者 mHeap 中获取进行兜底\n                v, span, shouldhelpgc = c.nextFree(tinySpanClass)\n            }   \n// 分配空间      \n            x = unsafe.Pointer(v)\n           (*[2]uint64)(x)[0] = 0\n           (*[2]uint64)(x)[1] = 0\n           size = maxTinySize\n        } else {\n          // 根据对象大小，映射到其所属的 span 的等级(0~66）\n          var sizeclass uint8\n          if size &lt;= smallSizeMax-8 {\n              sizeclass = size_to_class8[divRoundUp(size, smallSizeDiv)]\n          } else {\n              sizeclass = size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]\n          }        \n          // 对应 span 等级下，分配给每个对象的空间大小(0~32KB)\n          size = uintptr(class_to_size[sizeclass])\n          // 创建 spanClass 标识，其中前 7 位对应为 span 的等级(0~66)，最后标识表示了这个对象 gc 时是否需要扫描\n          spc := makeSpanClass(sizeclass, noscan) \n          // 获取 mcache 中的 span\n          span = c.alloc[spc]  \n          // 从 mcache 的 span 中尝试获取空间        \n          v := nextFreeFast(span)\n          if v == 0 {\n          // mcache 分配空间失败，则通过 mcentral、mheap 兜底            \n             v, span, shouldhelpgc = c.nextFree(spc)\n          }     \n          // 分配空间  \n          x = unsafe.Pointer(v)\n          // ...\n       }      \n       // 大于 32KB 的大对象      \n   } else {\n       // 从 mheap 中获取 0 号 span\n       span = c.allocLarge(size, noscan)\n       span.freeindex = 1\n       span.allocCount = 1\n       size = span.elemsize         \n       // 分配空间   \n        x = unsafe.Pointer(span.base())\n   }  \n   // ...\n   return x\n}                               \ntiny分配\n每个 P 独有的 mache 会有个微对象分配器，基于 offset 线性移动的方式对微对象进行分配，每 16B 成块，对象依据其大小，会向上取整为 2 的整数次幂进行空间补齐，然后进入分配流程.\n\n\n                  \n                  Title \n                  \n                \n\n内存分配中,最小的分配单位是八字节,就算只存一个bool,也会给一个八字节的格子.是 mcache 先去申请一个普通的 mspan（比如 class 2）然后从里面拿出一个 16B 的块，专门标记为“现在的 tiny block”，然后开始往里面塞东西.   避免内部碎片\n\n\n\n\n                  \n                  Title \n                  \n                \n\n编译期结束后,就已经知道要为什么变量申请什么内存.只是把产生的tinyobject变量按照一定的规则塞进mcache的tiny block里面\n\n\n\n    noscan := typ == nil || typ.ptrdata == 0\n    // ...\n    //只收不含指针且大小小于 16B的对象\n        if noscan &amp;&amp; size &lt; maxTinySize {\n        // tiny 内存块中，从 offset 往后有空闲位置\n          off := c.tinyoffset\n          // off 此时是经过“对齐算法”调整后的新偏移量\n          // ...\n          // `c.tiny` 指向当前那个 16B 的内存块的**起始地址**。`c.tinyoffset` 是一个游标，记录当前用到哪里了。\n            // 如果当前 tiny 内存块空间还够用，则直接分配并返回\n            if off+size &lt;= maxTinySize &amp;&amp; c.tiny != 0 {\n            // 分配空间\n                x = unsafe.Pointer(c.tiny + off)//计算内存地址\n                c.tinyoffset = off + size//更新游标\n                c.tinyAllocs++//统计数据\n                mp.mallocing = 0//恢复状态\n                releasem(mp)\n                return x\n            }\n        //都是纳秒级操作,基本等同于CPU的加法指令\n           // ...\n        }\nmcache分配\n宏观流程\n          // 根据对象大小，映射到其所属的 span 的等级(0~66）\n          //比如申请 20字节，Go 会匹配到 32字节 的规格,这个sizeclass是一个编号id.比如32B对应编号是3\n          var sizeclass uint8\n          // get size class ....     \n          // 对应 span 等级下，分配给每个对象的空间大小(0~32KB)\n          \n          // 但是同一个size  还有两种span .spanclass就是,sizeclaass左移一位,最后一位标记是否noscan\n          //get span class\n          spc := makeSpanClass(sizeclass, noscan) \n          \n          //c 是 mcache，alloc 是一个数组 [134]*mspan。这就是用spanclass把span拿出来\n          //这里拿出来完全不需要加锁,因为mcache是绑定在p上的\n          span = c.alloc[spc]  \n          // 从 mcache 的 span 中尝试获取空间.这里的nextFreeFast是极速地指一个空座位.span结构体里面有一个allocCache,有64个bit,缓存了当前的座位中接下来64个座位的空闲状态\n          //这个 allocCache 被加载到了 CPU 的寄存器 中。 CPU 有一条特殊的指令（TZCNT 或 BSF，Go 里的 sys.Ctz64），它能在一个 CPU 周期内，直接算出这个 64 位的数字里，倒数第几位是 1。\n          v := nextFreeFast(span)\n          if v == 0 {\n          // mcache 分配空间失败，则通过 mcentral、mheap 兜底 \n          // 这里的nextfree.这个方法可能会1. 刷新位图:加载下64个槽位的状态.2.如果mspan彻底满了,就向mcentral申请新的span[Refill]\n             v, span, shouldhelpgc = c.nextFree(spc)\n          }     \n          // 分配空间  \n          x = unsafe.Pointer(v)\n微观算法\nfunc nextFreeFast(s *mspan) gclinkptr {\n    // 通过 ctz64 算法，在 bit map 上寻找到首个 object 空位\n    theBit := sys.Ctz64(s.allocCache) \n    \n    if theBit &lt; 64 {//如果返回64的话说明没有找到.返回&lt;64的数字就是这非0bit的位置\n\t    //计算全局索引,要加上freeindex:也就是alloccache对应的起始游标\n        result := s.freeindex + uintptr(theBit)\n        \n        //边界检查\n        if result &lt; s.nelems {//这个nelems是当前span总共能容纳的对象数\n            freeidx := result + 1\n            if freeidx%64 == 0 &amp;&amp; freeidx != s.nelems {\n                return 0\n            }//如果刚好用完了当前的64位,且span还有剩余的对象,那么可以退出去慢分配.\n            \n            //更新位图,向右移动多少多少位,变成theBit的接下来64位\n            s.allocCache &gt;&gt;= uint(theBit + 1)\n            // 更新 freeindex \n            s.freeindex = freeidx\n            s.allocCount++\n            // 返回获取 object 空位的内存地址 \n            return gclinkptr(result*s.elemsize + s.base())//比如分配到了第二个对象,那么计算实际的地址\n        }\n    }\n    return 0\n}\nmcentral分配\ntiny分配和mcache分配都失败之后,就会进入这个慢分配路径\nfunc (c *mcache) nextFree(spc spanClass) (v gclinkptr, s *mspan, shouldhelpgc bool) {\n    s = c.alloc[spc]//从mcache里面把特定spanclass的span拿出来\n    // ...\n    // 从 mcache 的 span 中获取 object 空位的偏移量\n    freeIndex := s.nextFreeIndex()\n    if freeIndex == s.nelems {\n        // ...\n        // 倘若 mcache 中 span 已经没有空位，则调用 refill 方法从 mcentral 或者 mheap 中获取新的 span    \n        c.refill(spc)\n        // ...\n        // 再次从替换后的 span 中获取 object 空位的偏移量\n        s = c.alloc[spc]\n        freeIndex = s.nextFreeIndex()\n    }\n    // ...\n    v = gclinkptr(freeIndex*s.elemsize + s.base())\n    s.allocCount++\n    // ...\n    return\n}    \nfunc (c *mcache) refill(spc spanClass) {  \n    s := c.alloc[spc]\n    // ...\n    // mheap_.central[spc]：根据规格 (spanClass)，找到管理这种规格的中心仓库。\n    // 调用 .cacheSpan() 方法，让 mcentral 给一个可用的 span。\n    s = mheap_.central[spc].mcentral.cacheSpan()\n    // ...\n    // 将新的 span 添加到 mcahe 当中\n    c.alloc[spc] = s\n}\nmcentral管理着两个链表\n\npartial:有空闲空间的span\nfull:被认为是满的span\n\n\nGC（服务员）的工作 - 标记： 服务员（GC）每隔一小时巡视一圈。他不收盘子，只是看哪张桌子的客人都走光了，就在桌子上贴个“可回收”的标签（Marking）。经理指着账本 B 上的一张桌子说：“这一桌，你过去看看。” 领位员走过去（Acquire 锁定），发现桌子上贴着“可回收”，于是顺手把盘子收了（Sweep）。 瞬间，一张“满桌”变成了“空桌”。领位员就可以安排新客人入座了。把清理垃圾的开销，平摊（Amortize） 到了每一次内存分配中。\n\nfunc (c *mcentral) cacheSpan() *mspan {\n    // ...\n    var sl sweepLocker //特殊的锁,用于并发清扫 \n    // ...\n    sl = sweep.active.begin()\n    if sl.valid {\n    \n    //尝试从partial部分找\n        for ; spanBudget &gt;= 0; spanBudget-- {\n            s = c.partialUnswept(sg).pop()//partialUnswept里面存的是上次看还有空位,但是还没清扫过的span,先拿出来一个\n            // ...\n            //尝试获取tryAcquire,这个动作会触发sweep清扫,如果有垃圾被回收,这里就会成功\n            if s, ok := sl.tryAcquire(s); ok {\n                // ...\n                sweep.active.end(sl)\n                goto havespan//成功了那么跳转结尾\n            }\n            /-\n        // 通过 sweepLock，加锁尝试从 mcentral 的非空链表 full 中获取 mspan\n        for ; spanBudget &gt;= 0; spanBudget-- {\n            s = c.fullUnswept(sg).pop()//拿出一个原本满的\n           // ...\n           //尝试清扫\n            if s, ok := sl.tryAcquire(s); ok {\n                // ...\n                sweep.active.end(sl)\n                goto havespan//如果腾出了空间那么跳转结尾\n                } \n                // ...\n            }\n        }\n        // ...\n    }//这里如果partial和full都没货,会调用c.grow向mheap申请新的内存页\n    // ...\n \n \n    // 执行到此处时，s 已经指向一个存在 object 空位的 m0span 了\nhavespan:\n    // ...\n    return\n}0\nsweeplocker\n\n核心,cas(compare and swap) \n双重身份验证sweep.active\n不阻塞\n这个begin和end,是对当前p的清扫状态的注册和注销,便于更新全局gc统计信息.\n\nmheap分配\n如何在一个碎片化的内存空间里,快速找到连续的n个空闲页?\nfunc (c *mcentral) cacheSpan() *mspan {\n    // ...\n    // mcentral 中也没有可用的 mspan 了，则需要从 mheap 中获取，最终会调用 mheap_.alloc 方法\n    s = c.grow()\n   // ...\n \n \n    // 执行到此处时，s 已经指向一个存在 object 空位的 mspan 了\nhavespan:\n    // ...\n    return\n}\nfunc (c *mcentral) grow() *mspan {\n//计算进货量\n// class_to_allocnpages 是一个预定义的数组。 \n// 比如：你要申请 sizeclass=3 的对象，Go 规定这种规格的 Span 一次必须申请 1 页。 \n// 如果是 sizeclass=40，可能规定一次必须申请 5 页。\n//所以这里实际上是,把规格id换算成了具体需要多少物理页数.\n    npages := uintptr(class_to_allocnpages[c.spanclass.sizeclass()])\n    //计算总字节数\n    size := uintptr(class_to_size[c.spanclass.sizeclass()])\n \n\t//向mheap下单.调用alloc,传入需要的 页数和规格\n    s := mheap_.alloc(npages, c.spanclass)\n    // ...\n \n \n    // ...\n    return s\n}\nfunc (h *mheap) alloc(npages uintptr, spanclass spanClass) *mspan {\n    var s *mspan\n    //go会强制切换到g0系统栈来实行这段代码,是m专用的,空间大并且安全\n    systemstack(func() {\n        // ...\n        //在系统栈上安全🉐进行分配逻辑\n        s = h.allocSpan(npages, spanAllocHeap, spanclass)\n    })\n    return s\n}\nfunc (h *mheap) allocSpan(npages uintptr, typ spanAllocType, spanclass spanClass) (s *mspan) {\n    gp := getg()\n    base, scav := uintptr(0), uintptr(0)\n    \n    // ...此处实际上还有一阶缓存，是从每个 P 的页缓存 pageCache 中获取空闲页组装 mspan，此处先略去了...\n    \n    // 加上堆全局锁因为mheap是全局唯一的,所有p都在抢夺.是整个内存分配路径中锁竞争最激烈的地方\n    lock(&amp;h.lock)\n    if base == 0 {\n        // 通过基数树索引快速寻找满足条件的连续空闲页\n        //h.pages就是基数树,在基数树上调用alloc找到连续的npages个空闲页\n        base, scav = h.pages.alloc(npages)\n        //如果基数树也找不到内存了,这里会触发grow去操作系统的mmap要内存\n        // ...\n    }\n    \n    // ...\n    unlock(&amp;h.lock)\n \n \nHaveSpan:\n    // 把空闲页组装成 mspan\n    //比如设置base npages nelems等等\n    s.init(base, npages)\n    \n    // 将这批页添加到 heapArena 中，建立由页指向 mspan 的映射\n    //以后 GC 扫描到一个指针指向这块内存时，查一下 heapArena，就能立马知道它属于哪个 span\n    h.setSpans(s.base(), npages, s)\n    // ...\n    return s\n}```\n \n#### 向操作系统申请\n//因为系统调用很贵所以每次都预获取多一点\n```go\nfunc (h *mheap) grow(npage uintptr) (uintptr, bool) {\n// ask 是经过对齐计算后的字节数。\n    av, asize := h.sysAlloc(ask)\n}\n \n//**含义**：这是中间层，主要负责维护一些统计信息（代码中省略了），并把具体的“保留内存”工作交给 `sysReserve`。\nfunc (h *mheap) sysAlloc(n uintptr) (v unsafe.Pointer, size uintptr) {\n       v = sysReserve(unsafe.Pointer(p), n)\n}\n \n//`sysReserve` 是一个通用接口。在 Linux 下它会调用下面的 `sysReserveOS`，在 Windows 下它会调用 `VirtualAlloc`。它屏蔽了底层操作系统的差异。\nfunc sysReserve(v unsafe.Pointer, n uintptr) unsafe.Pointer {\n    return sysReserveOS(v, n)\n}\n \nfunc sysReserveOS(v unsafe.Pointer, n uintptr) unsafe.Pointer {\n// mmap 是 Unix/Linux 系统中最常用的内存映射系统调用。\n // 它通常用于文件映射，但加上特定的参数，就变成了“申请堆内存”。\n    p, err := mmap(v, n, _PROT_NONE, _MAP_ANON|_MAP_PRIVATE, -1, 0)\n    //v 期望地址.如果传nil,就会随便找一块空地,如果传了具体地址,就会尽量满足\n    //n 申请大小\n    //PROT NONE 没有任何权限.这块内存申请下来之后没有任何权限,这是保留,Go 在这里只是在操作系统的“账本”上把这块虚拟地址范围占住了，防止被别人用了。但此时，这块内存完全不占用物理 RAM.\n    //等到go真的需要使用这块地址的时候,再调用sysMap函数修改权限,这是为了节省物理内存\n    //_MAP_ANON|_MAP_PRIVATE 匿名映射\\私有映射,说明这块内存不对应磁盘上的任何文件,就是纯粹的RAM堆内存.私有映射表示这块内存是当前进程独享的,不会跟其他进程共享\n    //-1 文件描述符,因为匿名映射不需要文件,所以写1\n    //0 匿名映射无偏移量,0\n    if err != 0 {\n        return nil\n    }\n    return p\n}\n基数树寻页\n//在一个巨大的内存空间中，高效地找到 N 个连续的空闲页。\nsummary是一个五层金字塔结构,L0每个店表示很大的区域,L5直接对应具体的内存页.每个节点sum里面都保存了三个信息,在这一大块区域里面\n\nstart 开头有多少连续空位\nmax 内部最大有多少连续空位\nend 结尾有多少连续空位\n\nfunc (p *pageAlloc) find(npages uintptr) (uintptr, offAddr) {\n    // 必须持有堆锁\n    assertLockHeld(p.mheapLock)\n \n \n    // current level.\n    i := 0\n \n \n    // ...\n    lastSum := packPallocSum(0, 0, 0)\n    lastSumIdx := -1\n \n \nnextLevel:\n    // 1 ~ 5 层依次遍历\n    for l := 0; l &lt; len(p.summary); l++ {\n        // ...\n        // 根据上一层的 index，映射到下一层的 index.\n        // 映射关系示例：上层 0 -&gt; 下层 [0~7]\n        //             上层 1 -&gt; 下层 [8~15]\n        //             以此类推\n        i &lt;&lt;= levelBits[l]//算出我的下属在下一张表里的起始行号,如果一个上司管理8个下属,那么上司要左移3位,可以得到下属的起始号码\n        entries := p.summary[l][i : i+entriesPerBlock]//拿出所有的下属放到entries里面\n        // ...\n        // var levelBits = [summaryLevels]uint{\n        //   14,3,3,3,3\n        // }\n        // 除第一层有 2^14 个节点外，接下来每层都只要关心 8 个 节点.\n        // 由于第一层有 2^14 个节点，所以 heap 内存上限为 2^14 * 16G = 256T\n        //一个一个看这些下属\n        var base, size uint\n        for j := j0; j &lt; len(entries); j++ {\n        \n            sum := entries[j]\n            // ...\n            // 倘若当前节点对应内存空间开头即满足，直接返回结果\n            s := sum.start()\n            if size+s &gt;= uint(npages) {   //size:直到这一刻，我手里已经攒着的、紧挨着当前区域左边的、连续空位数\n                if size == 0 {//不需要拼上一个区域的时候,起点就是当前区域的开头\n                    base = uint(j) &lt;&lt; logMaxPages//j是当前扫描到的子区域索引,比如第三个小区.然后logMaxPages是一个倍率表示这个小区里面有多少页,所以base=j*小区容量,\n                }             \n                size += s//这就是计算一下总共攒了多少,反正后面break退出循环了.\n                break\n            }\n            // 倘若当前节点对应内存空间首部不满足，但是内部最长连续页满足，则到下一层节点展开搜索\n            if sum.max() &gt;= uint(npages) {               \n                i += j//更新索引,定位到这个子区域 i+j\n                lastSumIdx = i//\n                lastSum = sum\n                continue nextLevel //直接跳到下一层去找.因为知道了最大的连续空位就是我们要的 所以我们继续往下找.\n            }\n            // 即便内部最长连续页不满足，还可以尝试将尾部与下个节点的首部叠加，看是否满足\n            if size == 0 || s &lt; 1&lt;&lt;logMaxPages {\n                                size = sum.end()\n                base = uint(j+1)&lt;&lt;logMaxPages - size //计算base\n                continue\n            }\n            // The entry is completely free, so continue the run.\n            size += 1 &lt;&lt; logMaxPages\n        }\n    \n    //**Go 的内存管理架构**： Go 的堆内存不是完全连续的一整块，而是切分成很多巨大的块，叫 **Chunk**（通常是 512MB 一个）。\n    \n    // 根据 i 和 j 可以推导得到对应的内存地址，进行返回\n    //根据我们在树里的索引 `i`，算出这块地皮属于**第几个 Chunk**\n    ci := chunkIdx(i)\n    //去查表，问第 5 号 Chunk 在内存里的**真实首地址**是多少？再加上真实的页偏移\n    addr := chunkBase(ci) + uintptr(j)*pageSize\n    // ...\n    return addr, p.findMappedAddr(firstFree.base)\n}"},"技术积累/Golang/核心知识/05-GC垃圾回收原理":{"slug":"技术积累/Golang/核心知识/05-GC垃圾回收原理","filePath":"技术积累/Golang/核心知识/05 GC垃圾回收原理.md","title":"05 GC垃圾回收原理","links":["技术积累/Golang/核心知识/05-GC垃圾回收原理"],"tags":[],"content":"垃圾回收算法\n背景介绍\n垃圾回收（Garbage Collection，简称 GC）是一种内存管理策略，由垃圾收集器以类似守护协程的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间.\n\nGC 带来的优势包括：\n\n屏蔽内存回收的细节\n\n拥有 GC 能力的语言能够为用户屏蔽复杂的内存管理工作，使用户更好地聚焦于核心的业务逻辑.\n\n\n以全局视野执行任务\n\n现代软件工程项目体量与日剧增，一个项目通常由团体协作完成，研发人员负责各自模块的同时，不可避免会涉及到临界资源的使用. 此时由于缺乏全局的视野，手动对内存进行管理无疑会增加开发者的心智负担. 因此，将这部分工作委托给拥有全局视野的垃圾回收模块来完成，方为上上之策.\n\n\n\n\nGC 带来的劣势：\n\n提高了下限但降低了上限\n\n将释放内存的工作委托给垃圾回收模块，研发人员得到了减负，但同时也失去了控制主权. 除了运用有限的GC调优参数外，更多的自由度都被阉割，需要向系统看齐，服从设定.\n\n\n增加了额外的成本\n\n全局的垃圾回收模块化零为整，会需要额外的状态信息用以存储全局的内存使用情况. 且部分时间需要中断整个程序用以支持垃圾回收工作的执行，这些都是GC额外产生的成本.\n\n\n\n\nGC 的总体评价\n\n除开少量追求极致速度的特殊小规模项目之外，在绝大多数高并发项目中，GC模块都为我们带来了极大的裨益，已经成为一项不可或缺的能力.\n\n\n\n下面对几类经典的垃圾回收算法进行介绍\n标记清扫Mark-Sweep算法\n\n\n蓝色 是还需要使用的变量\n橙色 是已经不使用了但是房间还没打扫\n白色 是打扫干净的空房间\n\n\n标记出蓝色对象\n清扫掉未被标记到的垃圾对象:橙色变白了\n\n缺点:会产生内存碎片. 经过几轮标记清扫之后，空闲的内存块可能零星碎片化分布，此时倘若有大对象需要分配内存，可能会因为内存空间无法化零为整从而导致分配失败.\n标记压缩Mark-Compact算法\n\n在第二步”清扫“的同时还会对存活对象进行压缩整合，使得整体空间更为紧凑，从而解决内存碎片问题\n标记压缩算法在功能性上呈现得很出色，而其存在的缺陷也很简单，就是实现时会有很高的复杂度.\n半空间复制Semispace Copy\n\n\n分配两片相等大小的空间，称为 fromspace 和 tospace\n每轮只使用 fromspace 空间，以GC作为分水岭划分轮次\nGC时，将fromspace存活对象转移到tospace中.那么fromspace里面只剩下垃圾了,可以一口气清空.\nGC后，交换fromspace和tospace，开启新的轮次\n\n显然，半空间复制算法应用了以空间换取时间的优化策略，解决了内存碎片的问题，也在一定程度上降低了压缩空间的复杂度. 但其缺点也同样很明显——比较浪费空间.\n引用计数Reference Counting\n\n对象每被引用一次，计数器加1\n对象每被删除引用一次，计数器减1\nGC时，把计数器等于 0 的对象删除\n然而，这个朴素的算法存在一个致命的缺陷：无法解决循环引用(只有两个对象在互相引用,但是实际上两个人都不被大部队需要了)或者自引用(没有别人需要了,但是一直无法被回收)问题.\n\ngolang中的垃圾回收\nGolang 在 1.8版本之后，GC策略框架已经奠定，就是并发三色标记法+混合写屏障机制\n三色标记法\n\nGolang GC 中用到的三色标记法属于标记清扫-算法下的一种实现，由荷兰的计算机科学家 Dijkstra 提出，下面阐述要点：\n\n\n                  \n                  基本概念 \n                  \n                \n\n存活: GC开始时,有一组根对象roots,比如全局变量,当前正在运行的函数栈里的变量等.只要能顺着箭头,从root一路顺藤摸瓜找到的,就算是存活\n指向:就是指针引用.而且是表层的指针引用,不会一直dfs下去\n\n\n\n对象分为三种颜色标记：黑、灰、白\n黑对象代表，对象自身存活，且其指向对象都已标记完成\n灰对象代表，对象自身存活，但其指向对象还未标记完成\n白对象代表，对象尙未被标记到，可能是垃圾对象\n标记开始前，将根对象（全局对象、栈上局部变量等）置黑，将其所指向的对象置灰\n标记规则是，从灰对象出发，将其所指向的对象都置灰. 所有指向对象都置灰后，当前灰对象置黑\n标记结束后，白色对象就是不可达的垃圾对象，需要进行清扫.\n\n并发垃圾回收\n\nGolang 1.5 版本是个分水岭，在此之前，GC时需要停止全局的用户协程，专注完成GC工作后，再恢复用户协程，这样做在实现上简单直观，但是会对用户造成不好的体验.\n\n自1.5版本以来，Golang引入了并发垃圾回收机制，允许用户协程和后台的GC协程并发运行，大大地提高了用户体验. 但“并发”是一个值得大家警惕的字眼. 用户协程运行时可能对对象间的引用关系进行调整，这会严重打乱GC三色标记时的标记秩序.\n几个问题\ngolang并发垃圾回收可能存在漏标问题\n在用户协程与GC协程并发执行的场景下，部分存活对象未被标记从而被误删的情况\n\n\n条件：初始时刻，对象B持有对象C的引用\n\n\nmoment1：GC协程下，对象A被扫描完成，置黑；此时对象B是灰色，还未完成扫描\n\n\nmomen2：用户协程下，对象A建立指向对象C的引用\n\n\nmoment3：用户协程下，对象B删除指向对象C的引用\n\n\nmoment4：GC协程下，开始执行对对象B的扫描\n\n\n由于GC协程在B删除C的引用后才开始扫描B，因此无法到达C. 又因为A已经被置黑，不会再重复扫描，因此从扫描结果上看，C是不可达的.\n\n\n然而事实上，C应该是存活的（被A引用），而GC结束后会因为C仍为白色，因此被GC误删.\n\n\n针对这个问题 屏障机制可以解决。\ngolang并发垃圾回收可能存在多标问题\n在用户协程与GC协程并发执行的场景下，部分垃圾对象被误标记从而导致GC未按时将其回收的问题\n\n条件：初始时刻，对象A持有对象B的引用\nmoment1：GC协程下，对象A被扫描完成，置黑；对象B被对象A引用，因此被置灰\nmomen2：用户协程下，对象A删除指向对象B的引用\n\n上述场景引发的问题是，在事实上，B在被A删除引用后，已成为垃圾对象，但由于其事先已被置灰，因此最终会更新为黑色，不会被GC删除.\n错标问题对比于漏标问题而言，是相对可以接受的. 其导致本该被删但仍侥幸存活的对象被称为“浮动垃圾”，至多到下一轮GC，这部分对象就会被GC回收，因此错误可以得到弥补.\nGolang 垃圾回收如何解决内存碎片问题\n标记清扫算法会存在产生“内存碎片”的缺陷\nGolang采用 TCMalloc 机制，依据对象的大小将其归属为到事先划分好的spanClass当中，这样能够消解外部碎片的问题，将问题限制在相对可控的内部碎片当中\n基于此，Golang选择采用实现上更为简单的标记清扫算法，避免使用复杂度更高的标记压缩算法，因为在 TCMalloc 框架下，后者带来的优势已经不再明显.\nGolang为什么不选择分代垃圾回收机制\n分代算法指的是，将对象分为年轻代和老年代两部分（或者更多）采用不同的GC策略进行分类管理. 分代GC算法有效的前提是，绝大多数年轻代对象都是朝生夕死，拥有更高的GC回收率，因此适合采用特别的策略进行处理.\n然而Golang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\n综上，内存逃逸机制减弱了分代算法对Golang GC所带来的优势，考虑分代算法需要产生额外的成本（如不同年代的规则映射、状态管理以及额外的写屏障）Golang 选择不采用分代GC算法.\n屏障机制\n主要就是为了解决漏标问题\n强弱三色不变式\n漏标问题的本质就是，一个已经扫描完成的黑对象指向了一个被灰\\白对象删除引用的白色对象. 构成这一场景的要素拆分如下：\n（1）黑色对象指向了白色对象\n（2）灰、白对象删除了白色对象\n（3）12步中谈及的白色对象是同一个对象\n（4）1发生在2之前\n一套用于解决漏标问题的方法论称之为强弱三色不变式：\n\n强三色不变式：白色对象不能被黑色对象直接引用（直接破坏1）\n\n当你的代码试图执行 A.next = C（A黑，C白）时，强制把 C 涂成灰色\n\n\n弱三色不变式：白色对象可以被黑色对象引用，但要从某个灰对象出发仍然可达该白对象（间接破坏了1、2的联动）\n\n试图执行 B.next = nil（切断灰 B 对白 C 的引用）时，我强制把 C 涂成灰色\n\n\n\n插入写屏障\n屏障机制类似于一个回调保护机制，指的是在完成某个特定动作前，会先完成屏障成设置的内容.\n插入写屏障（Dijkstra）的目标是实现强三色不变式，保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用.\n如果所有流程都能保证做到这一点，那么 3.1 小节中的（1）就会被破坏，漏标问题得以解决.\n删除写屏障\n删除写屏障（Yuasa barrier）的目标是实现弱三色不变式，保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用.\n这一流程中，3.1小节的步骤（2）会被破坏，漏标问题得以解决.\n混合写屏障\n插入写屏障、删除写屏障二者择其一，即可解决并发GC的漏标问题，至于错标问题，则采用容忍态度，放到下一轮GC中进行延后处理即可.\n然而真实场景中，需要补充一个新的设定——屏障机制无法作用于栈对象.\n\n这是因为栈对象可能涉及频繁的轻量操作，倘若这些高频度操作都需要一一触发屏障机制，那么所带来的成本将是无法接受的.\n栈（Stack）内存是绝对私有的，不能被跨栈引用。如果被跨站引用了，这个对象会被升级成堆对象\n在这一背景下，单独看插入写屏障或删除写屏障，都无法真正解决漏标问题，除非我们引入额外的Stop the world（STW）阶段[暂停其他线程]，对栈对象的处理进行兜底。\n为了消除这个额外的 STW 成本，Golang 1.8 引入了混合写屏障机制，要点如下：\n\n【栈对象还是符合三色标记法的，引用对象还是会变成灰色】\n\nGC 开始前，以栈为单位分批扫描，将栈中所有对象置黑\nGC 期间，栈上新创建对象直接置黑\n堆对象正常启用插入写屏障\n堆对象正常启用删除写屏障\n\n下面我们通过几个 show case，来论证混合写屏障机制是否真的能解决并发GC下的各种极端场景问题.\nshow case\n堆对象删除引用，栈对象建立引用\n\n\n背景：存在栈上对象A，黑色（扫描完）\n存在堆上对象B，白色（未被扫描）\n存在堆上对象C，被堆上对象B引用，白色（未被扫描）\nmoment1：A建立对C的引用，由于栈无屏障机制，因此正常建立引用，无额外操作\nmoment2：B尝试删除对C的引用，删除写屏障被触发，C被置灰，因此不会漏标\n\n一个堆对象删除引用，成为另一个堆对象下游\n\n存在堆上对象A，白色（未被扫描）\n存在堆上对象B，黑色（已完成扫描）\n存在堆上对象C，被A引用，白色（未被扫描）\n\nmoment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\nmoment2：A删除对C的引用，此时C已置灰，因此不会漏标\n\n栈对象删除引用，成为堆对象下游\n\n\n背景：存在栈上对象A，白色（未完成扫描，说明对应的栈未扫描）\n存在堆上对象B，黑色（已完成扫描）\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\nmoment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\nmoment2：A删除对C的引用，此时C已置灰，因此不会漏标\n\n一个栈中对象删除引用，另一个栈中对象建立引用\n\n\n背景：存在栈上对象A，白色（未扫描，这是因为对应的栈还未开始扫描）\n存在栈上对象B，黑色（已完成扫描，说明对应的栈均已完成扫描）\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\nmoment1：B建立对C的引用；\nmoment2：A删除对C的引用.\n结论：这种场景下，C要么已然被置灰，要么从某个灰对象触发仍然可达C.\n原因在于，对象的引用不是从天而降，一定要有个来处. 当前 case 中，对象B能建立指向C的引用，至少需要满足如下三个条件之一：\nI 栈对象B原先就持有C的引用，如若如此，C就必然已处于置灰状态（因为B已是黑色）\nII 栈对象B持有A的引用，通过A间接找到C. 然而这也是不可能的，因为倘若A能同时被另一个栈上的B引用到，那样A必然会升级到堆中，不再满足作为一个栈对象的前提；\nIII B同栈内存在其他对象X可达C，此时从X出发，必然存在一个灰色对象，从其出发存在可达C的路线.\n\n综上，我们得以证明混合写屏障是能够胜任并发GC场景的解决方案，并且满足栈无须添加屏障的前提."},"技术积累/Golang/核心知识/05.1-GC源码":{"slug":"技术积累/Golang/核心知识/05.1-GC源码","filePath":"技术积累/Golang/核心知识/05.1 GC源码.md","title":"05.1 GC源码","links":[],"tags":[],"content":"触发GC\n触发GC类型\n触发GC的事件类型可以分为如下三种\n\ngcTriggerHeap 分配对象时触发\n\n校验条件是 堆已分配内存达到阈值\n\n\ngcTriggerTime 由forcechelper守护协程定时触发\n\n每两分钟触发一次\n\n\ngcTriggerCycle 用户调用runtime.GC方法\n\n上一轮GC已结束\n\n\n\n在触发GC时，会通过 gcTrigger.test 方法，结合具体的触发事件类型进行触发条件的校验，对应的源码如下：\ntype gcTriggerKind int\n \n \nconst (\n    // 根据堆分配内存情况，判断是否触发GC\n    gcTriggerHeap gcTriggerKind = iota\n    // 定时触发GC\n    gcTriggerTime\n    // 手动触发GC\n    gcTriggerCycle\n}\n \n \nfunc (t gcTrigger) test() bool {//如果true 说明应当启动GC\n    // ...\n    switch t.kind {//根据gcTrigger的不同类型,选取不同的校验条件\n    case gcTriggerHeap:\n        // ...\n        //这个trigger值是根据gogc环境变量动态计算出来的.\n        trigger, _ := gcController.trigger()\n        //判断当前活跃的堆内存是否&gt;=触发阈值?如果已分配内存大于阈值,说明需要启动GC分配\n        return atomic.Load64(&amp;gcController.heapLive) &gt;= trigger\n    case gcTriggerTime:\n    //如果gcPercent&lt;0,即环境变量gogc=off,则彻底关闭gc,永远不触发\n        if gcController.gcPercent.Load() &lt; 0 {\n            return false\n        }\n        //获取上一次gc结束的时间\n        lastgc := int64(atomic.Load64(&amp;memstats.last_gc_nanotime))\n        //如果lastgc!=0,确保之前至少发生过一次gc,并且距离上次gc的时间间隔超过了强制周期,这里的强制周期一般是2分钟\n        return lastgc != 0 &amp;&amp; t.now-lastgc &gt; forcegcperiod\n    case gcTriggerCycle:\n        // ...\n        //这里的t.n是调用者期望达到的gc周期编号,work.cycles是当前已完成的gc周期编号  比如说我需要gc5个周期,而当前只gc了四个周期,那么就要发起gc\n        //如果期望的大于已完成的,说明目标gc还没有启动 那么久返回true去启动.\n        return int32(t.n-work.cycles) &gt; 0\n    }\n    return true\n}\n对象分配触发GC\n定时触发GC\n启动定时触发协程并阻塞等待\n\nruntime 包初始化的时候，即会异步开启一个守护协程，通过 for 循环 + park 的方式，循环阻塞等待被唤醒.\n当被唤醒后，则会调用 gcStart 方法进入标记准备阶段，尝试开启新一轮 GC，此时触发 GC 的事件类型正是 gcTriggerTime（定时触发）.\n在 gcStart 方法内部，还会通过 gcTrigger.test 方法进一步校验触发GC的条件是否满足\n\n对象分配触发GC\n手动触发GC\n标记准备\n主流程\n启动标记协程\nstop the world\n控制标记协程频率\n设置写屏障\ntiny对象标记\nstart the world\n并发标记\n调度标记协程\n并发标记启动\n标记主流程\n灰对象缓存队列\n三色标记实现\n中止标记协程\n扫描根对象\n扫描普通对象\n对象置灰\n新分配对象置黑\n辅助标记\n辅助标记策略\n辅助标记执行\n标记终止\n标记完成\n标记终止\n标记清扫\n设置下轮GC阈值\n系统驻留内存清理\n回收协程启动\n执行频率控制\n回收空闲内存"},"技术积累/Golang/核心知识/06-Channel-实现原理":{"slug":"技术积累/Golang/核心知识/06-Channel-实现原理","filePath":"技术积累/Golang/核心知识/06 Channel 实现原理.md","title":"06 Channel 实现原理","links":[],"tags":[],"content":""},"技术积累/Golang/核心知识/数据结构的实现":{"slug":"技术积累/Golang/核心知识/数据结构的实现","filePath":"技术积累/Golang/核心知识/数据结构的实现.md","title":"数据结构的实现","links":[],"tags":[],"content":"map: 带有溢出桶机制的哈希表\n字符串: 只读的字节切片\n切片: 动态数组描述符\n接口: 带着类型信息的胖指针\n通道channel: 带锁的环形队列"},"技术积累/Golang/核心知识/死锁":{"slug":"技术积累/Golang/核心知识/死锁","filePath":"技术积累/Golang/核心知识/死锁.md","title":"死锁","links":[],"tags":[],"content":""},"技术积累/Golang/语法特性/值传递与引用传递":{"slug":"技术积累/Golang/语法特性/值传递与引用传递","filePath":"技术积累/Golang/语法特性/值传递与引用传递.md","title":"值传递与引用传递","links":[],"tags":[],"content":"go的默认传参方式是copy,如果传递的不是地址的话,对参数的修改无法生效.\n一般来说我们认为,传指针比传值更快.但是实际上,传递指针在go中存在隐性成本\n垃圾回收 (GC) 压力\n如果你返回一个指针 *MysqlConfig：\n\nGo 编译器会发现：“哎呀，这个变量的地址被丢到函数外面去了\n为了防止函数结束时变量被销毁，Go 必须把这个变量分配到 堆内存 (Heap) 上。\n后果： 垃圾回收器 (GC) 需要盯着这块内存，以后还要花时间去回收它。这会增加 GC 的负担。\n\n如果你返回一个值 MysqlConfig\n\nGo 编译器会发现：“这个变量只是复印了一份出去\n它通常会把变量留在 栈内存 (Stack) 上。\n好处： 栈内存是用完即扔的，完全不需要 GC 介入，速度极快！\n\n原则\n✅ 这种情况用传值 (Pass by Value)\n\n对象很小：比如你的 Config，或者 Time，或者坐标 Point{x, y}。\n为了安全（只读）：你不希望调用者修改原本的数据。\n为了并发安全：如果不让改，那多线程读的时候就不用加锁，省事！\n\n✅ 这种情况用指针 (Pass by Pointer)\n\n\n对象超级大：比如你有一个结构体里存了 [10000]int（几万个数字）或者一个巨大的缓存对象。这时候复制一次太慢了，必须给钥匙（指针）。\n\n\n需要修改原件：比如 func (u *User) ChangeName(newName string)，你必须改原数据，不传指针改不了。\n\n"},"技术积累/Golang/语法特性/多态-接口interface":{"slug":"技术积累/Golang/语法特性/多态-接口interface","filePath":"技术积累/Golang/语法特性/多态-接口interface.md","title":"接口","links":[],"tags":[],"content":"多态\n需要有接口概念interface\n只要符合接口定义的函数,就被认为是这个接口的一分子.然后可以作为接口成员,调用相应包函数..\n注意: 符合接口定义的函数: 传入的参数类型的定义也必须严格一致.\n// src/container/heap/heap.go\n \ntype Interface interface {\n    sort.Interface\n    Push(x any)    // 👈 官方规定：这里必须接收interface{}\n    Pop() any      // 👈 官方规定：这里必须返回interface{}\n}\n \n \n// 那么如果照着这样写编译器就会报错\nfunc (h *IHeap) Push(x [2]int) { // 直接接收 [2]int\n    *h = append(*h, x)\n}\n \ninterface类型:\n\n类似于slice,结构内部有指针*type 和 *data\n一个变量能不能赋给一个接口，唯一标准是：这个变量的“类型”是否实现了该接口要求的【所有方法】。要看方法到底是定义在了值上,还是定义在了指针上.\n\n类继承接口的话不需要写进结构体定义,只需要自己实现接口中的方法,就相当于继承了.那么接口的指针就可以指向这个子类.如果没有实现完全,也是无法继承的.\n让接口对到谁,就调用谁的方法\n\n\n相当于把有同样方法的类进行归类然后用一个接口可以统一进行管理\n理解\n比如: 调用方说想要一个能插USB口的东西,那么只要这个东西实现了USB规定的方法(触电\\数据传输等),就必须要能插进USB接口.\n与C++不同的是,Go中采用隐式结构.只需要方法名相同即可.\n有一个接口叫 Payer（支付方式），要求有一个 Pay() 方法。\n\n你写了一个 Alipay 结构体，里面写了个 Pay() 方法。\n你又写了一个 WeChat 结构体，里面也写了个 Pay() 方法。\n那么编译器就会认为这两个结构体都属于Payer接口.\n\n主要的目的是进行解耦,比如下面这个例子\n//不使用接口\nfunc 结账(用户选择 string) {\n    if 用户选择 == &quot;支付宝&quot; {\n        调用支付宝API()\n    } else if 用户选择 == &quot;微信&quot; {\n        调用微信API()\n    } else if 用户选择 == &quot;银行卡&quot; {\n        调用银行卡API()\n    }\n    // 明年如果出了个“抖音支付”，你还得回来改这行代码，烦死。\n}\n \n//使用接口\n//只要是实现了 Payer 的东西，都能传进来\nfunc 结账(p Payer) {\n    p.Pay() \n}\n使用\n//定义\ntype Payer interface {\n\tPay(amount int) // 只要能从兜里掏钱，就是 Payer\n}\n \n//类型1\ntype Alipay struct {\n\tAccountName string\n}\nfunc (a Alipay) Pay(amount int) {\n\tfmt.Printf(&quot;【支付宝】%s 扫码支付了 %d 元\\n&quot;, a.AccountName, amount)\n}\n \n//类型2\ntype Cash struct {\n\tBalance int // 余额\n}\n// 实现 Pay 方法\n// 注意：这里使用的是【指针接收者】 (c *Cash)\n// 意思：现金支付会减少我的余额，必须修改内部数据！\nfunc (c *Cash) Pay(amount int) {\n\tif c.Balance &gt;= amount {\n\t\tc.Balance -= amount // 修改了结构体内部的值\n\t\tfmt.Printf(&quot;【现金】从钱包扣款 %d 元，剩余 %d 元\\n&quot;, amount, c.Balance)\n\t} else {\n\t\tfmt.Println(&quot;【现金】余额不足！&quot;)\n\t}\n}\n \n//多态函数\nfunc Checkout(p Payer, price int) {\n\tfmt.Println(&quot;&gt;&gt;&gt; 开始结账...&quot;)\n\tp.Pay(price) // 多态调用\n\tfmt.Println(&quot;&gt;&gt;&gt; 结账完成\\n&quot;)\n}\n \n \n//main函数\nfunc main() {\n\t// 场景 1：使用支付宝 (值接收者)\n\tmyAlipay := Alipay{AccountName: &quot;Deng&#039;s Phone&quot;}\n\tCheckout(myAlipay, 100) \n\t// 传入值 myAlipay 没问题，因为它的方法是值接收者\n \n\t// 场景 2：使用现金 (指针接收者)\n\tmyWallet := Cash{Balance: 500}\n\tCheckout(myWallet, 200) //❌\n\tCheckout(&amp;myWallet, 200) \n\t// ✅ 必须传入地址 (&amp;myWallet)\n\t// 因为 Cash 的 Pay 方法是挂在指针上的,所以会认为指针才是实际的payer\n}\n使用2\nIHeap定义的Pop函数,会被作为heap.Pop的一部分被调用.\nheap.Pop会先把某个元素换到最后面,然后我用自己的Pop方法去把最后一个元素切掉.\n空接口\n\n作为通用万能类型:空接口interface{}\n可以用interface{}类型引用任意的数据类型   [go中数据类型基本都实现了这个空接口]\n\n断言\n如果断言成功了,这个类型就从一个空接口变成了一个具体的类型,可以认为是做了一个类型转换了\n// 语法： value, ok := 接口变量.(目标类型)\nrealValue, ok := x.([2]int)\n \nif ok {\n    // 成功！\n    // realValue 现在是 [2]int 类型，可以放心用\n    fmt.Println(&quot;成功拿到数组：&quot;, realValue)\n} else {\n    // 失败！\n    // x 里装的根本不是 [2]int，可能是别的，或者 x 是 nil\n    // 此时程序不会崩，realValue 会是零值\n    fmt.Println(&quot;类型不对，不是数组&quot;)\n}\n \n \n// 语法： value := 接口变量.(目标类型) \nrealValue := x.([2]int) // 只有这一行，没有 ok\n \n \n \n\n关于指针\n如果方法定义在值上,就算把指针拿去调用接口,也是成立的.\n因为编译器允许你用 *Cat 类型的指针去调用 Cat 类型（值）的方法，所以 Go 认为 *Cat（指针）和 Cat（值）都实现了这个接口\n但是如果方法定义在指针上,用值去调用接口是不行的."},"技术积累/Golang/语法特性/大小写与作用域":{"slug":"技术积累/Golang/语法特性/大小写与作用域","filePath":"技术积累/Golang/语法特性/大小写与作用域.md","title":"大小写与作用域","links":[],"tags":[],"content":"\n结构体首字母大写: 别的包需要根据这个图纸来定义变量.\n具体的对象首字母小写: 如果要用到的话 就调用一个首字母大写的Get函数,然后复制一个对象的值出来.\n具体对象内部字段的首字母大写: 这样可以在复制出对象之后,获取他内部的值.\n"},"技术积累/Golang/语法特性/未命名":{"slug":"技术积累/Golang/语法特性/未命名","filePath":"技术积累/Golang/语法特性/未命名.md","title":"未命名","links":[],"tags":[],"content":""},"技术积累/Golang/语法特性/语法细节":{"slug":"技术积累/Golang/语法特性/语法细节","filePath":"技术积累/Golang/语法特性/语法细节.md","title":"语法细节","links":[],"tags":[],"content":"变量声明与运算逻辑\n\n左大括号不能单独一行。\n不允许有未使用的变量和import，必须用——别名来忽略\n在if或者代码块内使用:=可能会意外覆盖同名变量，导致外部变量没有被修改\n:=只能在函数内部使用,且不能用于设置结构体字段\n不要用nil初始化未指定类型的变量\n自增自减只有后置,没有前置\n\n其他\n\n接口的底层是(Type,Value),只有(nil,nil)才是nil.\n\n"},"技术积累/go项目/00-初始化":{"slug":"技术积累/go项目/00-初始化","filePath":"技术积累/go项目/00 初始化.md","title":"00 初始化","links":[],"tags":[],"content":"\ngo语言\nmysql数据库\nredis/docker\n\nmkdir short_url\ncd short_url\ngo mod init short_url\n数据库\nmysql -u root -p\nCREATE DATABASE seqsrv;\nUSE seqsrv;\n创建数据库表\nCREATE TABLE `links` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `url` varchar(200) COLLATE utf8mb4_bin NOT NULL COMMENT &#039;长链接&#039;,\n  `keyword` varchar(50) COLLATE utf8mb4_bin NOT NULL COMMENT &#039;短链接码&#039;,\n  `status` tinyint(1) NOT NULL COMMENT &#039;1系统分配 2用户自定义&#039;,\n  `create_time` bigint(20) NOT NULL,\n  `update_time` bigint(20) NOT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `links_UN` (`url`),\n  UNIQUE KEY `links_keyword` (`keyword`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;\ngo get -u github.com/go-ini/ini\n\n这个-u就是 如果不加的话 会优先在本地找是否下载过这个包,然后优先用本地的.\n如果加上-u的话 就会优先下载最新的,如果本地有,就会被覆盖"},"技术积累/go项目/01-Go语言的err处理":{"slug":"技术积累/go项目/01-Go语言的err处理","filePath":"技术积累/go项目/01 Go语言的err处理.md","title":"01 Go语言的err处理","links":[],"tags":[],"content":"panic(err)\n程序立刻停止运行,打印出一堆红色的堆栈信息表明是哪一行代码导致了崩溃，然后退出.\n\n一般只在程序启动阶段,或者遇到了修复不好的逻辑错误的时候使用\n\nreturn err\n函数无法处理,但是不崩溃,而是通过函数返回值告诉调用者,让它决定应该怎么办.一般都会用这种.\nlog.Fatal(err)\n打印一条错误日志,然后直接退出程序.\n通常用在main函数里,或者命令行工具中,其实效果和panic差不多,但是没有那么多日志,比较清爽"},"技术积累/go项目/ORM框架---gorm与xorm":{"slug":"技术积累/go项目/ORM框架---gorm与xorm","filePath":"技术积累/go项目/ORM框架 - gorm与xorm.md","title":"ORM框架 - gorm与xorm","links":[],"tags":[],"content":"就是帮助我们把go语言翻译成sql语句.\ngorm\ngo get -u gorm.io/gorm\ngo get -u gorm.io/driver/mysql\n\n读取config\n连接mysql\n将连接句柄存在一个全局变量里面\n\nvar DB *gorm.DB\n然后别的包如果要操作数据库的话,只需要用db.DB就行"},"技术积累/go项目/ini格式":{"slug":"技术积累/go项目/ini格式","filePath":"技术积累/go项目/ini格式.md","title":"ini格式","links":[],"tags":[],"content":""},"技术积累/go项目/计划":{"slug":"技术积累/go项目/计划","filePath":"技术积累/go项目/计划.md","title":"计划","links":[],"tags":[],"content":"📅 第一阶段：核心功能速成 (1月2日 - 1月4日)\n目标： 写出“最小可行性产品” (MVP)。 验收标准： 用 Postman 发一个长链接，能返回短链接；在浏览器输入短链接，能跳转到原网页。\nDay 1 (今晚 1月2日)：打通血管 (Config &amp; Base)\n今晚别太累，把最枯燥的配置搞定，让程序能连上数据库。\n\n\n任务 1：填写配置文件\n\n\n位置： conf/config.toml (或 .ini)\n\n\n动作： 把你刚才的 MySQL 和 Redis 账号密码填进去。\n\n\n\n\n任务 2：初始化 MySQL 连接\n\n\n位置： base/db/mysql.go\n\n\n动作： 复制 GORM 的连接代码，读取配置文件里的参数，赋值给全局变量 var DB *gorm.DB。\n\n\n\n\n任务 3：初始化 Redis 连接\n\n\n位置： base/db/redis.go\n\n\n动作： 复制 go-redis 的连接代码，赋值给全局变量 var RDB *redis.Client。\n\n\n\n\n任务 4：在 main 中测试\n\n\n位置： main.go\n\n\n动作： 调用 db.InitMySQL() 和 db.InitRedis()。如果不报错，打印“连接成功”，今晚收工！\n\n\n\n\nDay 2 (1月3日 周六)：核心零件 (Model &amp; Logic)\n这是写代码最关键的一天。我们要造“雪花ID”和“进制转换”这两个核心零件。\n\n\n任务 1：搬运工具代码\n\n\n位置： base/tool/base62.go\n\n\n动作： 把 10进制转 62进制 的算法代码（找我要或网上搜）复制进去。写个 _test.go 测一下。\n\n\n\n\n任务 2：接入雪花算法\n\n\n位置： model/sequence/snowflake.go\n\n\n动作： 引入 bwmarrin/snowflake 包，写一个单例模式的 GetID() 函数。\n\n\n\n\n任务 3：定义数据库模型\n\n\n位置： model/short_url/model.go\n\n\n动作： 把 struct Link {...} 写好（就是我们刚才定义的表结构）。\n\n\n\n\n任务 4：写“存”的逻辑 (Service层)\n\n\n位置： model/short_url/service.go\n\n\n动作： 写一个 Create 函数。\n\n\n逻辑流：\n\n\n调用 snowflake.GetID() 拿到 ID。\n\n\n调用 base62.Encode(id) 拿到短码 code。\n\n\n拼装 Link 对象。\n\n\ndb.DB.Create(&amp;link) 存入 MySQL。\n\n\n(可选) db.RDB.Set(...) 顺手存入 Redis。\n\n\n\n\n\n\nDay 3 (1月4日 周日)：对外营业 (Controller &amp; Server)\n要把里面的逻辑暴露给外面用了。\n\n\n任务 1：写接口处理函数\n\n\n位置： controller/handler.go\n\n\n动作：\n\n\nfunc Create(...): 解析 JSON → 调 Service → 返回 JSON。\n\n\nfunc Redirect(...): 解析 URL 短码 → 查 Redis/MySQL → c.Redirect(301, longUrl)。\n\n\n\n\n\n\n任务 2：配置路由\n\n\n位置： server/router.go\n\n\n动作： r.POST(&quot;/api/create&quot;, controller.Create) 和 r.GET(&quot;/:code&quot;, controller.Redirect)。\n\n\n\n\n任务 3：最终测试\n\n动作： go run main.go。打开浏览器测一下。只要能跳转，MVP 宣告成功！\n\n\n\n\n🛑 第二阶段：强制熔断 &amp; 简历投递 (1月5日 - 1月12日)\n目标： 考试求稳，简历投递。\n\n\n1月5日 - 1月11日：\n\n\n完全停止写代码！ 全力复习期末考。\n\n\n你的项目现在虽然只有基础功能（没有布隆过滤器、没有 SingleFlight），但它能跑。这就足够让你安心考试了。\n\n\n\n\n1月12日 (投简历日)：\n\n\n把写着“布隆过滤器、SingleFlight”的简历投出去。\n\n\n心理建设： 此时代码里还没有这两个功能，但别怕，面试官不会立马看你代码。你有 3-5 天的时间差。\n\n\n\n\n\n🛠️ 第三阶段：补全“简历牛皮” (1月13日 - 1月16日)\n目标： 在面试前，把简历上吹过的牛实现出来。\n\n\n利用复习间隙（每天 1-2 小时）：\n\n\n加布隆过滤器： 在 Service 层 Create 时写入布隆，Redirect 时先查布隆。\n\n\n加 SingleFlight： 在 Service 层查数据库的那一步，外面包一层 sg.Do(...)。\n\n\n\n\n具体\n6.5 创建数据库连接 base/db/mysql.go\npackage db\nimport (\n    “fmt”\n    “short_url/base/config”\n    _ “github.com/go-sql-driver/mysql”\n    “github.com/go-xorm/xorm”\n)\nvar mysqlDb *xorm.Engine\nfunc initMySql() {\n    cfg := config.GetMysqlConfig()\n    // 构建连接字符串\n    dataSourceName := fmt.Sprintf(“%s:%s@tcp(%s:%s)/%s?charset=utf8mb4”,\n        cfg.GetName(),\n        cfg.GetPass(),\n        cfg.GetIP(),\n        cfg.GetPort(),\n        cfg.GetDb(),\n    )\n    var err error\n    mysqlDb, err = xorm.NewEngine(“mysql”, dataSourceName)\n    if err != nil {\n        panic(err)\n    }\n    // 设置连接池\n    mysqlDb.SetMaxIdleConns(cfg.GetMaxIdle())\n    mysqlDb.SetMaxOpenConns(cfg.GetMaxOpen())\n    // 测试连接\n    err = mysqlDb.Ping()\n    if err != nil {\n        panic(err)\n    }\n}\nfunc GetMySqlDb() *xorm.Engine {\n    return mysqlDb\n}\n6.6 创建Redis连接 base/db/redis.go\npackage db\nimport (\n    “fmt”\n    “short_url/base/config”\n    “github.com/go-redis/redis”\n)\nvar redisDb *redis.Client\nfunc initRedis() {\n    cfg := config.GetRedisConfig()\n    redisDb = redis.NewClient(&amp;redis.Options{\n        Addr:     fmt.Sprintf(“%s:%s”, cfg.GetIP(), cfg.GetPort()),\n        Password: cfg.GetPass(),\n        DB:       0,\n        PoolSize: cfg.GetMaxOpen(),\n    })\n    // 测试连接\n    _, err := redisDb.Ping().Result()\n    if err != nil {\n        panic(err)\n    }\n}\nfunc GetRedisDb() *redis.Client {\n    return redisDb\n}\n6.7 数据库初始化入口 base/db/db.go\npackage db\nfunc Init() {\n    initMySql()\n    initRedis()\n}\n6.8 创建进制转换工具 base/tool/ten_to_any.go\n这是核心算法！把数字ID（1,2,3…）转换成短码（a,b,c…）\npackage tool\nimport (\n    “math”\n    “strconv”\n    “strings”\n)\n// 62进制字符映射表（0-9, a-z, A-Z）\nvar tenToAnyMap = map[int]string{\n    0: “0”, 1: “1”, 2: “2”, 3: “3”, 4: “4”,\n    5: “5”, 6: “6”, 7: “7”, 8: “8”, 9: “9”,\n    10: “a”, 11: “b”, 12: “c”, 13: “d”, 14: “e”,\n    15: “f”, 16: “g”, 17: “h”, 18: “i”, 19: “j”,\n    20: “k”, 21: “l”, 22: “m”, 23: “n”, 24: “o”,\n    25: “p”, 26: “q”, 27: “r”, 28: “s”, 29: “t”,\n    30: “u”, 31: “v”, 32: “w”, 33: “x”, 34: “y”,\n    35: “z”, 36: “A”, 37: “B”, 38: “C”, 39: “D”,\n    40: “E”, 41: “F”, 42: “G”, 43: “H”, 44: “I”,\n    45: “J”, 46: “K”, 47: “L”, 48: “M”, 49: “N”,\n    50: “O”, 51: “P”, 52: “Q”, 53: “R”, 54: “S”,\n    55: “T”, 56: “U”, 57: “V”, 58: “W”, 59: “X”,\n    60: “Y”, 61: “Z”,\n}\n// 10进制转62进制（数字ID → 短码）\nfunc TenToAny(num, n int) string {\n    result := &quot;&quot;\n    for num != 0 {\n        remainder := num % n\n        result = tenToAnyMap[remainder] + result\n        num = num / n\n    }\n    return result\n}\n// 62进制转10进制（短码 → 数字ID）\nfunc AnyToTen(num string, n int) int {\n    var result float64\n    length := len(num) - 1\n    for _, char := range num {\n        value := findKeyInMap(string(char))\n        if value != -1 {\n            result += float64(value) * math.Pow(float64(n), float64(length))\n            length—\n        }\n    }\n    return int(result)\n}\nfunc findKeyInMap(in string) int {\n    for k, v := range tenToAnyMap {\n        if in == v {\n            return k\n        }\n    }\n    return -1\n}\n6.9 创建日志工具 base/tool/log.go\npackage tool\nimport (\n    “go.uber.org/zap”\n)\nvar logger *zap.Logger\nfunc initLog() {\n    var err error\n    logger, err = zap.NewProduction()\n    if err != nil {\n        panic(err)\n    }\n}\nfunc GetLogger() *zap.Logger {\n    return logger\n}\n6.10 工具初始化 base/tool/tool.go\npackage tool\nfunc Init() {\n    initLog()\n}\n6.11 基础层统一初始化 base/base.go\npackage base\nimport (\n    “short_url/base/config”\n    “short_url/base/db”\n    “short_url/base/tool”\n)\nvar ServerUrl string\nfunc Init(path string) {\n    config.Init(path)  // 1. 先读取配置\n    tool.Init()        // 2. 初始化工具（日志等）\n    db.Init()          // 3. 连接数据库\n步骤7：数据模型层\n7.1 创建Links表模型 model/short_url/links.go\npackage short_url\nimport (\n    “time”\n)\n// Links 对应数据库的 links 表\ntype Links struct {\n    Id         int    xorm:&quot;pk autoincr &#039;id&#039;&quot;        // 主键，自增\n    Url        string xorm:&quot;varchar(200) &#039;url&#039;&quot;       // 长链接\n    Keyword    string xorm:&quot;varchar(50) &#039;keyword&#039;&quot;    // 短码\n    Status     int    xorm:&quot;tinyint &#039;status&#039;&quot;         // 1=系统生成，2=用户自定义\n    CreateTime int64  xorm:&quot;&#039;create_time&#039;&quot;            // 创建时间\n    UpdateTime int64  xorm:&quot;&#039;update_time&#039;&quot;            // 更新时间\n}\n// TableName 指定表名\nfunc (Links) TableName() string {\n    return “links”\n}\n// GetLinksByUrl 根据长链接查询短链接记录\nfunc (s *service) GetLinksByUrl(url string) (*Links, error) {\n    links := &amp;Links{}\n    has, err := s.m.Where(“url = ?”, url).Get(links)\n    if err != nil {\n        return nil, err\n    }\n    if !has {\n        return nil, nil\n    }\n    return links, nil\n}\n// GetLinksByKeyword 根据短码查询记录（用于跳转）\nfunc (s *service) GetLinksByKeyword(keyword string) (*Links, error) {\n    links := &amp;Links{}\n    has, err := s.m.Where(“keyword = ?”, keyword).Get(links)\n    if err != nil {\n        return nil, err\n    }\n    if !has {\n        return nil, nil\n    }\n    return links, nil\n}\n// CreateLinks 创建短链接（核心业务逻辑）\nfunc (s *service) CreateLinks(url, key string, status int) (string, error) {\n    var keyword string\n    // 检查长链接是否已存在\n    if links, err := s.GetLinksByUrl(url); err == nil &amp;&amp; links != nil {\n        return “http://” + base.ServerUrl + ”/” + links.Keyword, nil\n    }\n    // 根据状态选择生成方式\n    if status == 1 {\n        // 系统自动生成：使用Redis自增ID + 62进制转换\n        id, err := s.sequence.GetBorrowOrder()\n        if err != nil {\n            return &quot;&quot;, err\n        }\n        keyword = tool.TenToAny(int(id), 62) // 将数字ID转换为62进制短码\n    } else if status == 2 {\n        // 用户自定义短码\n        keyword = key\n        // 检查自定义短码是否已被使用\n        if links, err := s.GetLinksByKeyword(keyword); err == nil &amp;&amp; links != nil {\n            return &quot;&quot;, fmt.Errorf(“关键字已存在”)\n        }\n    }\n    // 保存到数据库\n    now := time.Now().Unix()\n    links := &amp;Links{\n        Url:        url,\n        Keyword:    keyword,\n        Status:     status,\n        CreateTime: now,\n        UpdateTime: now,\n    }\n    _, err := s.m.Insert(links)\n    if err != nil {\n        return &quot;&quot;, err\n    }\n    return “http://” + base.ServerUrl + ”/” + keyword, nil\n}\n但是我注意到代码中需要导入一些包，让我补充完整版本：\npackage short_url\nimport (\n    “fmt”\n    “short_url/base”\n    “short_url/base/tool”\n    “time”\n)\n7.2 创建序列生成器 model/sequence/generator.go\n这是生成唯一ID的核心！使用Redis的INCR命令保证全局唯一。\npackage sequence\nimport (\n    “fmt”\n)\nconst (\n    // Redis中存储自增ID的key\n    RedisKeySequence = “short_url:sequence”\n)\n// GetBorrowOrder 获取唯一的自增ID\nfunc (s *service) GetBorrowOrder() (int64, error) {\n    // 使用Redis的INCR命令，原子性自增\n    result := s.r.Incr(RedisKeySequence)\n    if result.Err() != nil {\n        return 0, fmt.Errorf(“redis incr error: %v”, result.Err())\n    }\n    return result.Val(), nil\n}\n7.3 模型层初始化 model/model.go\npackage model\nimport (\n    “short_url/model/sequence”\n    “short_url/model/short_url”\n)\nfunc Init() {\n    sequence.Init()   // 初始化序列生成器\n    short_url.Init()  // 初始化短链接服务\n}\n\n步骤8：控制器层\n8.1 创建响应结构 controller/code.go\npackage controller\nimport (\n    “net/http”\n    “github.com/gin-gonic/gin”\n)\n// Response 统一响应结构\ntype Response struct {\n    Code int         json:&quot;code&quot;\n    Msg  string      json:&quot;msg&quot;\n    Data interface{} json:&quot;data&quot;\n}\n// Success 成功响应\nfunc Success(c *gin.Context, data interface{}) {\n    c.JSON(http.StatusOK, Response{\n        Code: 200,\n        Msg:  “success”,\n        Data: data,\n    })\n}\n// Error 错误响应\nfunc Error(c *gin.Context, msg string) {\n    c.JSON(http.StatusOK, Response{\n        Code: 400,\n        Msg:  msg,\n        Data: nil,\n    })\n}\n8.2 创建短链接控制器 controller/sequence.go\npackage controller\nimport (\n    “github.com/gin-gonic/gin”\n)\n// CreateLinkRequest 创建短链接的请求参数\ntype CreateLinkRequest struct {\n    Url     string form:&quot;url&quot; binding:&quot;required&quot;      // 长链接（必填）\n    Status  int    form:&quot;status&quot; binding:&quot;required&quot;   // 1=自动，2=自定义\n    Keyword string form:&quot;keyword&quot;                     // 自定义短码（status=2时必填）\n}\n// CreateLink 创建短链接的HTTP处理函数\nfunc (b *BaseController) CreateLink(c *gin.Context) {\n    var req CreateLinkRequest\n    // 解析请求参数\n    if err := c.ShouldBind(&amp;req); err != nil {\n        Error(c, “参数错误: “+err.Error())\n        return\n    }\n    // 验证：如果是自定义模式，keyword不能为空\n    if req.Status  2 &amp;&amp; req.Keyword  &quot;&quot; {\n        Error(c, “自定义模式下，keyword不能为空”)\n        return\n    }\n    // 调用业务逻辑创建短链接\n    shortUrl, err := b.shortUrl.CreateLinks(req.Url, req.Keyword, req.Status)\n    if err != nil {\n        Error(c, err.Error())\n        return\n    }\n    Success(c, shortUrl)\n}\n\n步骤9：服务器层（HTTP服务）\n服务器层的代码你已经看到了，这里再完整列出：\n9.1 路由配置 server/route.go\npackage server\nimport (\n    “short_url/controller”\n    “short_url/model/short_url”\n    “strings”\n    “github.com/gin-contrib/cors”\n    “github.com/gin-gonic/gin”\n)\nfunc Route(r *gin.Engine) {\n    // 配置CORS跨域\n    r.Use(cors.New(cors.Config{\n        AllowAllOrigins:  true,\n        AllowMethods:     []string{”*”},\n        AllowHeaders:     []string{“Origin”, “Authorization”, “Access-Control-Allow-Origin”},\n        ExposeHeaders:    []string{“Content-Length”, “Access-Control-Allow-Origin”},\n        AllowCredentials: true,\n    }))\n    // 获取控制器\n    ctrl, err := controller.GetBaseController()\n    if err != nil {\n        panic(err)\n    }\n    // 全局中间件：处理短链接跳转\n    r.Use(Middleware)\n    // API路由组\n    v1 := r.Group(“/v1”)\n    {\n        v1.POST(“/create_url”, ctrl.CreateLink)  // 创建短链接接口\n    }\n}\n// Middleware 中间件：拦截所有请求，检查是否是短链接访问\nfunc Middleware(c *gin.Context) {\n    urlPath := c.Request.URL.Path\n    // 如果是API接口，直接放行\n    if strings.Contains(urlPath, “create_url”) {\n        c.Next()\n        return\n    }\n    // 否则当作短码处理，查询并跳转\n    shortCode := strings.ReplaceAll(urlPath, ”/”, &quot;&quot;)\n    if shortCode != &quot;&quot; {\n        if svc, err := short_url.GetServer(); err == nil {\n            if links, err := svc.GetLinksByKeyword(shortCode); err == nil &amp;&amp; links != nil {\n                // 301永久重定向到长链接\n                c.Redirect(301, links.Url)\n                return\n            }\n        }\n    }\n    // 找不到对应的短链接，返回404\n    c.Status(404)\n    c.Abort()\n}\n9.2 服务器启动 server/server.go\npackage server\nimport (\n    “net/http”\n    “short_url/base”\n    “short_url/base/tool”\n    “time”\n    “github.com/gin-gonic/gin”\n)\nfunc Run(addr string) {\n    base.ServerUrl = addr\n    gin.SetMode(gin.ReleaseMode)  // 生产模式\n    g := gin.Default()\n    Route(g)  // 注册路由\n    // 配置HTTP服务器\n    s := &amp;http.Server{\n        Handler:        g,\n        Addr:           addr,\n        WriteTimeout:   10 * time.Second,\n        ReadTimeout:    10 * time.Second,\n        MaxHeaderBytes: 1 &lt;&lt; 20,\n    }\n    tool.GetLogger().Info(“server start success : ” + addr)\n    // 启动服务器\n    err := s.ListenAndServe()\n    if err != nil {\n        panic(err)\n    }\n}\n\n步骤10：主程序入口 main.go\npackage main\nimport (\n    “flag”\n    “short_url/base”\n    “short_url/controller”\n    “short_url/server”\n)\nvar path = flag.String(“p”, “./conf/”, “配置文件路径”)\nvar addr = flag.String(“s”, “127.0.0.1:8099”, “服务器地址”)\nfunc main() {\n    flag.Parse()\n    // 1. 初始化基础层（配置、数据库、工具）\n    base.Init(*path)\n    // 2. 初始化控制器\n    controller.Init()\n    // 3. 启动HTTP服务器\n    server.Run(*addr)\n}\n\n🔧 步骤11：安装依赖并运行\n11.1 创建 go.mod（切换到Agent模式执行）\ncd E:\\2025-2026\\short_url\ngo mod init short_url\n11.2 安装所有依赖\ngo mod tidy\n这个命令会自动下载以下依赖：\n\n\ngithub.com/gin-gonic/gin - Web框架\n\n\ngithub.com/gin-contrib/cors - 跨域中间件\n\n\ngithub.com/go-xorm/xorm - ORM框架\n\n\ngithub.com/go-redis/redis - Redis客户端\n\n\ngithub.com/go-sql-driver/mysql - MySQL驱动\n\n\ngopkg.in/ini.v1 - 配置文件解析\n\n\ngo.uber.org/zap - 日志库\n\n\n11.3 运行项目\ngo run main.go -p ./conf/ -s 127.0.0.1:8099\n\n🧪 步骤12：测试\n测试1：创建短链接（自动生成）\ncurl -X POST http://127.0.0.1:8099/v1/create_url \\\n  -F “url=www.google.com” \\\n  -F “status=1”\n响应：\n{\n  “code”: 200,\n  “msg”: “success”,\n  “data”: “http://127.0.0.1:8099/b”\n}\n测试2：创建短链接（自定义）\ncurl -X POST http://127.0.0.1:8099/v1/create_url \\\n  -F “url=www.baidu.com” \\\n  -F “status=2” \\\n  -F “keyword=baidu”\n响应：\n{\n  “code”: 200,\n  “msg”: “success”,\n  “data”: “http://127.0.0.1:8099/baidu”\n}\n测试3：访问短链接\n浏览器打开：http://127.0.0.1:8099/baidu\n会自动跳转到：www.baidu.com"},"技术积累/兴趣驱动的待学清单":{"slug":"技术积累/兴趣驱动的待学清单","filePath":"技术积累/兴趣驱动的待学清单.md","title":"兴趣驱动的待学清单","links":[],"tags":[],"content":"\nPython爬虫\nJS逆向\n"},"技术积累/杂项/JSON":{"slug":"技术积累/杂项/JSON","filePath":"技术积累/杂项/JSON.md","title":"JSON","links":[],"tags":[],"content":"为了一个项目不同语言间的交流,设计的标准格式.\nJSON(JavaScript Object Notation)本质上就是一段 纯文本（String），长得非常有规律。不管是 C++、Go、Java 还是 Python，都能读写。\n{\n    &quot;stackIn&quot;: &quot;对象1&quot;,\n    &quot;stackOut&quot;: &quot;对象2&quot;\n}"},"技术积累/短链接/mysql":{"slug":"技术积累/短链接/mysql","filePath":"技术积累/短链接/mysql.md","title":"mysql","links":[],"tags":[],"content":"mysql -u root -p\nENGINE=InnoDB\ninnoDB支持事务、不丢数据\nCHARSET=utf8mb4\n字符集使用utf8mb4：可以存emoji的真正的utf8\nCOLLATE=utf8mb4_bin\n校对规则使用二进制模式\nutf8mb4_general_ci： 大小写不敏感\nutf8mb4_bin: 大小写敏感: 用二进制进行比较"},"技术积累/短链接/shortURL项目总览":{"slug":"技术积累/短链接/shortURL项目总览","filePath":"技术积累/短链接/shortURL项目总览.md","title":"shortURL项目总览","links":[],"tags":[],"content":"核心思想\n\n用户输入一个很长的网址（比如：www.google.com/search）\n系统生成一个短码（比如：abc123）\n用户访问短链接（比如：http://你的域名/abc123）\n系统自动跳转到原始长网址\n\n项目结构\nmain.go 程序入口 启动整个服务\nbase 基础层 包括初始化配置 数据库 工具\nconf 配置文件\ncontroller 控制器层 处理http请求\nmodel 模型层 业务逻辑 包括序列生成器和短链接业务逻辑\nserver 服务器层,包括路由和http服务\ncontroller: 只负责接收http请求和解析参数\nservice 负责核心逻辑 包括雪花算法生成和布隆过滤判断\nmodel 只负责存取数据库/redis\n\nController 调 Service。\nService 调 Model。\n永远不要让 Model 去调 Controller（这就是循环引用，Go 编译器会报错）\n\n服务\ngin web框架\ngin是go语言里面最流行的web框架.\n\n当用户在浏览器输入网址请求,gin负责接收请求\n解析参数\n把结果打包发回给用户.\n替代了手写解析http协议哪些繁琐的底层代码\n\nmysql 数据库\n关系型数据库 负责永久存储数据\n\n为了把长链接存进数据库,我们需要给它一个唯一id,然后把这个id转成短码.如果用自增id,容易被猜出总共有多少数据,而且如果有多个数据库,id就会重复.\n\nsnowflake\ntwitter发明的一种算法\n不重复: 利用时间戳+机器编号+序列号生成一个64位整数,可以做到全球唯一\n有序: 并且总体上是随时间递增的,对数据库索引比较的友好.\n高性能: 而且本地生成,不需要联网查询数据库,速度很快.\nredis 缓存\n内存数据库 速度极快比mysql快几万倍,但是断电可能会丢失部分数据,所以主要当作缓存在使用.\n因为短链接业务是读多写少,生成一次,可能会被几万人点击访问,如果都去查mysql会被挤爆炸,所以引入redis来抗并发\n布隆过滤器 bloom filter\n\n如果黑客疯狂请求一堆不存在的短链接,redis查不到mysql也查不到,大量的空请求直接打穿redis压在mysql上,数据库直接挂掉,叫做缓存穿透.\n\n是一个节省内存的数据结构,守在最前面,如果他说不在,那就肯定不在,把请求驳回,不查询redis和mysql了.\nSingleFlight\n\n如果某个短链接同一秒钟有一万人点击,刚好这时候redis里面这个链接的缓存过期了,那么又达成了缓存击穿.\n\nsingleflight是go官方的一个库,当一万个请求同时来的时候,singleflight会挡住他们,只放第一个人查询数据库"},"技术积累/算法题/1143.-最长公共子序列":{"slug":"技术积累/算法题/1143.-最长公共子序列","filePath":"技术积累/算法题/1143. 最长公共子序列.md","title":"1143. 最长公共子序列","links":[],"tags":[],"content":"给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。\n一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。\n\n例如，&quot;ace&quot; 是 &quot;abcde&quot; 的子序列，但 &quot;aec&quot; 不是 &quot;abcde&quot; 的子序列。\n两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。\n\n小记\n感觉字符串序列的问题很多都是倒着想的并且主要是选和不选的这么一个思想,需要特别注意.\n怎么想出来的?\n\n从这两个字符串的最后一个字符开始看.如果末尾一样,说明这个字符一定在最长公共子序列里面\n如果末尾不一样,意味着这两个字符不可能同时是lcs的结尾,但是其中一个是有可能的,于是进行下一步尝试(两个分支).然后结果就应该是max(尝试1,尝试2)的长度.\ndp就是带备忘录的递归.因为不同的分支最后可能变成一个很大的树,但是比如dfs44就可能被很多次使用,所以存下来比较好.没进行计算过的会是初始值-1,检测到-1就要计算.如果检测到不是-1说明已经有计算过的结果了 可以直接拿来用.\n\n一维数组写法要注意,这里因为需要上一行的左上角,所以需要额外的处理\n代码\nfunc longestCommonSubsequence(s, t string) int {\n    n, m := len(s), len(t)\n    f := make([][]int, n+1)\n    for i := range f {\n        f[i] = make([]int, m+1)\n    }\n    for i, x := range s {\n        for j, y := range t {\n            if x == y {\n                f[i+1][j+1] = f[i][j] + 1\n            } else {\n                f[i+1][j+1] = max(f[i][j+1], f[i+1][j])\n            }\n        }\n    }\n    return f[n][m]\n}\n \n \nfunc longestCommonSubsequence(text1 string, text2 string) int {\n     m := len(text2)\n     f:=make([]int,m+1)\n     for _,x:=range text1{\n        pre:=0\n        for j,y:=range text2{\n            if x==y{\n                f[j+1],pre=pre+1,f[j+1]\n            }else{\n                pre = f[j+1]\n                f[j+1]=max(f[j+1],f[j])\n            }\n        }\n     }\n     return f[m]\n}"},"技术积累/算法题/128.-最长连续序列":{"slug":"技术积累/算法题/128.-最长连续序列","filePath":"技术积累/算法题/128. 最长连续序列.md","title":"128. 最长连续序列","links":[],"tags":[],"content":"给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。\n请你设计并实现时间复杂度为 O(n) 的算法解决此问题。\n排序版O(N \\log N)\nfunc longestConsecutive(nums []int) int {\n    //直觉上:按顺序匹配出来放到新数组里面,但是可想而知时间复杂度应该很爆炸的\n    //先排序.然后快慢指针遍历?慢指针指向第一个连续,快指针一直遍历.如果遇到不连续的就把慢指针换过去从头开始计算.\n    slices.Sort(nums)\n    slow:=0\n    res:=0\n    cnt:=0\n    for fast,c:=range nums{\n        if fast&gt;0&amp;&amp;c!=nums[fast-1]&amp;&amp;c!=nums[fast-1]+1{\n            slow=fast\n        }\n        cnt=nums[fast]-nums[slow]+1\n        res=max(res,cnt)\n    }\n    return res\n}\nO(n)版\n小记\n\n用哈希表,可以自动去重\n从尾往前计算,如果对于x, x-1在哈希表中,那么说明x并不是连续序列的起点.\n小优化: 如果目前已有的连续序列已经大于剩下的不重复数字的个数了,那么说明没必要再往下找了\n\n代码\nfunc longestConsecutive(nums []int) (ans int) {\n    has := map[int]bool{}\n    for _, num := range nums {\n        has[num] = true // 把 nums 转成哈希集合\n    }\n \n    for x := range has { // 遍历哈希集合\n        if has[x-1] { // 如果 x 不是序列的起点，直接跳过\n            continue\n        }\n        // x 是序列的起点\n        y := x + 1\n        for has[y] { // 不断查找下一个数是否在哈希集合中\n            y++\n        }\n        // 循环结束后，y-1 是最后一个在哈希集合中的数\n        ans = max(ans, y-x) // 从 x 到 y-1 一共 y-x 个数\n    }\n    return\n}\n "},"技术积累/算法题/20.-有效的括号":{"slug":"技术积累/算法题/20.-有效的括号","filePath":"技术积累/算法题/20. 有效的括号.md","title":"20. 有效的括号","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n有效的括号\n给定一个只包括 &#039;(&#039;，&#039;)&#039;，&#039;{&#039;，&#039;}&#039;，&#039;[&#039;，&#039;]&#039; 的字符串 s ，判断字符串是否有效。\n有效字符串需满足：\n\n\n左括号必须用相同类型的右括号闭合。\n左括号必须以正确的顺序闭合。\n每个右括号都有一个对应的相同类型的左括号。 flashcard\n\n小记\n\n可以遇到左括号的时候,直接把对应右括号入栈.然后消除的时候逻辑就会变得简单,还可以统一处理.\n还可以做剪枝,如果总长度不是偶数可以直接return false\n\n代码\nfunc isValid(s string) bool {\n    // 1. 逻辑剪枝：奇数长度绝对不可能有效\n    if len(s)%2 != 0 {\n        return false\n    }\n    // 命名优化：cnt -&gt; stack，明确这是个栈\n    stack := []rune{}\n    for _, c := range s {\n        // 2. 转换思维：遇到左括号，把&quot;未来期待的右括号&quot;入栈\n        // 这样就把复杂度分摊到了 switch 中，而不是堆积在后面的 if 判断里\n        switch c {\n        case &#039;(&#039;:\n            stack = append(stack, &#039;)&#039;)\n        case &#039;[&#039;:\n            stack = append(stack, &#039;]&#039;)\n        case &#039;{&#039;:\n            stack = append(stack, &#039;}&#039;)\n        default:\n            // 3. 统一逻辑：处理右括号\n            // 只要栈空了，或者栈顶不是我期待的那个字符，直接挂掉\n            if len(stack) == 0 || stack[len(stack)-1] != c {\n                return false\n            }\n            // 匹配成功，消除待办事项\n            stack = stack[:len(stack)-1]\n        }\n    }\n    // 4. 最终状态检查：所有期待都满足了吗？\n    return len(stack) == 0 //这个也明显比我自己写的更精简!学习学习\n}"},"技术积累/算法题/287.-寻找重复数":{"slug":"技术积累/算法题/287.-寻找重复数","filePath":"技术积累/算法题/287. 寻找重复数.md","title":"287. 寻找重复数","links":[],"tags":[],"content":"给定一个包含 n + 1 个整数的数组 nums ，其数字都在 [1, n] 范围内（包括 1 和 n），可知至少存在一个重复的整数。\n假设 nums 只有 一个重复的整数 ，返回 这个重复的数 。\n你设计的解决方案必须 不修改 数组 nums 且只用常量级 O(1) 的额外空间。\n小记\n数组长度是 n+1。数值范围是 1 到 n。这意味着：数组里的任何一个值，都一定是一个合法的、非 0 的下标索引\n\n确定环内的某个相遇点\n然后根据推导可以发现,从起点走到环入口的距离,恰好等于从相遇点继续往前走到环入口的距离.所以要再找一个head,和slow一起向前走直到相遇(下标指向同一个节点 就说明相遇 相遇就说明一定是入口 这是经过数学推导的)\n\n代码\nfunc findDuplicate(nums []int) int {\n    //只能用o(1)就是不能用map 不修改数组就是不能排序.\n    //那就要牺牲时间复杂度了 走两个循环还是可以解出来的,但是有没有更好的办法呢.. 还有特点是 都是正数 但是感觉也用不上 \n    slow,fast:=0,0\n    for {\n        slow=nums[slow]\n        fast=nums[nums[fast]]\n        if slow==fast{\n            break\n        }\n    }\n    head:=0\n    for slow!=head{\n        slow=nums[slow]\n        head=nums[head]\n    }\n    return slow\n}"},"技术积累/算法题/347.-前-K-个高频元素":{"slug":"技术积累/算法题/347.-前-K-个高频元素","filePath":"技术积累/算法题/347. 前 K 个高频元素.md","title":"347. 前 K 个高频元素","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n前 K 个高频元素\n给你一个整数数组 nums 和一个整数 k ，请你返回其中出现频率前 k 高的元素。你可以按 任意顺序 返回答案。 flashcard\n\n小记\n\n先用哈希表乱序统计次数。\n再把数据“倒腾”到一个数组里，让次数成为数组下标。\n最后利用数组下标天然有序的特性，从后往前拿数据，自然就是 Top K 了。\n\n代码\nfunc topKFrequent(nums []int, k int) []int {\n    // 第一步：统计每个元素的出现次数\n    cnt := map[int]int{}\n    maxCnt := 0\n    for _, x := range nums {\n        cnt[x]++\n        maxCnt = max(maxCnt, cnt[x])\n    }\n    // 第二步：把出现次数相同的元素，放到同一个桶中\n    buckets := make([][]int, maxCnt+1)\n    for x, c := range cnt {\n        buckets[c] = append(buckets[c], x)\n    }\n    // 第三步：倒序遍历 buckets，把出现次数前 k 大的元素加入答案\n    ans := make([]int, 0, k) // 预分配空间\n    // 注意题目保证答案唯一，一定会出现某次 append 后 len(ans) 恰好等于 k 的情况\n    for i := maxCnt; i &gt;= 0 &amp;&amp; len(ans) &lt; k; i-- {\n        ans = append(ans, buckets[i]...)\n    }\n    return ans\n}\n还有朴素的解法如下\nfunc topKFrequent(nums []int, k int) []int {\n    //首先哈希统计频率\n    f:=map[int]int{}\n    for _,c:=range nums{\n        f[c]++\n    }\n    //初始化堆.将每个元素加入堆\n    h:=&amp;Iheap{}\n    heap.Init(h)//其实这里不init也可以啊,反正调用heap的时候就是会自动当作堆的\n    for key,v:=range f{\n        heap.Push(h,[2]int{key,v})\n        if h.Len()&gt;k{\n            heap.Pop(h)\n        }\n    }\n    //倒序pop堆得到ans\n    ans:=make([]int,k)\n    for i:=0;i&lt;k;i++{\n        ans[k-i-1]=heap.Pop(h).([2]int)[0]\n    }\n    return ans\n}\n&lt;!--ID: 1767668518795--&gt;\n \n \ntype Iheap [][2]int\n \nfunc (h Iheap) Len()int{\n    return len(h)\n}\n \nfunc (h Iheap) Swap(i,j int){\n    h[i],h[j]=h[j],h[i]\n}\n \nfunc (h Iheap) Less(i,j int)bool{\n    return h[i][1]&lt;h[j][1]\n}\n \nfunc (h *Iheap) Push(v any){\n    *h=append(*h,v.([2]int))\n}\n \nfunc (h *Iheap) Pop()any{\n    a:=*h\n    n:=len(a)\n    old:=a[n-1]\n    *h=a[:n-1]\n    return old\n}"},"技术积累/算法题/39.-组合总和":{"slug":"技术积累/算法题/39.-组合总和","filePath":"技术积累/算法题/39. 组合总和.md","title":"39. 组合总和","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n组合总和\n给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按 任意顺序 返回这些组合。\ncandidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。 \n对于给定的输入，保证和为 target 的不同组合数少于 150 个 flashcard\n\n小记\n\n代码\nfunc combinationSum(candidates []int, target int) [][]int {\n    slices.Sort(candidates)\n    path:=[]int{}\n    ans:=[][]int{}\n    var dfs func(i,left int)//当前candidates的下标\n    dfs=func(i ,left int){\n        if left==0{\n            ans=append(ans,slices.Clone(path))\n            return \n        }\n        for j:=i;j&lt;len(candidates)&amp;&amp;candidates[j]&lt;=left;j++{//因为现在candidates是递增 所以如果candidates已经够了的话就不往下了\n            path=append(path,candidates[j])\n            dfs(j,left-candidates[j])\n            path=path[:len(path)-1]\n        }\n    }\n    dfs(0,target)\n    return ans\n}\n"},"技术积累/算法题/437.-路径总和-III":{"slug":"技术积累/算法题/437.-路径总和-III","filePath":"技术积累/算法题/437. 路径总和 III.md","title":"437. 路径总和 III","links":[],"tags":[],"content":"给定一个二叉树的根节点 root ，和一个整数 targetSum ，求该二叉树里节点值之和等于 targetSum 的 路径 的数目。\n路径 不需要从根节点开始，也不需要在叶子节点结束，但是路径方向必须是向下的（只能从父节点到子节点）\n小记\n\n就是把当前路径记录成前缀和数组.然后回到分岔口准备走下一条路的时候,记得把错误的前缀和删掉\n代码\n/**\n * Definition for a binary tree node.\n * type TreeNode struct {\n *     Val int\n *     Left *TreeNode\n *     Right *TreeNode\n * }\n */\nfunc pathSum(root *TreeNode, targetSum int) int {\n    //感觉很熟悉,应该是动态规划..但是没做过二叉树的动态规划! 感觉可以回溯\n    //但是不需要从根节点开始也不需要在子节点结束 感觉很难回溯\n    ans:=0\n    pre:=map[int]int{0:1}//确保前缀和为0是一直存在的\n    var dfs func(node *TreeNode,s int)\n    dfs=func(node *TreeNode ,s int){\n        if node==nil{\n            return \n        }\n        s+=node.Val\n        ans+=pre[s-targetSum]//之前有多少个前缀和是满足的\n        pre[s]++//这个要看 自己到自己的算不算在内\n        dfs(node.Left,s)\n        dfs(node.Right,s)\n        pre[s]--\n    }\n    dfs(root,0)\n    return ans\n}"},"技术积累/算法题/5.-最长回文子串":{"slug":"技术积累/算法题/5.-最长回文子串","filePath":"技术积累/算法题/5. 最长回文子串.md","title":"5. 最长回文子串","links":["tags/flashcard"],"tags":["flashcard"],"content":"给你一个字符串 s，找到 s 中最长的回文子串。 flashcard\n小记\n\n关键是枚举回文子串的中心。\n\n然后从该中心触发,分奇数和偶数两种情况讨论即可\n在左右相等时,持续扩散,直到数组边界\n今天又做了一遍没有做出来,感觉自己还没有理解到核心..\n\n\n\n代码\nfunc longestPalindrome(s string) string {\n    n:=len(s)\n    ans:=0\n    resl:=-1\n    resr:=n\n    for i,_:=range s{\n        l,r:=i,i\n        for l&gt;=0&amp;&amp;r&lt;n&amp;&amp;s[l]==s[r]{\n            ans=max(ans,r-l+1)\n            if ans==r-l+1{\n                resl=l\n                resr=r\n            }\n            l--\n            r++\n        }\n        l,r=i,i+1\n        for l&gt;=0&amp;&amp;r&lt;n&amp;&amp;s[l]==s[r]{\n            ans=max(ans,r-l+1)\n            if ans==r-l+1{\n                resl=l\n                resr=r\n            }\n            l--\n            r++\n        }\n    }\n    return s[resl:resr+1]\n}\n\n拓展:manacher算法\n\n在空隙插入符号,统一奇数偶数的情况\n记录目前发现的右边最远的回文串的中心点,以及他的右边界.\n这个中心点视作镜子,那么左右两边的回文串可以只算一次\n"},"技术积累/算法题/75.-颜色分类":{"slug":"技术积累/算法题/75.-颜色分类","filePath":"技术积累/算法题/75. 颜色分类.md","title":"75. 颜色分类","links":[],"tags":[],"content":"给定一个包含红色、白色和蓝色、共 n 个元素的数组 nums ，原地 对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。\n必须在不使用库内置的 sort 函数的情况下解决这个问题。\n小记\n两趟很容易想到.\n一趟算法:\n代码\n "},"技术积累/算法题/76.-最小覆盖子串":{"slug":"技术积累/算法题/76.-最小覆盖子串","filePath":"技术积累/算法题/76. 最小覆盖子串.md","title":"76. 最小覆盖子串","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n最小覆盖子串 给定两个字符串 s 和 t，长度分别是 m 和 n，返回 s 中的 最短窗口 子串，使得该子串包含 t中的每一个字符（包括重复字符）。如果没有这样的子串，返回空字符串 &quot;&quot; flashcard\n\n小记\n滑动窗口的移动逻辑：\n\n右指针 (扩张): 应该无条件向右移动。每移动一步，更新 s 中新进入字符的计数。\n左指针 (收缩): 只有在窗口已经 完全覆盖 t 的时候，才需要收缩左指针。左指针收缩是为了寻找最短子串。[这个是最重要的]\n引入两个数据结构\nneed哈希表:存储t中所有字符以及其所需的数量\nwindow哈希表:存储当前滑动窗口中所有字符及其数量\n这两个数据结构可以合并\nneed哈希表\nmatch(int):记录当前窗口中已经满足\n所需数量的字符种类的数量\n还有很多细节上的东西 要仔细看一下代码\n\n代码\nfunc minWindow(s string, t string) string {\n    cnt := [128]int{}\n    requiredKinds := 0\n    for i := 0; i &lt; len(t); i++ {\n        if cnt[t[i]] == 0 { requiredKinds++ }\n        cnt[t[i]]++\n    }\n    left, match := 0, 0\n    start, minLen := -1, len(s) + 1\n    for right := 0; right &lt; len(s); right++ {\n        // 1. 入窗：账本减 1\n        cnt[s[right]]--\n        // 如果减完刚好变 0，说明这个字符的数量刚好达到了 t 的要\n        if cnt[s[right]] == 0 {\n            match++\n        }\n        // 2. 满足条件，尝试收缩\n        for match == requiredKinds {\n            // 更新结果\n            if right - left + 1 &lt; minLen {\n                minLen = right - left + 1\n                start = left\n            }\n            // 3. 出窗：账本加 1\n            // 如果出窗前是 0，说明移走它后，该字符就不再达标了\n            if cnt[s[left]] == 0 {\n                match--\n            }\n            cnt[s[left]]++\n            left++\n        }\n    }\n    if start == -1 { return &quot;&quot; }\n    return s[start : start + minLen]\n}"},"技术积累/算法题/二叉树/102.-二叉树的层序遍历":{"slug":"技术积累/算法题/二叉树/102.-二叉树的层序遍历","filePath":"技术积累/算法题/二叉树/102. 二叉树的层序遍历.md","title":"102. 二叉树的层序遍历","links":[],"tags":[],"content":"给你二叉树的根节点 root ，返回其节点值的 层序遍历 （即逐层地，从左到右访问所有节点）。\n小记\n双数组写法\n把树看作一层一层的切片（Slice）\n\ncur (Current)：代表 当前层 的所有节点。\nnxt (Next)：代表 下一层 的所有节点。\n每次循环，遍历 cur，收集所有的孩子放到 nxt，然后把 nxt 变成新的 cur。\n\n单队列写法\n实际上就是把之前的cur和nxt合起来变成了一个队列，先进先出而已。但是要注意的是队列中，上一层和下一层需要有分界线，因为输出答案是根据层序打包成一个一个小切片。而具体实现中，是先将本次循环的len(q)作为大小,与分配好一个val数组存放本次层序的答案,而val数组遍历完之后打包好答案,可以自然而然进入下一行.\n代码\nfunc levelOrder(root *TreeNode) [][]int {\n    if root==nil{\n        return nil\n    }//如果树为空 那么层序遍历当然也是空\n    //cur是当前层节点的集合切片\n    //nxt是下一层节点的集合切片\n    //val是当前层节点的值捞出来得到的切片\n    //ans是层序遍历,是val的集合\n    ans:=[][]int{}\n    cur:=[]*TreeNode{root}\n    for len(cur)&gt;0{\n        nxt:=[]*TreeNode{}\n        val:=make([]int,len(cur))\n        for i,c:=range cur{\n            val[i]=c.Val\n            if c.Left!=nil{\n                nxt=append(nxt,c.Left)\n            }\n            if c.Right!=nil{\n                nxt=append(nxt,c.Right)\n            }\n        }\n        cur=nxt        \n        ans=append(ans,val)\n    }\n    return ans\n}\nfunc levelOrder(root *TreeNode) [][]int {\n\tif root == nil {\n\t\treturn nil\n\t} //空树当然层序遍历是nil\n\tq := []*TreeNode{root} //初始化为第一层\n\tans := [][]int{}\n\tfor len(q) &gt; 0 {\n\t\tval := make([]int, len(q)) //这里确定当前层有多少节点了,那么只要这么多个节点的答案打包起来就是最终二维切片中的一个.\n\t\tfor i, _ := range val {\n\t\t\tnode := q[0]\n\t\t\tq = q[1:]\n\t\t\tval[i] = node.Val\n\t\t\tif node.Left != nil {\n\t\t\t\tq = append(q, node.Left)\n\t\t\t}\n\t\t\tif node.Right != nil {\n\t\t\t\tq = append(q, node.Right)\n\t\t\t}\n\t\t}\n\t\tans = append(ans, val)\n\t}\n\treturn ans\n}\n "},"技术积累/算法题/二叉树/105.-从前序与中序遍历序列构造二叉树":{"slug":"技术积累/算法题/二叉树/105.-从前序与中序遍历序列构造二叉树","filePath":"技术积累/算法题/二叉树/105. 从前序与中序遍历序列构造二叉树.md","title":"105. 从前序与中序遍历序列构造二叉树","links":[],"tags":[],"content":"给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。\n小记\n\n前序的第一个数就是根 那么在中序里面,根前面的节点都是左子树,后面都是右子树\n怎么把“中序”里看到的左子树的长度，映射回“前序”数组里去切分？ 左子树在两个数组里的「长度（节点个数 ）」是一模一样的\n\n代码\n//方法一\nfunc buildTree(preorder, inorder []int) *TreeNode {\n    n := len(preorder)\n    if n == 0 { // 空节点\n        return nil\n    }\n    leftSize := slices.Index(inorder, preorder[0]) // 左子树的大小\n    left := buildTree(preorder[1:1+leftSize], inorder[:leftSize])\n    right := buildTree(preorder[1+leftSize:], inorder[1+leftSize:])\n    return &amp;TreeNode{preorder[0], left, right}//组装得到返回值!\n}\n \n \n//用哈希表,把前序中数值和下标都记录下来,这样不用每次都用Index去找.以后想知道“根在哪里”，查一下 Map 就行了，耗时瞬间变成 $O(1)$\n//传参用的是子数组下标区间的左右端点,不用复制数组\nfunc buildTree(preorder, inorder []int) *TreeNode {\n    n := len(preorder)\n    index := make(map[int]int, n)\n    for i, x := range inorder {\n        index[x] = i\n    }\n \n    var dfs func(int, int, int, int) *TreeNode\n    dfs = func(preL, preR, inL, inR int) *TreeNode {\n        if preL == preR { // 空节点\n            return nil\n        }\n        leftSize := index[preorder[preL]] - inL // 左子树的大小\n        left := dfs(preL+1, preL+1+leftSize, inL, inL+leftSize)\n        right := dfs(preL+1+leftSize, preR, inL+1+leftSize, inR)\n        return &amp;TreeNode{preorder[preL], left, right}\n    }\n    return dfs(0, n, 0, n) // 左闭右开区间\n}\n \n// preL, preR: 当前要在 preorder 数组里处理的范围 [开始, 结束)\n// inL, inR: 当前要在 inorder 数组里处理的范围 [开始, 结束)"},"技术积累/算法题/二叉树/22.-括号生成":{"slug":"技术积累/算法题/二叉树/22.-括号生成","filePath":"技术积累/算法题/二叉树/22. 括号生成.md","title":"22. 括号生成","links":[],"tags":[],"content":"小记\n比如n=3 那么就是6个位置,你可以选择放左括号还是右括号,只需要遵循两个原则\n\n左括号和右括号个数相等\n当前已放置的右括号的个数必须小于等于左括号的个数\n\n\n决策树根节点是空字符串,向左的分支是左括号,向右的分支是右括号,树的叶子节点是最终生成的字符串\ndfs: 一条路走到黑\n回溯: 1. 及时止损,剪枝 2. 存档回到上一步继续,这样可以遍历所有的情况\n\n代码\nfunc generateParenthesis(n int) (ans []string) {\n    path := make([]byte, n*2) // 所有括号长度都是一样的 2n\n \n    // 目前填了 left 个左括号，right 个右括号\n    var dfs func(int, int)\n    dfs = func(left, right int) {\n        if right == n { // 填完 2n 个括号\n            ans = append(ans, string(path)) // 加入答案\n            return\n        }\n        if left &lt; n { // 可以填左括号\n            path[left+right] = &#039;(&#039; // 直接覆盖\n            dfs(left+1, right)\n        }\n        if right &lt; left { // 可以填右括号\n            path[left+right] = &#039;)&#039; // 直接覆盖\n            dfs(left, right+1)\n        }\n    }\n \n    dfs(0, 0) // 一开始没有填括号\n    return\n}"},"技术积累/算法题/二叉树/236.-二叉树的最近公共祖先":{"slug":"技术积累/算法题/二叉树/236.-二叉树的最近公共祖先","filePath":"技术积累/算法题/二叉树/236. 二叉树的最近公共祖先.md","title":"236. 二叉树的最近公共祖先","links":["技术积累/算法题/栈与队列/递归"],"tags":[],"content":"给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。\n最近公共祖先的定义为：“对于有根树 T 的两个节点 p、q，最近公共祖先表示为一个节点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。”\n小记\nTransclude of 递归#递归算法三要素\n代码\n/**\n * Definition for a binary tree node.\n * type TreeNode struct {\n *     Val int\n *     Left *TreeNode\n *     Right *TreeNode\n * }\n */\nfunc lowestCommonAncestor(root, p, q *TreeNode) *TreeNode {\n    //边界条件\n  if root==nil||root==p||root==q{\n    return root\n  }\n  //递归得到返回值\n  left:=lowestCommonAncestor(root.Left,p,q)\n  right:=lowestCommonAncestor(root.Right,p,q)\n  //如何获取其他递归返回值\n  if left!=nil&amp;&amp;right!=nil{\n    return root\n  }\n  if left!=nil{\n    return left\n  }\n  return right\n}"},"技术积累/算法题/二叉树/46.-全排列":{"slug":"技术积累/算法题/二叉树/46.-全排列","filePath":"技术积累/算法题/二叉树/46. 全排列.md","title":"46. 全排列","links":[],"tags":[],"content":"给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n小记\n\n一层一层地进行递归\n\npath就是当前全排列的情况.\nonpath是一个布尔数组,标记元素在之前的盒子里用过了,因为全排列不能有重复元素\n\n\n递归终止条件: 当盒子里的元素都放满了之后,ans = append(ans, copy_of_path).注意这里是copyofpath,因为path切片是值引用,如果只是appendpath这个切片的话,会映射到同一块地址,最后全都是最后一次回溯的内容.\ndfs(i),i表示第几层递归\n因为已经知道了不重复,所以就只需要关心下标就可以了,不需要关心实际的数字值\n\n代码\nfunc permute(nums []int) (ans [][]int) {\n    n := len(nums)\n    path := make([]int, n)\n    onPath := make([]bool, n)\n    var dfs func(int)\n    dfs = func(i int) {\n        if i == n {\n            ans = append(ans, append([]int(nil), path...))\n            return\n        }\n        for j, on := range onPath {\n            if !on {\n                path[i] = nums[j]\n                onPath[j] = true\n                dfs(i + 1)\n                onPath[j] = false\n            }\n        }\n    }\n    dfs(0)\n    return\n}\n "},"技术积累/算法题/二叉树/94.-二叉树的中序遍历":{"slug":"技术积累/算法题/二叉树/94.-二叉树的中序遍历","filePath":"技术积累/算法题/二叉树/94. 二叉树的中序遍历.md","title":"94. 二叉树的中序遍历","links":[],"tags":[],"content":"给定一个二叉树的根节点 root ，返回 它的 中序 遍历 。\n小记\n递归算法\n迭代算法:Morris\n\n如果用递归或者栈迭代,空间复杂度是O(h),那么就考虑到 我们可以利用树中大量的空指针nil,暂时指向它的后续节点,搭建一条临时通道来进行回溯.\nMorris遍历的精髓:线索化\n\n 在进入左子树之前，先找到左子树里“最后一个被访问的节点”（即左子树的最右节点）把这个节点的右指针（本应该是 nil），指向当前根节点。整个遍历过程完全靠root指针的移动来遍历\n 具体实现:\n - root没有左孩子,直接记录+打印.\n - root有左孩子 不能直接往左走,需要先记录下左子树里最右边的节点\n\n如果preright是空的,说明我们第一次来到root,还没有遍历左子树.所以找到preright,指向root.\n如果preright已经指向root,说明我们已经遍历完了左子树,回来了,那么就复原preright\n\n代码\n/**\n * Definition for a binary tree node.\n * type TreeNode struct {\n *     Val int\n *     Left *TreeNode\n *     Right *TreeNode\n * }\n */\nfunc inorderTraversal(root *TreeNode) []int {\n    //递归\n    ans:=[]int{}\n    var dfs func(root *TreeNode)\n    dfs=func(root *TreeNode){\n        if root==nil{\n            return \n        }\n        dfs(root.Left)\n        ans=append(ans,root.Val)\n        dfs(root.Right)\n    }\n    dfs(root)\n    return ans\n}\nmorris\n具体实现上还是比较绕的,解说一下:\n如果左子树不为空 就要找一个前驱，为了遍历完左子树立刻回到root\n\n如果是因为preright=nil而导致循环结束的话 就说明是第一次来到root 那么就做连接 并且使得root进行左子树遍历\n如果是因为preright=root中断的循环 就说明是第二次到达了所以把preright复原\n然后这是左子树结束了 接下来正常的记录root和右子树遍历\n\n "},"技术积累/算法题/二叉树/二叉树":{"slug":"技术积累/算法题/二叉树/二叉树","filePath":"技术积累/算法题/二叉树/二叉树.md","title":"二叉树","links":["技术积累/算法题/栈与队列/递归"],"tags":[],"content":"二叉树的种类\n满二叉树\n只有度为0的结点和度为2的结点,而且度为0的结点在同一层上\n完全二叉树\n在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层（h从1开始），则该层包含 1~ 2^(h-1) 个节点。\n\n堆就是一棵完全二叉树\n二叉搜索树\n有序树.\n\n若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n它的左、右子树也分别为二叉搜索树\n\n\n平衡二叉搜索树\n又称作AVL树.\n它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\n\n二叉树的存储方式\n可以链式存储(指针),也可以顺序存储(数组)\n如果父节点的数组下标是 i，那么它的左孩子就是 i * 2 + 1，右孩子就是 i * 2 + 2\n遍历方式\n深度优先遍历\n先往深处走,遇到叶子节点再往回走\n这里的前中后指的是中间节点的遍历顺序\n前序遍历: 递归/迭代法    中左右\n中序遍历: 递归/迭代法    左中右\n后序遍历: 递归/迭代法    左右中\n用递归比较方便.同时,栈其实是递归的一种实现结构,因此前中后序遍历是可以用栈实现的.\n广度优先遍历\n层次遍历: 迭代法\n一般用队列来实现,因为队列是先进先出的,这样才能一层一层地遍历二叉树\n具体实现\ntype TreeNode struct {\n    Val int\n    Left *TreeNode\n    Right *TreeNode\n}\n递归遍历\nTransclude of 递归#递归算法三要素\n\n参数应该是子树的根节点.首先这个递归函数是得作用在一整棵树上的.然后再递归去对各个子树做操作.而结果数组不需要经过传递.\n最终到子树的叶子节点,node==nil的时候就返回,也不需要加入res数组\n\n\nfunc preorderTraversal(root *TreeNode) (res []int) {\n    var traversal func(node *TreeNode)//声明递归函数变量\n    traversal = func(node *TreeNode) {//给变量赋值\n\t//base case\n\tif node == nil {\n            return\n\t}\n\t\n\tres = append(res,node.Val)//把中(也就是自己)放进篮子\n\ttraversal(node.Left)//左递归\n\ttraversal(node.Right)//右递归\n    }\n    traversal(root)//使用递归函数\n    return res\n}\n \n迭代遍历\nTransclude of 递归#递归的实现\n因此直接用栈也可以实现深度优先遍历.\n前序遍历\n前序遍历是中左右.因此每次先将根节点放入栈中,然后将右节点加入栈,再加入左节点.这样出栈的时候是中左右的顺序\n中序遍历\n统一迭代法\n层序遍历"},"技术积累/算法题/二叉树/对称二叉树":{"slug":"技术积累/算法题/二叉树/对称二叉树","filePath":"技术积累/算法题/二叉树/对称二叉树.md","title":"对称二叉树","links":[],"tags":[],"content":""},"技术积累/算法题/二叉树/翻转二叉树":{"slug":"技术积累/算法题/二叉树/翻转二叉树","filePath":"技术积累/算法题/二叉树/翻转二叉树.md","title":"翻转二叉树","links":[],"tags":[],"content":""},"技术积累/算法题/前缀和/121.-买卖股票的最佳时机":{"slug":"技术积累/算法题/前缀和/121.-买卖股票的最佳时机","filePath":"技术积累/算法题/前缀和/121. 买卖股票的最佳时机.md","title":"121. 买卖股票的最佳时机","links":[],"tags":[],"content":"给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。\n你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。\n返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。\n小记\n维护两个关键变量:\n\n记录从第一天到当前这一天为止,出现的最低价格(假设买入点)\n\n顺手记住的,所以只需要遍历一遍即可.\n\n\nans:记录到目前为止能获得的历史最大利润\n\n代码\nfunc maxProfit(prices []int) (ans int) {\n    minPrice := prices[0]\n    for _, p := range prices {\n        ans = max(ans, p-minPrice)\n        minPrice = min(minPrice, p)\n    }\n    return\n}"},"技术积累/算法题/前缀和/53.-最大子数组和":{"slug":"技术积累/算法题/前缀和/53.-最大子数组和","filePath":"技术积累/算法题/前缀和/53. 最大子数组和.md","title":"53. 最大子数组和","links":[],"tags":[],"content":"给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组是数组中的一个连续部分(非空元素序列)\n前缀和\n小记\n\n题目要求子数组不能为空，应当先计算前缀和-最小前缀和，再更新最小前缀和。相当于不能在同一天买入股票又卖出股票。\n而且实际上前缀和并不需要维护整个前缀和数组\n\n代码\nfunc maxSubArray(nums []int) int {\n    ans := math.MinInt\n    minPreSum := 0\n    preSum := 0\n    for _, x := range nums {\n        preSum += x // 当前的前缀和\n        ans = max(ans, preSum-minPreSum)   // 减去前缀和的最小值\n        minPreSum = min(minPreSum, preSum) // 维护前缀和的最小值\n    }\n    return ans\n}\n \n动态规划\n小记\nf[i] 代表：如果必须以第 i 个人作为终点，这一队人能凑出的最大数值是多少？\nf[i] = \\max(f[i-1], 0) + nums[i]\n代码\nfunc maxSubArray(nums []int) int {\n    ans := math.MinInt // 注意答案可以是负数，不能初始化成 0\n    f := 0\n    for _, x := range nums {\n        f = max(f, 0) + x\n        ans = max(ans, f)\n    }\n    return ans\n}\n "},"技术积累/算法题/前缀和/KMP算法":{"slug":"技术积累/算法题/前缀和/KMP算法","filePath":"技术积累/算法题/前缀和/KMP算法.md","title":"KMP算法","links":[],"tags":[],"content":"取了三位学者名字的首字母。所以叫做KMP\n主要思想\n当出现字符串不匹配时,可以知道一部分之前已经匹配的内容,可以利用这些信息,避免从头匹配.\n原理\nnext数组\n本质上即为前缀表prefixtable\n\n用来回退.记录了模式串与主串不匹配的时候,模式串应该从哪里开始重新匹配.\n\n\n但是实现上也可以采用前缀表统一减一\n\n生成\n\n记录下标i之前（包括i）的字符串中，有多大长度的相同前后缀\n\n\n\n                  \n                  最长公共前后缀 \n                  \n                \n\n前缀:不包含最后一个字符的,所有以第一个字符开头的连续字串.\n后缀:不包含第一个字符的,所有以最后一个字符结尾的连续子串.\n\n\n\n前后缀相等（KMP的逻辑）： A B C … A B C （平移重复，同向）\n\n对于下标0: 单独一个’a’ 最长公共前后缀是0(因为计算公共前后缀是不包括第一个/最后一个的)\n对于下标1: ‘aa’ 最长公共前后缀是1\n对于下标2: ‘aab’最长公共前后缀是0\n\n使用\n使用前缀表的情况下: 找到不匹配的位置,那么去看它的前一个字符对应前缀表的数值是多少. 前往前面字符串的最大公共后缀的前一个位置重新匹配\n用next数组的情况下: 前往前面字符串的最大公共后缀的开头重新匹配\n\n实现\n\n单独生成next数组，时间复杂度是O(m)\n根据前缀表不断调整匹配的位置O(n)\n所以整个KMP算法的时间复杂度是O(n+m)\n\n构造next数组\n是针对模式串[即目标字符串]做的准备\n\n初始化\n\nj指向前缀末尾位置,i指向后缀末尾位置\n初始化next[0]-[可以让j=-1,然后next[0]=j,之后检索都用next[j+1]]\n\n\n处理前后缀不相同的情况\n\n下标i从1开始遍历,如果 s[i] 和 s[j+1] 不匹配，我们想找一个更短的前缀，这个前缀刚好也是当前 i 之前的后缀。\n因为next数组里面记录着以下标结尾的字串的相同前后缀长度.\n当我们从一个较长的匹配（L）回退到一个较短的匹配（X）时，X 的下一个字符可能依然无法满足当前的匹配需求。 因此这里要用for,直到下一个字符能匹配为止\naabaa 这时候j+1=2指向b,i指向新来的字符,如果是a那么匹配失败[aab!=aaa]\nj=next[j]=next[1]=1,从这个位置开始重新匹配,这样就可以aabaaa 把第二个a和最后一个a匹配起来.\n\n\n\n\n\n                  \n                  思考过程 \n                  \n                \n\nQ: 为什么j=next[j]就能达到这样的效果?next[j]里面放的是0j这个字符串的最大公共前后缀,为什么能对0i的这个字符串起到一个回退的作用?我觉得应该是看next[i-1] 发现前面这个字符串里面最大前后缀是1,然后新来了一个没匹配上,本来最大前后缀应该是2的,所以2-1=1 ,让前缀从这个1的地方开始重新匹配.\n\n\n\nS：主字符串（0 ~ i-1）。\nL：S 的最长公共前后缀（即 next[i-1] 对应的串）。\nX：S 的次长公共前后缀（我们需要找的目标）。\n需要证明的是：X 一定是 L 的最长公共前后缀。\n实际上是把L切成了两部分,前缀放到S的最前面,后缀留在原地,然后x作为s的次长公共前后缀,就确实是L的最长公共前后缀\n\n\n处理前后缀相同的情况\n\n如果 s[i] 与 s[j + 1] 相同，那么就同时向后移动i 和j 说明找到了相同的前后缀，同时还要将j（前缀的长度）赋给next[i]记录下来\n\n\n\n做匹配\n\n下标j指向模式串起始位置,i指向文本串起始位置.j初始值依然为-1[用-1表示起始/空状态]\ni在文本串中不断进行遍历,并且s[i]和s[j+1]作比较.\n\n如果不同,j就从next数组里寻找下一个匹配的位置(如果j在开头,就不动)\n如果相同,那么ij同时向后移动\n\n\n如果j指向了模式串的末尾,那么就说明模式串t完全匹配文本串s里的某子串了\n\n\n实际上i是一直往下走的,只有j一直在调整位置变换到(假设当前是文本串中的模式串,那么为了继续往下遍历, 应该处在哪个下标处)\n\n代码\n暴力解\n \nfunc strStr(haystack string, needle string) int {\n    l1:=len(haystack)\n    l2:=len(needle)\n    if l2==0{\n        return 0\n    }\n    if l1==0||l1&lt;l2{\n        return -1\n    }\n    for i:0=;i&lt;=l1-l2;i++{\n        if haystack[i:i+l2]==needle{\n            return i\n        }\n    }\n    return -1\n}\nkmp\nfunc strStr(haystack string, needle string) int {\n    if len(needle) == 0{\n        return 0\n    }\n    next:=make([]int,len(needle))\n    getNext(next, needle)\n    j:=-1\n    for i := 0; i &lt; len(haystack); i++ {\n\t\tfor j &gt;= 0 &amp;&amp; haystack[i] != needle[j+1] {\n\t\t\tj = next[j]     // 寻找下一个匹配点\n\t\t}\n\t\tif haystack[i] == needle[j+1] {\n\t\t\tj++\n\t\t}\n\t\tif j == len(needle)-1 {      // j指向了模式串的末尾\n\t\t\treturn i - len(needle) + 1\n\t\t}\n\t}\n    return -1\n}\n \n \nfunc getNext(next []int, s string){\n    j:=-1\n    next[0]=j\n    for i:=1;i&lt;len(next);i++{\n        for j&gt;=0&amp;&amp;s[i]!=s[j+1]{\n            j=next[j]\n        }\n        if s[i]==s[j+1]{\n            j++\n        }\n        next[i]=j\n    }\n}"},"技术积累/算法题/动态规划与回溯/131.-分割回文串":{"slug":"技术积累/算法题/动态规划与回溯/131.-分割回文串","filePath":"技术积累/算法题/动态规划与回溯/131. 分割回文串.md","title":"131. 分割回文串","links":[],"tags":[],"content":"给你一个字符串 s，请你将 s 分割成一些 子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。\n小记\n一般写着所有可能的分割方案,就往回溯去想.\n\n第一种方法,输入的视角.\n\n切或者不切.如果切一刀,前面的部分变成一个子串\n\n\n第二种方法,答案的视角,枚举选哪个.\n\n第一刀切在哪？ (枚举 i 从 1 到 n)\n\n切 1 个字 a：是回文吗？是 → 剩下 ab 丢给递归去切。\n切 2 个字 aa：是回文吗？是 → 剩下 b 丢给递归去切。\n切 3 个字 aab：是回文吗？否 → 跳过。\n\n\n\n\n\n代码\n\nans存所有的可能方案\npath存当前方案\ndfs是干活的函数\n\ndfs是递归函数,先考虑终止条件.当剩下长度为0的时候,说明s已经被分割完了,那么把当前的path存到ans里面.\n因为本题中path这个切片一直在复用,所以如果要存进ans一定要用slices.Clone(path)\n然后进行切割.对于当前dfs的字符串来说,可以切1~n这么多种.而且要是回文子串,才可以切.那么就循环去判断当前切的这个长度是否是回文子串.\n\n是回文子串的话,还要面临下面三步.\n选入path.那么继续剩下的字符串的dfs.dfs结束后回来,还要做一次后悔的回溯,把放进path的再去掉.这样才能遍历到所有的方法\n\n\n\n\n\nfunc partition(s string) [][]string {\n    ans:=[][]string{}\n    path:=[]string{}\n    var dfs func(s string)\n    dfs=func(s string){\n        n:=len(s)\n        if n==0{\n            ans=append(ans,slices.Clone(path))\n            return \n        }\n        for i:=1;i&lt;=n;i++{// i 的值是 0, 1, 2 ... n-1\n            if isPalindrome(s[:i]){\n                 path=append(path,s[:i])\n                 dfs(s[i:])\n                 path=path[:len(path)-1]\n            }\n        }\n    }\n    dfs(s)\n    return ans\n}\n \nfunc isPalindrome(s string) bool{\n    n:=len(s)\n    for i:=range n/2{\n        if s[i]!=s[n-1-i]{\n            return false\n        }\n    }\n    return true\n}"},"技术积累/算法题/动态规划与回溯/139.-单词拆分":{"slug":"技术积累/算法题/动态规划与回溯/139.-单词拆分","filePath":"技术积累/算法题/动态规划与回溯/139. 单词拆分.md","title":"139. 单词拆分","links":[],"tags":[],"content":"给你一个字符串 s 和一个字符串列表 wordDict 作为字典。如果可以利用字典中出现的一个或多个单词拼接出 s 则返回 true。\n注意：不要求字典中出现的单词全部都使用，并且字典中的单词可以重复使用。\n小记\n\n预处理.将字典中的词放入哈希表.并记下最长单词的长度\n定义dp状态数组\n\nf[i] 的含义：字符串 s 的前 i 个字符（即 s[0…i-1]）能否被拆分成字典中的单词.\\\n\n注意f[0]需要先默认为true 否则是无法进行接下来的递归了\n\n\n内层循环j,将前i个字符切分成s[0…j-1] 和 s[j…i-1] 然后判断f[j-1]是否能被拆分\\s[j…i-1]是否在字典里.如果都满足,说明f[i]也能够被拆分.\n\n只要找到一种合法的切分方式，f[i] 就是 true，无需继续尝试其他 j\n\n\n注意这里的s[j…i-1] 如果超过了最长单词长度,就不需要再循环了,因为是不可能事件.\n\n\n最后返回f[n],就可以知道整个字符串能否被拆分了.\n\n代码\nfunc wordBreak(s string, wordDict []string) bool {\n\tinDict := map[string]bool{}\n\tmaxLen := 0\n\tfor _, c := range wordDict {\n\t\tinDict[c] = true\n\t\tmaxLen = max(maxLen, len(c))\n\t}\n\tn := len(s)\n\tf := make([]bool, n+1)\n\tf[0] = true\n\tfor i := 1; i &lt; n+1; i++ { //i最大值需要到n 因为必须要计算到f[n]\n\t\tfor j := i - 1; j &gt;= max(i-maxLen, 0); j-- {\n\t\t\t//f[i-1]和 s[i-1到i] 前j个:0~j-1,后面:j到n-1  n)\n\t\t\tif f[j] &amp;&amp; inDict[s[j:i]] {\n\t\t\t\tf[i] = true\n\t\t\t\tbreak //只要有一种可以划分成功的方案,就可以跳出这次循环了.毕竟i是从小到大的\n\t\t\t}\n\t\t}\n\t}\n\treturn f[n]\n}"},"技术积累/算法题/动态规划与回溯/198.-打家劫舍":{"slug":"技术积累/算法题/动态规划与回溯/198.-打家劫舍","filePath":"技术积累/算法题/动态规划与回溯/198. 打家劫舍.md","title":"198. 打家劫舍","links":[],"tags":[],"content":"你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。\n给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。\n小记\n代码\nfunc rob(nums []int) int {\n    n:=len(nums)\n    f:=make([]int,n+2)\n    f[0],f[1]=0,0\n    for i,x:=range nums{\n        f[i+2]=max(f[i+1],f[i]+x)\n    }\n    return f[n+1]\n}\n \n \n \n算出当前状态 `f[i]`，只需要前面两个状态 `f[i-1]` 和 `f[i-2]`\nfunc rob(nums []int) int {\n    f0,f1:=0,0\n    for _,x:=range nums{\n        f0,f1=f1,max(f1,f0+x)\n    }\n    return f1\n}"},"技术积累/算法题/动态规划与回溯/279.-完全平方数":{"slug":"技术积累/算法题/动态规划与回溯/279.-完全平方数","filePath":"技术积累/算法题/动态规划与回溯/279. 完全平方数.md","title":"279. 完全平方数","links":[],"tags":[],"content":"给你一个整数 n ，返回 和为 n 的完全平方数的最少数量 。\n完全平方数 是一个整数，其值等于另一个整数的平方；换句话说，其值等于一个整数自乘的积。例如，1、4、9 和 16 都是完全平方数，而 3 和 11 不是。\n小记\n\n完全背包问题\n\n物品:完全平方数\n物品重量:数值本身.每个数字算一个计数.\n特点:每个数可以无限次使用,就是完全背包问题.\n目标:把背包装满,并且用的物品数量最少\n\n\n记忆化搜索形式(递归)\n\n只考虑前i个完全平方数,凑出和为j,最少需要几个数\n如果不选i,那就得去前i-1个数里面凑j\n如果选了i,那剩余容量变成j-i平方.但是因为i可以重复选,所以还是在[选了i个数凑成j-i平方]的基础上,又加了一个数i.\n在选和不选中取一个最小值\n\n\n递推数组形式\n\n换成数组\n\n\n空间优化推荐\n\n计算fij的时候其实只需要上一行的数据和本行左边的数据,其实只需要一个一维数组,本来放旧的,然后一个个去覆盖就可以\n注意这个思维,具体代码中是固定拿着一个i,去一个个更新数组里的内容.实现上需要注意\n写法细节\n\nweight[i]：当前要往包里塞的那个 “大石块”（比如是 9）\nj：也就是想凑出的目标数字. 代码中从weight[i]凑到目标n\n\n当j小于物体体积的时候这个物体根本不可用,所以直接从能装得下的那个容量开始,前面的容量直接忽略\n\n\ndp[j]：凑出数字 j 最少需要几个石块。\n\n\n\n\n\n空间优化的内外层循环能否互换?\n\n外层循环物品,内层循环容量: 把硬币1能干的事都干完,就换硬币2.这样能保证物品出现的顺序固定,算的是组合数.\n\n注意这里一个物品是可以重复用的,因为循环容量的时候,对不同的容量会一直更新的\n如果物品不能重复用,我们内层循环改成从大到小,就可以防止本层的数据有一次污染本层了.\n\n\n如果外层循环容量,内层循环物品,算的是排列数,不同顺序.因为是在上一个容量的排列的基础上,又循环了物品.\n对于最值问题,因为算的是步骤数,而且加法可以交换,其实顺序并不影响结果,那么用两种循环都可以的.\n\n代码\nfunc numSquares(n int) int {\n    dp:=make([]int,n+1) \n    for i := 1; i &lt;= n; i++ {\n        dp[i] = math.MaxInt\n    }//注意这里要保留第一个数为0才可以往下进行\n    for i:=1;i*i&lt;n+1;i++{\n        for j:=i*i;j&lt;=n;j++{\n            dp[j]=min(dp[j],dp[j-i*i]+1)//这里这个j-i*i,实际上就是把i放进去了.\n        }\n    }\n    return dp[n]\n}"},"技术积累/算法题/动态规划与回溯/300.-最长递增子序列":{"slug":"技术积累/算法题/动态规划与回溯/300.-最长递增子序列","filePath":"技术积累/算法题/动态规划与回溯/300. 最长递增子序列.md","title":"300. 最长递增子序列","links":[],"tags":[],"content":"给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n小记\n\n\n假设 nums[i] 必须是被选中的，且是子序列的最后一个数。\nf[i] 表示：以 nums[i] 这个数结尾的最长递增子序列的长度。\n\n\n在长度相同的情况下，子序列的末尾元素越小，未来变长的潜力越大\n所以g数组记录了,各个长度队伍的最小队尾.\n\n\n\ng 数组的每一次增长（append），都意味着我们真的找到了一个比当前最长链结尾还要大的数，从而把最长链延长了 1 位。\n中间的那些替换（g[j] = x），只是在“优化内部结构”，虽然没有立刻让数组变长，但它把门槛降低了，是为了让后面能有更多机会触发“增长”.\n\n因此,对于新来的数字,我们用二分查找,在g中查找.如果x比g中所有数都大,说明x可以接在最大的数字后面.如果g里面有一个数大于等于x,就替换.\n\n\n\n\n如果是10 20 30 这时候来了个12 会变成10 12 30 其实这本身是不符合题意的,因为12是后来的,不应该排在30的前面.\n实际上本题只关心长度,并不关心具体是谁构成的这个长度.但是换成12是必要的,如果后续来了15,应该替换掉30,优化结构成10 12 15,这样后续来了29,就可以增长这个序列的长度.如果保持本来的10 20 30 的话u29是无法加进去的.\n\n踢掉某个元素,并不会导致结果错误.如果没走到长度增加的那一步,是不影响的\n而如果走到长度增加的程度,正好说明每次进行替换得到最终的这个长度是最优序列.\n\n\n\n相邻无关子序列问题（比如 0-1 背包），适合「选或不选」。 相邻相关子序列问题（比如本题），适合「枚举选哪个」\n这解释了为什么我们不用背包问题的思路（对于每个数，决定选它还是不选它）\n\n\n选或不选 (0-1 背包): 我拿了这个苹果，并不影响我能不能拿下一个梨。它们之间没有大小关系的约束，只受总容量约束。\n枚举选哪个 (LIS): 我选了 nums[i]，那么我上一个选的必须是 nums[j]，且必须满足 nums[j] &lt; nums[i]。元素之间有强烈的次序和大小依赖。如果强行用“选或不选”，需要多一个状态参数来记录“上一个选的数是谁”，这会把空间复杂度撑大。\n\n代码\nfunc lengthOfLIS(nums []int) int {\n    g:=[]int{}\n    for _,x:=range nums{\n        j:=sort.SearchInts(g,x)//返回第一个&gt;=x的下标位置\n        if j==len(g){\n            g=append(g,x)\n        }else{\n            g[j]=x\n        }\n    }\n    return len(g)\n}"},"技术积累/算法题/动态规划与回溯/322.-零钱兑换":{"slug":"技术积累/算法题/动态规划与回溯/322.-零钱兑换","filePath":"技术积累/算法题/动态规划与回溯/322. 零钱兑换.md","title":"322. 零钱兑换","links":["技术积累/算法题/动态规划与回溯/279.-完全平方数"],"tags":[],"content":"给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。\n计算并返回可以凑成总金额所需的 最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。\n你可以认为每种硬币的数量是无限的。\n小记\n详见279. 完全平方数\n代码\nfunc coinChange(coins []int, amount int) int {\n    dp:=make([]int,amount+1)\n    n:=len(coins)\n    for i:=1;i&lt;amount+1;i++{\n        dp[i]=amount + 1\n    }\n    for j:=0;j&lt;n;j++{\n        for k:=coins[j];k&lt;amount+1;k++{\n            dp[k]=min(dp[k],dp[k-coins[j]]+1)\n        }\n    }\n    if dp[amount]==amount + 1{\n        return -1\n    }else{\n        return dp[amount]\n    }\n}"},"技术积累/算法题/动态规划与回溯/45.-跳跃游戏II":{"slug":"技术积累/算法题/动态规划与回溯/45.-跳跃游戏II","filePath":"技术积累/算法题/动态规划与回溯/45. 跳跃游戏II.md","title":"45. 跳跃游戏II","links":[],"tags":[],"content":"给定一个长度为 n 的 0 索引整数数组 nums。初始位置在下标 0。\n每个元素 nums[i] 表示从索引 i 向后跳转的最大长度。换句话说，如果你在索引 i 处，你可以跳转到任意 (i + j) 处：\n0 ⇐ j ⇐ nums[i] 且\ni + j &lt; n\n返回到达 n - 1 的最小跳跃次数。测试用例保证可以到达 n - 1。\n小记\n只要最大跳跃距离超过目标地点就可以。\n在可以选的桥中，选择右端点最大的桥。重复该过程，在能到达终点时退出循环\n一旦的 curRight 覆盖了终点，i 就再也追不上 curRight 了，所以 ans++ 就永远不会再触发了\n\n不是在无路可走的那个位置造桥，而是当发现无路可走的时候，时光倒流到能跳到最远点的那个位置造桥。换句话说，在无路可走之前，我们一直在默默地收集信息。当发现无路可走的时候，才从收集到的信息中，选择最远点造桥。所建造的这座桥的左端点（起跳位置）可能在我们当前走的这座桥的中间。\n\n代码\nfunc jump(nums []int) (ans int) {\n    curRight := 0  // 已建造的桥的右端点\n    nextRight := 0 // 下一座桥的右端点的最大值\n    for i, num := range nums[:len(nums)-1] {\n        // 遍历的过程中，记录下一座桥的最远点\n        nextRight = max(nextRight, i+num)\n        if i == curRight { // 无路可走，必须建桥\n            curRight = nextRight // 建桥后，最远可以到达 next_right\n            ans++\n        }\n    }\n    return\n}"},"技术积累/算法题/动态规划与回溯/51.-N-皇后":{"slug":"技术积累/算法题/动态规划与回溯/51.-N-皇后","filePath":"技术积累/算法题/动态规划与回溯/51. N 皇后.md","title":"51. N 皇后","links":[],"tags":[],"content":"按照国际象棋的规则，皇后可以攻击与之处在同一行或同一列或同一斜线上的棋子。\nn 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 &#039;Q&#039; 和 &#039;.&#039; 分别代表了皇后和空位。\n小记\n返回所有方案:回溯\n\n先写一个小函数.在当前的摆放情况下,摆放在当前位置是否有效.\n三步走:摆放\\深度\\回溯\n\n但是还有问题需要解决\n结构问题: 这个一行是一个字符串,然后四行组成一个切片.\n代码\nfunc solveNQueens(n int) [][]string {\n    queens:=make([]int,n)//第i行的皇后所在列.n是行数.\n    col:=make([]bool,n)//第i列是否存在皇后.n是列数\n    diag1:=make([]bool,2*n-1) //左上角\n    diag2:=make([]bool,2*n-1) //右上角\n    ans:=[][]string{}\n    var dfs func(r int)  //确定特定row的皇后位置\n    dfs=func(r int){\n        if r==n{\n            //组织答案,加入答案数组\n            vals:=make([]string,n)\n            for i,c:=range queens{\n                //第i行需要一个string,前c个是.\n                vals[i]=strings.Repeat(&quot;.&quot;,c)+&quot;Q&quot;+strings.Repeat(&quot;.&quot;,n-1-c)\n            }\n            ans=append(ans,vals)\n            return \n        }\n \n        //接下来进入回溯阶段\n        // \n        for c:=range n{//c从1到n-1\n            rc:=r-c+n-1\n            if !col[c]&amp;&amp;!diag1[r+c]&amp;&amp;!diag2[rc]{\n                queens[r]=c//假设当前row的皇后位置在c\n                col[c],diag1[r+c],diag2[rc]=true,true,true\n                dfs(r+1)\n                col[c],diag1[r+c],diag2[rc]=false,false,false\n            }\n        }\n    }\n    dfs(0)\n    return ans\n }\n "},"技术积累/算法题/动态规划与回溯/56.-合并区间":{"slug":"技术积累/算法题/动态规划与回溯/56.-合并区间","filePath":"技术积累/算法题/动态规划与回溯/56. 合并区间.md","title":"56. 合并区间","links":[],"tags":[],"content":"以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 \\一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间。\n小记\n\n先对每个区间的左端点进行排序,这样可以保证,如果下一个区间不能和当前区间合并,说明当前区间确实合并完毕了,可以以下一个数组为开头元素往下合并.\n合并逻辑:当sj落在第一个区间内,那么两个区间就可以合并,→[si,max(ei,ej)]\n实际上合并的过程是在答案数组中完成的,如果合并就更新,无法合并就把新的开头元素加进去,等待后续更新.\n\n代码\nfunc merge(intervals [][]int) (ans [][]int) {\n    slices.SortFunc(intervals, func(p, q []int) int { return p[0] - q[0] }) // 按照左端点从小到大排序\n    for _, p := range intervals {\n        m := len(ans)\n        if m &gt; 0 &amp;&amp; p[0] &lt;= ans[m-1][1] { // 可以合并\n            ans[m-1][1] = max(ans[m-1][1], p[1]) // 更新右端点最大值\n        } else { // 不相交，无法合并\n            ans = append(ans, p) // 新的合并区间\n        }\n    }\n    return\n}"},"技术积累/算法题/动态规划与回溯/62.-不同路径":{"slug":"技术积累/算法题/动态规划与回溯/62.-不同路径","filePath":"技术积累/算法题/动态规划与回溯/62. 不同路径.md","title":"62. 不同路径","links":[],"tags":[],"content":"一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。\n问总共有多少条不同的路径？\n小记\n回溯通常用于求具体的路径列表（例如：打印出所有路径），而不是求路径的数量。求数量通常使用动态规划\n代码\nclass Solution:\n    def uniquePaths(self, m: int, n: int) -&gt; int:\n        f = [[0] * (n + 1) for _ in range(m + 1)]\n        f[0][1] = 1\n        for i in range(m):\n            for j in range(n):\n                f[i + 1][j + 1] = f[i][j + 1] + f[i + 1][j]\n        return f[m][n]\n \nfunc uniquePaths(m, n int) int {\n    f := make([]int, n+1)\n    f[1] = 1\n    for range m {\n        for j := range n {\n            f[j+1] += f[j]\n        }\n    }\n    return f[n]\n}\n \n \n还可以用组合数,时间复杂度就是min(m,n)因为只有数学计算. 但是阶乘会有大数溢出风险."},"技术积累/算法题/动态规划与回溯/64.-最小路径和":{"slug":"技术积累/算法题/动态规划与回溯/64.-最小路径和","filePath":"技术积累/算法题/动态规划与回溯/64. 最小路径和.md","title":"64. 最小路径和","links":[],"tags":[],"content":"给定一个包含非负整数的 _m_ x _n_ 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。\n说明：每次只能向下或者向右移动一步。\n小记\n写法2: 带哨兵的 2D DP—优雅解决边界问题\n\n定义 dfs(i,j) 表示从左上角到第 i 行第 j 列这个格子（记作 (i,j)）的最小价值和.\n状态转移方程:dfs(i,j)=min(dfs(i,j−1),dfs(i−1,j))+grid[i][j]\n哨兵就是 多申请一行一列,一开始初始化为最大值,后续动态规划都从+1开始\n\n写法3: 一维滚动数组\n\n注意给左边哨兵和第一行哨兵赋最大值\n然后从f[1]开始,所以f[1]一开始要赋值0.这样才能通用状态转移方程.但是f[0]一定要是最大值\n\n新的 f[0] 其实不会被覆盖\n因为 f[j+1] 不可能等于 f[0] 所以一直不被赋值\n但是会用到 f[0]，这个 f[0] 必须不影响 f[1] 的结果\n那么之后的新f[1]就是这个f[0]和之前的旧f[1]取最小值并且加上自己的大小,完全符合题目要求.\n\n\n\n代码\n初见的写法: 但是if判断太多了.写法2改成先处理第一行和第一列\nfunc minPathSum(grid [][]int) int {\n\t//从左上角到右下角的路径:只能向右或者向下,移动一步.\n\t//一个mxn的grid 存储到达这个格子ij的最小数字总和.然后求mn就行\n\tm := len(grid)\n\tn := len(grid[0])\n\tsum := make([][]int, m)\n\tfor i := range m {\n\t\tsum[i] = make([]int, n)\n\t}\n\tsum[0][0] = grid[0][0]\n\tfor i, row := range sum {\n \n\t\tfor j, _ := range row {\n\t\t\tif i == 0 &amp;&amp; j &gt; 0 {\n\t\t\t\tsum[0][j] = grid[0][j] + sum[0][j-1]\n \n\t\t\t}\n\t\t\tif j == 0 &amp;&amp; i &gt; 0 {\n\t\t\t\tsum[i][0] = grid[i][0] + sum[i-1][0]\n \n\t\t\t} else if i &gt; 0 &amp;&amp; j &gt; 0 {\n\t\t\t\tsum[i][j] = min(sum[i][j-1], sum[i-1][j]) + grid[i][j]\n \n\t\t\t}\n\t\t}\n\t}\n\treturn sum[m-1][n-1]\n}\n写法2: 带哨兵的 2D DP—优雅解决边界问题\nfunc minPathSum(grid [][]int) int {\n    m, n := len(grid), len(grid[0])\n    f := make([][]int, m+1)//多初始化一行\n    for i := range f {\n        f[i] = make([]int, n+1)//多初始化一行\n    }\n    for j := range f[0] {\n        f[0][j] = math.MaxInt\n    }\n    for i, row := range grid {\n        f[i+1][0] = math.MaxInt//// 在遍历每一行时，顺手把该行的第 0 列设为无穷大\n        for j, x := range row {\n            if i == 0 &amp;&amp; j == 0 {\n                f[1][1] = x\n            } else {\n                f[i+1][j+1] = min(f[i+1][j], f[i][j+1]) + x\n            }\n        }\n    }\n    return f[m][n]\n}\n \n写法3: 一维滚动数组\nfunc minPathSum(grid [][]int) int {\n    n:=len(grid[0])\n    f:=make([]int,n+1)\n    for i,_:=range f{\n        f[i]=math.MaxInt\n    }\n    f[1]=0\n    for _,row:=range grid{\n        for j,x:=range row{\n            f[j+1]=min(f[j],f[j+1])+x\n        }\n    }\n    return f[n]\n}\n "},"技术积累/算法题/动态规划与回溯/70.-爬楼梯":{"slug":"技术积累/算法题/动态规划与回溯/70.-爬楼梯","filePath":"技术积累/算法题/动态规划与回溯/70. 爬楼梯.md","title":"70. 爬楼梯","links":["技术积累/算法题/动态规划与回溯/动态规划-贪心算法"],"tags":[],"content":"假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\nTransclude of 动态规划-贪心算法#动态规划思路\n代码\n//易读版\nfunc climbStairs(n int) int {\n    if n == 1 {\n        return 1 // 特殊处理\n    }\n    f:=make([]int,n+1)\n    f[1],f[2]=1,2\n    for i:=3;i&lt;=n;i++{\n        f[i]=f[i-1]+f[i-2]\n    }\n    return f[n]\n}\n \n//不易读版\nfunc climbStairs(n int) int {\n    // 定义 dp 数组（这里叫 f）\n    f := make([]int, n+1)\n    // 初始化边界\n    f[0], f[1] = 1, 1//其实这个f[0]=1是很不好解释的,但是出于结果驱动还是=1吧\n    for i := 2; i &lt;= n; i++ {\n        f[i] = f[i-1] + f[i-2]\n    }\n    return f[n]\n}\n \n \n//空间优化版\nfunc climbStairs(n int) int {\n    p, q := 1, 1 // p是前两步，q是前一步\n    for i := 2; i &lt;= n; i++ {\n        p, q = q, p+q // 滚动更新\n    }\n    return q\n}"},"技术积累/算法题/动态规划与回溯/72.-编辑距离":{"slug":"技术积累/算法题/动态规划与回溯/72.-编辑距离","filePath":"技术积累/算法题/动态规划与回溯/72. 编辑距离.md","title":"72. 编辑距离","links":[],"tags":[],"content":"太难了不看视频根本想不通\n给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数_\n你可以对一个单词进行如下三种操作：\n\n插入一个字符\n删除一个字符\n替换一个字符\n\n小记\ns下标i表示字符串里的第i+1个字符.\nf[k][…] 的k表示前k个字符组成的字符串.0就表示前0个字符也就是空字符串\n所以当我拿着下标i的字符时,我实际上在处理前i+1个字符.对应的也就是f[i+1]\n所以遍历ij的时候实际上在填写f[i+1][j+1]这个格子\n\n当x=y(第i+1个字符和第j+1个字符相等的时候 )f[i+1][j+1] (当前格) 的值，直接继承 f[i][j] (左上角)。\n当x!=y的时候\n\n删除s的字符.那么就是用前i个字符匹配j+1个字符.再加上删除操作:f[i][j+1] + 1\n类似的.\n\n\n\n代码\nfunc minDistance(s, t string) int {\n    n, m := len(s), len(t)\n    f := make([][]int, n+1)\n    for i := range f {\n        f[i] = make([]int, m+1)\n    }\n    for j := range m {//注意这里的写法 1.22的特性 可以遍历整数\n        f[0][j+1] = j + 1\n    }\n    for i, x := range s {//下标i的字符x,实际上是第i+1个字 填入到f[i+1里面去]\n        f[i+1][0] = i + 1\n        for j, y := range t {\n            if x == y {\n                f[i+1][j+1] = f[i][j]\n            } else {\n                f[i+1][j+1] = min(f[i][j+1], f[i+1][j], f[i][j]) + 1\n            }\n        }\n    }\n    return f[n][m]\n}\n "},"技术积累/算法题/动态规划与回溯/78.-子集":{"slug":"技术积累/算法题/动态规划与回溯/78.-子集","filePath":"技术积累/算法题/动态规划与回溯/78. 子集.md","title":"78. 子集","links":[],"tags":[],"content":"给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。\n解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。\n小记\n就是选不选的问题:所有可能:回溯.因为要记录具体的答案所以不能动态规划\n代码\nfunc subsets(nums []int) [][]int {\n    //就是选不选的问题:所有可能:回溯.因为要记录具体的答案所以不能动态规划\n    ans:=[][]int{}//这里最好进行预分配.ans := make([][]int, 0, 1&lt;&lt;n),最终一定是有2的n次方个解 所以分配好了.但是要注意长度要设置为0,不然不好append\n    path:=[]int{}//(0,n)\n    var dfs func(i int)\n    dfs=func(i int){\n        if i==len(nums){\n            ans=append(ans,slices.Clone(path))\n            return \n        }\n        dfs(i+1)\n        path=append(path,nums[i])\n        dfs(i+1)\n        path=path[:len(path)-1]\n    }\n    dfs(0)\n    return ans\n}\n解法2,如果遇到需要去重的,最好用这种\nfunc subsets(nums []int) [][]int {\n    n := len(nums)\n    ans := make([][]int, 0, 1&lt;&lt;n) // 预分配空间\n    path := make([]int, 0, n) // 预分配空间\n \n    // 枚举选哪个：在下标 i 到 n-1 中选一个数，加到 path 末尾\n    var dfs func(int)\n    dfs = func(i int) {\n        ans = append(ans, slices.Clone(path)) // 不选，把当前子集加入答案\n        for j := i; j &lt; n; j++ { // 选，枚举选择的数字\n            path = append(path, nums[j])\n            dfs(j + 1) // 选 nums[j] 意味着 i 到 j-1 都跳过不选，下一个数从 j+1 开始选\n            path = path[:len(path)-1] // 恢复现场\n        }\n    }\n \n    dfs(0)\n    return ans\n}\n \n "},"技术积累/算法题/动态规划与回溯/动态规划-贪心算法":{"slug":"技术积累/算法题/动态规划与回溯/动态规划-贪心算法","filePath":"技术积累/算法题/动态规划与回溯/动态规划-贪心算法.md","title":"动态规划-贪心算法","links":["技术积累/算法题/动态规划与回溯/70.-爬楼梯"],"tags":[],"content":"贪心算法\n\n贪心算法在每一步选择中，都采取在当前状态下最好、最优的选择（局部最优解）从而希望最终的结果也是全局最优的。\n只有当问题具备“贪心选择性质”时（即局部最优确实能推导出全局最优）才能得到正确答案。否则，它只能得到一个“差不多”的解，而不是最优解。\n\n动态规划\n\n动态规划将一个复杂的问题分解成若干个重叠的子问题。通过解决子问题，并将结果记录下来（Memoization/填表）避免重复计算，最后推导出原问题的解。\n核心在于“记表”，算过的东西绝对不算第二次。\n\n动态规划思路\n以70. 爬楼梯为例:\n第一层楼梯跨两步可以到第三层,第二层跨一步可以到第三层,因此,第三层楼梯的状态可以由前两层推导出来.也就是动态规划了.\n\n确定dp数组以及下标的含义:  爬到i层楼梯,有dp[i]种方法\n确定递推公式:  dp[i] = dp[i - 1] + dp[i - 2]\ndp数组如何初始化:  dp[1] = 1，dp[2] = 2.因为这题里n为正整数,因此不要考虑n=0的情况,反正也不符合生活实际\n确定遍历顺序:  从递推公式可以看出递推顺序一定是从前往后的\n举例推导dp数组: 就是检查一下\n"},"技术积累/算法题/动态规划与回溯/回溯":{"slug":"技术积累/算法题/动态规划与回溯/回溯","filePath":"技术积累/算法题/动态规划与回溯/回溯.md","title":"回溯","links":[],"tags":[],"content":"回溯就是“暴力枚举”的一种优雅写法。想象你在走迷宫，遇到分岔路口：\n\n先走左边（做出选择）。\n走到死胡同，退回来（回溯/恢复现场）。\n再走右边（尝试下一个选项）\n\n回溯与动态规划的区别\n回溯是暴力穷举,只管试错.:\n\n寻找所有可能的方案\n而动态规划是聪明复用,每次都从最优解开始向下.\n求最终值\n可行性\n求总数(有多少种方法)\n\n所有的 DP 都可以写成“记忆化搜索”（Memoization Search），而记忆化搜索本质上就是 带备忘录的递归（回溯）。\n演变路径：\n\n纯回溯 (Backtracking)： 暴力尝试所有解。\n\n缺点： 遇到重复状态会重复计算，可能会超时。\n\n\n记忆化搜索 (Memoization)： 在回溯的基础上，加一个 memo 数组。如果 memo[state] 有值，直接返回。\n\n效果： 剪掉了重复的树枝，效率等同于 DP。\n\n\n动态规划 (DP)： 把递归改成循环（自底向上），填表。\n\n但是！并非所有回溯都能变成 DP。\n\n能变 DP 的： 计算个数字结果（最大值、方案数）。比如“爬楼梯有多少种爬法”。\n不能变 DP 的： 需要列出所有具体路径。比如“请打印出所有爬楼梯的具体方案（1-1-2, 1-2-1…）”。这种必须用回溯，因为你要记录路径（Path），每个路径都是独一无二的，不存在“复用”的概念。\n\n回溯模板\n "},"技术积累/算法题/双指针/11.-盛最多水的容器":{"slug":"技术积累/算法题/双指针/11.-盛最多水的容器","filePath":"技术积累/算法题/双指针/11. 盛最多水的容器.md","title":"11. 盛最多水的容器","links":["技术积累/算法题/双指针/42.-接雨水"],"tags":["盲过"],"content":"给定一个长度为 n 的整数数组 height 。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i]) 。\n找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。\n返回容器可以储存的最大水量。\n**说明：**你不能倾斜容器。\n\n其实思路跟42. 接雨水一模一样,没啥好说了\nfunc maxArea(height []int) (ans int) {\n    left, right := 0, len(height)-1\n    for left &lt; right {\n        area := (right - left) * min(height[left], height[right])\n        ans = max(ans, area)\n        if height[left] &lt; height[right] {\n            // height[left] 与右边的任意垂线都无法组成一个比 ans 更大的面积\n            left++\n        } else {\n            // height[right] 与左边的任意垂线都无法组成一个比 ans 更大的面积\n            right--\n        }\n    }\n    return\n}\n "},"技术积累/算法题/双指针/234.-回文链表":{"slug":"技术积累/算法题/双指针/234.-回文链表","filePath":"技术积累/算法题/双指针/234. 回文链表.md","title":"234. 回文链表","links":[],"tags":[],"content":"给你一个单链表的头节点 head ，请你判断该链表是否为回文链表。如果是，返回 true ；否则，返回 false 。\n小记\n\n用快慢指针法找中点：fast一次走两步。如果是偶数长度，就返回下半部分的第一个节点。就是确定了从哪里开始算是后半段\n反转链表\n主函数逻辑\n\n首先找到中点\n反转后半段，head2指向后半段的开头。\n循环比较。反转后，head2 代表的链表长度 ⇐ head 代表的链表长度\n\nfor head2 != nil\n\n\n\n\n\n代码\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc isPalindrome(head *ListNode) bool {\n    head2:=reverseLink(middleNode(head))\n    for head2!=nil{\n        if head.Val!=head2.Val{\n            return false \n        }\n        head=head.Next\n        head2=head2.Next\n    }\n    return true \n}\n \nfunc middleNode(head *ListNode)*ListNode{\n   slow,fast:=head,head\n   for fast!=nil&amp;&amp; fast.Next != nil{\n        fast=fast.Next.Next\n        slow=slow.Next\n   }\n   return slow \n}\n \nfunc reverseLink(head *ListNode)*ListNode{\n    var pre *ListNode=nil\n    cur := head\n    for cur!=nil{\n        nxt:=cur.Next\n        cur.Next=pre\n        pre=cur\n        cur=nxt\n    }\n    return pre \n}"},"技术积累/算法题/双指针/42.-接雨水":{"slug":"技术积累/算法题/双指针/42.-接雨水","filePath":"技术积累/算法题/双指针/42. 接雨水.md","title":"42. 接雨水","links":[],"tags":[],"content":"接雨水\n给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n就是左右两边柱子最大值的最小值,减去当前位置柱子的高度,即为当前位置能接的雨水数量.\n\n遍历三遍数组\n需要三个额外的数组\n\n优化:\n只遍历一遍,不用额外数组\n\n初始化LR两个指针指向数组头和数组尾.\n当maxL⇐maxR.因为maxL是从左到右递增,maxR从右到左递增.所以说明L指向的位置,左右两边最小值就是maxL.因为area[i]是在maxL和maxR中取最小值嘛.然后减去柱子的高度可以直接得到雨水数量,再L++\n如果大于就反过来.\n\n这一题的重点在于,对于某个柱子来说,一定要比如他的左边最高值已经确定,并且左右中左为最小值,才可以计算出结果.所以这里是 哪里计算出结果,哪边可以缩小范围.\n\nfunc trap(height []int) (ans int) {\n    preMax, sufMax := 0, 0\n    left, right := 0, len(height)-1\n    for left &lt; right {//如果left=right 因为max是把当前的柱长计算在内,最后left\\right会相遇到场上最高点的.\n        preMax = max(preMax, height[left])\n        sufMax = max(sufMax, height[right])\n        if preMax &lt; sufMax {\n            ans += preMax - height[left]\n            left++\n        } else {\n            ans += sufMax - height[right]\n            right--\n        }\n    }\n    return\n}\n "},"技术积累/算法题/图论/200.-岛屿数量":{"slug":"技术积累/算法题/图论/200.-岛屿数量","filePath":"技术积累/算法题/图论/200. 岛屿数量.md","title":"200. 岛屿数量","links":[],"tags":[],"content":"给你一个由 &#039;1&#039;（陆地）和 &#039;0&#039;（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n小记\n\n深度优先搜索.\n\n一旦我们发现 (i,j) 是 1，就从 (i,j) 开始，DFS 这个岛.主要是不能重复访问之前访问过的格子。\n找到一个岛(1)就开始左右上下四个方向走,直到全岛插满旗子(2)\n\n未发现的陆地格子:变2\n出界/水/已发现的陆地,就停止递归.\n\n\n\n如果都没有1了算法就结束了,返回岛屿个数\n为什么用图论思想?\ngrid中每个格子是一个节点,上下左右相邻说明存在边.所以题目就变换为寻找连通分量的总个数.\n\n\n\n代码\n注意二维数组的行列索引\nfunc numIslands(grid [][]byte) int {\n    m,n:=len(grid)-1,len(grid[0])-1\n    ans:=0\n    var dfs func(int ,int )\n    dfs =func(i,j int){\n        if i&lt;0||i&gt;m||j&lt;0||j&gt;n||grid[i][j]==&#039;0&#039;||grid[i][j]==&#039;2&#039;{\n            return \n        }\n        grid[i][j]=&#039;2&#039;\n        dfs(i,j-1)\n        dfs(i,j+1)\n        dfs(i-1,j)\n        dfs(i+1,j)\n    }\n \n    for i,row:=range grid{\n        for j,c:=range row{\n            if c==&#039;1&#039;{\n                dfs(i,j)\n                ans++\n            }\n        }\n    }\n    return ans\n}\n \n "},"技术积累/算法题/图论/ACM模式输出":{"slug":"技术积累/算法题/图论/ACM模式输出","filePath":"技术积累/算法题/图论/ACM模式输出.md","title":"ACM模式输出","links":[],"tags":[],"content":""},"技术积累/算法题/图论/图":{"slug":"技术积累/算法题/图论/图","filePath":"技术积累/算法题/图论/图.md","title":"图","links":[],"tags":[],"content":"图的基本概念\n二维坐标中，两点可以连成线，多个点连成的线就构成了图。\n当然图也可以就一个节点，甚至没有节点（空图\n图的种类\n整体上一般分为 有向图 和 无向图。\n有向图: 边是有方向的\n无向图: 边没有方向\n加权有向图: 就是边是有权值的\n加权无向图同理\n度\n无向图:\n\n有几条边连接该节点，该节点就有几度。\n有向图:\n每个节点有出度和入度。\n\n出度：从该节点出发的边的个数。\n入度：指向该节点边的个数。\n\n\n\n连通性\n\n连通图: 在无向图中,任何两个节点都是可以到达的,我们称之为连通图\n非连通图: 有节点不能到达其他节点\n强连通图: 在有向图中，任何两个节点是可以相互到达的\n连通分量: 无向图中的极大连通子图\n强连通分量: 有向图中极大强连通子图\n\n图的构造-如何用代码表示一个图\n朴素存储\n\n有8条边，我们就定义 8 * 2的数组，即有n条边就申请n * 2，这么大的数组.然后将每两个节点的关系记录到表中.\n可以用数组\\map\\类实现,但是如果想知道不相邻的两个节点是否相连,就必须要把存储空间都枚举一遍.\n\n邻接表\n数组+链表,是从边的数量来表示图,有多少边就申请对应大小的链表.\n\n\n利于稀疏图的存储,因为只需要存储边,空间利用率高\n遍历节点连接情况相对容易\n然是如果检查任意两个节点间是否存在边,效率就比较低,需要O(v)时间:V表示某节点连接其他节点的数量\n\n邻接矩阵\n使用二维数组来表示图结构,有多少节点就申请多大的二维数组\n例如： grid[2][5] = 6，表示 节点 2 连接 节点5 为有向图，节点2 指向 节点5，边的权值为6\n想表示无向图，即：grid[2][5] = 6，grid[5][2] = 6，表示节点2 与 节点5 相互连通，权值为6。\n\n\n适合稠密图(边数接近顶点数平方).在边少节点多的情况下会导致申请过大的二维数组,造成空间浪费.\n在寻找节点连接情况的时候,需要遍历整个矩阵(n平方).\n检查任意两个顶点之间是否存在边的操作非常快\n\n图的遍历方式\n深度优先搜索dfs\n递归深度达到最大:\n\n递归深度:“当前还没结束的函数调用数量”\n递归深度最深的情况，就是一条路走到黑，完全不回头，也不分叉\n\n广度优先搜索bfs"},"技术积累/算法题/字符串处理":{"slug":"技术积累/算法题/字符串处理","filePath":"技术积累/算法题/字符串处理.md","title":"字符串处理","links":[],"tags":[],"content":"rune与byte与string\n\n&#039;a&#039; (单引号)：字符（Go 里叫 rune，本质是整数 `int32\n\nint32，有 32 位，最大能表示几十亿,会根据字符串里的元素自动匹配要表示什么.比如”an按”会解析出3个rune:a\\n\\按\n\n\n&quot;a&quot; (双引号：字符串`string\nbyte\n\n只有 8 位，最大只能表示到 255。英文字符（ASCII）比如 &#039;a&#039; 是 97，能装下。但汉字 &#039;按&#039; 的编号是 25353，一般是3个byte。\n\n\n\n\n\n                  \n                  Title \n                  \n                \n\n‘a’虽然被认为是rune,但是实际上属于无类型常量 (Untyped Constant).参与运算时自动适配对方类型。\n\n\nrange与下标\n字符串本质是只读的byte切片.如果要修改,一定要转换成真正的byte切片.[]byte(s),然后string(cnt)变回字符串\n\n如果是纯英文,数字,英文符号,字符串里的每一个byte都完全对应ASCII码\n如果是中文,emoji等非ASCII码字符,一个汉字在 UTF-8 编码中通常占用 3 个 byte.这时候要改用rune\n\n\nrange循环得到的是rune.\n\n因此如果字符串中有中文,遍历下标其实是跳跃的.\nfor i := 0; i &lt; len(s); i++循环得到的是byte,因为就是按照原字符串的byte切片下标来的.\n\n\n下标.s[0]默认拿出来的是字节.\n\n如果想要拿出来中文字符,需要runes := []rune(s)转换成rune切片,然后用下标拿取.\n\n\n\n哈希表\n//rune作为key\nm := map[rune]int{}\nm[&#039;a&#039;]=1\nm[&#039;某个表情符号&#039;]=2\n \n//byte作为key\nm :=map[byte]int){}\nm[&#039;x&#039;] = 100//这里如果要写中文和表情符号就不行了,因为不符合byte\n数组填充类\n其实很多数组填充类的问题，其做法都是先预先给数组扩容带填充后的大小，然后在从后向前进行操作。"},"技术积累/算法题/排序/215.-数组中的第K个最大元素":{"slug":"技术积累/算法题/排序/215.-数组中的第K个最大元素","filePath":"技术积累/算法题/排序/215. 数组中的第K个最大元素.md","title":"215. 数组中的第K个最大元素","links":["技术积累/算法题/排序/排序算法"],"tags":[],"content":"给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。\n请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。\n你必须设计并实现时间复杂度为 O(n) 的算法解决此问题。\n小记\nTransclude of 排序算法#快速选择思路\n代码\nTransclude of 排序算法#代码"},"技术积累/算法题/排序/排序算法":{"slug":"技术积累/算法题/排序/排序算法","filePath":"技术积累/算法题/排序/排序算法.md","title":"排序算法","links":["技术积累/算法题/排序/排序算法","tags/待解决"],"tags":["待解决"],"content":"快速选择quick select\n核心目的: 解决 Top K 问题，并且要做到 O(N) 的时间复杂度\n快速选择思路\nTransclude of 排序算法#快速排序思路\n而针对Top K问题,可以做如下优化.\n如果pivot&lt;K,那么不用进行左边递归,只需要进行右边递归即可.只处理一边，另一边直接忽略\n\n类似于二分，只要确定排序之后下标在n-k处的数据即可。\n主要是实现上的细节。循环的时候需要保证i⇐j 如果i&gt;j了会退出循环,i⇐j的时候进行交换,能够保证左边小右边大.\ni&gt;j的时候说明j到了小的这边,i到了大的那边,因此pivot跟nums[left]换一下位置就可以了.\n\n代码\n// 在子数组 [left, right] 中随机选择一个基准元素 pivot\n// 根据 pivot 重新排列子数组 [left, right]\n// 重新排列后，&lt;= pivot 的元素都在 pivot 的左侧，&gt;= pivot 的元素都在 pivot 的右侧\n// 返回 pivot 在重新排列后的 nums 中的下标\n// 特别地，如果子数组的所有元素都等于 pivot，我们会返回子数组的中心下标，避免退化\nfunc partition(nums []int, left int, right int) int {\n    // 1. 在子数组中随机选择一个下标，并换到最左边\n    i := left + rand.Intn(right-left+1)\n    pivot := nums[i]\n    // 把 pivot 与子数组第一个元素交换，避免 pivot 干扰后续划分，从而简化实现逻辑\n    nums[i], nums[left] = nums[left], nums[i]\n \n    // 2. 相向双指针遍历子数组 [left + 1, right]\n    // 循环不变量：在循环过程中，子数组的数据分布始终如下图\n    // [ pivot | &lt;=pivot | 尚未遍历 | &gt;=pivot ]\n    //   ^                 ^     ^         ^\n    //   left              i     j         right\n \n    i, j := left+1, right\n    for {\n        for i &lt;= j &amp;&amp; nums[i] &lt; pivot {\n            i++\n        }//i还没遇到j且i指向的元素小于pivot（不需要交换）的话就一直向右\n        // 此时 nums[i] &gt;= pivot：停下\n \n        for i &lt;= j &amp;&amp; nums[j] &gt; pivot {\n            j--\n        }\n        // 此时 nums[j] &lt;= pivot：停下\n \n        if i &gt;= j {\n            break\n        }\n \n        // 维持循环不变量\n        nums[i], nums[j] = nums[j], nums[i]\n        i++\n        j--\n    }\n \n    // 循环结束后\n    // [ pivot | &lt;=pivot | &gt;=pivot ]\n    //   ^             ^   ^     ^\n    //   left          j   i     right\n \n    // 3. 把 pivot 与 nums[j] 交换，完成划分（partition）\n    // 为什么与 j 交换？\n    // 如果与 i 交换，可能会出现 i = right + 1 的情况，已经下标越界了，无法交换\n    // 另一个原因是如果 nums[i] &gt; pivot，交换会导致一个大于 pivot 的数出现在子数组最左边，不是有效划分\n    // 与 j 交换，即使 j = left，交换也不会出错\n    nums[left], nums[j] = nums[j], nums[left]\n \n    // 交换后\n    // [ &lt;=pivot | pivot | &gt;=pivot ]\n    //               ^\n    //               j\n \n    // 返回 pivot 的下标\n    return j\n}\n \nfunc findKthLargest(nums []int, k int) int {\n    n := len(nums)\n    targetIndex := n - k  // 第 k 大元素在升序数组中的下标是 n - k\n    left, right := 0, n-1 // 闭区间\n    for {\n        i := partition(nums, left, right)\n        if i == targetIndex {\n            // 找到第 k 大元素\n            return nums[i]\n        }\n        if i &gt; targetIndex {\n            // 第 k 大元素在 [left, i - 1] 中\n            right = i - 1\n        } else {\n            // 第 k 大元素在 [i + 1, right] 中\n            left = i + 1\n        }\n    }\n}\n \n \n手写堆排序\n待解决\n手写快排\n待解决\n快速排序思路\n\n选定一个pivot,左边都是比它小的,右边都是比它大的,那么这个pivot的位置就固定正确了.\n然后到这个pivot的左边递归,右边也递归,重复上述操作.复杂度是 O(N \\log N)\n\n代码\nfunc QuickSort(nums, left, right) {\n    if left &gt;= right { return }\n    \n    // 1. 排好一个基准，拿到他的位置 pivotIndex\n    pivotIndex := partition(nums, left, right)\n    \n    // 2. 递归处理左边 (勤奋)\n    QuickSort(nums, left, pivotIndex - 1)\n    \n    // 3. 递归处理右边 (勤奋)\n    QuickSort(nums, pivotIndex + 1, right)\n}"},"技术积累/算法题/数/15.-三数之和":{"slug":"技术积累/算法题/数/15.-三数之和","filePath":"技术积累/算法题/数/15. 三数之和.md","title":"15. 三数之和","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n三数之和\n给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请你返回所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。 flashcard\n\n小记\n\n最重要的是去重逻辑,必须发生在已经记录了答案之后,因为会有前后两个数相等的时候也可以组成答案的情况.\n另外还有两个排序之后可以做的优化\n注意细节\n\n代码\nfunc threeSum(nums []int) [][]int {\n    slices.Sort(nums)\n    n := len(nums)\n    ans := [][]int{}\n    for i := 0; i &lt; n-2; i++ {\n        x := nums[i]\n        // 1. 外层去重\n        if i &gt; 0 &amp;&amp; x == nums[i-1] {\n            continue\n        }\n        // 【关键优化 1】：最小的三个数相加都 &gt; 0，后面肯定没戏了，直接结束\n        if x + nums[i+1] + nums[i+2] &gt; 0 {\n            break\n        }\n        // 【关键优化 2】：当前数加上最大的两个数都 &lt; 0，说明当前数太小，跳过看下一个\n        if x + nums[n-2] + nums[n-1] &lt; 0 {\n            continue\n        }\n        left, right := i+1, n-1\n        for left &lt; right {\n            sum := x + nums[left] + nums[right]\n            if sum == 0 {\n                ans = append(ans, []int{x, nums[left], nums[right]})\n                // 内层去重（你的写法很好，保持住）\n                for left &lt; right &amp;&amp; nums[left] == nums[left+1] { left++ }\n                for left &lt; right &amp;&amp; nums[right] == nums[right-1] { right-- }\n                left++\n                right--\n            } else if sum &lt; 0 {\n                left++\n            } else {\n                right--\n            }\n        }\n    }\n    return ans\n}"},"技术积累/算法题/数/n数之和":{"slug":"技术积累/算法题/数/n数之和","filePath":"技术积累/算法题/数/n数之和.md","title":"n数之和","links":[],"tags":[],"content":"一个数组中不重复\n\n0 &lt;= a, b, c, d &lt; n\na、b、c 和 d 互不相同\nnums[a] + nums[b] + nums[c] + nums[d] == target\n\n\n\n保证数组有序.不有序就排一下序.\n需要保证a&lt;b&lt;c&lt;d,同时外层一个for循环把a固定住.\n内层for循环固定b,剩下c和d在[b+1,len(数组)]的范围内进行双指针即可.[二者相加结果为target-nums[a]-nums[b]]\n\n\n\n\n                  \n                  语法细节 \n                  \n                \n\n\n注意找到一组解之后不能停止,要一直循环到c&lt;d的临界\n注意去重.如果不允许重复的元组,那么就要用for a &gt; 0 &amp;&amp; nums[a] == nums[a-1] { continue }这种写法去重.\n\n注意这里一定要是for,就是去重到无重为止.//或者用ifcontinue,跳出当次循环,重新走一遍for的条件判断.\n\n\n小优化:如果在固定ab的时候,如果最小的abc和最大的d加起来就&gt;target的话,d就可以直接—.类似这样的技巧如果内存要求严格的话可以用\n\n\n"},"技术积累/算法题/数/二分查找":{"slug":"技术积累/算法题/数/二分查找","filePath":"技术积累/算法题/数/二分查找.md","title":"二分查找","links":[],"tags":[],"content":"\n数组下标都是从0开始的。\n数组内存空间的地址是连续的\n数组的元素是不能删的，只能覆盖。\n\n二分查找\n搜索的区间是左闭右闭还是左闭右开还是全开\n这个是一个原则,在后面的区间处理中要贯彻.区间是一个不变量\n\n在区间为空后再进行返回,可以找第一个等于target的数的下标,泛用性更强.\n返回值=目标的下标,找不到就返回数组长度\n暴力做法遍历,时间是on的时间复杂度\n二分查找利用了数组有序的性质\n\n// 【下面列了三种写法，选一种自己喜欢的就行】\n \n// lowerBound 返回最小的满足 nums[i] &gt;= target 的 i\n// 如果数组为空，或者所有数都 &lt; target，则返回 nums.length\n// 要求 nums 是非递减的，即 nums[i] &lt;= nums[i + 1]\n \n// 闭区间写法\nfunc lowerBound(nums []int, target int) int {\n    left, right := 0, len(nums)-1 // 闭区间 [left, right]\n    for left &lt;= right {           // 区间不为空\n \n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid + 1 // 范围缩小到 [mid+1, right]\n        } else {\n            right = mid - 1 // 范围缩小到 [left, mid-1]//这里right一定要-1 反正最后是返回left的值,不会存在正好错过target的情况\n        }\n    }//最后一步应该是L=R的时候,发现num[mid]&gt;=target,那么right-1\n    //没找到就是L=R的时候num[mid]&lt;target,那么left+1\n    return left // 或者 right+1///循环结束时,一定是left=right+1,违背while循环条件,那么返回left,就会是target的下标.\n}\n//如果所有元素都比8小,那么left回一直向右移动,最后就会返回整个数组的长度(R的右边也就是下标+1=数组长度)\n \n// 左闭右开区间写法\nfunc lowerBound2(nums []int, target int) int {\n    left, right := 0, len(nums) // 左闭右开区间 [left, right)\n    for left &lt; right {          // 区间不为空\n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid + 1 // 范围缩小到 [mid+1, right)\n        } else {\n            right = mid // 范围缩小到 [left, mid)\n        }\n    }\n    return left // 或者 right\n}\n \n// 开区间写法[推荐!]\nfunc lowerBound3(nums []int, target int) int {\n    left, right := -1, len(nums) // 开区间 (left, right)\n    for left+1 &lt; right {         // 区间不为空\n        // 循环不变量：\n        // nums[left] &lt; target\n        // nums[right] &gt;= target\n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid // 范围缩小到 (mid, right)\n        } else {\n            right = mid // 范围缩小到 (left, mid)\n        }\n    }\n    return right // 或者 left+1\n}\n- **Left**：初始化为“一定满足条件的值”或者“最小边界 - 1”。\n- **Right**：初始化为“一定不满足条件的值”或者“最大边界 + 1”。\n \nfunc search(nums []int, target int) int {\n    i := lowerBound(nums, target) // 选择其中一种写法即可\n    if i == len(nums) || nums[i] != target {\n        return -1\n    }//排错逻辑:都比目标小,或者只有比目标大的数\n    return i\n}\n \n作者：灵茶山艾府\n链接：leetcode.cn/problems/binary-search/solutions/2023397/er-fen-cha-zhao-zong-shi-xie-bu-dui-yi-g-eplk/\n来源：力扣（LeetCode）\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\ntips\n为什么要写成 left + (right-left)/2 而不是 (left+right)/2？\n\n防止相加太大会溢出.跟计算顺序有关,最好先算相减的部分除2,得到一个比较小的结果,所以计算过程中永远不会产生超过right的值,是绝对安全的.[既然right都没有溢出,那么这个mid的值也不会溢出了]\ngo中用&gt;&gt;1来代替除2,因为位运算比除法运算更快,虽然go自己会进行优化,但是这样写显得比较专业吧\n\n\n\n                  \n                  有符号数的范围 \n                  \n                \n\n\n负数怎么理解?理解为,符号位代表-2的六十三次方,而数字位是加上对应正数.所以10000就是2的六十三次方,加的正数部分为0\n\n\n时间复杂度\n每次循环，查找范围都缩小一半。\n第 1 次循环：你比较了中间值，如果不匹配，你扔掉了一半。剩下 N/2 个元素。\n第 k 次循环：剩下 N / 2^k 个元素。\n什么时候结束？\n当剩下的元素只有 1 个（或者 0 个）时，循环结束。\n也就是说：\n\\frac{N}{2^k} = 1\nN = 2^k\n如果每次都对N除2 那么除干净的时候应该除了log2N次\n忽略底数（因为常数差异不影响增长量级)和一次计算中的时间部分，记作 O(\\log n)\n语法\nleft和right不能在循环里面重新定义,否则while的条件一直不变.\n而middle最好在循环里面定义,因为\n"},"技术积累/算法题/栈与队列/对称匹配":{"slug":"技术积累/算法题/栈与队列/对称匹配","filePath":"技术积累/算法题/栈与队列/对称匹配.md","title":"对称匹配","links":[],"tags":[],"content":"由于栈结构的特殊性,非常适合做对称匹配类的题目\n不匹配的三种情况\n\n已经遍历完了字符串，但是栈不为空，说明有相应的左括号没有右括号来匹配，所以return false\n遍历字符串匹配的过程中，发现栈里没有要匹配的字符。所以return false\n遍历字符串匹配的过程中，栈已经为空了，没有匹配的字符了，说明右括号没有找到对应的左括号return false\n\n技巧:\n计算字符串长度如果是奇数那么一定不true\n在遇到左括号的时候把右括号入栈，那么下次遇到右括号就只需要比较当前元素和栈顶是否相等就可以了\nfunc isValid(s string) bool {\n    if len(s)%2 != 0 { // s 长度必须是偶数\n        return false\n    }\n    st := []rune{}\n    for _, c := range s {\n        switch c {\n        case &#039;(&#039;:\n            st = append(st, &#039;)&#039;) // 入栈对应的右括号\n        case &#039;[&#039;:\n            st = append(st, &#039;]&#039;)\n        case &#039;{&#039;:\n            st = append(st, &#039;}&#039;)\n        default: // c 是右括号\n            if len(st) == 0 || st[len(st)-1] != c {\n                return false // 没有左括号，或者左括号类型不对\n            }\n            st = st[:len(st)-1] // 出栈\n        }\n    }\n    return len(st) == 0 // 所有左括号必须匹配完毕\n}\n "},"技术积累/算法题/栈与队列/栈与队列":{"slug":"技术积累/算法题/栈与队列/栈与队列","filePath":"技术积累/算法题/栈与队列/栈与队列.md","title":"栈与队列","links":[],"tags":[],"content":"\n\ngo 中没有名为Stack的容器, 一般直接用切片作为栈\n\n\nstack是如何实现的？\n\n实现：[]int (或其他类型的切片)。\nPush (入栈)：使用 append 函数。\nPop (出栈)：使用切片的截取操作\nTop (取栈顶)：直接索引 len(s)-1。\n\n\n\n// 这是一个 Go 语言实现栈的标准写法\nstack := make([]int, 0)\n \n// Push\nstack = append(stack, 1)\nstack = append(stack, 2)\n \n// Top (获取栈顶元素)\ntop := stack[len(stack)-1]\n \n// Pop (移除栈顶元素)\nstack = stack[:len(stack)-1]\n\n可以遍历stack空间么？\n栈的核心定义是后进先出,虽然说对于切片实现的栈可以用range去遍历,但是不建议,会破坏栈的封装性和逻辑定义.\n\n用两个栈实现先入先出队列\n\n输入栈 输入的时候放进来就好\n输出栈 输出的的时候,如果输出栈为空,就把进栈数据全部导入进来,再从出栈导入数据.\n如果输入栈和输出栈都为空,则说明模拟的队列为空\n\ntype MyQueue struct {\n    stackIn  *MyStack\n    stackOut *MyStack\n}\n \nfunc Constructor() MyQueue {\n    return MyQueue{\n      stackIn: &amp;MyStack{},\n      stackOut: &amp;MyStack{},\n    }\n}\n \n func (this *MyQueue) fillStackOut() {\n    if this.stackOut.Empty() {\n        for !this.stackIn.Empty(){\n            val:=this.stackIn.Pop()\n            this.stackOut.Push(val)\n        }\n    }\n }\n \nfunc (this *MyQueue) Push(x int)  {\n    this.stackIn.Push(x)\n}\n \n \nfunc (this *MyQueue) Pop() int {\n    this.fillStackOut()\n    return this.stackOut.Pop()\n}\n \n \nfunc (this *MyQueue) Peek() int {\n    this.fillStackOut()\n    return this.stackOut.Peek()\n}\n \n \nfunc (this *MyQueue) Empty() bool {\n    if this.stackIn.Empty()&amp;&amp;this.stackOut.Empty(){\n        return true\n    }\n    return false\n}\n \n \n/**\n * Your MyQueue object will be instantiated and called as such:\n * obj := Constructor();\n * obj.Push(x);\n * param_2 := obj.Pop();\n * param_3 := obj.Peek();\n * param_4 := obj.Empty();\n */\n type MyStack []int\n \n func (s *MyStack) Push(v int){\n    *s=append(*s,v)\n }\n \n func (s *MyStack) Pop() int {\n    val:=(*s)[len(*s)-1]\n    *s=(*s)[:len(*s)-1]\n    return val\n }\n \n \n func (s *MyStack) Peek()int{\n    return (*s)[len(*s)-1]\n }\n \n func (s *MyStack) Size() int {\n\treturn len(*s)\n}\n \n func (s *MyStack) Empty()bool{\n    return s.Size()==0\n }\n \n用一个队列实现栈\n先说两个队列实现栈的思路\n一个负责主要的进出栈,另外一个负责备份\nqueue.push(1);        \nqueue.push(2);        \nqueue.pop();   // 对栈来说这时候应该弹出2.如果只用一个队列来模拟的话,会弹出1.因此我们先把1放到另外一个队列,把2弹出之后再把1移回来.  \nqueue.push(3);        \nqueue.push(4);       \nqueue.pop();  // 注意弹出的操作    \nqueue.pop();    \nqueue.pop();    \nqueue.empty();    \ntype MyStack struct {\n    queue1 *MyQueue\n    queue2 *MyQueue\n}\n \n \nfunc Constructor() MyStack {\n    return MyStack{\n    queue1: &amp;MyQueue{},\n    queue2: &amp;MyQueue{},   \n    }\n}\n \n \nfunc (this *MyStack) Push(x int)  {\n    this.queue1.Push(x)\n}\n \nfunc (this *MyStack) fillQueue2(){\n    n:=this.queue1.Size()//这里必须单独捞出来,因为如果放在循环里面,每次进行条件比较的时候,都会重新计算一次size,但是pop会导致size变小,所以循环实际上只进行了一半\n    for i:=0;i&lt;n-1;i++{\n        val:=this.queue1.Pop()\n        this.queue2.Push(val)\n    }\n}\nfunc (this *MyStack) fillQueue1(){\n    n:=this.queue2.Size()\n    for i:=0;i&lt;n;i++{\n        val:=this.queue2.Pop()\n        this.queue1.Push(val)\n    }\n}\n \nfunc (this *MyStack) Pop() int {\n    this.fillQueue2()\n    val:=this.queue1.Pop()\n    this.fillQueue1()\n    return val\n}\n//实际上这里最后可以用交换指针的方法,不用再费劲倒回去.具体做法如下\nthis.queue1, this.queue2 = this.queue2, this.queue1\n \nfunc (this *MyStack) Top() int {\n    return this.queue1.Tail()\n}\n \n \nfunc (this *MyStack) Empty() bool {\n    return this.queue1.Empty()&amp;&amp;this.queue2.Empty()\n}\n \n \n/**\n * Your MyStack object will be instantiated and called as such:\n * obj := Constructor();\n * obj.Push(x);\n * param_2 := obj.Pop();\n * param_3 := obj.Top();\n * param_4 := obj.Empty();\n */\n \ntype MyQueue []int\n \nfunc (s *MyQueue) Push(v int){\n    (*s)=append(*s,v)\n}\n \nfunc (s *MyQueue) Pop() int{\n    val:=(*s)[0]\n    (*s)=(*s)[1:]\n    return val\n}\n \nfunc (s *MyQueue) Peek() int{\n    return (*s)[0]\n}\n \nfunc (s *MyQueue) Tail() int{\n    return (*s)[len(*s)-1]\n}\n \nfunc (s *MyQueue) Size() int{\n    return len(*s)\n}\nfunc (s *MyQueue) Empty() bool{\n    return s.Size()==0\n}\n其实还有另外一种写法,是push比较麻烦,pop比较简单的\ntype MyStack struct {\n    //创建两个队列\n    queue1 []int\n    queue2 []int\n}\n \n \nfunc Constructor() MyStack {\n    return MyStack{\t//初始化\n        queue1:make([]int,0),\n        queue2:make([]int,0),\n    }\n}\n \n \nfunc (this *MyStack) Push(x int)  {\n     //先将数据存在空的queue2中\n    this.queue2 = append(this.queue2,x)\t\n   //将queue1中所有元素移到queue2中，再将两个队列进行交换\n    this.Move() \n}\n \n//核心目的是,确保最新的元素永远排在第一个队列的最前面.也就是数组下标0处.用这个函数,queue1一直是栈的状态(先进先出.)\nfunc (this *MyStack) Move(){    \n    if len(this.queue1) == 0{\n        //交换，queue1置为queue2,queue2置为空\n        this.queue1,this.queue2 = this.queue2,this.queue1\n    }else{\n        //queue1元素从头开始一个一个追加到queue2中\n            this.queue2 = append(this.queue2,this.queue1[0])  \n            this.queue1 = this.queue1[1:]\t//去除第一个元素\n            this.Move()     //重复\n    }\n}\n \nfunc (this *MyStack) Pop() int {\n    val := this.queue1[0]\n    this.queue1 = this.queue1[1:]\t//去除第一个元素\n    return val\n \n}\n \n \nfunc (this *MyStack) Top() int {\n    return this.queue1[0]\t//直接返回\n}\n \n \nfunc (this *MyStack) Empty() bool {\nreturn len(this.queue1) == 0\n}\n优化:只用一个队列.\n对于队列而言.如果想要删掉最后进来的那个元素,只需要把前面的人全部拿出来重新排到队尾,然后把队列最前面的元素[也就是栈顶]弹出即可.妙哉妙哉..\ntype MyStack struct {\n    queue []int//创建一个队列\n}\n \n \n/** Initialize your data structure here. */\nfunc Constructor() MyStack {\n    return MyStack{   //初始化\n        queue:make([]int,0),\n    }\n}\n \n \n/** Push element x onto stack. */\nfunc (this *MyStack) Push(x int)  {\n    //添加元素\n    this.queue=append(this.queue,x)\n}\n \n \n/** Removes the element on top of the stack and returns that element. */\nfunc (this *MyStack) Pop() int {\n    n:=len(this.queue)-1//判断长度\n    for n!=0{ //除了最后一个，其余的都重新添加到队列里\n        val:=this.queue[0]\n        this.queue=this.queue[1:]\n        this.queue=append(this.queue,val)\n        n--\n    }\n    //弹出元素\n    val:=this.queue[0]\n    this.queue=this.queue[1:]\n    return val\n    \n}\n \n \n/** Get the top element. */\nfunc (this *MyStack) Top() int {\n    //利用Pop函数，弹出来的元素重新添加\n    val:=this.Pop()\n    this.queue=append(this.queue,val)//只是拿出来看一眼,马上塞回去\n    return val\n}\n \n \n/** Returns whether the stack is empty. */\nfunc (this *MyStack) Empty() bool {\n    return len(this.queue)==0\n}\n "},"技术积累/算法题/栈与队列/递归":{"slug":"技术积累/算法题/栈与队列/递归","filePath":"技术积累/算法题/栈与队列/递归.md","title":"递归","links":[],"tags":[],"content":"递归的实现\n\n递归的实现就是：\n\n每一次递归调用都会把函数的局部变量、参数值和返回地址等压入调用栈中.\n然后递归返回的时候，从栈顶弹出上一次递归的各项参数\n\n\n因此实际上,栈与递归在某种程度上是可以转换的\n\n递归算法三要素\n\n确定单层递归的原理\n\n原问题和子问题要使用的相同函数.\n\n\n确定递归函数的参数和返回值\n确定边界条件.[如果递归没有终止会导致栈溢出]\n\n分解出子问题,直到最小的子问题,需要直接返回的值.\n比如要计算深度,共同的函数是左子树深度和右子树深度的最大值+1.而边界条件: 分解到最小就是叶子节点直接返回0\n\n\n"},"技术积累/算法题/滑动窗口与前缀和/3.-无重复字符的最长子串":{"slug":"技术积累/算法题/滑动窗口与前缀和/3.-无重复字符的最长子串","filePath":"技术积累/算法题/滑动窗口与前缀和/3. 无重复字符的最长子串.md","title":"3. 无重复字符的最长子串","links":["技术积累/算法题/字符串处理"],"tags":["盲过"],"content":"给定一个字符串 s ，请你找出其中不含有重复字符的 最长 子串 的长度\n小记\n\n滑动窗口思想\n重复字符:记录频率\nTransclude of 字符串处理#range与下标\n\n代码\nfunc lengthOfLongestSubstring(s string) int {\n    //不含有重复字符:一个数组来记录字符出现的频率,.如果新进来的这个数=2了,就缩小左边直到这个数前面那个重复的数出去,2-1=1.确保整个数组内没有重复元素的时候可以记录最大值ans.\n    cnt:=[128]int{}\n    left:=0\n    ans:=0\n    for i,c:=range s{\n        cnt[c]++\n        for cnt[c]&gt;1{\n            cnt[s[left]]--\n            left++\n        }\n        ans = max(ans, i-left+1)\n    } \n    return ans\n}\nfunc lengthOfLongestSubstring(s string) int {\n    //好吧现在看到这种乍一看就觉得应该用动态规划.再仔细看看\n    //不含有重复字符 看到这里觉得应该是哈希表+滑动窗口了\n    //右边一直纳入,如果遇到有重复的字符了,就左边缩小直到没有重复为止.这时候再记录最大值!感觉非常的可行\n    cnt:=map[rune]int{}\n    t:=[]rune(s)//这里必须要转成rune数组,不然后面s[left]是拿不出rune的只能拿出byte,又不符合哈希表了\n    //这里说s由英文字母数字符号和空格组成 所以这个大小应该是可控的但是我又忘记ascii码范围了所以还是没办法用数组了算了\n    left:=0\n    ans:=0\n    for right,c:=range t{\n        cnt[c]++\n        for cnt[c]==2{\n            cnt[t[left]]--\n            left++\n        }\n        //到这里的时候,窗口内应该都是不含有重复字符的,可以记录了\n        ans=max(ans,right-left+1)\n    }\n    return ans\n}"},"技术积累/算法题/滑动窗口与前缀和/560.-和为K的子数组":{"slug":"技术积累/算法题/滑动窗口与前缀和/560.-和为K的子数组","filePath":"技术积累/算法题/滑动窗口与前缀和/560. 和为K的子数组.md","title":"560. 和为K的子数组","links":["技术积累/算法题/数/n数之和"],"tags":[],"content":"给你一个整数数组 nums 和一个整数 k ，请你统计并返回该数组中和为 k 的子数组的个数。\n子数组是数组中元素的连续非空序列。\n小记\n\n使用n数之和的思想.\n\n当遍历到当前位置 j 时，前缀和是 s[j]。如果前面有个位置 i 的前缀和是 s[j] - k，那就说明中间这一段的和正好是 k。[target]\n\n\n查找前面有没有一个数=target,使用哈希表是最快的.\n\n代码\nfunc subarraySum(nums []int, k int) int {\n    // Key: 前缀和的值, Value: 这个前缀和出现的次数\n    // 预分配内存，避免map扩容，长度设为len(nums)+1\n    mp := make(map[int]int, len(nums)+1)\n    \n    //需要这个0存在。哈希表中存储的是index前缀和出现的次数\n    mp[0] = 1\n    \n    count := 0 // 记录最终答案\n    pre := 0   // 记录当前的前缀和\n    //如果当前前缀和直接等于 `k` (比如 `s[j]=2, k=2`)，我们需要找 `2-2=0`。如果不存 `0`，就会漏掉从头开始的子数组。\n    for _, x := range nums {\n        pre += x // 1. 更新当前前缀和\n        \n        // 2. 查表：看看前面有没有 前缀和 = (pre - k)\n        // 如果有，说明这两段前缀和的差值正好是 k.注意这里的写法\n        if c, ok := mp[pre-k]; ok {\n            count += c//因为重复也会被计入\n        }\n        // 3. 存表：把当前的前缀和记录下来，供后面查询\n        mp[pre]++\n    }\n    \n    return count\n}"},"技术积累/算法题/滑动窗口与前缀和/滑动窗口与前缀和":{"slug":"技术积累/算法题/滑动窗口与前缀和/滑动窗口与前缀和","filePath":"技术积累/算法题/滑动窗口与前缀和/滑动窗口与前缀和.md","title":"滑动窗口与前缀和","links":[],"tags":[],"content":"变长滑动窗口\n\n注意使用数组元素都是正数的性质\n\n右指针往右移 \\rightarrow 窗口内和一定变大。\n左指针往右移 \\rightarrow 窗口内和一定变小。\n\n\n如果题目中出现负数,则无法使用滑动窗口\n空间复杂度O(1)\n\n前缀和\n通常配合哈希表,通过数学差值计算解决问题,不依赖单调性(正负数均可)\n需要额外空间存储前缀信息:静态预处理\n定长滑动窗口\n正负数均可.\n空间复杂度O(1)"},"技术积累/算法题/移动匹配":{"slug":"技术积累/算法题/移动匹配","filePath":"技术积累/算法题/移动匹配.md","title":"移动匹配","links":[],"tags":[],"content":""},"技术积累/算法题/语法细节":{"slug":"技术积累/算法题/语法细节","filePath":"技术积累/算法题/语法细节.md","title":"语法细节","links":[],"tags":[],"content":"\ngo中的交换可以这样写:\n\n s[left], s[right] = s[right], s[left]\n\n\n关于小括号和花括号\n\n() 小括号：显式类型转换 (Type Conversion)可以写t:=[]byte(s)直接把字符串显式转换成数组.string(cnt)再这样转换回去就行了\n{} 花括号：初始化/构造 (Composite Literal)\n\n\n\nimport后面用的是小括号\n\n\n循环中断\n\ncontinue 跳出当次循环\nbreak 结束当前循环\n如果想要结束所有循环,可以使用go语言的配合标签的break(Label)\n\n\n\npackage main\n \nimport &quot;fmt&quot;\n \nfunc main() {\n// 给外层循环起个名字叫 MyLoop (名字随便起)\nMyLoop: \n    for i := 0; i &lt; 3; i++ {\n        for j := 0; j &lt; 5; j++ {\n            if j == 2 {\n                // 指名道姓：我要跳出名叫 MyLoop 的那个循环\n                break MyLoop \n            }\n            fmt.Printf(&quot;i:%d, j:%d\\n&quot;, i, j)\n        }\n    }\n    // break MyLoop 后直接来到这里，外层循环也被终止了\n    fmt.Println(&quot;彻底结束&quot;)\n}\n\n逗号\n\ntype MyQueue struct {\n    stackIn  *MyStack\n    stackOut *MyStack\n}\n \nfunc Constructor() MyQueue {\n    return MyQueue{\n      stackIn: &amp;MyStack{},\n      stackOut: &amp;MyStack{},\n    }\n}\n冒号含义:贴标签.\n逗号含义:列表分隔,为了git版本控制友好.这样下一次要加一个字段的时候只有一行修改,而不是上一行加上逗号+新字段行.\n实际上,这就是一个JSON写法,key-value对.\n\n\n函数调用操作符.\n调用一个函数一定要加上(),表示执行这个函数.即使不需要传参数也要加\n如果不加括号,表示提到这个函数本身,是把函数当作一个变量或者对象\n\n\n结构体\n\n\n//情况1\ntype MyQueue []int\nfunc (q *MyQueue) Push(...)//如果要修改长度,一定要传切片的指针进去.\n(*q)[0]//既然穿了指针,那么修改切片中某个元素的时候就必须解引用\n \n \n//情况2\ntype MyQueue struct {\n    queue []int\n}\n//那么默认传myqueue的指针.但是如果要改queue中的元素,不需要解引用,m.queue[0]就可以.\n//如果要增删字段也比较方便.\n//缺点是需要多写一个m."},"技术积累/算法题/贪心算法/300.-最长递增子序列":{"slug":"技术积累/算法题/贪心算法/300.-最长递增子序列","filePath":"技术积累/算法题/贪心算法/300. 最长递增子序列.md","title":"300. 最长递增子序列","links":[],"tags":[],"content":"给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n小记\n代码\n "},"技术积累/算法题/链表/141.-环形链表":{"slug":"技术积累/算法题/链表/141.-环形链表","filePath":"技术积累/算法题/链表/141. 环形链表.md","title":"141. 环形链表","links":[],"tags":[],"content":"给你一个链表的头节点 head ，判断链表中是否有环。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。注意：pos 不作为参数进行传递 。仅仅是为了标识链表的实际情况。\n如果链表中存在环 ，则返回 true 。 否则，返回 false 。\n小记\n代码\n/**\n * Definition for singly-linked list.\n * type ListNode struct {\n *     Val int\n *     Next *ListNode\n * }\n */\nfunc hasCycle(head *ListNode) bool {\n    //因为本体不需要找到环的开始位置 所以不用太复杂\n    //快指针:2x 慢指针x  差值为x 然后进入环之后,这个x将由x步追平.因此,如果相遇说明有环.\n    slow, fast := head, head\n    for fast!=nil&amp;&amp;fast.Next!=nil{\n        fast=fast.Next.Next\n        slow=slow.Next\n        if fast==slow{\n            return true \n        }\n    }\n    return false\n}"},"技术积累/算法题/链表/142.-环形链表-II":{"slug":"技术积累/算法题/链表/142.-环形链表-II","filePath":"技术积累/算法题/链表/142. 环形链表 II.md","title":"142. 环形链表 II","links":["tags/flashcard"],"tags":["flashcard"],"content":"给定一个链表的头节点  head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。 flashcard\n小记\n\n环形链表:快慢指针相遇之后,从头节点开始和慢指针相遇.相遇的节点就是环的入口\n我自己写倒是能写出来,但是就是觉得不太美观也没什么结构,还是多模仿多学习…\n只要 fast 不为空，且 fast.Next 不为空，就可以安全地执行 fast = fast.Next.Next..即使 fast.Next.Next 是空，赋值给 fast 后，fast 变成 nil 也就是了，下一轮循环自然会由 fast != nil 拦截住。\n\nfor ... {\n    if 相遇 {\n        处理;\n        return 结果; // 只要有环，这里就返回了\n    }\n}\nreturn nil; // 能走到这里，说明循环自然结束了，肯定无环\n//这样就不需要为了弥补 `break` 跳出循环后不知道是“因为相遇跳出”还是“因为走到尽头跳出” 而不得已加上补丁..\n代码\nfunc detectCycle(head *ListNode) *ListNode {\n    slow, fast := head, head\n    for fast != nil &amp;&amp; fast.Next != nil {\n        slow = slow.Next\n        fast = fast.Next.Next\n        if fast == slow { // 相遇\n            for slow != head { // 再走 a 步\n                slow = slow.Next\n                head = head.Next\n            }\n            return slow\n        }\n    }//所以说如果存在空,就不会进入上面这个循环,自然而然也就不存在环.\n    return nil\n}"},"技术积累/算法题/链表/反转链表/25.-K个一组翻转链表":{"slug":"技术积累/算法题/链表/反转链表/25.-K个一组翻转链表","filePath":"技术积累/算法题/链表/反转链表/25. K个一组翻转链表.md","title":"25. K个一组翻转链表","links":[],"tags":[],"content":"给你链表的头节点 head ，每 k 个节点一组进行翻转，请你返回修改后的链表。\nk 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。\n你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换\n小记\n\n分组看下一组是否够k个\n\n不够的话直接结束,\n如果够的话,记下这一组的头尾,和下一组的头\n\n\n每一组之间断开\n每组内各自翻转\n拼接\n推进\n\n代码\nfunc reverseKGroup(head *ListNode, k int) *ListNode {\n    i:=head\n    n:=0\n    for i!=nil{\n        n++\n        i=i.Next\n    }\n    dummy:=&amp;ListNode{Next:head}\n    p0:=dummy\n    var pre *ListNode=nil\n    cur:=head\n    for ;n&gt;=k;n-=k{\n \n        for j:=0;j&lt;k;j++{\n            next:=cur.Next\n            cur.Next=pre\n            pre=cur\n            cur=next\n        }\n \n        p0.Next.Next=cur\n        nxt:=p0.Next\n        p0.Next=pre\n        p0=nxt\n        \n    }\n    return dummy.Next\n}"},"技术积累/算法题/链表/反转链表/反转链表":{"slug":"技术积累/算法题/链表/反转链表/反转链表","filePath":"技术积累/算法题/链表/反转链表/反转链表.md","title":"反转链表","links":[],"tags":[],"content":"Dummy 节点通常用于“头节点可能会变动，或者需要在头节点之前进行插入/删除操作”的场景\n反转链表\n\n\ncur就是当前节点,初始化为head.pre初始化为空.最后为nil的时候循环结束.for cur!=nil\n\nfunc reverseList(head *ListNode) *ListNode {\n    var pre *ListNode =nil\n    cur:=head\n    for cur!=nil{\n        next:=cur.Next\n        cur.Next=pre\n        pre=cur\n        cur=next\n    }\n \n    return pre\n}\n反转链表2:反转从left到right之间的链表\n\n\n反转过后,pre指向这一段的末尾,cur指向这一段的下一个节点\n\n\n\n那么反转过后,这一段的前一个节点就要指向这一段的最后一个节点,然后这一段的开头节点需要指向这一段的下一个节点.总之如图所示\n\n\n\n当left=1的时候是没有p0的,所以我们用一个头节点来处理\n\n\n那么循环left-1次,就会到达反转这一段的上一个节点\n\n\n最主要的是,对于这个p0的概念要清晰,它代表的是分组的前一个节点.\n\n\n每次反转过后,新末尾要指向下一个头,这是反转链表的基本事件.等到下一次循环的时候分组的前一个节点会指向分组末尾的,所以不用担心多次反转会导致顺序错了.\n\n\nfunc reverseBetween(head *ListNode, left int, right int) *ListNode {\n    dummy:=&amp;ListNode{Next:head}\n    p0:=dummy\n    for i:=0;i&lt;left-1;i++{\n        p0 = p0.Next\n    }\n    var pre *ListNode = nil\n    cur:=p0.Next\n    for j:=0;j&lt;right-left+1;j++{\n        next:=cur.Next\n        cur.Next=pre\n        pre=cur\n        cur=next\n    }\n    nxt:=p0.Next\n    nxt.Next=cur\n    p0.Next=pre\n    \n    return dummy.Next\n}"},"技术积累/算法题/链表/合并链表/21.-合并两个有序链表":{"slug":"技术积累/算法题/链表/合并链表/21.-合并两个有序链表","filePath":"技术积累/算法题/链表/合并链表/21. 合并两个有序链表.md","title":"21. 合并两个有序链表","links":[],"tags":[],"content":"将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n小记\n\n最好画图看一下指针怎么变吧\n头节点真好用\n注意最后返回值,总之要思路清晰了再写不要乱写了\n\n代码\nfunc mergeTwoLists(list1, list2 *ListNode) *ListNode {\n    dummy := ListNode{} // 用哨兵节点简化代码逻辑\n    cur := &amp;dummy // cur 指向新链表的末尾\n    for list1 != nil &amp;&amp; list2 != nil {\n        if list1.Val &lt; list2.Val {\n            cur.Next = list1 // 把 list1 加到新链表中\n            list1 = list1.Next\n        } else { // 注：相等的情况加哪个节点都是可以的\n            cur.Next = list2 // 把 list2 加到新链表中\n            list2 = list2.Next\n        }\n        cur = cur.Next\n    }\n    // 拼接剩余链表\n    if list1 != nil {\n        cur.Next = list1\n    } else {\n        cur.Next = list2\n    }\n    return dummy.Next\n}"},"技术积累/算法题/链表/合并链表/23.-合并K个升序链表":{"slug":"技术积累/算法题/链表/合并链表/23.-合并K个升序链表","filePath":"技术积累/算法题/链表/合并链表/23. 合并K个升序链表.md","title":"23. 合并K个升序链表","links":["技术积累/算法题/栈与队列/堆"],"tags":[],"content":"给你一个链表数组，每个链表都已经按升序排列。\n请你将所有链表合并到一个升序链表中，返回合并后的链表。\n小记\n可以用最小堆实现。初始把所有链表的头节点入堆，然后不断弹出堆中最小节点 x，如果 x.next 不为空就加入堆中。循环直到堆为空。把弹出的节点按顺序拼接起来，就得到了答案.\n代码\n\n注意断言的写法Transclude of 堆#heap中的断言\n如果 node.Next 为空（nil），意味着这一条链表已经全部合并完了。此时我们什么都不做（不把 nil 入堆），让堆里的元素数量减 1，这正是我们要的效果。\n\nfunc mergeKLists(lists []*ListNode) *ListNode {\n    h := hp{}\n    for _, head := range lists {\n        if head != nil {\n            h = append(h, head) // 把所有非空链表的头节点入堆\n        }\n    }\n    heap.Init(&amp;h) // 堆化\n \n    dummy := &amp;ListNode{} // 哨兵节点，作为合并后链表头节点的前一个节点\n    cur := dummy\n    for len(h) &gt; 0 { // 循环直到堆为空\n        node := heap.Pop(&amp;h).(*ListNode) // 剩余节点中的最小节点\n        if node.Next != nil { // 下一个节点不为空\n            heap.Push(&amp;h, node.Next) // 下一个节点有可能是最小节点，入堆\n        }\n        cur.Next = node // 把 node 添加到新链表的末尾\n        cur = cur.Next // 准备合并下一个节点\n    }\n    return dummy.Next // 哨兵节点的下一个节点就是新链表的头节点\n}\n \ntype hp []*ListNode\nfunc (h hp) Len() int           { return len(h) }\nfunc (h hp) Less(i, j int) bool { return h[i].Val &lt; h[j].Val } // 最小堆\nfunc (h hp) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\nfunc (h *hp) Push(v any)        { *h = append(*h, v.(*ListNode)) }\nfunc (h *hp) Pop() any          { a := *h; v := a[len(a)-1]; *h = a[:len(a)-1]; return v }\n \n "},"生活杂谈/test":{"slug":"生活杂谈/test","filePath":"生活杂谈/test.md","title":"test","links":[],"tags":[],"content":""},"生活杂谈/面经/GC":{"slug":"生活杂谈/面经/GC","filePath":"生活杂谈/面经/GC.md","title":"GC","links":[],"tags":[],"content":"Garbage Collection\n工作原则是：只要这块内存还有人在用（有指针指向它）我就不能扔；没人指向它了，我就回收。\nSlice 导致内存泄露的经典场景： 想象一下，你从服务器下载了一个 100MB 的超大文件（比如一本小说），读到了内存里，变成了一个巨大的数组。\n// 1. 这是一个巨大的切片，底层数组占用 100MB\nbigData := getHugeFile() \n \n// 2. 你只需要前 10 个字节（比如只要标题）\ntinySlice := bigData[:10]\n \n// 3. 此时，你把 bigData 弄丢或者函数返回了，只留下了 tinySlice\nreturn tinySlice\n\n表面看： tinySlice 只有 10 个字节。\n实际上： tinySlice 的结构体里有一个指针,指向底层的那个数组\n结果： 只要 tinySlice 还活着，保洁阿姨（GC）就会认为：“哦，那个 100MB 的数组还有人（tinySlice）指着它呢，不能扔。”\n后果： 为了这 10 个字节的小数据，你强行占用了 100MB 的内存不释放。这就是内存泄露。\n\n解决办法:"},"生活杂谈/面经/summary":{"slug":"生活杂谈/面经/summary","filePath":"生活杂谈/面经/summary.md","title":"summary","links":[],"tags":[],"content":"一、 Go 语言基础（重灾区，必问）\n面试官非常喜欢问底层实现，特别是 Slice 和 GMP，几乎每场必面。\n\n\nSlice (切片) —— 出现频率：⭐⭐⭐⭐⭐\n\n\n底层原理： 数组指针 + 长度 (len) + 容量 (cap)。\n\n\n扩容机制： 什么时候翻倍？什么时候 1.25 倍？。\n\n\n引用 vs 复制： 传递 Slice 是值传递还是引用传递？（答案是值传递，但因为持有底层数组指针，所以修改元素会影响原数组，但 append 可能会导致扩容换数组）。\n\n\n\n\nGMP 模型 —— 出现频率：⭐⭐⭐⭐⭐\n\nG、M、P 分别是什么？调度流程是怎样的？。\n\n\n\nMap (字典) —— 出现频率：⭐⭐⭐⭐\n\n\n底层结构？是有序还是无序的？（无序）。\n\n\n并发读写会 Panic 吗？（会，怎么解决？用 sync.Map 或加锁）。\n\n\n\n\nChannel (通道) —— 出现频率：⭐⭐⭐⭐\n\n\n有缓冲 vs 无缓冲的区别。\n\n\n向关闭的 channel 读/写会发生什么？（写会 panic，读会返回零值）。\n\n\n\n\nContext &amp; Defer\n\n\ndefer 的执行顺序（栈，后进先出）。\n\n\ncontext 如何做超时控制？。\n\n\n\n\n\n二、 MySQL 数据库（结合你的 MiniSQL 项目看）\n这部分你结合你的项目复习，效果会翻倍。\n\n\n索引 (Index) —— 出现频率：⭐⭐⭐⭐⭐\n\n\nB+ 树： 为什么要用 B+ 树？和 B 树区别？。\n\n\n失效场景： where 条件、like 模糊查询、最左前缀原则。\n\n\n分类： 聚簇索引 vs 非聚簇索引。\n\n\n\n\n事务 (Transaction) —— 出现频率：⭐⭐⭐⭐\n\n\nACID 特性： 原子性、一致性、隔离性、持久性。\n\n\n隔离级别： 读未提交、读已提交、可重复读（默认）、串行化。如何解决幻读？（MVCC + Next-Key Lock）。\n\n\n\n\n慢查询优化\n\n\nlimit 分页太深怎么优化？。\n\n\nexplain 命令怎么看？\n\n\n\n\n\n三、 Redis &amp; 分布式（进阶加分项）\n字节跳动非常喜欢问 Redis，尤其是分布式锁。\n\n\n基础数据结构\n\nString, List, Hash, Set, ZSet (有序集合，底层是跳表)。\n\n\n\n分布式锁 (重点)\n\n怎么实现？SETNX 有什么问题？怎么续期（WatchDog 机制）？。\n\n\n\n消息队列 (Kafka)\n\n如何保证消息顺序？（Partition）消息积压怎么办？。\n\n\n\n\n四、 计算机网络 &amp; 操作系统\n\n\nTCP/IP\n\n\n三次握手： 为什么不是两次？最后一次 ACK 丢了怎么办？。\n\n\n输入一个 URL 到网页显示的流程（经典老题）。\n\n\n\n\nLinux 命令\n\n查询端口占用、查看磁盘/内存满没满 (top, df, netstat/lsof)。\n\n\n\n\n五、 手撕算法 (Code)\n从面经看，考的都是 Hot 100 里的经典题，没有怪题。\n\n\n链表类： 反转链表、反转链表 II。\n\n\nLRU 缓存： 设计 LRU（字节高频题）。\n\n\n字符串： 无重复字符的最长子串、回文串判断。\n\n\n排序： 快排（问最坏情况）。\n\n\n其他： 三数之和。\n\n"},"课程笔记/mySQL/其他/索引":{"slug":"课程笔记/mySQL/其他/索引","filePath":"课程笔记/mySQL/其他/索引.md","title":"索引","links":[],"tags":[],"content":""},"课程笔记/内存中的栈":{"slug":"课程笔记/内存中的栈","filePath":"课程笔记/内存中的栈.md","title":"内存中的栈","links":[],"tags":[],"content":""},"课程笔记/操作系统/01-introduction":{"slug":"课程笔记/操作系统/01-introduction","filePath":"课程笔记/操作系统/01 introduction.md","title":"01 introduction","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n操作系统概述\n定义与设计目标\n操作系统：\n\n职能：资源管理系统\n存在：本质上是软件程序\n\n最基础最中央的部分是内核kernel\n\n\n\n设计目标：\n\n可靠性和安全性\n\n异常处理机制：中断\n权限管理系统：特权\n\n\n易用性\n\n方便用户使用系统资源：系统调用\n\n\n高效性\n\n任务执行设计：批处理系统-》分时系统\n\n\n公平性\n\n进程管理的冲突与饥饿starvation\n\n\n可拓展性、易维护性\n\n设计与实现\n从目标/需求开始：user goals &amp; system goals\n机制和策略相分离 flashcard\n\n\n机制/规则被存在酒店的中心服务器上（database） 和策略分离开了,比如配置文件就相当于policy\n\n\n\n                  \n                  例题 \n                  \n                \n\n\n\n\n操作系统提供的三种能力\n复用 multiplexing\n\ncpu复用 多个程序共享 时间分配复用\n内存复用 多个进程  空间分配复用\n\n隔离  isolation\n\n程序之间不能访问对方的数据\n数据范围权限的隔离\n用户 kernel\n\n抽象 abstraction\n进程间通讯 interaction\n操作系统的整体设计\n计算机系统架构\n\n根据处理器的数量和组织形式，存在三种计算机系统架构\n\n单处理器\n\n有且仅有一个单核通用处理器general-purpose processor\n可以有若干专用处理器用来处理特定指令，并不运行线程\n\n\n多处理器系统\n\n有多个单核通用处理器的系统，处理器共享同一块主内存，通过总线或者交换网络连接\n增加了处理西数量能够增加吞吐量throughput，也就是单位时间内处理的任务数量，但是增加并不线性（处理器之间通信需要时间和额外开销）\n\n\n集群系统\n\n通过冗余实现高可用服务，通过并行实现高性能计算，由多个独立的计算机系统作为节点，通过高速通信网络相互连接形成\n分为对称和不对称两种，对称集群中各个节点互相监督，不对称集群中存在“替补”监督工作中的节点，或者接替有问题节点的工作。\n\n\n\n操作系统的任务执行设计\n1. （单道）批处理系统  flashcard\nbatch processing system\n\n批处理：若干任务被作为一整批交付给操作系统，操作系统会自动按照顺序串行serial执行任务\n单道：一段时间内内存中只有一道程序在运行（进程process ），结束后再切换到下一个任务\n问题：当存在I/O操作任务时，由于耗时，CPU长时间处于空闲状态\n\n\n\n                  \n                  I/O \n                  \n                \n\n即CPU和RAM（主内存）与“外部世界”之间进行数据交换的过程\n\n存储设备（磁盘IO）\n网络设备（网络IO）\n人机交互设备\n其他外部设备\n\n特点：速度慢。\n\n\n\n2. 多道批处理系统 flashcard\nmultiprogramming batch processing system\n\n一段时间内，四个进程 （job=process）都加载到内存中，并发运行（在A完成之前B可能也开始了）。当当前 job 发生 I/O 时，操作系统负责让 CPU 转而运行另一个 job。\n但微观来看，多道批处理仍然是顺序串行的。\n不关心运行的先后顺序（任意），只要同时加载进去就叫做multiprogramming。调度的部分是由jobschedule完成（批处理\n原因：内存大，cpu强，有能力同时处理4个进程，因此就可以提升硬件的使用效果\nneeded for硬件计算资源CPU utlization\n交互性差，在完成任务前用户无法操作\n\n\n\n                  \n                  并发与并行 \n                  \n                \n\n并发**(concurrency)**是指两个或多个事件在同一时间间隔内发生，而并行是指两个或多个事件在同一时刻发生。逻辑上，并行是并发的子集。\n\n3. 分时系统 flashcard\ntimesharing systems/multitasking\n\nmultiprogramming的逻辑拓展：保留其内存中有多个进程的并发特点\n处理器会在jobs上面轮流地赋予cpu资源，在进程间不断切换（很短的时间内），让用户察觉不到进程的切换/cpu的共享，达到近似于并行的效果。\n注重的是用户的交互性interactivity，允许多个用户同时使用同一台计算机，所有任务之间互相独立，互不干扰、互不阻塞，因此任务的最长周转时间减少，用户的操作也会被及时响应，实现了更方便进行人机对话。\n对硬件配置有较高要求（每个用户的terminal）和调度算法\n\n\n操作系统的结构设计\n宏/巨内核(monolithic-kernels) flashcard\n也叫单内核或大内核\n\n将所有主要功能紧密耦合，操作系统效率高\n维护十分困难；某个部分出现困难，整个系统都会受影响。\n\n\n\n分层设计(layer approach)\n\n将系统分为若干层，底层为硬件，顶层为用户接口，第 i 层只调用i−1 层提供的接口。每一层都实现良好的封装，于是开发过程中只需要逐步实现并调试验证每一层，再逐级向上开发即可；在维护或扩展过程中，只要修改每一层的内部实现，而不需要修改其它层的代码，这样就大大降低了开发和维护的难度。 \n由于每次执行一个功能都需要上下跨越多层，发生多次接口调用，分层设计下的系统效率往往都受到限制；不仅如此，要想真正意义上实现良好的分层设计，就需要对各层有良好的定义，这个设计难度是不小的。\n\n微内核(micro-kernels) flashcard\n\n将不是必要的东西都从内核拿出去，放到用户空间以用户态执行。只有通讯、内存管理、进程管理等基本功能直接运行在内核态。其他功能部件通过消息传递机制和内核互动。\n维护扩展变得容易，自身效率得到提升，可靠性也提高了。但是很多模块移到usermode不安全\n\n\n\n模块化设计(modules approach)\n模块-接口法。理想的设计可以让系统多线并行，只要商量好接口就能独立实现，维护和扩展容易。但是设计开发很困难。\n混合系统(hybrid systems)\n宏内核和微内核的思路结合起来，是目前主流的操作系统模式\n操作系统的运行原理\n中断interrupts\n中断（广义）是贯穿现代操作系统的一个重要技术，它使得“计划之外”的事情可以及时的被告知并处理（让产生意外的人自行上报这些意外） 现代操作系统都是中断驱动的\ninterrupt-request line flashcard\n\nCPU 有称为 interrupt-request line 的线路。CPU会在每一条指令结束后检测是否有中断发生，并会读取 interrupt number 并且以此作为 interrupt vector 中的 index 来跳转到对应的 interrupt-handler routine。\n\n\n中断向量表 interrupt vector table flashcard\n中断向量表是快速定位中断处理方法的手段。通过中断号来索引中断处理方法，实现了一种“随机访问”，大大加速了中断处理的速度。\n\n分类\n\n硬件引起的中断（外中断）\n软件引起的中断（内中断）trap\n\nerror 非主动的\nsystem call 程序主动的 调用操作系统的功能\n\n\n\n\n\n                  \n                  riscv的对应术语区别 \n                  \n                \n\n\n中断traps\n\n硬件中断 interrupts\n软件中断\n\nerror→exceptions\n系统调用→ecalls（环境调用）\n\n\n\n\n\n\n\n\n\n                  \n                  cause a page fault \n                  \n                \n\n缺页 访问memory地址的时候由于对应的地址内容非法而产生的中断\n\n\n\n过程\n\n\ndevice driver I/O与操作系统之间的驱动\n左边：CPU\n右边：I/O controller\nI/Ocontroller发起中断之后，CPU对其进行处理，调用interrupt handler，处理好之后return到被中断的下一条指令重新开始运行 的这么一个循环过程\n\n波动表示状态的改变\n\n\n\n                  \n                  中断状态的保存 \n                  \n                \n\n为了保证中断处理完成后仍能继续当前任务，操作系统需要保存当前任务的状态，以便完成中断处理后恢复当前任务的状态。\n\n\n中断冲突 flashcard\n中断处理也同样需要资源，这意味着中断也有可能产生冲突\n\n优先处理优先级高的中断：中断分级\n\n虽然低级的中断可以被高级的中断打断，但是保存和恢复现场状态的过程是不应当被打断的。\n\n\n原子性行为不可被中断，重要任务不应该被中断：中断屏蔽\n\n\n\n                  \n                  中断请求线 \n                  \n                \n\n\nmaskable interrupt-request line 可屏蔽的中断 它可以在执行不可中断的关键程序之前被 CPU 关闭，等到关键程序结束后再解除屏蔽处理其中的中断。\n 2. non-maskable interrupt-request line 不可屏蔽的中断 为一些不可恢复的内存错误等事件保留\n\n\n\n\n计时器 timer flashcard\n\n计时器需要一个固定频率的时钟以及一个计数器，在每个时钟周期令计数器减 1，当计数器归零时产生中断，告诉操作系统定的时已经到了\n功能虽然基础但是十分重要，例如分时系统中就需要计数器来控制时间片的长度，又比如操作系统需要定期检查内存中的进程，以防止进程一直占用系统资源\n\n\n特权模式privileged mode\n允许用户程序执行常规操作，危险操作由专业人士执行。\n工业上特权模式有许多复杂的实现形式，比如\n双模式(dual-mode） flashcard\n\n用户态  user mode\n内核态  kernel mode\nMode bit 为 0，表示 CPU 工作在内核态；mode bit 为 1 时，CPU 工作在用户态。modebit由特权指令进行管理。\n\n\n特权指令(privileged instruction)\n例如 I/O 控制，计时器管理，中断管理等。这些指令只能在内核态下执行，而用户态下执行这些指令时会认为这条指令不存在。\n\n\n                  \n                  是不是在kernalmode下运行的所有指令都是特权指令？ \n                  \n                \n\n不是，非特权指令也可以运行在kernalmode下，但是特权指令只能在kernalmode下运行\n\n\n双模式之间的交互\n用户委托进行危险操作的过程：比如writing data to a disk drive ，用户程序想要使用kernal提供的服务，需要调用系统调用（system call）切换到kernelmode。\n\n具体实现上即发生软中断（trap）的时候\n\n细节：将usermode本身执行的上下文保存下来以便于恢复等\n系统调用可能需要传递参数。参数可以放在寄存器里直接传递；也可以放在一块内存中，用寄存器传递地址；也可以用栈传递。\n\n\n\n                  \n                  能否让中断运行在usermode？ \n                  \n                \n\n不行，等同于kernel的权限和usermode是一样的，破坏了隔离性（多个user program都对设备进行io）\n\n\n系统调用\n\n系统向用户程序提供服务的一个接口，它们经常以 C/C++ 函数的形式存在，对于某些比较接近底层的任务，也可能是通过汇编编写的。\n但说到底，系统调用还是相对底层的设计，通常的开发并不基于如此底层的设计展开。更常见的是利用各种抽象层级更高的 Application Programming Interface, API 进行开发。\nAPI 是一个非常常见的概念，在我看来系统调用本身也是一种极为底层的 API。API 的核心思想是让调用者只需要知道如何与被调用者交流以实现目的，而不需要关心其具体实现。这同时也暗示着，只要 API 一致，同样的程序在不同的平台上也能直接编译后运行。\n显然，API 与编程语言往往是强相关的，特定编程语言在操作系统上运行也是需要一定的“环境”的，也就是我们所说的运行时环境(run-time environment, RTE)。RTE 通常包括了编译器(compilers)、解释器(interpreters)、库(libraries)和装载器(loaders)等，它们共同组成了一个完整的运行时环境。\n\n\n\n                  \n                  库函数与系统调用 \n                  \n                \n\n库函数运行在用户空间而系统调用运行在内核空间。大部分库函数可能使用系统调用来实现目的。\n\n\n\nsystemcall是函数 通过interface被调用 但是调用的过程比函数调用更复杂（根据systemcontrol的index下标去查询systemcall的表得到systemcall具体的内容）\n系统调用的分类\n\n链接器和装载器\n操作系统到底是如何执行一个程序的呢？以 C 为例，一个写完的代码需要经过编译、链接、装载三个步骤，才能成为一个在内存中的，可以被执行的程序。\n\n\n编译器首先将若干 .c 源文件编译为若干 .o 文件（这里合并了预处理、编译、汇编步骤），这些 .o 文件被称为可重定位目标文件(relocatable object file)，其存在形式为机器码\n\n\n随后链接器将若干 .o 文件连带所需要的一些库文件（如 .a 文件）链接为一个可执行目标文件(executable object file)。\n\n\n静态链接将库文件的代码直接合并进入最终的可执行文件\n\n\n动态链接仅仅将库文件的引用信息写入最终的可执行文件，而在程序运行时再去寻找这些库文件\n\n\n\n引导\n\n在计算机刚刚启动，操作系统还未开始运行之前，需要开机后的第一个程序——引导加载器(bootstrap loader)来一步一步地初始化操作系统。对大多数操作系统来说，bootstrap 都会被存储在 ROM 中，并且需要在一个已知的位置\nBootstrap loader 会载入更加复杂的，完整的 bootstrap，而包含 bootstrap 程序的分区就被称为引导分区(bootstrap partition)。\n\n同步/异步IO\n\n\n同步(synchronous)\n\n用户等待io操作的完成（控制权移交给操作系统直到io操作结束\n\n\n异步（Asynchronous)\n\nio操作启动以后用户发起io的请求后，控制权迅速返回调用程序，然后io操作再自己去进行（并记录好这个操作的有关信息比如是由哪个进程发起的 需要把得到的数据交给谁之类（device-status table\n\n\n\n\n\n三个management\nprocess management\n\n操作系统分配给进程一定的资源。进程在运行中需要始终拥有这些资源才能够运行完毕。\n\nprogram 静态概念\nprocess   运行中的动态实体（抽象概念\n\n一个程序可以有多个运行中的进程\n不同进程所占用的资源不同，因此可以说进程是一个资源分配的单位\n进程又可以有对应的子进程（树状继承关系\n\n\n\n进程当前指向的地址 pc寄存器\n一个程序可能有多个执行的顺序 叫做thread线程\n\n\n                  \n                  是否时在整个运行过程中，都要占有所有该进程需要的资源？ \n                  \n                \n\n进程运行的各个生命周期，需要的资源不同。在需要的时候再进行占用，不需要的时候进行释放，提高了灵活性和资源利用率。\n\n\n进程里面可以包含多个执行的序列：线程thread\n线程：执行的最小单位\n进程：分配资源的单位\n\n进程的创建\n\n进程的继承关系\n\n\n交互的能力（给另一个进程发消息 signal\n进程的状态\n删除进程\n多个进程之间共享内存（访问冲突\n\nmemory management\n\n让进程能（按照权限/规定）了解到自己目前所拥有的内存（静态分配or动态分配）的结构，的视图。\nstorage management\n在存储的介质上面（硬盘/SSD）\n\n提供一个抽象的访问接口：文件file\n文件的层结构：目录\n文件访问的权限\n文件是单个数据实体\n文件系统是一整套文件以及管理目录的整体\n磁盘上面分成若干块的partition 并赋予文件系统（一个盘符就代表一个单独的文件系统）\nmass-storage management\n海量存储管理，也就是磁盘管理\n相较于面向用户的storage管理 更多的是面向硬件的管理\nI/O subsystem\n\n\n\n                  \n                  system call能否实现成为library（函数调用 \n                  \n                \n\n存在安全性风险，比如软件调用特权指令等\n\n\n虚拟机\n本质其实是一种抽象\n给上层提供和底层硬件一样的interface\n\n\nhardware：host宿主机\nvirtual machine managerVMM/hypervisor：提供了具备操作系统特性的一个基本的管理软件，提供接口供虚拟机运行，结构相对来说简单\n\ntype1 裸金属的虚拟化baremtal hyperboza 比较好因为不需要完整的运行操作系统\ntype2 比如qemu 离不开地下原生os的运行\n\n\nguests：进程，可以运行多个进程（一个进程就是一个自成一体的完整操作系统 ）\n\n对guestos不做修改：全虚拟化\n对guestos做一点改动：半虚拟化，但是运行效率更高\nsysgen ：device driver之类的配置\n在操作系统power-on的过程中cpu执行的第一个软件（系统初始化自检硬件部分）：firmware固件\nbootloader是加载操作系统用的（locate kernel image on disk 并且加载进ram，switching the cpu mode for kernel execution）"},"课程笔记/操作系统/02.1-进程":{"slug":"课程笔记/操作系统/02.1-进程","filePath":"课程笔记/操作系统/02.1 进程.md","title":"02.1 进程","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n进程基本概念 flashcard\n\n一段本质上是静态的、存储在硬盘上的指令数据，而当它附带运行程序所需要的必要信息进入内存，得到相关资源后，它成为一个动态的、与计算机资源互动的实体，这个实体就是进程(process)。简单来说就是运行中的一个实例。\nprocess=job。\n\n\n进程的形式 flashcard\n在内存中需要一块虚拟的地址空间来存储。包含两个部分\n虚拟地址空间中的用户部分\n\ntext section(code) 存储代码 加载到内存前以 executable file 的形式存储在 disk 中\nstack section 常说的栈 存储一些暂时性的数据，如函数传参、返回值、局部变量等\ndata section 存储代码中的全局变量、静态变量\nheap section 常说的堆，被动态分配的内存\n\n\n内存映像：0~max地址之间的区域叫做address space\n\n\n进程访问的物理空间是虚地址，因此这里的max也叫做maxVA(最大的虚地址)\n空洞hole：这个部分其实占比例很大，是无法合法访问的区域。\ntext和data部分所需要的空间在一开始就被确定，heap和stack可以动态扩展和收缩（但是加上hole的整个空间不变）\n\n\n虚拟地址空间中的内核部分\nPCB\n\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\n\n\nprocess control block（PCB） flashcard\n操作系统用一个PCB表示进程，每个进程有且仅有一个PCB，PCB 是进程存在的唯一标志。其中包含许多当前进程的相关信息\n\nprocess state 进程的状态\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\nCPU-scheduling information CPU调度参考的信息，包括优先级、调度队列的指针、调度参数等。\nmemory-management information 包括页表、段表等信息，具体与实现的内存系统有关。\nAccounting information 一些关于进程的动态数据的统计和记录，比如已经跑了多久、时间限制、进程号等等\nIO status information 被分配给进程的IO设备列表、打开的文件列表等\n\n\n是每个进程所独有的数据，和别的进程无关。\n是抽象概念的数据结构，不一定实现为block。不同的系统可能有不同的 PCB。Linux 中的进程用结构体 task_struct存储。\n如果只是中断去处理什么而不涉及进程切换，PCB也可以不用工作，而重要的信息直接保存到kernel stack里面。\n\n\n\n进程管理\n进程树 (process tree)\n\n\n用户进程在操作系统中，总体上遵循树状组织形式，每一个进程有一个唯一标识符进程号（通常为pid）\n进程之间存在一种父子关系，即 child 进程是由 parent 进程创建的，用 ppid 来标识它的 parent 进程\n\n进程的创建 flashcard\n\nchild 进程的资源可能直接来自操作系统的分配，也可能来自 parent 进程的继承，限制使用后者的好处是能够避免因为创建太多子进程而导致资源不够用。\n进程树的根是 systemd，历史上也曾叫过 init，它是操作系统启动后运行的第一个用户进程，至少在 Linux 中，它的 pid 被分配为 1，而它的 ppid 是 0，可以理解为这个进程的 parent 是 scheduler 而非一个进程\n\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;sys/types.h&gt;\n \nint main() {\n    printf(&quot;A process starts!\\n&quot;);\n \n    pid_t pid;\n    **pid = fork();**\n \n    if (pid &lt; 0) {\n        printf(&quot;Fork failed!\\n&quot;);\n    } else if (pid == 0) {\n        // sleep(1);\n        printf(&quot;pid is zero, so it&#039;s child process!\\n&quot;);\n    } else {\n        **// wait(NULL);**\n        // sleep(1);\n        printf(&quot;pid is nonzero thus it&#039;s parent process!\\n&quot;);\n    }\n}\n \n\nUNIX 系统中可以使用系统调用 fork() 来创建一个新进程。这个新进程是父进程的一份拷贝，它们只有 pid 和 ppid 不同，另外子进程当前内存使用记录为 0，除此以外全部相同。\npid = fork()之后，内存中有两个进程，一起从这行代码的下一行往下执行，通过检查返回值pid来判断属于parent还是child。在父进程中，fork（）返回的是创建的子进程的pid，子进程返回0，执行失败返回负数。\n\n这里的pid_t是一个局部变量\n\n\nwaite（NULL） 即父进程可以继续运行，或者等待子进程运行完以后再运行\n\n使得当前进程进入 waiting 状态，并在任一子进程终止，或被信号停止，或被信号恢复时进入 ready 状态，同时返回发生该事件的子进程的 pid\n如果第 18 行仍然被注释，那么 parent 进程和 child 进程将并发执行，即完成 fork() 后两个进程都从 11 行开始继续向下并发的执行，互不阻塞\n\n操作系统会让它们交替使用CPU。谁先完成自己的printf，完全取决于操作系统的“心情”（调度）。所以可能会先看到父进程的输出，也可能先看到子进程的输出。\n\n\n如果 18 行的注释被取消，那么 parent 进程将等待 child 进程结束后再继续。\n\n父进程执行wait(NULL)这行时，会被阻塞，需要等到子进程完全结束（执行完所有代码或调用了exit）之后才能继续往下执行自己的内容，子进程输出一定在父进程之前\n逻辑上创建的新进程有两种情况：\n\n\n\n\n\n\n复制 parent 进程的代码数据；\n载入新的程序并继续执行；\n而实际在 Linux 中，第一种通过 fork() 实现，第二种通过 fork() 后 execXX() 实现，execXX() 会覆盖那个进程的地址空间，以实现执行其他程序\n\n进程的终止 flashcard\n\n当进程调用 exit() 这个系统调用时，将被终止。\nC 语言 main 函数返回时也会隐式地调用 exit()。\n进程也会由于一些信号、异常等终止。\n这意味着这个进程将不再执行，其资源将被释放，同时返回状态值，而这个状态值将被 parent 进程的 wait() 接收。\n\n父进程通过调用 wait() 来做两件事：\n\n等待子进程结束。\n接收（回收） 子进程的这个“状态码”（检查作业本）。\n\n\n特别的，如果 parent 进程尚未调用 wait()，则这个 child 进程还不会完全消失，因为要返回的东西还没返回（child 并不知道 parent 会不会、什么时候来回收它）。这种逻辑上已经终止，但仍然占有一部分资源，等待 parent 进程调用 wait() 的进程，我们称之为僵尸进程(zombie)。\n当子进程没有结束，或者终止了但父进程没有调用 wait() 的情况下，父进程就结束了，子进程就会成为 孤儿进程 (orphan processes)（如果parent exiting ，成为孤儿进程，它的父进程变成init process（pid=1）init 进程会定期调用 wait()）\n\n\n\n进程间通信\n\n\n如果一个进程受到其它进程的影响，或会影响其它进程，那么我们称之为协作进程(cooperation process)，比如一个进程的输出作为另一个进程的输入使用，之类的。\n\n为了模块化设计，必不可少\n\n\n\n进程间通信(inter-process communication, IPC) flashcard\n\n是为了在进程的资源相互隔离的情况下，让不同的进程能相互访问资源从而协调工作。\n两种方式\n\n共享内存(shared memory)：（a）\n\n相比下面几种效率更高，需要用到 system call 的地方只有建立共享内存的时候\n两个进程各自有一块虚拟内存，映射到同一块物理内存。\n也需要信号量等同步手段保护\n\n\n消息传递(message passing)：（b）\n\n在分布式系统中更容易实现，对于少量数据通信很有用（因为不需要处理冲突问题 ）；\n\n建立link\n\n直接通信 特定某个id的进程\n间接通信 中转手段，比如信箱mailbox（well-known mailbox//ports）\n\n\n同步 blocking\n\nblocking send  让sender blocked 直到信息被接收到\nblocking receive receiver block直到信息可以被接收到\n\n\n异步 non-blocking\n\n\n\n\n\n\n\n\n\n信号量(semaphores)：本意用来线程间同步，但是可以通过 sem_open() 系统调用来建立和维护进程间的信号量；这样的信号量属于 OS 资源，它会在相关进程结束后由 OS 释放\n\n\n文件 / 管道(pipe)：\n\n管道本质上也是一种文件，创建管道时操作系统会返回两端的文件描述符\n但一个管道只支持单向传输，即只能 A 写 B 读，如果要实现双向需要两个管道【逻辑上是一个半双工的信道】\n\n\n\n\n【模型】producer-consumer problem\nproducer 信息输出方\nconsumer 信息接收方\n\n无界缓冲区 unbounded-buffer 缓冲区的大小相比于发送的信息相比不会满\n有界缓冲区 bounded-buffer\n\nproducer往buffer中放入items，consumer取出\n指定指针index-in给producer使用，index-out提供给consumer\n\n\n检查如果==out：认为没有freeitem是可以放的【下一个位置就是out指针】\n否则放入并且后移一位：0~buffersize-1，下一个又从0开始【理解为环形队列】\n\n\n\n\n如果有可取用的item 就往后移一位，并取出使用\n问题是：会浪费一个element 当out=1 in=0的时候 in没有办法insert进去了\n：\n\n\n\n\n"},"课程笔记/操作系统/02.2-调度":{"slug":"课程笔记/操作系统/02.2-调度","filePath":"课程笔记/操作系统/02.2 调度.md","title":"02.2 调度","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n就绪队列(ready queue)和等待队列(wait queue) flashcard\n实际上换进程就是换PCB的指针位置放到哪个队列（kernel负责移动）\n\n\nready quene（里面的process都处在ready状态）（ CPU等待队列：）\n实际实现中，由于等待的io或者事件不同，可能维护多个等待队列。\n\nIO设备等待队列：device queue 等待完用好IO设备之后PCB被移走\n\n\n\n不需要等待其他设备也不需要使用处理器的进程？：空闲状态、将要结束的状态等，这样的进程就不会出现在上述队列中，会被放在job queue（系统中所有进程都在其中）\n\n\n进程状态state flashcard\n进程在execute时会改变状态。一个处理器上只有一个进程可以running。\n\nnew\n\n进程正在创建过程中，包括申请 PCB，分配初始资源等；\n\n\nrunning\n\n进程正在运行（正在使用CPU资源）\n有几个核就最多有几个进程处于running状态\n\n\nwaiting\n\n进程正在等待某个事件的发生，比如调用systemcall之后进程暂停的状态/IO操作中/其他event\n此时即使有空余的 CPU 资源，该进程也无法继续\n一般进程从running到waiting是主动的（系统调用之类 ），离开waiting进入ready是被动的\n\n\nready\n\n进程已经准备好了只差CPU资源，一旦有CPU资源可以分配给该进程，就会变为running态（等待 CPU 资源的派发(dispatch)，接受调度）\n如果有进程ready 说明一定有进程正在running\nCPU 调度实际上指的就是若干进程在ready和running之间的切换，当发生了 interrupt，如计时器到时间了，running就会切换到ready\n\n\nterminated\n\n进程因为某些原因终止，结束运行，需要释放资源；\n\n\ninterrupt触发后，本来要执行的指令被中断，os陷入到kernel中，在进行中断处理的时候，发现允许进程处理的时间片到了，那么就需要把这个进程换下来换成别的进程。原本的那个进程进入ready的状态。\nscheduler dispatch 调度程序，决定下一个将要运行的进程\nwaiting不能直接进入到runing必须经过ready\n\n\n调度\nscheduler类型 flashcard\n\n\nlong-term scheduler：（job scheduler）\n\n历史上的概念，主流操作系统里面已经没有了，现在实际上就是用户自己在担任这个角色。选择哪个processes需要从硬盘进入memory（the ready queue）\n如果允许太多io bound的进程进入cpu 那么就会阻塞在io queue里面，那么cpu就得不到有效的使用，因为等待io的进程太多，而准备运行的进程太少\n\n\nshort-term scheduler （CPU scheduler）\n\n多道 (multiprogramming) 环境下，进程的个数通常大于 CPU 的个数。CPU 调度就是 OS 关于哪个 ready 进程可以运行（使用 CPU）以及运行多久的决定。\n\n\nmedium term scheduler\n\n主内存严重不足时，需要将优先级较高的进程先加载到RAM（主内存）中。\n换到外存（硬盘）中（wipe out）之后状态仍然是waiting，当接收到所需的用户输入之后，会被考虑重新换到内存中。\n\n\n\n\n进程类型\n\nI/O-bound (I/O 密集型): 这种程序大部分时间都在“等待”。比如等待网络数据、等待读取硬盘文件。它只需要 CPU 算一小会儿，然后就去等待 I/O。\nCPU-bound (计算密集型): 这种程序是需要 CPU 一直不停地算很久，很少需要等待 I/O。比如视频渲染、科学计算。\n一个好的操作系统会混合搭配这两种程序，确保 CPU 和硬盘/网络都能保持忙碌，提高整体效率。\n\n\n\n                  \n                  Title \n                  \n                \n\n\n主内存 就是内存，CPU工作的区域，而 RAM 是主内存的物理实现。\n外存  SSD/HDD(硬盘)是外存的物理实现\nROM 是一个完全不同的东西。它是一个小容量、只读、断电不丢的芯片，它的唯一工作就是在你按下开机键时，引导电脑去“外存”里加载操作系统到“主内存(RAM)”中\n\n\n\n调度的时机 flashcard\n\nscheduler调度\n\n非抢占式调度(non-preemptive scheduling) running的进程由于某些原因需要主动离开running状态【绿色】\n抢占式调度(preemptive scheduling) ready的某个进程需要立刻得到CPU资源【蓝色】\n\n其他态转变为ready态来排队\n或者在排队的时候某个人想插队（优先级调度 ）\n\n\n非抢占式调度是由已经拥有资源的进程主动释放 CPU 资源引起的，而抢占式调度则是不占有资源的进程索取 CPU 资源成功引起的。\n\n\n调度的过程：上下文切换 flashcard\n由 CPU scheduler 选择哪一个ready态的将要被执行后，由 dispatcher 来完成具体的切换工作包括：\n\n在两个进程间进行上下文切换(context switch，包括恢复现场、保证进程执行一致性的过程)\n\n上下文：① CPU 寄存器中的值，② 进程状态，③ 内存的管理信息\n\n\n切换到用户态；\n跳转到用户程序中合适的位置以继续进程执行；\n\n\n进程切换：包括被中断和systemcall两种\n\n被中断 进入ready\nsystem call 进入waiting\n\n\n而从 dispatcher 停止上一个运行时的进程，完成上下文切换，并启动下一个进程的延时，称为 dispatch latency。\n\n\n\n调度算法\n调度算法的评价指标(scheduling criteria) flashcard\n\nMaximize CPU Utilization \n\nCPU 使用率，CPU 使用时间 / 总时间。即 CPU 非空闲的时间比例\n从 CPU 是否足够忙碌来看硬件性能是否充分发挥\n\n\nMaximize Throughput \n\n吞吐量，每个时间单元内完成的进程数\n从结果来看任务完成是否足够高效\n\n\nMinimize Turnaround Time\n\n周转时间，从进程创立到进程完成的时间，包括等待进入内存、在 ready queue 中等待、在 CPU 上执行、I/O 执行等时间\n通过观察最大周转时间，能反映调度的效率和“公平性”\n\n\nMinimize Waiting Time \n\n等待时间，在 ready queue 中（或在 Ready 状态下）等待所花的时间之和\n由于任务所需要的 CPU 时间、I/O 时间不受调度算法影响，所以抛开这些只看在 ready queue 中的等待时间，能反映调度算法的效率\n等待时间 = 周转时间 - 运行时间\n\n\nMinimize Response Time \n\n响应时间，交互系统从进程创立到第一次产生响应的时间\n能反应交互式系统中调度算法的“及时性”\n\n\n\n\n调度算法\n以下调度算法存在理想化建模，以及以multiprogram为基础\nFirst-Come, First-Serve (FCFS) | Nonpreemptive flashcard\n先申请 CPU 的进程首先获得 CPU，用First-In, First-Out（FIFO）队列实现\n\n\nShortest-Job-First (SJF) flashcard\nSJF 的核心想法是，让下一次运行时间最短的进程先来运行；根据数学知识，我们可以得知这样能得到最少的平均等待时间\n\n对于非抢占式的系统来说，当我们忽略 I/O 等会进入 waiting 的情况（因为题目通常这样设计），进程「下一次运行时间」就是整个进程所需的总运行时间。\n对于抢占式的系统而言，「下一次运行时间」实际上是进程的剩余运行时间，因为进程可能曾经被打断过。\n因此我们将 SJF 进一步细分成了两种。\n\nNon-preemptive: Shortest-next-CPU-burst\n选取 ready queue 中下次 CPU 执行时间最短的进程。这样会使得给定的一组进程具有 minimum average waiting time.\n\n\n在这个情景中，0s 时只有 P1 到达，因此 P1 先运行\n由于是非抢占式的，因此 P1 运行过程中其他进程的到达并不会导致重新调度，P1 得以完全运行\nP1 结束时，剩余进程都已到达，处于 ready 状态，因此调度器从 ready queue 中选取 brust time 最短的来运行，以此类推。[一个进程运行结束后进行再调度]\n\n​Preemptive: Shortest-remaining-time-first(SRTF)\n​每当 CPU 调度时（注意抢占式调度的调度时机），选择最短剩余运行时间的进程。\n\n\n在这个情境中，0s 时只有 P1 到达，因此 P1 先运行\n但不同的是，由于是抢占式的，因此 2s P2 到达时也会引发一次调度，此时 P1 的剩余时间是 8s，P2 是 6s，因此 P2 优先运行\n4s 时 P3 到达也引发一次调度，但此时 P1 的剩余时间是 8s，P2 是 4s，P3 是 7s，其中 P2 最短，因此仍然是 P2 继续运行[新进程到达时发生一次调度]\n5s 时 P4 到达也引发一次调度，此时 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，P4 是 2s，其中 P4 最短，因此 P4 优先运行\nP4 运行结束时，ready queue 中 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，因此 P2 先运行，以此类推。\n​SJF 的两个版本都可以获得最小的平均等待时间，但最大的问题在于我们并不知道「下一次运行时间 」。解决方案是预测，将下次执行时间预测为此前 CPU 执行长度的指数平均。指数平均需要操作系统统计该进程此前的运行情况\n\n\nRound-Robin (RR) | Preemptive flashcard\n定义一个 时间片 (time slice / time quantum) ，即一个固定的较小时间单元 (10-100ms)。\n\n除非一个 process 是 ready queue 中的唯一进程，它不会连续运行超过一个时间片的时间。\nReady queue 是一个 FIFO 的循环队列。每次调度时取出 ready queue 中的第一个进程，设置一个计时器使得进程在一个时间片后发生中断，然后 dispatch the process。\n\n相比 SJF 而言，平均等待时间更长，但响应时间更短。\n​RR scheduling 的性能很大程度上取决于时间片的大小。如果时间片较小，则 response/interactivity 会很好，但会有较大的 overhead，因为有较多的 context-switch；时间片较大则响应较差，但 overhead 会较小。\n如果时间片无限大，则 RR≈FCFS。\n在实践中，时间片大约 10~100ms，每次 contest-switch 约 10μs。即 context-switch 的时间花费是比较小的。\n\n\nPriority Scheduling flashcard\n每个进程都有一个优先级，每次调度时选取最高优先级的进程。（下例中规定优先级值小的优先级高）\n优先级可以是内部的或者外部的：\n\ninternal: 一些测量数据，例如 SJF 是 Priority 的一个特例，即优先级由预测 CPU 运行时间决定。\nexternal: 由用户指定进程的重要性。\n​要实现 Priority Scheduling，可以简单地将 ready queue 用 priority queue 实现；priority queue 也可以是抢占式或非抢占式的，如 SJF 一样。\n​Priority 的一个重要问题是 indefinite blocking / starvation ，即低优先级的进程可能永远没有机会被执行。一个解决方法是 Priority Aging ，即根据等待时间逐渐增加在系统中等待的进程的优先级。\n\n\nMultilevel Queue Scheduling flashcard\n在实际应用中，进程通常被分为不同的组，每个组有一个自己的 ready queue，且每个队列内部有自己独立的调度算法。\n\n前台队列使用 RR 调度以保证 response，后台队列可以使用 FCFS。\n队列之间也应当有调度。通常使用 preemptive priority scheduling，即当且仅当高优先级的队列（如前台队列）为空时，低优先级的队列（如后台队列）中的进程才能获准运行。\n使用队列间的 time-slicing，例如一个队列使用 80% 的时间片而另一个使用 20%。\n\n\n\nMultilevel Feedback Queue Scheduling flashcard\n​Multilevel Feedback Queue Scheduling 允许进程在队列之间迁移。这种算法可以有很多种实现，因为队列的数量、每个队列中的调度策略、队列之间的调度算法以及将进程升级到更高优先级/降级到更低优先级的队列的条件都是可变的。一个系统中的最优配置在另一个系统中不一定很好。这种算法也是最为复杂的。\n\n有三个队列 0, 1, 2，优先级逐次降低。\n当进程 ready 时被添加到 Q0 中，Q0 内部采用 RR Scheduling，的每个进程都有 8ms 的时间完成其运行，如果没有完成则被打断并进入 Q1；\n只有当 Q0 为空时 Q1 才可能被运行。Q1 内部也使用 RR Scheduling，每个进程有 16ms 时间完成其运行，如果没有完成则被打断并进入 Q2；\n只有当 Q1 也为空时 Q2 才可能被运行。Q2 内部采用 FCFS 算法。\n"},"课程笔记/操作系统/02.3-线程":{"slug":"课程笔记/操作系统/02.3-线程","filePath":"课程笔记/操作系统/02.3 线程.md","title":"02.3 线程","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n多线程编程Multi-Threaded Programming flashcard\n》线程是一种轻量级的进程，它在进程的基础上进行划分，是进程内的一个可调度的执行单元，以减小进程 folk 和切换的开销为目的。\n》对于支持线程的操作系统，实际调度的是内核级线程而非进程。也就是说，线程是运行以及 CPU 调度的基本单元。（而进程是分配资源的基本单元。）\n同一进程的若干线程\n\n共享代码、数据等“相对静态”的资源\n各自维护寄存器、栈、PC 等“相对动态”的资源\n\n优点\n\n立线程相比进程是很经济的，因为 code, data &amp; heap 已经在内存中了。在同一进程的线程间进行 context switch 时也会更快，因为不需要 cache flush\n线程天生和同一进程内的其它线程共享资源，因此同进程内线程天生就有线程间通信的能力。不需要IPC（inter-process communication）进行不同进程间交流\n同时，由于将进程进行了再划分，一方面在硬件支持的情况下能更好地适配并行，另一方面也能（代价更小地）让任务的粒度变小，此时可以将整个进程的阻塞转移到单个线程的阻塞上，进一步减少响应时间。\n\n缺点\n\n虽然将若干任务都放到一个进程的多线程可以提高效率，但是一旦“篮子”坏了，那所有“鸡蛋”都无法幸免；\n其次，虽然天然的共享属性让线程能更方便地进行线程间通信，但也带来了内存保护的问题。\n由于 OS 对每个进程地址空间的大小限制，多线程可能会使得进程的内存限制更加紧缩（这在 64 位体系结构中不再是问题）\n\n\n线程实现方式 flashcard\n按照线程划分的实现位置，多线程模型分为\n\n用户级多线程(user threads)\n\n它在操作系统上只是一个进程，这个进程包含 线程库 (Thread Library) 的部分，​这部分代码负责完成线程的创建、切换等操作；\n\n\n内核级多线程(kernel threads)。\n\n内核级线程则是由操作系统支持这些操作。\n两者各有优缺点：\n\n\n用户级多线程 &gt; 内核级多线程\n\n用户级多线程不需要进入内核态实现多线程，也不需要占用线程 ID，因此理论上可以比内核级支持更多的线程数；\n由于其划分是针对进程的，而不同进程之间的线程实现没有直接关系，而且由于是在用户空间实现算法，所以能够更容易的对单个进程内的多个线程的调度算法进行自定义；\n\n\n用户级多线程 &lt; 内核级多线程\n\n由于对内核来说，用户级多线程仍然是一个普通的进程，所以当用户级的线程出现阻塞时，内核会认为整个进程都被阻塞；内核级线程由于是内核实现，所以单线程的阻塞并不会导致整个进程阻塞；\n在多核的情况下，用户级多线程没法利用多核进行线程并行；只有内核 (OS) 才能把工作分配到不同的 CPU 核心上\n\n\n\n\n多线程主要模型 flashcard\n需要注意的是，用户级多线程和内核级多线程并不冲突，因而排列组合后得到多线程主要有如下三种模型：\n\n(a) One-to-one model. (b) Many-to-many model. (c) Many-to-one model.\n\n每个用户线程都创建一个内核线程，开销大，但是不会有一个阻塞都被阻塞的问题\n可以智能地调度userthread要用哪个kernelthread，一个被阻塞了就换另一个kernelthread工作\n只给kernelthreads分配一个CPUcore，一个被阻塞就会都被阻塞[kernelthread的阻塞问题]\n\n\n\n线程池\n\n适用场景：大量同时并发任务处理"},"课程笔记/操作系统/03.1-进程同步及其工具":{"slug":"课程笔记/操作系统/03.1-进程同步及其工具","filePath":"课程笔记/操作系统/03.1 进程同步及其工具.md","title":"03.1 进程同步及其工具","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n并发: 同时运行但不一定完全对齐重叠,\n并行: 更加严格\n\n\n「​同步」的核心意义是，规定进程所做的工作之间的顺序或者先序关系，从而防止一些非法情况的发生。\n\n为什么需要同步\n\n Cooperating Process 是可以影响系统中其他运行进程或被其他进程影响的进程。\nCooperating processes 会共同使用一些数据\n\n可能是直接使用同一段地址空间（代码+数据）\n或者是通过共享的内存或信息传递来共用一些数据。\n\n\n因为数据的一致性需要 cooperating processes 有序的运行[与操作的时序有关]。对数据的同时访问 (concurrent access) 可能会导致 data inconsistency\n\nrace condition:\n\n多个进程同时操控同一个数据，因而结果取决于每一种操控的出现顺序的情形\n防止 race condition，我们需要保证同一时间只有一个进程可以操控某个变量。\n\nBounded-buffer Problem中的race condition问题\n给定两个进程：producer 和 consumer，它们共用大小为  的 buffer。Producer 生产数据放入 buffer，consumer 从 buffer 取出数据从而使用之。\n该问题需要保证：producer 不应当在 buffer 满时放入数据，consumer 也不应当在 buffer 空时取出数据。\n我们可能想要像这样实现这两个进程：\n/* Producer Process */\nwhile (true) {\n    /* produce an item in next_produced */\n    while (count == BUFFER_SIZE)\n        ; /* do nothing */\n    //直到消费者取走一个数据,导致count&lt;buffer_size\n    buffer[in] = next_produced;\n    in = (in + 1) % BUFFER_SIZE;\n    count++;\n}\n \n/* Consumer Process */\nwhile (true) {\n    while (count == 0)\n        ; /* do nothing */\n    next_consumed = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    count--;\n    /* consume the item in next_consumed */\n}\ncount++ (生产者做的) ：\n\nregister1 = count: 把内存里的数搬到 CPU 寄存器里\nregister1 = register1 + 1: 寄存器加 1\ncount = register1: 把算好的新值写回内存\ncount-- (消费者做的) 同理，也是搬运、减 1、写回。\n但是一系列操作是可以被打断的,所以可能会有下述运行顺序导致count值发生错误\n\nkernel中请求子进程pid中的race condition问题\n\n同时都去获取一个子进程pid,但是next_available_pid还未来得及更新的情况\nThe Critical-Section Problem flashcard\n\n考虑一个有 n 个进程的系统，每个进程中都有这样一段代码，它可能会修改一些与其他至少一个进程公用的数据，这段代码称为 critical section\n\n这个系统需要满足的重要性质是：当一个进程正在运行它的 critical section 时，其他进程都不能进入它的 critical section。\n\n\n需要设计一种能让各个进程 同步 (synchronize) 它们的活动，从而安全地共享数据的协议。\n\n\n\n​\nCritical-section problem 的解决方法必须满足如下三个要求 flashcard\n\nMutual exclusion:没有两个进程可以同时运行 critical section。\nProgress:系统整体上是在运行的,\nBounded waiting :提出请求后不会无限等待,最终一定能够进入 critical section\n\n\nkernel中的CS problem\n\n\n​对于单核系统，我们可以通过在 critical section 中禁止中断[即在 entry section 中 disable，在 exit section 中 enable]的方式来实现上述功能（虽然可能是危险的）\n\n\n但是对于多核系统，中断禁止的消息要传到所有核[不然别的进程会进入自己的cs]，消息传递会延迟进入临界区，会降低效率；同时也会影响时钟中断。\n\n\n我们需要保证 kernel 的设计实现了 critical section。Kernel 的实现分为两种类型\n\n分别是 抢占式内核 preemptive kernel 和 非抢占式内核 nonpreemptive kernel，其区别是是否允许处于 kernel mode 的进程被抢占。\n\n\n\n对单核来说\n\n非抢占式内核不会导致 kernel mode 的 race condition，因为在任一时间点只有一个进程能在内核态里跑.\n​抢占式内核要解决 critical-section problem 的话相对而言更难设计，但是同时也能有更快的响应。\n\n\n\n关于处理器/核/内核态/用户态的辨析.\n\n\nCPU(通常指物理封装的芯片)上可能有单核/多核.一个核只能同时运行一个任务.\n\n核之间共享总线接口和3级缓存\n但是12级缓存和计算单元是属于核自己的\n\n\n内存是单独的,cpu也是单独的,cpu只是加载内核代码去跑而已.实际上,内核态和用户态本质上没有区别,只是特权模式\\特权寄存器\\访问代码权限的区别.\n\n\nPeterson’s Solution\nPeterson’s solution 基于一定的假设解决了两个 task 的 synchornization：\nint turn;           // Who is allowed to enter\nboolean flag[2];    // Ready to enter its CS\n \nvoid foo() {\n    while (true) {\n        flag[i] = true;     // Mark self ready\n        turn = 1 - i;       // Assert that if the other process wishes to 如果我是1那么1-i就是0,如果我是0那么1-i就是1,这是一个谦让策略.\n                            // enter its CS, it can do so.\n        while (flag[1 - i] &amp;&amp; turn == 1 - i);   // Wait\n        /* critical section */\n        flag[i] = false;    // Set ready to false\n        /* remainder section */\n    }//谁最后执行 `turn = 1 - i`，谁就会因为“太客气”而被卡在门口等待\n}\n其中， i 是 0 或 1，表示第 i 个进程； turn 是当前有权进入 critical section 的进程（0 或 1）； flag[i] 是第 i 个进程是否准备好进入 critical section，初始值均为 FALSE。\n性质证明\n通过简易的分类讨论证明 Peterson’s Solution 满足三个性质：Mutual exclusion, process and bounded waiting。\n\np0已经在cs里面的时候p1无法进入\n\n如果p0成功进入cs,那么while (flag[1] &amp;&amp; turn == 1)为假.\np1的情况:可能是flag[1] = false,他自己不想进.或者flag[1] = true 但 turn = 1,但是这和上一条矛盾了.因此不存在.\nflag[1] = true 且 turn = 0符合.\n\n\n如果没有人在cs内,且有人想进去,就可以进,不会导致死锁\n\n因为 turn 或者是 0，或者是 1，不可能既是 0 又是 1。总有一个人能突破循环\n\n\n杜绝了饥饿\n\n当p1出来的时候会执行flag[1] = false,可以当p0进去.不会导致p0一直无法进入cs\n\n\n\nReordering\n1. 指令重排\n但实际上，Peterson’s solution 在现代计算机体系结构上不一定适用，因为现代的处理器和编译器有可能会为了优化性能而对一些读写操作进行重排。\n在优化中，处理器或编译器会考虑其重排的合理性，即保证了在单线程程序中结果值是稳定且正确的。但是这不能保证其在多线程共用数据时的正确性，重排可能会导致不稳定或者不期望的输出。例如如果编译器将对 flag[i] 和 turn 赋值的顺序交换：\n\n2. 内存访问重排Memory Access Reordering\n因为存在读写缓存,所以就算指令的执行顺序不变, 内存层面上的顺序还是有可能发生变化\nMemory Barrier\n​重排可能使得在多核运行时出现与期望不同的结果。为了解决这个问题，我们引入 Memory Barrier：它用来保证其之前的内存访问先于其后的完成。即，我们保证在此前对内存的改变对其他处理器上的进程是可见的\n遇到这行命令就停下来直到内存读写完毕.\nMemory Model\n​另外，在现代的体系结构上，一个线程写了对应的变量后有可能不会立刻写回内存，这也有可能导致问题：\n计算机架构如何确定它将向应用程序提供什么样的内存保证，这被称为其内存模型。通常，内存模型分为以下两类之一：\n\nStrongly ordered, 一个处理器[在操作系统原理和并发编程的语境下,处理器=核!=CPU]上修改了内存,其他所有处理器会马上看到修改后的值,即大家看到的顺序一致.\n\n友好,但是频繁通讯.比如x86\n\n\nWeakly ordered, 与strongly相反,其他处理器不一定能马上看到 ,甚至可能看到乱序.\n\n灵活,性能高;但是危险,需要显式使用memorybarrier.比如arm核riscv\n\n\n\n硬件指令\n​许多现代系统提供硬件指令，用于检测和修改 word 的内容，或者用于 atomically（uniterruptably，不可被打断地）交换两个 word。这里，我们不讨论特定机器的特定指令，而是通过指令 test_and_set() 和 compare_and_swap() 抽象了解这些指令背后的主要概念。\ntest_and_set\n指令 test_and_set() 的功能可以按如下方式来定义：这一指令的重要特征是，它的执行是 atomic 的。\nbool test_and_set(bool *target) {\n    bool rv = *target;\n    *target = true;\n    return rv;\n}\n我们可以在支持这个指令的机器上实现 mutual exclusive：定义一个 bool 变量 lock ，初始化为 false。进程的结构为：\nwhile (true) {\n    /* Entry Section */\n    while (test_and_set(&amp;lock))     \n        ; /* do nothing */\n \n    /* Critical Section */\n \n    /* Exit Section */\n    lock = false;\n \n    /* Remainder Section */\n}\n\n如果 lock 在 Entry Section 时为 true，那么 test_and_set(&amp;lock) 将返回 true，因此会始终在 while 循环中循环。[锁住了,所以不能进入cs]\n到某个时刻 lock 为 false，那么 test_and_set(&amp;lock) 将返回 false 同时将 lock 置为 true，进程进入 Critical Section，同时保证其他进程无法进入 Critical Section。\n当持锁的进程完成 Critical Section 的运行，它在 Exit Section 中释放 lock ，从而允许其他进程进入 Critical Section。\n而如果某个时刻 lock 为 false，而有两个或多个进程几乎同时调用了 test_and_set(&amp;lock) 。但由于它是 atomic 的，因此只有一个进程可以返回 false。\n​但是，如上所示的控制不能满足 bounded waiting 条件：\n\n​我们可以作如下更改以满足 bounded waiting：\n\nwhile (true) {\n    /* Entry Section */\n    waiting[i] = true;\n    while (waiting[i] &amp;&amp; test_and_set(&amp;lock))   \n        ; /* do nothing */\n    waiting[i] = false;\n \n    /* Critical Section */\n \n    /* Exit Section */\n    j = (i + 1) % n;\n    while ((j != i) &amp;&amp; !waiting[j]))\n        j = (j + 1) % n;\n    if (j == i)\n        lock = false;\n    else\n        waiting[j] = false;\n \n    /* Remainder Section */\n}\n我们引入了 bool 数组 waiting[] \n\n在 Entry Section 中，我们首先置 waiting[i] 为 true；当 waiting[i] 或者 lock 中任意一个被释放时，进程可以进入 Critical Section。\n初始时， lock 为 false，第一个请求进入 CS 的进程可以获许运行。\n在 Exit Section 中，进程从下一个进程开始，遍历一遍所有进程，发现正在等待的进程时释放它的 waiting[j] ，使其获许进入 CS，当前进程继续 Remainder Section 的运行；\n如果没有任何进程在等待，那么它释放 lock ，使得之后第一个请求进入 CS 的进程可以直接获许。\n这样的方式可以保证每一个进程至多等待 n-1 个进程在其前面进入 CS，满足了 bounded waiting 条件。\n\ncompare_and_swap\n指令 compare_and_swap() 可以如下定义：同样，compare_and_swap() 的执行是 atomic 的。\nint compare_and_swap(int *value, int expected, int new_value) {\n    int temp = *value;\n    if (*value == expected)\n        *value = new_value;\n    return temp;\n}\n类似地，我们声明一个全局变量 lock ，初始值设为 0。进程的结构为：\nwhile (true) {\n    /* Entry Section */\n    while (compare_and_swap(&amp;lock, 0, 1) != 0)  \n        ; /* do nothing */\n \n    /* Critical Section */\n \n    /* Exit Section */\n    lock = 0;\n \n    /* Remainder Section */\n}\n可见，compare_and_swap() 和 test_and_set() 没有本质区别。上例 compare_and_swap() 的使用方法同样无法保证 bounded waiting，我们可以使用与 test_and_set() 同样的方式来解决。\nAtomic Vaviables\n​可以使用 compare_and_swap() 指令来实现一些工具。其中一个工具就是 Atomic Variable。\n​一个变量在更新的过程中可能会导致一个 race condition，而 Atomic Variable 可以为数据提供 atomic updates。例如，我们使用不可打断的 increment(&amp;count); 指令来代替可被打断的 count++ 指令就可以解决本节开头的 Bounded-buffer Problem：\nvoid increment(atomic_int *v) {\n    int temp;\n    do {\n        temp = *v;\n    } while (temp != compare_and_swap(v, temp, temp+1));\n}//如果还是temp,那么+1,如果不是的话就修改失败:cas返回v的值,发现确实不相等,继续循环.\n\n\n并不是为了让v一直保持某个值,而是为了v变化时原本的值不丢掉.如果两个操作读到同一个v的旧值,那么它们各自相加的话不会得到叠加的结果而是会有人被覆盖掉.如果用AtomicVariable,如果原本的数值被改了,就取最新的值,确保了数据没有被损坏.\nCAS操作本身是原子的\n\n\n但是需要注意的是，Atomic Variable 并不能解决所有 race condition，因为它解决的问题仅是变量更新过程中的 race condition。因为check和act之间存在时间差,所以这个时间内还是可能被打断.\nMutex\n​我们尝试设计软件工具来解决 CS problem。我们讨论 Mutex (MUTual EXclusion) Lock 的实现，它通常被认为是最简单的 synchronization tool。\n​我们考虑让进程在 Entry Section 申请 acquire() 一个锁，然后在 Exit Section release() 一个锁。对于这个锁，我们用一个布尔变量来表示它是否 available：\nwhile (true) {\n    acquire();\n    /* critical section */\n    release();\n    /* remainder section */\n}\n \n/* ------- */\nvoid acquire() {\n    while (!available)\n        ; /* busy waiting */\n    avaliable = false;\n}\n \nvoid release() {\n    avaliable = true;\n}\n我们需要保证 acquire() 和 release() 是 atomic 的。我们可以使用 test_and_set() 和 compare_and_swap() 来实现：\nvoid acquire() {\n    while (compare_and_swap(&amp;available, 1, 0) != 1)\n        ; /* busy waiting */\n}\n \nvoid release() {\n    available = true;\n}\n\n​我们还可以考虑下面的设计，其中 yield() 会使程序从 running 转为 ready，从而让出 CPU：\nvoid acquire() {\n    while (compare_and_swap(&amp;avaliable, 1, 0) != 1)\n        yield(); \n}\n \nvoid release() {\n    avaliable = true;\n}\n​不过，如果所需的等待时间一般小于 context switch 所需的时间的话，用 spinlock 可能是更好的\nSemaphores\n我们给出一种更厉害的 synchronization tool，称为 semaphore信号量。一个 semaphore S 是一个整型变量，它除了初始化外只能通过两个 atomic 操作 wait() 和 signal() （原称为 P() 和 V() ）来访问：\nvoid wait(S) {\n    while (S &lt;= 0)\n        ;   /* busy waiting */\n    S--;\n}\n \nvoid signal(S) {\n    S++;\n}\n有 2 种 semaphore：\n\nCounting semaphore - S 的值不受限制；\nBinary semaphore - S 的值只能是 0 或 1。类似于互斥锁。\n但是，如同前面我们所说，semaphore 也具有 busy waiting 的问题。为了解决这个问题，我们可以为 semaphore 引入 waiting queue：\n\ntypedef struct {\n    int value;\n    struct list_head * waiting_queue;\n} semaphore; \n \nwait(semaphore *S) {\n    S-&gt;value--;\n    if (S-&gt;value &lt; 0) {\n        add this process to S-&gt;list;\n        block();\n    }\n}\nsignal(semaphore *S) {\n    S-&gt;value++;\n    if (S-&gt;value &lt;= 0) {\n        remove a process P from S-&gt;list;\n        wakeup(P);\n    }\n}\n操作 block() 挂起调用它的进程，操作 wakeup(P) 重新启动 P 的执行，这两个操作都是由操作系统作为基本系统调用提供的。错误地使用 semaphore 可能会导致 deadlock\n\nPriority Inversion\n\n这个问题称为 priority inversion，即具有中等优先级的 M 的运行时间反而影响了具有较高优先级的 H 的等待时间。\nnce** 来解决这一问题：所有正在访问资源（如上例中，低优先级的 L 所持的锁）的进程获得需要访问这个资源的更高优先级进程的优先级，直到它们用完有关资源为止。（如上例中，priority inheritance 将允许 L 临时继承 H 的优先级从而防止被 M 抢占；当 L 释放锁后则回到原来的优先级，此时 H 将在 M 之前执行。）"},"课程笔记/操作系统/03.2-经典同步问题":{"slug":"课程笔记/操作系统/03.2-经典同步问题","filePath":"课程笔记/操作系统/03.2 经典同步问题.md","title":"03.2 经典同步问题","links":[],"tags":[],"content":"经典同步问题\n一般我们用信号量解决问题，因为信号量相对来说功能更多，而且很多操作系统对信号量做了更多设计，用来避免 busy waiting 等问题。\n信号量的逻辑\n\n一个信号量用来表示 一类「资源」的余量\nwait() 等待到其有余量时从中取走一个\nsignal() 释放一个资源\n因此，在用信号量解决同步问题时，我们通常考虑哪些东西属于资源，对它们的访问有哪些。同时，通过考虑在哪些地方需要等待，我们也能够得到一些提示。\n\nBounded-Buffer Problem\n\n给定两个进程：producer 和 consumer，它们共用大小为n的buffer。Producer 生产数据放入 buffer，consumer 从 buffer 取出数据从而使用之。\n该问题需要保证：producer 不应当在 buffer 满时放入数据，consumer 也不应当在 buffer 空时取出数据。\n\n首先，根据我们在前一节中的讨论，produce 和 consume 的过程会访问到 buffer 的资源，因此是 critical section，我们需要使用一个锁（或者信号量，后同）来控制对 buffer 的访问：[这里lock的值只能是0/1]\n\n\n                  \n                  NOTE\n                  \n                \n\n如果lock=1 那么说明能拿 wait(lock)就会把lock变成0\n如果lock=0 那么wait(lock)将等待lock变成1 signal(lock)会把lock变成0并且叫醒wait\n\n\nsemaphore lock = 1;\n \nproducer() {\n    while (true) {\n        // &lt;1&gt; If buffer is full, wait \n        wait(lock);\n        add_to_buffer(next_produced);\n        signal(lock);\n    }\n}\n \nconsumer() {\n    while (true) {\n        // &lt;2&gt; If buffer is empty, wait\n        wait(lock);\n        next_consumed = take_from_buffer();\n        signal(lock);\n    }\n}\n不过，上面两处注释中要求根据 buffer 的容量决定是否需要等待的需求还没有实现。\n我们可以考虑使用一个变量 count 来记录 buffer 中有多少个元素；如果这样实现的话，对 count 的修改也是 critical section，因此也需要锁的控制：\nsemaphore lock = 1;\nint count = 0;\n \nproducer() {\n    while (true) { \n        wait(lock);\n        while (count == BUFFER_SIZE) ;  // If buffer is full, wait \n        add_to_buffer(next_produced);\n        count++;\n        signal(lock);\n    }\n}\n \nconsumer() {\n    while (true) {\n        wait(lock);\n        while (count == 0) ;    // If buffer is empty, wait\n        next_consumed = take_from_buffer();\n        count--;\n        signal(lock);\n    }\n}\n这种方式的实现问题是显然的：比如当前 buffer 为空，即 count 为 0，consumer 会在 16 行处等待；但因为此时它持有着 lock，任何 producer 都不能 produce，因此这个等待会永久持续下去。这违反了 Progress 和 Bounded waiting 的要求。\n我们可以稍作修改，当 count 的要求不满足时，立即释放 lock 并进入下一次循环，即：\nsemaphore lock = 1;\nint count = 0;\n \nproducer() {\n    while (true) { \n        wait(lock);\n        if (count == BUFFER_SIZE) {\n            // If buffer is full, give up\n            signal(lock);\n            continue;\n        } else {\n            add_to_buffer(next_produced);\n            count++;\n            signal(lock);\n        }\n    }\n}\n \nconsumer() {\n    while (true) {\n        wait(lock);\n        if (count == 0) {\n            // If buffer is empty, give up\n            signal(lock);\n            continue;\n        } else {\n            next_consumed = take_from_buffer();\n            count--;\n            signal(lock);\n        }\n    }\n}\n也就是：\nsemaphore lock = 1;\nint count = 0;\n \nproducer() {\n    while (true) { \n        wait(lock);\n        if (count != BUFFER_SIZE) {\n            add_to_buffer(next_produced);\n            count++;\n        }\n        signal(lock);\n    }\n}\n \nconsumer() {\n    while (true) {\n        wait(lock);\n        if (count != 0) {\n            next_consumed = take_from_buffer();\n            count--;\n        }\n        signal(lock);\n    }\n}\n但是，这种实现方法强制了 busy waiting[就是cpu并没有休息,而是不停地执行一段检查条件的代码循环,直到条件满足为止,这里说的是整个whiletrue循环,在signal释放了之后,马上会一直重复刚才的循环过程]。我们在前一节讨论过了 busy waiting 及其利弊；在这里 critical section 的运行时间明显比 context switch 的时间要长，因此这里使用 busy waiting 是浪费时间的。\n而我们之前提到，许多操作系统对信号量做了一些处理，使得其等待不再是 busy waiting，而是类似于第 6 节中讲到的解决方案。因此，我们更倾向于使用信号量来解决问题。\n首先我们尝试使用一个 lock  和一个 eslot (empty slot，空闲 buffer 的个数) 来解决：\nsemaphore lock = 1;\nsemaphore eslot = BUFFER_SIZE;\n \nproducer() {\n    while (true) {\n        wait(eslot);    // if buffer is full, i.e. eslot == 0, wait//满了的话,eslot就会被设置成0 整个程序卡在这个wait这里,不会一直做判断什么的\n                        // else, eslot--\n        wait(lock);\n        add_to_buffer(next_produced);\n        signal(lock);\n    }\n}\n \nconsumer() {\n    while (true) {\n        // &lt;2&gt; If buffer is empty, i.e. eslot == BUFFER_SIZE, wait\n        wait(lock);\n        next_consumed = take_from_buffer();\n        signal(lock);\n        signal(eslot);  // eslot++\n    }\n}\n由于 eslot 作为一个信号量，我们对它 ++ 和 -- (实际上是 wait 和 signal) 是 atomic 的，不需要考虑同步问题。\n但是，16 行处我们希望让 eslot == BUFFER_SIZE 的时候循环等待，不过信号量本身并没有提供这个功能。怎么办呢？我们需要一个额外的 semaphore fslot  (full slot) 来解决这个问题：\nsemaphore lock = 1;\nsemaphore eslot = BUFFER_SIZE;\nsemaphore fslot = 0;\n \nproducer() {\n    while (true) {\n        wait(eslot);    // if buffer is full, i.e. eslot == 0, wait\n                        // else, eslot--\n        wait(lock);\n        add_to_buffer(next_produced);\n        signal(lock);\n        signal(fslot);  // fslot++\n    }\n}\n \nconsumer() {\n    while (true) {\n        wait(fslot);    // if buffer is empty, i.e. fslot == 0, wait\n                        // else, fslot--\n        wait(lock);\n        next_consumed = take_from_buffer();\n        signal(lock);\n        signal(eslot);  // eslot++\n    }\n}\n事实上，如我们之前所说，分析两处需要 wait 的情况（即 producer 在 buffer 满时、consumer 在 buffer 空时）就可以得到使用信号量的提示。也就是说，对于 producer 来说，「空格子」是它需要的资源；而对于 consumer 来说，「有东西的格子」是它需要的资源。我们可以根据这样的提示来设计信号量。\n需要特别注意的是 wait 之间的顺序。例如如果将 wait(lock) 和 wait(fslot) 的顺序调转过来，就会发生和前面提到的情况一样的死锁。\nReaders-Writers Problem\n\n对一个数据，readers 读，writers 读和写。\n设计方案保证：多个 readers 可以同时读取，但是 writer 进行读写时不能有其他 writers 和 readers。\n\nwriter() {\n    while (true) {\n        // if there is any reader or any other writer, wait\n        read_and_write();\n    }\n}\n \nreader() {\n    while (true) {\n        // if there is any writer, wait\n        read();\n    }\n}\n我们分类讨论不同的情形下，reader 和 writer 在 entry section 中期望的做法：\n对于 reader：\n\n有 writer：等待\n有其他 reader：什么都不做，直接进入 CS\n都没有：禁止 writer，然后进入 CS\n这样的做法可以保证不会同时有 writer 和 reader 在 critical section。\n对于 writer；\n有其他 reader / writer：等待\n都没有：禁止 reader 和其他 writer，然后进入 CS\n\n在 exit section 的操作与之对称。\n这两处「禁止」可能对应着两处信号量，我们分别给它们起名为 R 和 W，初值均为 1；那么 reader 的 entry section 就形如：\nwait for W but not take;    // if there is a writer, wait\nif (no other readers)       // if no other readers, take R\n    wait(R);                // else, do nothing\n//这里是说,当我是第一个读者的时候我才负责锁门,挡住写者.如果这里不写if逻辑 直接wait(R)的话,因为这个wait(R)大家都要经过,那第二个读者就没办法到下一行了.\nwriter 的 entry section 形如：\nwait for R but not take;    // if there are some readers, wait\nwait(W);                    // if there is another writer, wait; else take W\n这里有两个问题没有解决，第一个是「wait but not take」这样的操作是不存在的，第二个是如何判定「no other readers」我们分别讨论这两个问题。\nwait but not take\n首先，wait but not take 肯定还是要使用 wait() 来解决的，因为我们没有除此之外的用来等待的信号量操作。我们分别考虑两处 wait but not take 如果直接用 wait() 实现会带来什么问题。\n对于 reader，如果我们直接改为 wait(W)，会出现的问题是：这样只有第一个 reader 能够进入 CS 了，后续的都会被阻塞。不过我们可以发现，要解决这个问题，只要把 wait(W) 也放到 if 里面去就好了，也就是说如果有其他 reader 在的情况下，一定不存在 writer，W 也一定被某个（第一个）reader 持有，就不需要再 wait 了。即：\nif (no other readers) {\n    wait(W);\n    wait(R);      \n}\n容易检查，这样的设计符合我们之前分类讨论的要求。\n对于 writer，我们可以直接改为 wait(R)，因为释放 W 之前一定不会有 reader 能够进入 CS，而释放 W 时可以一并释放 R。即：\nwait(R);      \nwait(W);\n这里本来应该检查一下死锁，因为从第 8 节可以看到，这种设计有循环等待的情况，因此有死锁的风险；但是我们可以发现，其实 R 和 W 总是会同时被获取（对称地，也同时被释放）[获取的就是第一个读者,和唯一的写者]因此其实我们可以合并为一个信号量，不妨叫做 write_lock。其设计为：\nsemaphore write_lock = 1;\n \nwriter() {\n    while (true) {\n        wait(write_lock);\n        read_and_write();\n        signal(write_lock);\n    }\n}\n \nreader() {\n    while (true) {\n        if (no other readers)\n            wait(write_lock);\n        read();\n        if (no other readers)\n            signal(write_lock);\n    }\n}\nno other readers\n这个问题比较好解决，我们引入一个整型 reader_count 用来保存有多少个 readers，当其值变为 0 时，代表没有其他 readers 在读了。我们同时增加保证其同步的信号量。即：\nsemaphore write_lock = 1;\nint reader_count = 0;//this one\nsemaphore reader_count_lock = 1;\n \nwriter() {\n    while (true) {\n        wait(write_lock);\n        read_and_write();\n        signal(write_lock);\n    }\n}\n \nreader() {\n    while (true) {\n        wait(reader_count_lock);\n        reader_count++;\n        if (reader_count == 1)     // first reader take write_lock\n            wait(write_lock);\n        signal(reader_count_lock);\n \n        read();\n \n        wait(reader_count_lock);\n        reader_count--;\n        if (reader_count == 0)      // release write_lock when ...\n            signal(write_lock);     // ... no other readers reading\n        signal(reader_count_lock);\n    }\n}\n另外需要注意的是，这种实现的结果是：当存在读进程时，写进程将被延迟。这可能导致写进程发生 starvation。\n如果希望写进程优先，我们可以规定，如果写进程 ready，那么其他读进程应当等待，直到写进程结束；即使得写进程尽可能早地开始。我们可以通过新增一个信号量实现：\nsemaphore write_lock = 1;\nint reader_count = 0;\nsemaphore reader_count_lock = 1;\nsemaphore writer_first = 1;//this\n \nwriter() {\n    while (true) {\n        wait(writer_first);\n        wait(write_lock);\n        read_and_write();\n        signal(write_lock);\n        signal(writer_first);\n    }\n}\n \nreader() {\n    while (true) {\n        wait(writer_first);\n        wait(reader_count_lock);\n        reader_count++;\n        if (reader_count == 1)\n            wait(write_lock);\n        signal(reader_count_lock);\n        signal(writer_first);\n \n        read();\n \n        wait(reader_count_lock);\n        reader_count--;\n        if (reader_count == 0)\n            signal(write_lock);\n        signal(reader_count_lock);\n    }\n}\nDining-Philosophers Problem\n5 个哲学家一起吃饭！每两个哲学家之间有一根筷子，每个人一次可以拿起来一根筷子，拿到两根筷子的就可以吃一段时间。吃完思考一段时间。\n\n一个朴素的解法是这样的：\nvector&lt;semaphore&gt; chopstick(5, 1);  // initialize semaphores to all 1\n \nphilosopher(int index) {\n    while (true) {\n        wait(chopstick[i]);\n        wait(chopstick[(i + 1) % 5]);\n        eat();\n        signal(chopstick[i]);\n        signal(chopstick[(i + 1) % 5]);\n        think();\n    }\n}\n问题是，可能某时刻每个人同时拿起左边的筷子，这样会导致死锁。\n解决方案之一是，只允许同时拿起两根筷子；这种方案的实现是，轮流询问每个人是否能够拿起两根筷子，如果能则拿起，如果不能则需要等待那些筷子放下：\n让“拿起两根筷子”这个动作变成了原子操作 (Atomic)。也就是说，一个哲学家要么一口气把两根筷子都拿起来，要么连拿第一根筷子的资格都没有。\nvector&lt;semaphore&gt; chopstick(5, 1);  // initialize semaphores to all 1\nsemaphore lock = 1;\n \nphilosopher(int index) {\n    while (true) {\n        wait(lock);\n        wait(chopstick[i]);\n        wait(chopstick[(i + 1) % 5]);\n        signal(lock);\n \n        eat();\n \n        signal(chopstick[i]);\n        signal(chopstick[(i + 1) % 5]);\n        think();\n    }\n}\n另一种解决方案是，奇数号人先拿左边筷子，偶数号人先拿右边筷子，这样也能避免死锁。\nLinux Sync\n2.6 以前的版本的 kernel 中通过禁用中断来实现一些短的 critical section；2.6 及之后的版本的 kernel 是抢占式的。\nLinux 提供：\n\nAtomic integers\nSpinlocks\nSemaphores\nReader-writer locks\n\nPOSIX Sync"},"课程笔记/操作系统/03.3-死锁":{"slug":"课程笔记/操作系统/03.3-死锁","filePath":"课程笔记/操作系统/03.3 死锁.md","title":"03.3 死锁","links":[],"tags":[],"content":"死锁的定义和例子\n死锁 (Deadlock) 是指，多个进程因竞争资源导致的一种僵局，即若干进程各自持有一些资源，同时等待获取另一个进程持有的资源，形成的互相等待的局面。\n一个例子是，一个系统里有两个进程，分别完成从一个磁盘驱动器拷贝内容到另一个磁盘驱动器的操作，即各自需要两个磁盘驱动器。系统里两个磁盘驱动器。当前，p1持有A并希望获取B，同时p2持有B并希望获取A，这两个进程就会相互等待，陷入死锁。\nsemaphore first_mutex = 1;\nsemaphore second_mutex = 1;\n \nthread_one() {\n    wait(first_mutex);\n    wait(second_mutex);\n    // ......\n}\n \nthread_two() {\n    wait(second_mutex);\n    wait(first_mutex);\n    // ......\n}\n\n\n                  \n                  Bridge Crossing Example \n                  \n                \n\n\n上图所示的情形也展示了一种死锁。\n可以看到，如果桥上的任一辆车愿意倒车回去，就能够解决死锁。我们可以通过分配优先级的方式要求哪辆车倒车。\n优先级可能导致 starvation。\n\n\n系统资源分配图\n\n\n本节第一个例子的情况，可以用如下的资源分配图刻画：\n\n当进程申请一个资源时，应当添加一条申请边；当该申请可以得到满足时，这条申请边应当 立即 转换为分配边；当进程不再需要某个资源时，就删除对应分配边。\n根据资源分配图的定义我们可以知道\n\n如果资源分配图当前没有环，那么系统当前 一定 没有死锁\n如果分配图有环，那么系统当前 可能 存在死锁。\n但是，如果分配图有环，且每个资源类型只有 1 个实例，那么 必定 存在死锁。\n\n\n分配图有环不一定存在死锁\n[\n\n死锁的必要条件\n事实上，当下面四个条件 同时 成立时，系统才会出现锁：\n\nMutual exclusion : 至少一个资源处于非共享模式；\nHold and wait : 一个进程应 占有 至少一个资源，并 等待 另一个为其他进程占有的资源；\nNo preemption : 资源不能被抢占，只能在进程结束后主动释放；\nCircular wait : 我等你的筷子，你等他的，他等我的……形成一个圈[最关键]\n这四个条件并不完全独立。\n\n下图中描述了一个死锁状态：\n我们验证它符合上述四个条件：\n\nmutual exclusive：每个路口（资源） 1 ~ 4 同时只能有一辆车等待或通行\nhold and wait：位于 1, 2, 3, 4 路口的车分别持有当前路口，并且等待 2, 3, 4, 1路口的车经过\nno preemption：显然，任何一个路口边等待的车不能先于当前在路口等待的车经过路口\ncircular wait：位于 1, 2, 3, 4 路口的车分别等待 2, 3, 4, 1路口的车经过\n\n死锁的处理策略\n如何处理死锁呢？有四种方法：\n\n保证系统不会进入死锁状态\n\n死锁预防 (deadlock prevention)\n死锁避免 (deadlock avoidance)\n\n\n在系统进入死锁状态后恢复\n\n死锁检测和恢复 (deadlock detection and recovery)：例如数据库\n\n\n假装系统不会发生死锁，真的发生了就寄(重启)\n\n事实上，大多数操作系统（包括 Linux 和 Windows）选择的是最后一种方案。因此，程序员需要自己编写程序来处理死锁。但是前面三种还是要学…\n死锁预防\n死锁预防的核心思路是，确保至少一个必要条件永不成立，来保证系统不会出现死锁。我们分别讨论四个条件如何破坏。\nMutual Exclusion\n如果保证系统资源都能共享，则该条件用不成立。\n但是这只是个美好的愿望，因为有很多资源天生就不能共享，比如信号量。\nHold and Wait\n保证每个进程在申请资源时不能占有其他资源。\n实现方式:\n\n在开始执行前申请并获得所有资源。\n或者，只允许进程在没有资源时才能申请资源。\n这种方式的问题是，资源利用率较低，而且需要资源较多的进程可能发生starvation。\n\nNo Preemption\n\nNo Preemption（不可抢占）：资源一旦给了你，除非你自愿用完，否则谁也不能让你吐出来。\n\n当一个进程请求一个资源但是没有立刻得到满足时，它必须释放已经持有的所有资源. 直到它需求的所有资源（包括刚才释放的那些资源）都可用时才能一并获取它们并继续执行。\n但是信号量之类的资源也不能这样用[主动释放也就相当于被抢占,但是信号量之间的cs是原子的不可被中断]；同时也会降低资源利用率。\nCircular Wait\n对所有资源类型进行排序，要求每个进程按照递增顺序申请资源。\n程序员需要保证按照这个顺序申请资源，也就是说如果程序员不听话，还是会发生死锁。这种方法也可能影响资源利用率。\n死锁避免\n避免死锁需要一些额外信息，例如进程未来需要使用哪些资源、资源的使用顺序等。在每次请求到来时，即使对应资源可用，系统也应该结合现有可用资源、现有已分配资源以及各个进程未来申请和释放的资源，考虑是否让这个请求等待从而避免未来可能的死锁。\n不同模型可能对上述额外信息有不同的需求。最简单且最有用的模型维护这样的 资源分配状态 (resource allocation state):\n\n每个进程声明可能对每种资源类型的 最大需求 (maximum demands)\n当前系统的 available 和 allocated 的资源数目。\n\n资源分配图算法\n这种算法适用于每种资源类型只有 1 个实例的情况。\n我们在资源分配图的基础上增加一种边，叫 claim edge，表示某个进程未来 可能 会需求某种资源，用虚线表示。\n\n\n\n当这个需求真的出现的时候，claim edge 转为 request edge； 虚线变需求线\n当需求被满足的时候，request edge 转为 assignment edge；需求线变分配线\n当该进程释放该资源时，assignment edge 转为 claim edge。分配线变回虚线\n当一个需求来了的时候，如果 request edge 转为 assignment edge 不会导致图中有一个 cycle，则该要求可以被满足；否则该请求应当等待。\n\n安全状态 | Safe State\n如果系统能够按照一定顺序为每个进程分配资源，同时避免死锁，那么系统就处在 安全状态 (safe state)。\n\n银行剩下的钱+前面所有人完成之后还给银行的钱,是否能满足自己的需求\n安全状态保证不发生死锁。\n\nExample\n\n 102是一个 safe sequence。因此系统处在安全状态。\n 就是一开始 只能满足p1的need 然后p1运行完了之后,还了4,3-2+4=5 然后给0跑.类似的..\n根据这一概念，我们可以这样定义死锁避免的算法：起初，系统处于安全状态。当有进程申请一个可用资源时，系统应确定，如果立刻进行这一分配后系统仍处于安全状态则可以分配，否则应当让进程等待。\n银行家算法 | Banker’s Algorithm\n我们通过 available, max, allocation, need 这四个矩阵刻画一个时间内各个进程对各种资源的持有和需求情况，以及当前系统的资源情况；操作系统根据这些数据保持系统处于安全状态，从而决定一个需求是否应当被立即满足。\n参考下面的例子中问题 1 理解，找一个安全序列的基本思路就是：选取一个 need（的每一项都对应地）小于 available（的对应项）的进程，其运行完后会将 allocation 释放回 available，以此类推。\n而决定一个需求是否应当被立即满足的方案是，假设 这个需求被接受了，根据该需求更新对应的 need, available, allocation，在此状态下推演是否有合法的安全序列。如果有，则可以立即满足，否则应等待。参考下面例子中的问题 2~4。\nQuestion\nConsider the following snapshot of a system:\n\nT表示不同的进程,ABCD表示不同类型的资源\n先用max-allocation,可以得到need\n然后就先看当前的avaliable能满足哪个need,然后第一个进程运行完之后,新 Available = 原Available + T2 Allocation = (2,2,2,4) + (2,4,1,3) = (4, 6, 3, 7)。再进行新一轮寻找!最终就可以找到一个安全序列,一般来说答案不唯一.只要存在安全序列,就说明处于安全状态\nAnswer the following questions using the banker’s algorithm:\n\nIllustrate that the system is in a safe state by demonstrating an order in which the threads may complete.\nIf a request from thread T4 arrives for (2, 2, 2, 4), can the request be granted immediately?\n小于等于need,小于等于avaliable.通过资格检查.\n但是如果假设进行分配之后,t4并没有满足能运行的条件(没跑完,当然也就不能释放),而且剩余的也不足以支持别的进程运行,所以是不安全的\n实际上就是 按照题意进行分配,然后用新的矩阵再做一次找安全序列的动作.\nIf a request from thread T2 ar7rives for (0, 1, 1, 0), can the request be granted immediately?\nIf a request from thread T3 arrives for (2, 2, 1, 2), can the request be granted immediately?\n\n答案\n\n如图：  \n我们可以先让 T2 运行（也可以是 T3），此后变成：\n[\n现在可以让除了 T4 以外的每个 thread 运行，后续类似。因此一个安全序列是 T2→T0→T1→T3→T4。因此当前系统是安全的。\n如果满足这一要求，之后的状态为：\n\n可见，此时任一线程都无法执行。因此此要求不能立即满足。\n如果满足这一要求，之后的状态为：  \n这不影响我们如 1) 那样完成全部线程的运行，即系统是安全的。因此此要求可以立即满足。\n如果满足这一要求，之后的状态为：  \n我们可以按 T3→T2→T4→T1→T0 等顺序完成全部线程的运行，即系统是安全的。因此此要求可以立即满足。\n\n死锁检测\nSingle Instance Resources\n可以通过资源分配图的变体 wait-for graph 来解决：\n\n在这个图里找环，用拓扑排序的话时间复杂度是  的，这最差情况下是  的。\nMulti-Instance Resources\n类似银行家算法。如果找不到任何安全序列，则说明系统处于死锁状态。\n死锁恢复\n死锁恢复有两个选择：\n进程终止 Treminate deadlocked processes\n终止进程并不简单，它需要维护终止时的状态，并且有可能需要重新计算一些内容，同时还需要避免产生重复的副作用（如输出）；这需要花费很多时间。\nOptions:\n\n放弃所有死锁进程。这样的花费会很大！\n每次放弃一个进程，直到死锁环解除。这样的花费也很大，因为每次放弃一个进程之后都需要调用死锁检测算法。\n\n同时后者需要考虑的是，如何选择放弃的进程？应当根据具体情况，参考如下指标选择造成的代价最小的进程来终止：\n\n进程的优先级\n已经算了多久，还要算多久\n用了哪些、多少资源，是否容易抢占\n还需要多少资源\n终止这一进程的话还需要终止多少进程\n进程是交互的还是批处理的\n\n资源抢占 Resource preemption\n不断抢占资源给其他进程用，直到消除死锁环为止。\n需要考虑三个问题：\n\n选择牺牲进程 (Select a victim)。抢占哪些进程的哪些资源？这和前一节的讨论差不多。\n回滚 (Rollback)。当一个进程的若干资源被抢占，我们需要将这个进程 回滚 到某个安全状态，即回滚到申请那些被抢占的资源之前。\n不过一般来说，很难确定什么是安全状态，最简单的方案就是完全回滚，也就是终止进程并重新执行。回滚到足够打断死锁的状态更加经济，但是需要系统保存更多资源。\n饥饿 (Starvation)。如何保证不会永远从一个进程中抢占资源？在代价评价中增加回滚次数，也类似于 priority aging。\n"},"课程笔记/操作系统/04.1-主存":{"slug":"课程笔记/操作系统/04.1-主存","filePath":"课程笔记/操作系统/04.1 主存.md","title":"04.1 主存","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n\n内存是一个很大的字节数组，CPU 根据 PC (Program Counter) 的值从内存中提取指令。程序需要运行，至少部分程序及其访问的数据应在内存中（或者更明确地，内存中的一个进程里）\nCPU 可以直接访问的通用存储只有 main memory 和 registers。对 registers 的访问通常可以在一个 CPU 时钟周期中完成，而完成内存的访问可能需要多个时钟周期。在这些时钟周期里，由于没有用来完成指令的数据，这会引起 stall）。\n\n为了补救，在 CPU 芯片上增设更快的内存，称为 cache 。\n\n\n同时，需要保护内存空间，防止用户程序修改操作系统或其他用户程序的代码或者数据。\n\nAddress Binding flashcard\n\n.c-&gt;.o的过程\n\n编译器complier将源代码中的地址绑定到Relocatable Address\n\n源代码中的地址通常是用符号表示（symbolic）： 例如各种变量、函数名；汇编中的 label 等\nRelocatable Address：可重定位地址。相对于某一个段/模块等的偏移，例如 sp - 8, ds:[0]。即把源代码符号地址背后的具体内容重排到源程序的相对位置\n\n\n\n\n.p-&gt;.exe（and其他可执行文件形式）的过程\n\n链接器linker 收集所有.o文件，将每个代码文件的地址绑定成相对整个程序的地址\n\n\n加载器loader 将可执行文件绑定到内存地址中，得到最终的绝对地址Absolute Address\n\n当然，如果编译器在编译时就知道程序所处的内存地址，则会生成 absolute code-》program in memory\n\n\n\n\n\n连续内存分配\n\n在 Batch（批处理）系统中，每次只有一个程序被加载入物理内存，并被运行至结束。\n\n如果程序所需的存储空间比物理内存大，则将程序分开为可以运行至产生某个结果且大小可以放入空余内存的部分，逐个运行，将运行结果传递给下一个部分。\n\n\n现在我们需要把多个进程同时放在内存中，并且支持其彼此之间的快速切换。最简单的内存分配方法之一，就是将内存分成许多的 partition，每个 partition 包含一个进程。其要求有：\n\nProtection: 保证进程之间不会互相闯入对方的存储。\nFast execution: 不能由于 protection 降低访问内存的效率。\nFast context switch: 每当进行 context switch 时，可以比较快地找到并访问当前进程的内存。\n\n\n当进程进入系统，操作系统根据各个进程的内存需要以及当前的空闲内存空间来决定为哪些进程分配内存。当一个进程被分配到了空间，他将被载入到内存中，并与其他进程竞争 CPU 时间。当一个进程结束时，它释放它的空间。\n如果一个进程请求空间来运行，但没有足够的内存来满足其要求\n\n直接拒绝其请求并给出一个错误信息\n或将其加入 waiting queue 中，当有内存被释放时 CPU 来检查是否为其分配内存。\n\n\n\n内存分区策略partion flashcard\nFixed Partition 固定大小partition\n\n固定 partition 的大小（除了 OS 使用的内存），只需要记录每个partition是否被占用即可。\nInternal Fragmentation：一个partition中剩余的空间不能够被别的进程所使用。【 不可用内存分布在 partition 之内】\n\nVariable Partition\n\n不固定 partition 的大小，维护一个表，记录可用和已用的内存。\n最开始时是一大块可用内存块（可用内存块称为hole），经过一段时间运行后可能就会包含一系列不同大小的孔\nExternal Fragmentation： 一段时间运行后，内存空间被分为大量的hole，加起来可以满足要求但是并不连续，所以无法被利用。【 不可用内存分布在 partition 之外】\n\n\n动态存储分配问题 Dynamic Storage-Allocation Problem flashcard\n根据一组 hole 来分配大小为 n 的请求，的问题\n解决方法有：\n\nfirst-fit 分配首个足够大的 hole。这种方法会使得分配集中在低地址区，并在此处产生大量的碎片，在每次尝试分配的时候都会遍历到，增大查找的开销。\nbest-fit 分配最小的足够大的 hole。除非空闲列表按大小排序，否则这种方法需要对整个列表进行遍历。这种方法同样会留下许多碎片。\nworst-fit 分配最大的 hole。同样，除非列表有序，否则我们需要遍历整个列表。这种方法的好处是每次分配后通常不会使剩下的空闲块太小，这在中小进程较多的情况下性能较好，并且产生碎片的几率更小。\n\n\n内存保护机制Protection flashcard\n保证一个进程能且仅能访问自己空间中的地址。通过一套 base 和 limit 寄存器来确定一个程序的空间：\n\n\n每当 context switch 到一个新的进程时，CPU 会 load 这两个寄存器的值\n每当 user mode 想要进行一次内存访问时，CPU 都要检查其是否试图访问非法地址；如果是，则会引发一个 trap 并被当做致命错误处理（通常会 terminate 掉进程 ）：\n\n\n分段Segmentation\nBasic Method\n虽然我们程序中的主函数、数组、符号表、子函数等等内部需要有一定的顺序，但是这些模块之间的先后顺序是无关紧要的。\n\n\n一个程序是由一组 segment （段）构成的，每个 segment 都有其名称和长度。我们只要知道 segment 在物理内存中的基地址 (base) 和段内偏移地址 (offset) 就可以对应到物理地址中了。\n对于每一个 segment，我们给其一个编号。即，我们通过二元有序组 表示了一个地址。这种表示称为 logical address（逻辑地址）或 virtual address（虚拟地址）。\n通常，在编译用户程序时，编译器会自动构造段。\n\nSegmentation—Logical Address &amp; MMU\n要将逻辑地址映射到物理地址，首先我们需要找到段的基地址。\n\nsegment table\n\n其中每个条目以 segment-number 索引\n存储其 段基地址 segment-base 和 段界限 segment-limit（可能还包含权限位）。\n因此逻辑地址的映射方式如下图：如果offset&lt;limit，则加上base得到物理地址\n\n\n这一过程是由硬件设备 MMU (Memory-Management Unit, 内存管理单元) 完成的。CPU 使用的是逻辑地址，而内存寻址使用的是物理地址，MMU 完成的是翻译（映射）和保护工作：这里的 relocation register 即为 base register。\n\nProblems\n分段将一个程序分为数个部分，但是其内存分配的策略与简单的 partition 是一致的。因此，分段仍然会存在 external fragmentation 的问题：其表征是总空余内存是足够的，但是由于它不连续导致其无法使用。也就是说，这个问题的核心点在于 not contiguous。我们有两种思路来解决这一问题：将\n\n内存重排使得 holes 连成一块\n\nCompaction 就是将内存中的内容重排使得所有空闲空间连续。这一操作要求内存中的程序是 relocatable  的，即其地址是相对 base 的偏移；这一要求在前面两种内存分配方式中是满足的。但是这一操作需要将内存逐一复制，这将消耗很多时间。\n\n\n或者设计方案让程序不再需要连续的地址。\n\n实际上，分段已经是这个方向上做出的一种尝试了，因为它将程序分为了几块，相比于简单的 partition，分段有助于减小 external fragmentation。为了更好地解决这个问题，我们提出 paging。\n\n\n\n分页Paging\nPaging （分页）是一种允许进程的物理地址空间不连续的内存管理方案。它避免了 external fragmentation 和 Compaction。各种形式的 paging 被大多数操作系统采用；实现 paging 需要 OS 和硬件的协作\nBasic Method\n\n物理地址:\n\n将 physical memory 切分成等大小的块（2 的幂，通常为 4KB = 2^12B ），称为 frames（帧）\n当一个进程要执行时，其内容填到一些可用的 frame 中，其中的每一个地址可以用这个 frame 的 base/number(唯一)以及相对这个 base 的 offset 表示\n\n\n逻辑地址:\n\n将 logical memory 切分成同样大小的块，称为 pages（页）\n同时 CPU 生成逻辑地址，逻辑地址包含一个 page number 和一个 page offset；另有一个 page table，它以 page number 索引，其中的第 i 项存储的是 page number 为 i 的 page 所在物理内存的 frame 的 base。这样，每一个 page 将通过其 page number 映射到一个 frame 上；进而 page 中的每一个地址也通过 offset 与frame中的对应地址建立映射。\n\n\n也就是说，当 MMU 需要将一个 logical address 翻译为 physical address 时，它需要获取 page number p，在 page table 中找到第 p 个 page 对应的的 frame number（也就是 frame base） f ，在 f 后面连接上 offset d 就得到了对应的 physical address。如我们之前所说，logical address 和 physical address 的 offset 应是一致的。\n\n当一个进程需要执行时，其每一页都需要一帧。因此，如果进程需要 n 页，则内存中需要有 n 个帧。如果有，那么就可以分配给新进程：进程的每一页装入一个帧，frame number 放入进程的 page table 中。\n由于操作系统管理物理内存，它应该知道物理内存的分配细节，即共有多少帧、帧是否空闲等。这些信息保存在 frame table 中，每个条目对应一个帧，保存其是否被占用；如果被占用，是被哪个进程的哪个页占用。\n\nWhy “Not Contiguous”\nPage table 硬件实现\n1. Simplest method\n最简单的方法是用一组专用的寄存器来实现。\n\n这一实现方法的优点是使用时非常迅速，因为对寄存器的访问是十分高效的。\n但是，由于成本等原因，寄存器的数量有限，因此这种方法要求 page table 的大小很小；同时，由于专用寄存器只有一组，因此 context switch 时需要存储并重新加载这些寄存器。\n\n2. Page table in memory &amp; PTBR\n\n大多数现代计算机允许页表非常大，因此对于这些机器，采用快速寄存器实现页表就不可行了。我们将页表放在内存中，并用 Page-Table Base Register (PTBR) 指向页表。在 context switch 时只需要修改 PTBR。\n但是这种方法的效率存在问题。要访问 logical address 对应的 physical address，我们首先要根据 PTBR 和 page number 来找到页表在内存的位置，并在其中得到 page 对应的 frame number，这需要一次内存访问；然后我们根据 frame number 和 page offset 算出真实的 physical address，并访问对应的字节内容。即，访问一个字节需要两次内存访问，这会加倍原本的内存访问的时间，这是难以接受的。\n\n3. TLB flashcard\n\n这个问题的解决方法用到一个专用的高速查找硬件 cache (associative memory，支持 parallel search)，这里称它为 translation look-aside buffer (TLB)。总之就是缓存!\nTLB 的每个条目由 key &amp; value 组成，分别表示 page number 和 frame number，通常有 641024 个条目（PPT 上说 641024，课本上说 32~1024，区别不大）\n当我们需要找到一个 page number 对应的 frame number 时，TLB 会 同时与其中所有的 key 进行比较：如果找到对应条目，就不必访问内存；如果没有找到（称为 TLB miss），则访问内存并将新的 key &amp; value 存入 TLB 中，这会替换掉 TLB 原有的一个条目。\n替换的策略包括 least recently used (LRU), round-robin, random 等。有些 TLB 支持将某些条目[比如重要的内核代码] wired down，即他们不会从 TLB 中被替换。在 MIPS 架构中，TLB miss 作为 exception 由操作系统处理；在 X86 架构中，TLB miss 由硬件处理。\n\n\nTLB with ASID\n\n每个进程都有自己的页表,每个页是按照多级结构存储的\n如同我们提到过的，每个 process 都有其自己的 page table。因此切换进程时也需要切换 page table。亦即，我们需要保证 TLB 与当前进程的 page table 是一致的。\n\n\n为了保证这一要求，我们可以在每次切换时 flush TLB。\n或者，有些 TLB 还在每个条目中保存 Address-Space Identifier (ASID)，每个 ASID 唯一标识一个进程。当 TLB 进行匹配时，除了 page number 外也对 ASID 进行匹配。\n\nEffective memory-access time EAT\n\nMemory Protection内存保护\n分页环境下的内存保护由与每个 frame 关联的 protection bits 实现。这些 bits 通常保存在页表中。例如 valid-invalid bit：\n\nv (Valid/有效)： 表示对应的页是进程合法地址空间的一部分，因此地址转换可以正常进行。\ni (Invalid/无效)： 表示对应的页不是进程合法地址空间的一部分，如果 CPU 试图生成该页号对应的地址，计算机将触发一个 trap (陷入) 到操作系统，表示这是一个无效的页引用 (invalid page reference)。\n如图所示，在一个具有 14 位地址空间（0 到 16383）的系统中，我们有一个程序应该仅使用地址 0 到 10468。给定页面大小为 2 KB，我们有如图 9.13 所示的情况。页面 0、1、2、3、4 和 5 中的地址通过页表正常映射。但是，尝试生成页面 6 或 7 中的地址会发现位被设置为无效，陷入无效页面引用异常\n注意，因为程序只延伸到地址 10468，任何超过该地址的引用都是非法的。然而，对页面 5 的引用被归类为有效的，所以对地址 12287 以内的访问都是有效的。只有从 12288 到 16383 的地址是无效的。这个问题是 2-KB 页面大小的结果，反映了分页的内部碎片。\n某些系统提供硬件形式的页表长度寄存器（PTLR），以指示页表的大小。这个值会针对每个逻辑地址进行检查，以验证该地址在进程的有效范围内。未通过此测试将导致对操作系统的错误陷阱。\n\nShared Pages\n分页可以允许进程间共享代码，例如同一程序的多个进程可以使用同一份代码，只要这份代码是 reentrant code （or non-self-modifying code : never changes between execution），如下图所示：图中所述的是多个进程共享一份库代码的情况；共享还可以用于进程之间的交流。当然，每个进程也可以有其自己的代码和数据。\n分页Problems\n\n会导致内部碎片。内存分配是以 frame 为单位执行的，如果进程要求的内存不是 frame 大小的整数倍，那么最后一个 frame 就会用不完，产生内部碎片。最坏的情况下，一个需要 n pages + 1 byte 的进程需要分配 n+1 个 frame，那么就会产生 FrameSize - 1 那么大的 Internal Fragmentation。\n如果进程的大小与页大小无关，每个进程中内部碎片的均值为 ½ FrameSize。在实际情况中，平均值比这小很多。当然，我们不能为了减小内部碎片而将 frame 的大小无限减小，因为更小的 frame size 需要更多的页表项。\n\nStructure of Page Table\n多级页表\n页表是一个数组， page_table[i] 中存储的是 page number 为 i 的 page 所对应的 frame number。考虑我们的逻辑地址结构：\n\n这样的逻辑地址结构需要一个存储 2^p 个元素的 page table，即需要这么大的连续内存，这是非常大的消耗。我们考虑将 p 再分为 p1 和 p2 ：\n\n两级页表， outer_page_table[i] 中存储的是 p1 为 i 的 inner page table，即inner_page_table[i][] 的基地址；\n而 inner_page_table[i][j] 中存储的就是 p1 为 i，p2 为 j 的 page 对应的 frame number，即 page number 为 p1p2 （没有分割时的 p）对应的 frame number。\n称 p1 为 page directory number ，p2 为 page table number，d 为 page offset。 \n逻辑地址 代替 物理地址满足了程序的 contiguous 要求。考虑这中分两页的 page table 结构，我们可以发现我们只是将 p 分成了两部分；对于程序来说，p+d 构成的整体（即逻辑地址）仍然是 contiguous 的，而且程序并不会意识到我们将 p 分成了 p1 和 p2 两部分，就像曾经它没有意识到我们将 address 分为了 p 和 d 两部分一样。这些划分只是我们为了更好地分配内存所做的、Operating-System-Level 的事情而已。\n考虑这样做的好处：hierarchical paging 其实就是对页表的分页（page the page table）。因此，它避免了 page table 必须处在连续内存的问题，这一问题在 p 比较大时尤其严重。\n另外，这样做在一般情况下可以节省空间。我们之前提到，页表不一定会全部使用；并且由于逻辑地址是连续的，因此用到的页表项也是连续的，都排在页表的头部。因此如果我们采用了二级页表，那么许多排在后面的 inner page table 将完全为空；此时我们可以直接不给这些 inner page table 分配空间，即我们只分配最大的 p1 那么多个 inner page table。这样我们可以节省很多空间。即使在最差的情况下，所有页表都被使用了，我们的页表所用的总条目数也只有类似地，我们可以设计更多级的页表。例如，64 位的逻辑地址空间使用二级页表就是不够的，否则它的页表就会长成这样：这样，我们就建立了一个三级页表。\n实际上，我们不必使用全部的 64 位，即我们不需要一个 64 位那么巨大的 virtual address space。AMD-64 支持 48-bit 的虚拟地址，ARM64 支持 39-bit 和 48-bit 的虚拟地址空间：\n\nHashed Page Tables 哈希页表\n前面介绍的页表是使用一个 table 保存 page# 对应的 frame#，这种解决方案面临的问题是空间需求是且连续的；我们通过多级页表解决这个问题。而哈希页表给 page# 分配 frame# 并不是随意分配，而是通过哈希计算得到。这样的方式将空间需求降低到且每个 page 对应的表项在内存中并不需要连续，从而解决了这个问题。哈希页表的每一个条目除了 page number 和 frame number 以外，还有一个指向有同一哈希值的下一个页表项的指针。这个结构与一般的哈希表是一致的。这是 32-bit address spaces 页表的一个常用方案。\nInverted Page Tables 倒排页表\n在之前的分页方法时，每个进程都有一个页表。这种方法会导致这些表可能使用大量的物理内存。\nInverted page tables 索引 physical address 而不是 logical address，也就是说，整个系统只有一个页表，并且每个物理内存的 frame 只有一条相应的条目。寻址时，CPU 遍历页表，找到对应的 pid 和 page number，其在页表中所处的位置即为 frame number：==页表的第 i 项（帧 i）存储了哪个进程的哪个页占用了这个帧，即存储了 (pid, p) 对。==\n\n这种做法的缺点是\n\n寻址过程需要很长时间。我们也可以用 TLB 或者 hashed table 来加速。\n这种方法不能够共享内存，因为 page table 的每一个条目（与 frame number 一一对应）只能存储一个 page number。\n传统页表是每个进程有一个独立的页表，把用到的页和对应的frame联系起来。倒排页表整个系统只有一个，第i项表示帧i，存储了哪个进程的哪个页占用了这个帧。\n\nSwapping\n\n进程的指令和数据必须在内存中以执行，但是我们可以将进程或进程的一部分暂时从内存 swap 到 ==backing store （备份存储，通常是一个比较快的磁盘）==中，继续运行时从中重新拿回到内存。\nSwapping 使得所有进程总的物理地址空间总和超过系统中真实的物理地址空间称为可能，提高了系统的 degree of multiprogramming。\n当然，在内存比较充足的情况下，swapping 并不必使用。Swapping 可能会导致很长的 context switch 用时，因为下一个进程可能并不在内存中，而由于磁盘的 I/O 很慢，swapping 到内存会花费很长时间。\n在分页的机制中，我们可以只 swap out 一些 pages，而不必 swap out 一整个进程：\n"},"课程笔记/操作系统/04.2-virtual-memory":{"slug":"课程笔记/操作系统/04.2-virtual-memory","filePath":"课程笔记/操作系统/04.2 virtual memory.md","title":"04.2 virtual memory","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n地址空间与异常\n地址空间 (address space) 指的是地址取值的全集。\n\n物理地址空间\n\n例如，对于一个 32 位寻址的体系结构，其 物理地址空间（物理地址的集合）就是 ，亦即 0x00000000 ~ 0xffffffff。\n- flat memory内存模型: 在引入分段 / 分页技术之前，各个进程和操作系统共同使用同一个物理地址空间。它会带来比较大的碎片，同时隔离性较差，内存的保护较弱。\n\n\n虚拟地址空间\n\n而在引入了分段 / 分页技术之后，每个进程都有了自己的一套 logical memory (a.k.a. virtual memory) ，其对应的的地址空间就叫做 逻辑地址空间 (logical address space) 或者 虚拟地址空间 (virtual address space)；而对应的段表 / 页表的作用就是提供从虚拟地址空间到物理地址空间的映射（映射过程中，由于 swapping 机制的存在，也有可能出现 swap 的过程）。\n\n\n我们知道，上述的映射过程由 OS 和 MMU 共同实现，因此进程的虚拟地址空间是被隔离的；只要 MMU 不出现问题以及页表不被篡改（这通常比较困难），其他进程就没有办法访问到这个进程的内存。\n也就是说，虚拟内存供软件使用，而 CPU 在访问对应的内存地址时会由 MMU 自动转换为对应的物理地址；如果对应的 page 不在物理内存中，就会触发一次 page fault，这是一个 exception。有 3 种可能的情况：\n\n当前的进程的页表中并没有这个虚拟地址对应的 page；\n权限不符，例如试图运行某个权限位是 RW- 的 page 中的代码，或者试图写入某个权限位是 R-X 或 R-- 的 page 中的某个内存单元；\n当前虚拟地址是合法的，但是对应的 page 被 swapped out 了。\n\n\n我们知道，exception 会交由操作系统处理；如果是前两种情况，操作系统应当报错并做相关处理（例如杀掉对应进程）；而如果是后一种情况，操作系统应当将进程阻塞，并将对应的 page 交换回来，调页完成后唤醒进程。\n在一条指令执行期间，可能触发多次 page fault（指令本身和访问的地址可能都不在物理内存中）。当 page fault 被解决后，指令被重新运行；因此一条指令在真正成功运行之前可能会被尝试运行多次。\n\nKernel Addresses &amp; Userspace Addresses flashcard\n\n每个进程的虚拟地址空间（下简称地址空间、AS）被分为了 Kernel Portion 和 User Portion\n\nkernel 模式下的代码可以访问这两块空间 [CPU 陷入内核代码，进入高权限，但它依然是在这个进程的上下文中工作]\nuser 模式下的代码只能访问 User Portion。\n\n\n每个进程的 AS 的 kernel portion 都映射到了同一块物理内存。原因是显然的：所有进程用到的都是同一套 kernel，因此没必要把 kernel 用的内存（存例如各个进程的页表、各种队列之类的东西）复制好几份。\n\n实现\n\n在 32 位虚拟地址空间（4GB）的设计里，kernel 默认使用高 1GB，各个进程的 user portion 使用低 3GB 的虚拟地址空间；通过在 build kernel 之前更改 CONFIG_PAGE_OFFSET 可以更改这一分配\n\n32位系统只使用一套页表\n\n\n对于 64 位虚拟地址空间的设计，由于根本用不了这么多，因此 kernel space 和 user space 被自然分隔开：其中 TTBR (Translation Table Base Register) 保存页表的基地址\n=TTBR0 管理的用户空间 + TTBR1 管理的内核空间。对应两套页表\nTTBR0 是每个进程的页表对应的 TTBR\nTTBR1 是 kernel portion 的页表对应的 TTBR。\n\n\n\n\n                  \n                  分配策略和置换策略的区别 \n                  \n                \n\n\n延迟分配 和 COW 是在内存充足时优化分配或复制的策略，目的是推迟或避免分配，从而节省内存。\n页面置换 是在内存不足时（物理帧耗尽）强制释放内存的策略，目的是在资源紧张时保证系统能继续运行。\n\n\n\n分配策略\nLazy Allocation / Demand Paging flashcard\n操作系统在分配 user space 的内存时，会使用 lazy allocation：\n\n当用户程序申请一块内存时，操作系统并不会真的立即在物理内存中分配对应的内存；直到这块内存被真正访问。\n原理: 很多用户程序申请的内存大小比真正需要使用的通常要大，例如 buffer 等。\n\n\n程序（例如通过 malloc 库函数）发现需要更多内存，于是调用 brk() 系统调用来请求扩大其堆（Heap）的边界。\n\n此时，虚拟堆大小为 8KB，物理内存占用（Rss - Resident Set Size）也是 8KB。\n\n\n内核响应 brk() 请求，仅仅扩大了进程的虚拟内存区域（VMA）。新的页面此时并未映射到任何物理内存。\n\n进程的虚拟堆大小（Size）增加到 16KB，但其物理内存占用（Rss）仍然是 8KB。内核只是在进程的虚拟地址空间中“画了一块饼”，但没有给它“真正的食物”（物理内存）。\n\n\n程序执行代码，试图第一次读取或写入刚刚申请到的新虚拟内存地址。\n\nCPU（通过 MMU）在页表中查找该虚拟地址，发现它没有任何对应的物理内存映射。\n处理器触发一个缺页中断（Page Fault）。这不是一个程序错误，而是一个给内核的信号。\n\n\n内核捕获这个中断，意识到这是一个合法的“按需分页”请求。\n- 它从可用的“free”列表中找到一个空闲的物理页帧（Page Frame）。\n- 内核将这个物理页帧映射到程序试图访问的虚拟地址。\n- 它为此创建或更新页表项（PTE - Page Table Entry）。\n- 状态： 物理内存占用（Rss）现在增加到 12KB（假设新分配的页是 4KB）。\n\n\nCopy-on-Write flashcard\n\n很多子进程在 fork() 之后立刻调用 exec()[创建一个复制的子进程,并且用一个全新的程序(可执行文件)的内容覆盖内核态中父进程的代码、数据、栈和堆.]因此将父进程的地址空间整个复制一份是比较浪费的明明马上就会被覆盖.\nCopy-on-Write机制允许父进程和子进程最初使用同一份物理页来进行工作，在任何一个进程需要写入某个共享 frame 时再进行复制。\n进一步地，Linux 等操作系统提供了 vfork()，进一步优化子进程在 fork() 之后立刻调用 exec() 的情形。vfork() 并不使用 copy-on-write；调用 vfork() 之后，父进程会被挂起，子进程使用父进程的地址空间。如果子进程此时修改地址空间中的任何页面，这些修改对父进程都是可见的。\n\n\n置换策略\nPage Replacement flashcard\n\n我们在Lazy Allocation或者Copy-on-Write讨论的情况下，或者在 kernel、I/O buffer 之类的情况下,需要从磁盘将页调入内存,会需要空闲的物理帧[需要有一个位置].\n\n但是没有空闲的物理帧时应该怎么办呢？我们可以交换出去一整个进程:\n\n将一个进程的所有页都写回磁盘（备份存储），释放它占用的所有帧。\n\n\n更常见地，我们找到一个当前不在使用的帧，并释放它。\n基本步骤是：\n\n\n\n\n找到这个 victim frame；\n将其内容写回备份存储swap space/disk；\n\n dirty bit (a.k.a. modify bit) 该位保存对应 frame 是否被修改过；如果没有被修改过,就不用写回\n\n\n调入 Page X： 将进程 P 缺失的 Page X 从硬盘（备份存储）调入到刚刚腾出的物理帧 F_A 中。\n修改页表（和 TLB 等）以表示它不在内存中了。\n\n将页表中的有效位设置为无效\n从TLB中删除对应条目\n如何确定哪个 frame 应当用来作为 victim frame 呢？我们的核心目标是，降低 page fault 的频率。\n\n\n\n\n\n\n                  \n                  如何从磁盘匹配和找回被换出的页面？ \n                  \n                \n\n被换出的页面总能被系统准确找回，这是因为页表和备份存储（Backing Store）有明确的记录机制。\n当下次 CPU 再次请求访问这个已被换出的页面时，步骤如下：\n\n触发缺页中断（Page Fault）： CPU 请求访问 Page X，MMU 查阅该进程的页表。页表显示 X 的 valid-invalid bit 设置为 无效（i），触发 Page Fault，控制权交给 OS 内核。\n定位 Page X： OS 检查页表中的其他信息（这些信息在页被换出时被记录）\n\n页表项： 页表项不再存储帧号，而是存储一个特殊标记，该标记指向 Page X 在**备份存储（磁盘）**上的确切位置（例如，交换空间中的块地址）。\n\n\n调页（Paging）：\n\nOS 执行页面置换流程（找到 Victim Frame）。\nOS 从备份存储中，根据第 2 步记录的地址，将 Page X 调入到这个 Victim Frame 中。\n\n\n更新页表： Page X 被调入后，OS 更新页表，将该页的 valid-invalid bit 设置为有效（v），并记录它现在所处的物理帧号。\n指令重执行： OS 将控制权交还给 CPU，让 CPU 重新执行被中断的那条指令。\n\n\n\n页面置换算法 (page replacement algorithms) flashcard\nOptimal\n这种算法选择 最长时间内不再被访问的页面 换出。容易证明，这种方案的 page-fault rate 是最低的。不过，由于实际实现中我们没有办法预测结果，因此它只作为理论最优解用来判定其他算法的优劣。\nFIFO (First In First Out)\n这种算法换出 最先进入内存的页面。实现比较简单，使用一个队列保存调入内存的顺序即可。\n这种算法的问题是，其逻辑和实际不符；实际情况下有很多页面会经常被访问。\n另外，这种算法可能会遇到物理帧增加的时候 page-fault 反而更多的异常情况。这被称为 Belady’s Anomaly：\n\n123412512345是一次请求访问的页面号\n\n上半部分:限制进程只能使用 3 个帧。\n\n关键页 A 可能会在它再次被访问之前就被淘汰了（FIFO 逻辑）。\n\n\n下半部分:限制进程可以使用 4 个帧。\n\n由于内存变大，关键页 A 驻留的时间变长了。但与此同时，它占用的位置可能会导致另一个很快就要被用到的更关键的页 B 被提前淘汰，从而导致总体缺页次数增加\n\n\n\n\n\n\nLRU (Least Recently Used)\n\n实现的一种策略是给每个页表项一个 counter，每次访问某个 page 时，将 counter 更新为当前的时间[只要被用了,就会往后调,从淘汰最早变成了淘汰间隔最长]\n\n每次需要置换时，搜索 counter 最小的页。也可以用 heap 来优化。\n\n\n另一种策略是用一个栈保存 page numbers，每次访问时找到它然后把它挪到栈顶。\n这两种实现开销都比较大。\n\nLRU-Approximation\n\n因此，我们在 LRU 和性能之间做一个折中；引入一个 reference bit，来近似地实现 LRU。当一个 page 被访问时这个 bit 被置为 1；操作系统定期将 reference bit 清零。因此，在需要交换时，只需要找一个 reference bit 为 0 的就可以说明它在这段时间内没有被访问过。\n或者加上优先级bit\n加上counting bit 记录被访问的次数\n\n\n进阶策略\nAllocation of Frames\n为什么要分配frame\n\n\n采取 全局置换 (global replacement)\n\n当进程 A 发生缺页中断需要一个新的帧时，操作系统可以从所有物理帧中（即系统中所有进程 P1, P2, P3… 占用的帧）中选取一个 Victim Frame[灵活:更好的系统吞吐量但是不隔离:自己的pagefault率会取决于其他进程的运行状况]\n那么我们就不一定有必要提前规定每个进程最多能够使用多少个 frame；\n\n\n\n采取 局部替换 (local replacement)[隔离但僵化]\n\n只在当前进程分配到的物理帧中进行替换\n那么我们就需要提前把物理 frame 的资源分配给各个进程[要划分好区间不然就跟全局置换一样了]。\n\n\n\n当我们需要决定一个进程能够使用的页面总数时，我们在上述最小和最大的区间内有非常多的选择，这就引入了分配算法。常见的分配算法包括平均分配，或者按进程对内存的实际需求按比例分配；也可以参考进程的优先级，高优先级相对分配到的更多，或者更能满足其实际需求。\n\n\n现在的很多计算机都有多个 CPU，而每个 CPU 都可以比其他 CPU 更快地访问内存的某些部分。如果这种差异比较明显，我们称这种系统为 非均匀内存访问 (NUMA, Non-Uniform Memory Access) 系统。在这种系统下，为了更好的性能表现，前述的分配和调页算法可能更加复杂。\n\n\n分配多少个 Frames\n给每个进程分配多少个 frame 呢？\n\n最大值不可能超过物理内存包含的 frame 总数\n最小值是由具体的计算机架构决定的。[作系统只需要确保在执行任意一条指令时，该进程拥有足够的帧来容纳该指令涉及的所有页。因此最小值是最复杂的那条指令的帧]\n\n指令在解决其涉及的全部 page fault 之后才能真正被运行[指令是原子操作,如果发生pagefault,cpu会暂停当前指令并进行中断处理]\n因此每个进程分配的 frame 的最小值不应小于单个指令可能使用到的 frame 总数[允许指令运行,是最低要求,还会有其他帧来存储整个进程的代码\\全局变量\\堆\\栈等等]。一般情况如下\n\n指令本身:1个page[指令会进行对齐]\n两个访问内存的操作数，其中每个操作数访问的内存[可能]跨越 2 个 page（即，这块数据在一个 page 的末尾和下一个 page 的开头）\n那么这个架构上运行的进程的 minimum frame number 是 5。\n\n\n\n\n\nThrashing  flashcard\n\n如果一个进程可用的帧数量比较少（少于其频繁访问的页面数目），那么它会频繁出现 page fault；同一个 page 可能会被频繁地换入换出，以满足运行的要求。这种高度的页面调度活动成为称为 抖动 (thrashing)；其调页时间甚至会大于执行时间。\n工作集模型 (working set model) 用来确定一个进程频繁访问的页面，保证这些页面不被换出；需要调页时从剩余的页面进行交换。如果频繁访问的页面数已经大于了当前进程可用的页面数，操作系统就应当把整个进程换出，以防止出现抖动现象。\n\n\nKernel Memory Allocation\n\nKernel 中的很多数据结构大小区分比较大，其中很多小于甚至远小于一个 page.因此，kernel 的设计应当尽可能节省内存，努力减少碎片。\n尽可能减小 kernel 内存开销的考虑是：\n\n一方面，kernel 有可能有一部分常驻在物理内存中，不受调页系统的控制\n另一方面，有的硬件设备可能和物理内存直接交互，因此可能会需要连续的物理内存。\n这两者对物理内存的要求都比较严格，因此我们应当尽可能减小这些开销。\n\n\n\nBuddy System flashcard\n\nBuddy system 从物理连续的段上分配内存；每次分配内存大小是 2 的幂次方，例如请求是 11KB，则分配 16KB。\n当分配时，从物理段上切分出对应的大小，例如下图体现了分配 21KB 时的情况， 会被分配。\n当它被释放时，会 合并 (coalesce) 相邻的块形成更大的块供之后使用。\n\n\nSlab Allocation flashcard\n核心的原理是，操作系统中很多 object 的大小是已知且固定的[PCB/socket buffers/PTE之类的]。内存被划分成若干个固定大小的块，每个块都被分配给一个具体的类型。当进程需要分配内存时，它会查询缓存，如果找到一个空闲的块，就直接使用该块；如果缓存中没有空闲的块，就会从系统内存中申请一个新的块：\n"},"课程笔记/操作系统/06.1-文件系统":{"slug":"课程笔记/操作系统/06.1-文件系统","filePath":"课程笔记/操作系统/06.1 文件系统.md","title":"06.1 文件系统","links":[],"tags":[],"content":"在存储管理中，我们讨论了大容量存储和 I/O；这一部分中，我们讨论如何使用这些存储。\n在本章中，我们主要讨论文件系统提供的功能；在下一章中，我们具体讨论文件系统的实现。\n文件系统 (file system) 提供了 disk 的抽象，给用户提供存储的逻辑视图。文件系统由两个部分组成：\n\n文件 (file) 的集合，每个文件存储一些数据，是存储的逻辑单位；\n以及 目录结构 (directory structure)，用于组织系统内的文件并提供相关信息，例如提供权限信息以实现一些保护。\n\nFiles | 文件\n文件由操作系统映射到物理存储设备上；在 Unix 中就是一块连续的字节。由于前述存储设备通常是非易失性的，因此文件内容在断电后也能保持。\n文件是用户和程序用来存储和获取信息的途径。从用户角度来看，文件是逻辑外存的最小分配单元；也就是说，数据只有通过文件才能写到外存。\n文件有不同的类型，例如数据文件、可执行文件等。数据文件又可能是 numeric, alphabetic, alphanumeric, binary 的。\n文件属性\n不同的操作系统可能会保存不同的文件属性 (attributes)，但是通常包括：\n\nName。这是唯一的以 human-readable 形式保存的信息。\nIdentifier。一个在当前文件系统中唯一的 tag（通常为 number）文件系统用它来标识文件。\nType。一些文件系统支持不同的文件类型。\nLocation。标识文件在哪个设备的哪个位置。\nSize。当前文件大小，也可能包含文件允许的最大大小。\nProtection。Access-control information。\nTimestamp。保存创建时间、上次修改时间、上次使用时间等。\nUser identification。创建者、上次修改者、上次访问者等。\n一些文件系统还支持 extended file attribute，例如 file checksum。\n这些信息是前述 目录结构 (directory structure) 的一部分。\n\n文件操作\n操作系统可以提供相关的系统调用来完成一些基本的文件操作，例如：\n\nCreate。在 FS 中为文件找到空间，然后在 directory 中创建条目。\nRead / Write。维护一个 current-file-position pointer 表示当前读写的位置，在对应位置上做读写操作（从磁盘读到内存或者相反）\nRepositioning within a file (a.k.a. Seek)。将 current-file-position pointer 的位置重新定位到给定值，例如文件开头或结尾。\nDelete。在 directory 中找到对应条目，释放文件空间，删除对应条目。\nTruncate。清空文件内容，但保留文件属性。\n\n文件打开\nOpen。返回一个 handler 用来执行其他操作。\n可能会把文件放在 打开文件表 (open-file table) 中以便索引，直到 Close\n可能允许一个文件被打开多次，因此在打开文件表中可以维护一个 file-open count\n文件锁\n一些 FS 也会提供 文件锁 (file lock) 来协调文件访问，例如允许一个进程锁定文件来避免其他文件访问它。\n\n文件锁类似于第 7 节中讨论的 reader-writer lock。有的 FS 提供两种锁：\n\n共享锁 (shared lock) 类似于 reader lock\n独占锁 (exclusive lock) 类似于 writer lock。有的 FS 只提供独占锁。\n\n\n同时，文件锁也有两种可能的机制，由操作系统决定。\n\n 强制锁定 (mandatory lock)，即一旦进程获取了独占锁，操作系统就阻止任何其他进程访问对应文件，即操作系统本身确保了完整性；\n建议锁定 (advisory lock)，即进程可以自己得知锁的状态然后决定要不要坚持访问。Windows 使用前者，而 UNIX 使用后者。\n\n\n也应当采取措施，来确保不会出现死锁。\n\n文件类型\n文件有不同的类型。操作系统可以选择是否需要识别不同的文件类型。\n\n识别不同文件类型的方式之一是 文件扩展名 (file extension)；例如规定只有扩展名是 .com, .exe, .sh 的文件才能执行。\n另外，也可以通过在文件开始部分放一些 magic number 来表明文件类型；但是由于不是所有文件都有 magic number，因此系统不能只基于这种方式判断文件的类型。\n也可以采用的一种方式是，操作系统不试图识别文件的类型；当用户尝试运行一个文本文件，或者试图用文本编辑器打开一个二进制文件时，会照常按照预期的编码方式解析；但操作系统以及打开这个文件的应用程序本身的安全设计使得这样的操作不会带来太坏的后果。\nUNIX 允许文件扩展名的提示，但是扩展名主要是帮助用户来确定内容类型；操作系统本身并不强制文件扩展名，也并不依赖这些扩展名。应用程序的开发者可以选择是否忽略文件扩展名。\n\n文件结构\n文件可以有不同的结构，由操作系统或者用户程序定义。\n\n最简单的是 无结构 (no structure) 文件，它只是 a stream of bytes or words。例如 UNIX operating system defines all files to be simply streams of bytes。\n另外也有 simple record structure 文件，以 record 为单位，每个 record 可以是定长或者变长的，例如数据库。\n还有 complex structures 文件。例如 Microsoft Word 文档。\n\nAccess Methods | 访问方式\n我们讨论有哪些访问文件信息的方式。\n\n最简单也最常见的访问方式是 顺序访问 (sequential access)。就像磁带那样，逐字节或者逐 record 地访问。\n另一种方法是 直接访问 (direct access) 或称 相对访问 (relative access) 或称 随机访问 (random access)。即支持以几乎相同的时间访问任意位置。\n在直接访问的方法之上，还有可能提供索引，即先在索引中得知所需访问的内容在哪里，然后去访问。也有可能使用多层索引表。\n为了防止索引表过大，也可能引入 索引顺序访问 (Indexed Sequential-Access)，即像字典那样确定所需访问的内容在哪一块，再在对应块中顺序寻找。\n\nDirectory Structure | 目录结构\n如我们之前所说，directory 中包含了文件的很多信息；\ndirectory structure 应当实现新建、删除、查找、遍历、列出目录中的文件等基本操作。\n同时，设计也应当兼顾效率、便于使用、便于按一些属性聚合等要求。\n单级目录\n最简单的目录结构是 single-level directory，即将所有文件都包含在同一目录中：\n\n这种实现方式的问题是，当文件数量增加时，并没有有效的方法来查找或者给文件分组（例如找出所有的 Java 程序）\n同时，由于所有文件位于同一目录下，因此它们的名称必须是唯一的。在有多个用户时，这种需求是不太合理的。\n\n两级目录\n\nTwo-level directory 为每个用户创建自己的 用户文件目录 (User File Directory, UFD)；\n这些 UFD 聚合成为 主文件目录 (Master File Directory, MFD)，当用户登录时，操作系统从 MFD 中找到用户的 UFD。\n这种实现方式一定程度上减少了文件数量多的问题，同时不同用户也可以分别创建同名的文件了。但是分组仍然没有支持。\n用户 1 访问自己的文件，可以直接通过 test 的方式访问；为了访问其他用户的文件，需要通过 user2/data 的方式访问。这样的实现方法其实是把二级目录视作一棵高度为 2 的树。\n\n树形目录\nTree-Structured Directories 是上面方案的自然推广。在这种实现方案中，目录本身也被放在父目录的一个条目中；每个条目有一个 bit 来表示这个条目表示的是一个文件还是一个子目录。目录也被认为是一种特殊的文件。\n\n在正常使用时，每个进程有一个 当前目录 (current directory)；当用户指定一个文件名时，就在当前目录中寻找。用户也可以通过系统调用 change_directory() 来更改当前目录。\n如果所需目录不在当前目录，那么用户就必须提供一个 路径名 (path name)，表示在这棵树上如何走可以找到所需的文件。路径名分为两种：\n\n绝对路径名 (absolute path name)，表示从根开始到指定文件的路径，例如 /bin/count, programs/p/list；\n相对路径名 (relative path name)，表示从当前目录开始的路径。\n\n当删除一个目录时，一种设计思路是不允许删除非空的目录；另一种是，删除目录下的所有文件（包括子目录）\n无环图目录\nAcyclic Graph Directories 在上面的方案的基础上支持了目录共享子目录或者文件：\n\n一种实现方式是，引入一个名为 链接 (link) 的新的目录条目类型，表示另一个文件或者子目录的指针。在遍历目录树时，操作系统忽略链接以维护系统的无环结构。\n\n这个指针的实现方式之一是用链接文件来记录指向文件的绝对或相对路径，这种方式称为 符号链接 (symbolic link) 或者 软链接 (soft link)。当访问这种文件时，操作系统通过该路径名来 resolve 链接，从而定位真实文件。\n这种方式存在的一个问题是，如果删除一个被某个 soft link 所引用的文件，则会留下 dangling pointer，即那些 link 现在指向并不存在的文件。UNIX 和 Windows 采用的方式是，当真实文件被删除时，并不试图处理这些 link；用户在试图访问这些 link 时会发现真实文件已经被删除。\n\n\n另一种实现方式是复制被引用文件的所有信息，放在当前目录中。\n\n由于这里的「信息」中也包含文件存储在外存中的哪个部分，因此事实上这个新的条目和被引用的条目指向的是同一个文件。\n这种方式称为 硬链接 (hard link)。这个链接和原文件本身相同且相等，因此可能没有办法区分它们。这种实现的主要问题是，在修改文件时要维护一致性，即需要在所有包含这个文件的目录中更新对应的信息。\n\n\n这种实现给每个文件引入了一个 引用计数 (reference counter)；在每个文件被创建一个新的硬链接时，该计数 +1；而删除一个硬链接或原文件本身时，该计数 -1。当计数为 0 时，文件可以删除。\n\nUNIX 同时支持上述两种链接。为了维护无环图结构，hard link 不允许引用目录，而 soft link 可以。\n\n\n                  \n                  Hard link &amp; soft link \n                  \n                \n\nHard link 是一个 directory entry[复制被引用文件的所有信息]，而 soft link 是一个 file。\nHard link 不能引用 directory，因为这会带来很多问题[比如死循环]，但是 soft link 可以。\n\n一个例外是，每个目录中的 file name . 是指向自己的 hard link，而 .. 是指向父目录的 hard link。这个时候hardlink是可以引用directory地\nHard link 不能跨越 file-system boundaries，但是 soft link 可以。这是因为，在多个 file-system 之间，FCB 的标识号不再一定是唯一的。\n\n\n\n通用图目录\nGeneral Graph Directory 允许目录中有环。这会使得遍历图的算法更加复杂，因为需要避免重复遍历一些部分。同时也会给确定何时可以删除某个文件或者目录带来麻烦，因为可能存在的相互引用或者自我引用会使得在没有可能引用一个目录或文件时引用计数也不为 0。\n为了解决这种问题，通常需要使用 垃圾回收 (garbage collection) 方案来确定哪些文件可以删除。这是非常费时的。\nFS Mounting | 文件系统挂载\nDirectory Structure 可以构建在多个 volume 上，这些 volume 必须先 挂载 (mount) 到文件系统的某个位置，这个位置称为 挂载点 (mount point)。\n例如，下面右图展示了左图的 volume 被挂载到 /users 下的结果：\nProtection\n文件的所有者或者创建者应该有权限决定哪些用户有权限做哪些事情。\n给每个文件和目录维护一个 Access Control List (ACL)，指定每个用户及其允许的访问类型。为了精简 ACL，可以将用户分为不同的类型。\nUNIX 将用户分为了三类（owner0, group, others)，并将文件访问也分为了三类 (read, write, execute)：\n\n》root 的权限\n\n当一个文件的 read 或 write bit not set 时，root 用户仍然能够读或写它。\n当一个目录的 execute bit 对于一个用户所在的分类 not set 时，该用户不能进入该目录；但是 root 用户可以。\n但是，如果一个文件对三类用户的 execute bit 均 not set 时，这个文件被认为不是可执行的，因此 root 用户也不能执行这个文件。\n"},"课程笔记/操作系统/其他/lab4-report":{"slug":"课程笔记/操作系统/其他/lab4-report","filePath":"课程笔记/操作系统/其他/lab4 report.md","title":"lab4 report","links":[],"tags":[],"content":"小组成员: 邓静怡,肖惠文\n准备工作\n\n\n从仓库拉取最新的代码\n\n\n修改 vmlinux.lds，将用户态程序 uapp 加载至 .data 段\n\n\n\n修改makefile编译且链接新的文件夹\n\n\n创建用户态进程\n更新结构体\n\n本次实验只需要创建4个用户态进程\n将特权寄存器设置到thread_struct中\n\n为多个用户态进程设置自己的页表\n\n内核线程可以共享一个页表,多个用户态进程则需要保证相对隔离\n\n修改task_init\n对于每个用户进程的初始化:\n\n增加用户态标志位\n\n初始化 sepc、sstatus、sscratch\n\n创建页表并复制内核页表到创建的页表中\n\n\n复制递归函数入口\n\n复制递归函数实现\n\n如果是一级/二级页表,就对页表的每一项(共512项)\n1. 从源页表PTE中提取下一级页表的物理地址\n2. 为新页表分配下级页表的空间,递归复制下级页表\n3. 为新页表PTE设置好对下级页表指向\n如果是三级页表.复制源页表的每一项即可.\n\n\n\n\n\n分配一块新的内存地址,拷贝 uapp 进去.然后将页面映射到页表中\n\n先计算所需的页数（uapp 的大小除以 PGSIZE 后向上取整）\n调用 alloc_pages() 函数\n再将 uapp memcpy 过去\n\n映射到页表中.\n\n\n\n设置栈-两个\n\n用户态栈：我们可以申请一个空的页面来作为用户态栈，并映射到进程的页表中\n\n内核态栈: 在 lab3 中已经设置好了，就是 thread.sp\n\n\n\nalloc_pages:\n\n分配物理页号并转换为虚拟地址返回.\nuapp:\n用户程序,编译生成uapp.bin纯二进制文件,链接时放入内核数据段.然后为每个进程拷贝一份uapp[到新分配的物理内存中][并且重新映射到用户进程自己的虚拟地址],防止冲突.\n每个用户态进程有自己的虚拟地址0x0 → 0x4000000000 (USER_END)\n\n切换逻辑\n由另一位同学负责\n异常分发与调试\n由另一位同学负责\nELF 解析与系统调用实现\n系统调用实现\n\n在发生系统调用异常时,调用系统调用处理函数\n\n进入系统调用处理函数,根据系统调用号分发到各个分处理函数,传入不同的参数\n\n然后设置regs中的返回值并手动将sepc+4\n\nwrite() 逻辑\n\ngetpid()逻辑\n\n\n\n\nELF\n\n\nsection:细粒度\n\n\nsegment:粗粒度.一个segment里面可能包含多个section.我们按segment为单位加载到内存\n\n\nELF header: 包含入口地址\\program headers在文件中的偏移量\\有多少个program headers(需要加载的段)\n\n\nprogram header: 每个program header描述一个segment\n\n段类型:是否需要加载\n在文件中的位置:从文件第几个字节开始\n虚拟地址:加载到内存的哪个地址\n文件里这段有多大size\n内存里需要多大空间\n权限\n\n\n\n未初始化数据在文件中不需要存储,只需要记录有多大\n但是在内存中就需要确切地分配好空间.file大小和mem大小的的差别就在这里(bss段.)加载之后直接清零即可\n\n更换payload\n\n修改task_init初始化步骤\n\n\n将原本读取二进制文件相关代码修改为使用 ELF 解析和加载程序\n分配完用户态栈后,设置sscratch寄存器\n\n\nELF加载函数\n\n内核区读取 ELF 信息[本实验中所有进程共用一个uapp因此是读取一样的代码和数据]\n\n为这个程序的每个 segment 分配独立的物理内存\n\n计算需要映射的内存大小并计算需要映射的页数\n\n按照页对齐分配物理内存\n\n将段内容从ELF文件拷贝到分配的内存[拷贝filesize]\n\n将bbs段空间清零[memsize-filesize]\n\n设置权限\n\n\n\n建立虚拟地址映射\n\n设置程序入口地址sepc[ELF]\n\n\n\n\n编译并运行\n\n思考题\n\n\n我们在实验中使用的用户态线程和内核态线程的对应关系是怎样的？（一对一，一对多，多对一还是多对多，言之有理即可）\n实验里调度的基本单位就是 task_struct.它同时保存了内核线程的寄存器上下文和对应用户态的关键寄存器.调度器每次切换的其实是这个结构本身,这个结构又只对应一个用户态进程.而没有在多个用户线程之间再映射同一个内核线程,因此可以认为是一对一的关系.\n\n\n系统调用返回为什么不能直接修改寄存器？\n陷入内核时 _traps 会把所有寄存器复制到 pt_regs,真正返回用户态时会从 pt_regs 恢复.如果内核里直接改真实寄存器,下一次 sret 恢复又会被 pt_regs 覆盖,所以必须写回 regs→a0 等保存区，保证状态一致.\n\n\n针对系统调用，为什么要手动将 sepc + 4？\nsepc 保留触发异常的指令地址.ecall 是一条 4 字节的指令,如果不手动加 4,sret 回去后还会再次执行同一条 ecall,进入死循环,所以要显式加 4 跳过它.\n\n\n为什么 Phdr 中，p_filesz 和 p_memsz 是不一样大的，它们分别表示什么？\np_filesz 是 segment 在 ELF 文件里真实占用的字节，比如 .text、.data；p_memsz 是进程运行时需要的内存大小，它还包含 .bss 这种在文件里不占空间,但运行时要被清零的部分，所以常常更大.加载时要先拷贝 p_filesz 区间,再把 p_filesz 到 p_memsz 清零.\n\n\n为什么多个进程的栈虚拟地址可以相同？用户态程序有没有方法知道栈所在的物理地址？\n每个进程有私有页表,把同一个用户栈虚拟地址映射到不同的物理页.因为用户态无法访问页表,也不能读取物理地址,所以它看不到真实物理位置,只能按虚拟地址使用,来做到地址空间隔离.\n\n\n心得体会\n\nELF: 一种可执行文件格式,里面除了代码和数据以外还包括目录[说明文件结构\\入口点\\段信息],以及附录[符号表,调试信息等]\n纯二进制文件: 只包含代码和数据,没有目录和附录\nstrip: 去掉ELF中非必须信息的过程.一般是用 objcopy 将 ELF 转换为纯二进制（.bin）\n先运行纯二进制文件,再切换成ELF文件.是为了通过简单操作验证基本流程是否正常,再切换到ELF支持更复杂的功能\n\n用户态进行系统调用的过程\n\n用户态调用ecall\ncpu会自动做的事情\n\n保存异常发生的PC到sepc\n记录异常原因到scause\n记录来自Umode到s’s’tasstatus\n切换到Smode\nstvec写入PC: 跳转到_traps\n\n\ntraps会切换栈:\n\n从用户栈切换到内核栈\n在内核栈上分配空间[pt_regs]并保存寄存器\n\n\n调用handler,调用的时候会覆盖原本的寄存器\n\nsie: 中断类型开关.决定哪些终端类型可以作用\nsstatus.sie: s态全局开关,决定在s态(内核态执行时),是否允许中断.\n当cpu在用户态运行时,特权级的中断总是启用的,不管sstatus是如何设置的."},"课程笔记/操作系统/操作系统期末":{"slug":"课程笔记/操作系统/操作系统期末","filePath":"课程笔记/操作系统/操作系统期末.md","title":"操作系统期末","links":[],"tags":[],"content":"计算大题\n\n进程调度算法：\n◦ 重点：熟练绘制 FCFS、SJF（抢占与非抢占）、优先级调度（抢占）、RR（时间片轮转） 的甘特图。\n◦ 要求：准确计算平均等待时间和平均周转时间。\n信号量同步（PV操作）：\n◦ 重点：掌握 生产者-消费者、读者-写者、哲学家进餐、医生看病、会议室管理 等经典模型。\n◦ 注意：理解信号量初值设定及 PV 顺序（特别是同步与互斥相邻时，先执行同步 wait）。\n内存管理与分页架构：\n◦ 重点：二级页表（甚至三级）的地址转换，计算页号（Page Number）、页内偏移（Offset）。\n◦ 关键计算：有效访问时间（EAT），需考虑 TLB 命中率、内存访问时间及缺页处理时间。\n死锁避免（银行家算法）：\n◦ 重点：根据 Max、Allocation 矩阵计算 Need 矩阵，判断系统是否处于 安全状态，并给出一个安全序列。\n\n存储与文件\n文件系统和磁盘调度在选择题和中型计算题中出现频率极高。\n\n页面置换算法：\n◦ 重点：FIFO、LRU、OPT（最佳置换） 的置换过程及缺页数计算。\n◦ 考点：理解 Belady 异常（FIFO 特有）及 抖动（Thrashing） 现象。\n文件分配方式与索引：\n◦ 重点：计算 混合索引（如 Linux inode 的 12直接+一级+二级+三级索引） 能管理的最大文件大小。\n◦ 对比：连续分配（Contiguous）、链接分配（Linked）与索引分配（Indexed）的优缺点（如：连续分配不支持动态增长，链接分配不支持随机访问）。\n磁盘调度算法：\n◦ 重点：SSTF（最短寻道时间优先）、SCAN（电梯算法）、C-SCAN 的移动距离计算。\n◦ 特性：SSTF 可能导致饥饿，而 C-SCAN 提供更均匀的等待时间。\n\n进程线程 linux\n第三优先级：进程、线程与 Linux 特色（选择与填空）\n此部分内容多见于小测和回忆卷的选择题，侧重概念理解。\n\n进程与线程模型：\n◦ 考点：线程共享资源（堆、全局变量、代码段），不共享（栈、寄存器、Thread ID）。\n◦ 多线程模型：many-to-one（一个阻塞全部阻塞）、one-to-one、many-to-many。\n◦ 系统调用：fork() 创建进程（注意返回值，父进程返回子 PID，子进程返回 0）、exec() 替换进程映像。\n操作系统结构与机制：\n◦ 考点：双模式执行（用户态 vs 内核态），特权指令的定义，触发状态切换的事件（异常、中断、陷入/系统调用）。\n◦ 中断处理：中断向量、DMA（不经过 CPU 直接交换数据）、软中断（Trap）。\nLinux/Windows 特色：\n◦ Linux：task_struct 结构、CFS 调度器、/proc 文件系统（伪文件系统）、内核模块加载命令（insmod, lsmod） [26, 20.7, 2951, 3195]。\n◦ RAID 级别：RAID 0（条带化）、RAID 1（镜像）、RAID 5（分布式奇偶校验，兼顾容量与容错）、RAID 1+0。\n\n低频\n\n操作系统目标：方便性、效率。\n存储体系：寄存器 &gt; 缓存 &gt; 主存 &gt; 辅存的层次与速度对比。\n微内核与宏内核对比：微内核更易扩展、更安全，但通信开销大。\n地址绑定时机：编译时、加载时、执行时（动态重定位）。\n\n面试导向\nGo 的杀手锏是高并发（Goroutine），而理解 Goroutine 的前提是理解操作系统原本的进程/线程模型。\n1. 进程、线程与协程 (Process, Thread, Coroutine)\n\n\n基础概念： 进程和线程的区别（资源分配 vs 调度单位）。\n\n\n上下文切换 (Context Switch)： 进程切换 vs 线程切换的开销区别。\n\nGo 关联： 为什么 Goroutine 切换成本极低（用户态切换，只需保存极少寄存器）？\n\n\n\n进程间通信 (IPC)： 管道、消息队列、共享内存、信号量。\n\nGo 关联： Go 推荐 “不要通过共享内存来通信，而要通过通信来共享内存” (Channel)，这对应了哪种 IPC 思想？\n\n\n\n2. I/O 模型 (必考核心)\n这是 Go 后端面试中最硬核的部分，因为 Go 的高性能主要源于此。\n\n五种 I/O 模型： 阻塞 I/O、非阻塞 I/O、I/O 多路复用、信号驱动 I/O、异步 I/O。\nIO 多路复用 (IO Multiplexing)：\n\nselect, poll, epoll 的区别： 为什么 epoll 在高并发下性能更好？（红黑树、就绪链表）。\n触发模式： 水平触发 (LT) vs 边缘触发 (ET)。\nGo 关联： Go 的 Netpoller（网络轮询器）底层就是基于 epoll (Linux) / kqueue (Mac) / IOCP (Windows) 实现的。面试常问：Go 如何用同步的代码逻辑实现了异步的 I/O 性能？\n\n\n\n3. 内存管理\n\n虚拟内存： 什么是虚拟内存？分页 (Paging) 和分段。\n用户态 vs 内核态： 系统调用 (System Call) 会导致状态切换。\n堆 (Heap) vs 栈 (Stack)：\n\nGo 关联： 逃逸分析 (Escape Analysis)。在 C/C++ 中你需要手动管理堆内存，但在 Go 中，编译器决定变量是在栈上还是堆上。你需要复习一下什么情况会导致变量“逃逸”到堆上（如返回局部变量指针）。\n\n\n\n4. 死锁 (Deadlock)\n\n产生死锁的四个必要条件： 互斥、占有且等待、不可抢占、循环等待。\n如何预防/避免： 破坏其中一个条件。\n\nGo 关联： RWMutex, Channel 如果使用不当会导致死锁（fatal error: all goroutines are asleep - deadlock!）。\n\n\n"},"课程笔记/操作系统/流程总览/01-系统启动与进程创建":{"slug":"课程笔记/操作系统/流程总览/01-系统启动与进程创建","filePath":"课程笔记/操作系统/流程总览/01 系统启动与进程创建.md","title":"01 系统启动与进程创建","links":["课程笔记/操作系统/01-introduction","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"系统启动流程\n上电与引导\n计算机上电后的启动过程：\n\nCPU执行ROM中的引导加载器（bootstrap loader）\n\n这是开机后执行的第一个软件\n位置固定且已知\n\n\n引导加载器完成的任务\n\n硬件自检（POST）\n定位磁盘上的操作系统内核镜像\n将内核加载到主内存（RAM）\n切换CPU为内核态，开始执行内核代码\n\n\n\n内核初始化\n内核加载到内存后的初始化步骤：\n初始化中断系统\n\n设置中断向量表（interrupt vector table）\n\n建立中断号到中断处理程序的映射\n\n\n配置中断请求线（interrupt-request line）\n初始化计时器（timer）\n\n用于时间片管理\n\n\n\n初始化内存管理\n\n建立物理内存的帧表（frame table）\n\n记录每个物理帧的使用情况\n\n\n初始化内核的页表结构\n设置内存保护机制\n\n初始化进程管理\n\n创建初始的内核数据结构\n准备就绪队列（ready queue）\n准备等待队列（wait queue）\n\n创建第一个用户进程\n内核初始化完成后，创建第一个用户进程：\n\nLinux中通常是init或systemd\n进程ID（PID）为1\n\n创建步骤：\n\n分配进程控制块（PCB）\n建立虚拟地址空间\n建立页表映射\n通过加载器（loader）加载可执行文件\n切换到用户态并开始执行\n\n程序的地址绑定\n程序从源代码到内存的完整过程。\n编译、链接、加载\n\n\n编译阶段（.c → .o）\n\n编译器将源代码中的符号地址转换为可重定位地址\n符号地址：变量名、函数名等\n可重定位地址：相对于某个段的偏移\n\n\n\n链接阶段（.o → .exe）\n\n链接器将多个目标文件合并\n生成可执行文件\n地址变为相对于整个程序的地址\n\n\n\n加载阶段（.exe → 内存）\n\n加载器将可执行文件加载到内存\n完成地址绑定（Address Binding）\n得到绝对物理地址\n\n\n\n虚拟地址空间的建立\n每个进程拥有独立的虚拟地址空间：\n用户部分（User Portion）\n\ntext section：代码段\ndata section：全局变量、静态变量\nheap section：动态分配的内存（堆）\nstack section：函数调用、局部变量（栈）\n\n内核部分（Kernel Portion）\n\n存储PCB等内核数据结构\n所有进程的内核部分映射到同一块物理内存（参见Kernel Addresses &amp; Userspace Addresses）\n\n进程创建机制\nfork系统调用\nfork()是系统调用，用于创建子进程。\nfork的执行流程\n\n\n触发系统调用\n\n用户程序调用fork()\n触发软中断（trap）\nCPU切换到内核态\n\n\n\n内核创建子进程\n\n分配新的PCB\n子进程获得新的PID\n子进程的PPID指向父进程\n复制父进程的虚拟地址空间\n\n\n\n返回用户态\n\n父进程：fork()返回子进程的PID（非零值）\n子进程：fork()返回0\n两个进程从fork()后继续执行\n\n\n\nCopy-on-Write机制\nCopy-on-Write（COW）优化fork的性能：\n基本原理\n\nfork后，父子进程最初共享同一份物理页\n页表项标记为只读\n当任一进程尝试写入共享页时，触发写保护异常\n操作系统此时才真正复制该页\n\n优势\n\n节省内存空间\n提高fork效率\n特别适用于fork后立即exec的场景\n\nexec系统调用\nexec()用新程序覆盖当前进程的地址空间。\nexec的执行流程\n\n加载新的可执行文件\n\n从磁盘读取新程序\n解析可执行文件格式\n\n\n覆盖当前虚拟地址空间\n\n释放原有的页表映射\n建立新的页表映射\n\n\n重置执行环境\n\n重置程序计数器（PC）\n从新程序的入口点开始执行\n进程PID不变\n\n\n\nfork与exec的组合使用\n典型用法：\n\n父进程调用fork()创建子进程\n子进程调用exec()执行新程序\n父进程可选择调用wait()等待子进程结束\n\n示例场景：\n\nshell执行命令\n服务器处理请求\n\n进程的终止\n进程终止的方式（参见进程的终止）：\n正常终止\n\n调用exit()系统调用\nmain函数返回（隐式调用exit）\n\n异常终止\n\n信号终止\n异常导致的终止\n\n相关概念\n\n僵尸进程（zombie）：已终止但未被父进程回收\n孤儿进程（orphan）：父进程先于子进程终止\n\n相关概念\n\n01 introduction - 操作系统概述、中断、特权模式、引导\n02.1 进程 - 进程概念、PCB、进程创建与终止\n02.2 调度 - 进程状态、就绪队列、等待队列\n04.1 主存 - 内存保护、分页、页表、帧表\n04.2 virtual memory - 虚拟地址空间、COW机制\n"},"课程笔记/操作系统/流程总览/02-内存管理":{"slug":"课程笔记/操作系统/流程总览/02-内存管理","filePath":"课程笔记/操作系统/流程总览/02 内存管理.md","title":"02 内存管理","links":["课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"\n\n物理内存\n\n高地址 动态分配区域.剩下的空闲内存,所有后来创建的东西都塞在这里\n\n用户进程代码(从磁盘读进来的)\n用户栈\n内核栈\n页表\n等等等 都是动态且可能不连续的\n\n\n低地址 内核的代码和静态数据.\n\n_ekernel 内核结束\n.bss 未初始化数据(全局变量之类的)\n.data 数据+uapp\n.rodata 只读数据\n.text 代码\n最低的80000000开始 opensbi(2MB)\n\n\n\n\n\n虚拟内存\n\n高地址 映射到物理内存的低处固定静态区域.也有内核栈会映射到物理内存高处动态分配区域\n空洞 不可达,做区分用\n低地址\n\n通过页表,可以将这些低的虚拟地址,映射到物理内存的高处动态分配区域\n\n\n\n\n\n虚拟内存概述\n基本概念\n虚拟内存的作用\n\n每个进程拥有独立的虚拟地址空间\nCPU使用虚拟地址，由MMU（内存管理单元）自动转换为物理地址\n实现进程间的隔离与保护\n\n虚拟地址空间的结构\n\n用户空间（User Portion）：0 ~ 3GB（32位系统）\n内核空间（Kernel Portion）：3GB ~ 4GB（32位系统）\n所有进程的内核空间映射到同一块物理内存（参见Kernel Addresses &amp; Userspace Addresses）\n\n虚拟内存的优势\n\n隔离性：每个进程拥有独立的虚拟地址空间，互不干扰\n灵活性：进程可以使用比物理内存更大的虚拟地址空间\n效率：通过按需分页和页面置换，提高内存利用率\n共享性：多个进程可以共享同一块物理内存\n\n分页机制\n基本原理\n现代操作系统使用分页（Paging）机制管理内存。\n物理内存分帧\n\n将物理内存切分为等大小的帧（frame）\n通常大小为4KB\n\n虚拟内存分页\n\n将虚拟地址空间切分为等大小的页（page）\n大小与帧相同\n\n页表映射\n\n通过页表建立页到帧的映射关系\n页表存储在内存中\nPTBR（Page-Table Base Register）指向页表基地址\n\n地址转换过程\nCPU生成的虚拟地址转换为物理地址：\n\nCPU生成虚拟地址（page number + offset）\nMMU根据页表将page number转换为frame number\n物理地址 = frame number + offset\n\n地址结构\n\n虚拟地址 = 页号（p） + 页内偏移（d）\n物理地址 = 帧号（f） + 页内偏移（d）\n页内偏移在转换前后保持不变\n\n页表的硬件实现\n页表存储方式\n寄存器方式\n\n优点：访问速度快\n缺点：页表大小受限，上下文切换开销大\n适用于小型页表\n\n内存方式\n\nPTBR指向页表基地址\n优点：支持大型页表\n缺点：每次地址转换需要两次内存访问\n\nTLB加速机制\nTLB（Translation Look-aside Buffer）是页表的高速缓存：\n工作原理\n\nCPU访问虚拟地址时，首先查询TLB\nTLB命中：直接获得物理地址（一次内存访问）\nTLB未命中：访问内存中的页表（两次内存访问），并将结果存入TLB\n\nTLB特点\n\n支持并行搜索（associative memory）\n通常包含64~1024个条目\n每个条目包含：page number → frame number\n\nTLB与进程切换\n\n每个进程有自己的页表，切换时需要处理TLB\n方法1：flush TLB（清空所有TLB条目）\n方法2：使用ASID（Address-Space Identifier）\n\nTLB条目同时存储ASID\n匹配时同时检查page number和ASID\n避免频繁清空TLB\n\n\n\n多级页表\n为解决页表占用过多连续内存的问题，采用多级页表结构。\n基本思想\n\n对页表进行分页\n外层页表指向内层页表\n内层页表存储实际的frame number\n\n二级页表示例\n\n虚拟地址 = 外层页号（p1） + 内层页号（p2） + 页内偏移（d）\n通过p1索引外层页表，得到内层页表基地址\n通过p2索引内层页表，得到frame number\n\n优势\n\n页表不需要占用连续内存\n未使用的内层页表可以不分配\n节省内存空间\n\n按需分页\nLazy Allocation机制\n操作系统采用延迟分配（Lazy Allocation）策略：\n基本流程\n\n进程申请内存时，操作系统只扩大虚拟地址空间\n不立即分配物理内存\n当进程首次访问该虚拟地址时，触发缺页中断（page fault）\n操作系统在中断处理程序中分配物理内存\n\n优势\n\n节省物理内存\n提高系统响应速度\n很多申请的内存实际不会被使用\n\n缺页中断处理流程\n当进程访问的虚拟地址对应的页面不在物理内存中：\n\n\n触发page fault\n\nMMU在页表中查找\n发现valid bit为invalid\nCPU触发page fault异常，切换到内核态\n\n\n\n检查页面合法性\n\n检查虚拟地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n非法访问则终止进程\n\n\n\n分配物理帧\n\n如果有空闲帧，直接使用\n如果没有空闲帧，执行页面置换算法\n\n\n\n调入页面\n\n页面在磁盘上（被swap out）：从backing store读取\n页面是首次访问：分配新的零页\n\n\n\n更新页表\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n\n\n重新执行指令\n\n返回到用户态\n重新执行触发page fault的指令\n\n\n\n页面置换\n基本概念\n当物理内存不足时，需要将某些页面换出到磁盘。\n置换流程\n\n选择victim frame\n\n使用页面置换算法\n\n\n写回磁盘\n\n如果页面被修改过（dirty bit=1），将其写回磁盘\n未修改过的页面可以直接丢弃\n\n\n调入新页面\n\n将需要的页面从磁盘调入到victim frame\n\n\n更新页表\n\n将victim页面的页表项设置为无效\n记录页面在磁盘的位置\n\n\n\n页面置换算法\n详见页面置换算法 (page replacement algorithms)\n常见算法\n\nFIFO（First In First Out）：最简单，可能有Belady异常\nOptimal：理论最优，实际无法实现\nLRU（Least Recently Used）：近似最优，开销较大\nLRU-Approximation：使用reference bit近似实现\n\nreference bit机制\n\n每个页面关联一个reference bit\n页面被访问时置为1\n操作系统定期清零\n置换时选择reference bit为0的页面\n\n进程间内存共享\n多个进程可以共享同一块物理内存：\n共享代码\n参见Shared Pages\n应用场景\n\n多个进程执行同一程序时\n可以共享text段（代码段）\n\n实现方式\n\n不同进程的页表中，不同的虚拟页映射到同一物理帧\n\n要求\n\n代码必须是可重入的（reentrant code）\n\n共享内存IPC\n参见进程间通信\n应用场景\n\n进程间通信（IPC）\n高效的数据共享\n\n实现方式\n\n通过系统调用建立共享内存区域\n多个进程的虚拟地址空间映射到同一物理内存\n\n注意事项\n\n需要同步机制（如信号量）保护共享数据\n避免race condition\n\n内存保护\n页表保护位\n参见内存保护机制Protection和Memory Protection内存保护\nvalid-invalid bit\n\nvalid：页面在进程的合法地址空间内\ninvalid：页面不属于该进程，访问会触发trap\n\n权限位\n\n读权限（R）\n写权限（W）\n执行权限（X）\n\n保护机制\n\nMMU在地址转换时检查权限\n非法访问触发异常\n操作系统处理异常（通常终止进程）\n\nbase和limit寄存器\n参见内存保护机制Protection\n传统保护方式\n\nbase寄存器：进程地址空间的起始地址\nlimit寄存器：进程地址空间的大小\n每次访问检查：base ≤ 地址 &lt; base + limit\n\n相关概念\n\n04.1 主存 - 内存分配、分页、页表、TLB、帧表\n04.2 virtual memory - 虚拟内存、按需分页、页面置换\n02.1 进程 - 进程地址空间、进程间通信\n"},"课程笔记/操作系统/流程总览/03-进程调度":{"slug":"课程笔记/操作系统/流程总览/03-进程调度","filePath":"课程笔记/操作系统/流程总览/03 进程调度.md","title":"03 进程调度","links":["课程笔记/操作系统/02.2-调度","课程笔记/操作系统/01-introduction","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.3-线程"],"tags":[],"content":"进程状态\n五种基本状态\n进程在运行过程中会经历以下进程状态：\nNew（新建）\n\n进程正在创建过程中\n包括申请PCB、分配初始资源等\n\nReady（就绪）\n\n进程已准备好，等待CPU资源\n一旦获得CPU就可以立即执行\n\nRunning（运行）\n\n进程正在使用CPU执行\n单核系统中同时只有一个进程处于Running状态\n多核系统中Running进程数不超过核心数\n\nWaiting（等待）\n\n进程等待某个事件（如I/O完成、信号等）\n即使有空余的CPU资源，该进程也无法继续\n从Running到Waiting通常是主动的\n\nTerminated（终止）\n\n进程已结束\n需要释放资源\n\n状态转换\nReady → Running\n\n被调度器选中\n获得CPU资源\n称为派发（dispatch）\n\nRunning → Ready\n\n时间片用完（timer中断）\n被更高优先级进程抢占\n从Running到Ready是被动的\n\nRunning → Waiting\n\n主动等待（系统调用、I/O请求）\n需要等待某个事件发生\n\nWaiting → Ready\n\n等待的事件发生（如I/O完成）\n被中断唤醒\nWaiting不能直接进入Running，必须经过Ready\n\n队列管理\n就绪队列和等待队列\n参见就绪队列(ready queue)和等待队列(wait queue)\n就绪队列（Ready Queue）\n\n存放处于Ready状态的进程\n实际上是PCB的队列\n调度器从就绪队列选择进程执行\n\n等待队列（Wait Queue）\n\n存放处于Waiting状态的进程\n根据等待的事件类型可能有多个等待队列\n\nI/O设备等待队列\n信号量等待队列\n其他事件等待队列\n\n\n\n队列操作\n\n实际上是移动PCB指针在不同队列之间\n由内核负责管理\n\n调度时机\n非抢占式调度\n参见调度的时机\n触发条件\n\n进程主动释放CPU\n进入Waiting状态（系统调用、I/O请求）\n进程终止\n\n特点\n\n进程自愿放弃CPU\n调度开销小\n响应时间可能较长\n\n抢占式调度\n参见调度的时机\n触发条件\n\n时间片用完（timer中断）\n更高优先级的进程变为Ready状态\n当前进程被中断打断\n\n特点\n\n强制性调度\n调度开销较大\n响应时间更短\n现代操作系统普遍采用\n\n上下文切换\n基本概念\n上下文切换（context switch）是进程切换的核心机制。\n上下文包含的内容\n\nCPU寄存器的值（通用寄存器、PC、SP等）\n进程状态信息\n内存管理信息（页表指针等）\n\n完整切换流程\n当调度器决定切换到另一个进程时：\n1. 保存当前进程的上下文\n\n保存CPU寄存器到当前进程的PCB\n\n程序计数器（PC）\n通用寄存器\n栈指针（SP）\n\n\n保存进程状态\n保存内存管理信息\n\n2. 更新进程状态\n\n将当前进程从Running状态改为Ready或Waiting\n将当前进程的PCB移入相应的队列\n\n时间片用完 → Ready Queue\n等待事件 → Wait Queue\n\n\n\n3. 选择下一个进程\n\n调度器从Ready Queue中选择\n根据调度算法决定（参见调度算法）\n\nFCFS（First-Come, First-Served）\nSJF（Shortest-Job-First）\nRR（Round-Robin）\nPriority Scheduling\n多级队列调度\n\n\n\n4. 恢复下一个进程的上下文\n\n加载新进程的PCB中的寄存器值\n恢复CPU状态\n\n内存管理操作\n\n更新PTBR指向新进程的页表\n不同进程的虚拟地址空间被隔离\n\nTLB管理（参见TLB）\n\n方法1：flush TLB（清空所有TLB条目）\n\n简单但开销大\n下次访问需要重新加载TLB\n\n\n方法2：使用ASID（Address-Space Identifier）\n\nTLB条目同时存储ASID和page number\n切换时不需要清空TLB\n减少TLB miss\n\n\n\n内存保护（参见内存保护机制Protection）\n\n通过页表的保护位确保进程只能访问自己的虚拟地址空间\nvalid-invalid bit\n读写执行权限位\n\n5. 切换到新进程\n\n更新进程状态为Running\n设置CPU的mode bit为用户态\n跳转到新进程的PC指向的指令继续执行\n\n上下文切换的开销\n时间开销\n\n保存和恢复寄存器\n切换页表\n可能需要flush TLB\n更新内核数据结构\n典型的context switch时间约为10μs\n\n性能影响\n\n频繁切换会降低系统效率\n需要在响应时间和效率之间平衡\n\n中断驱动的调度\n中断机制\n现代操作系统是中断驱动的。\n中断的作用\n\n提供调度的时机\n响应外部事件\n处理异常情况\n\nTimer中断\n参见计时器 timer\n工作流程\n\n计时器定期产生中断（如每10ms）\nCPU保存当前上下文，跳转到中断处理程序\n中断处理程序检查当前进程的时间片是否用完\n如果用完，触发调度，将当前进程切换为Ready状态\n选择下一个进程执行\n\n时间片机制\n\n时间片（time quantum）：进程每次运行的最长时间\n通常为10~100ms\nRR调度算法的核心参数\n\nI/O中断\n工作流程\n\nI/O操作完成时，设备控制器发起中断\n中断处理程序唤醒等待该I/O的进程\n将进程从Waiting状态切换为Ready状态\n将进程PCB移入Ready Queue\n可能触发调度\n\n系统调用\n参见系统调用\n工作流程\n\n用户程序调用系统调用\n触发软中断（trap）\n切换到内核态执行系统调用\n如果系统调用需要等待（如read），进程进入Waiting状态\n触发调度\n\n调度算法简述\n详见调度算法\n基本算法\nFCFS（First-Come, First-Served）\n\n先来先服务\n非抢占式\n简单但可能导致长作业阻塞短作业\n\nSJF（Shortest-Job-First）\n\n最短作业优先\n可以是抢占式或非抢占式\n理论上最优，但难以预测运行时间\n\nRR（Round-Robin）\n\n时间片轮转\n抢占式\n响应时间好，但平均等待时间可能较长\n\nPriority Scheduling\n\n优先级调度\n可能导致饥饿（starvation）\n可通过aging机制解决\n\n多级队列调度\n参见Multilevel Queue Scheduling和Multilevel Feedback Queue Scheduling\n基本思想\n\n将进程分为不同类别\n每个类别有自己的队列和调度算法\n队列之间也有调度策略\n\n多级反馈队列\n\n允许进程在队列之间迁移\n根据进程行为动态调整优先级\n\n线程与调度\n线程概念\n参见02.3 线程\n线程的特点\n\n轻量级进程\n共享进程的代码、数据、堆\n各自维护寄存器、栈、PC\n\n线程与进程的关系\n\n进程是资源分配的基本单位\n线程是CPU调度的基本单位\n线程间切换开销小于进程间切换\n\n线程调度\n用户级线程\n\n线程库在用户空间实现\n对内核透明\n一个线程阻塞会导致整个进程阻塞\n\n内核级线程\n\n内核直接支持线程\n可以利用多核并行\n一个线程阻塞不影响进程内其他线程\n\n相关概念\n\n02.2 调度 - 进程状态、调度算法、上下文切换\n02.3 线程 - 线程概念、用户级线程、内核级线程\n01 introduction - 中断机制、计时器、系统调用\n02.1 进程 - PCB、进程创建与终止\n04.1 主存 - 页表、TLB、内存保护\n"},"课程笔记/操作系统/流程总览/04-完整流程示例":{"slug":"课程笔记/操作系统/流程总览/04-完整流程示例","filePath":"课程笔记/操作系统/流程总览/04 完整流程示例.md","title":"04 完整流程示例","links":["课程笔记/操作系统/流程总览/01-系统启动与进程创建","03-进程调度与切换","课程笔记/操作系统/流程总览/02-内存管理","课程笔记/操作系统/01-introduction","课程笔记/操作系统/03.1-进程同步及其工具","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"系统启动到第一个进程运行\n参考：系统启动流程\n完整流程\n1. 上电与引导\n\nCPU执行ROM中的引导加载器\n硬件自检（POST）\n定位并加载操作系统内核到RAM\n切换到内核态\n\n2. 内核初始化\n\n初始化中断系统：中断向量表、中断请求线、计时器\n初始化内存管理：帧表、内核页表、内存保护\n初始化进程管理：创建就绪队列和等待队列\n\n3. 创建第一个用户进程\n\n分配PCB\n建立虚拟地址空间\n建立页表映射\n加载可执行文件\n切换到用户态并开始执行\n\nfork创建新进程\n参考：fork系统调用\n场景：shell执行ls命令\n1. shell进程调用fork()\n\n触发系统调用，CPU切换到内核态\n内核分配新的PCB给子进程\n使用COW机制共享父进程地址空间\n返回：父进程得到子进程PID，子进程得到0\n\n2. 子进程调用exec(“ls”)\n\n触发系统调用\n内核加载ls程序的可执行文件\n建立新的页表映射，覆盖原有地址空间\n从ls程序入口点开始执行\n\n3. 父进程调用wait()\n\nshell进入Waiting状态\nshell的PCB移入等待队列\nCPU调度其他进程运行\n\n4. 子进程执行完毕\n\nls进程调用exit()\n触发系统调用\n释放资源，唤醒父进程\nshell从Waiting变为Ready\n\n时间片用完的进程切换\n参考：上下文切换\n场景：进程A的时间片用完\n1. Timer中断触发\n\n硬件计时器产生中断\nCPU保存当前指令的上下文\n跳转到中断处理程序（内核态）\n\n2. 中断处理\n\n内核的中断处理程序执行\n检查发现进程A的时间片已用完\n将进程A的状态改为Ready\n将进程A的PCB移入Ready Queue\n\n3. 调度决策\n\n调度器从Ready Queue中选择进程B\n根据调度算法（如RR、Priority等）决定\n\n4. 上下文切换\n\n保存进程A的寄存器到PCB\n加载进程B的寄存器从PCB\n切换页表：更新PTBR\n处理TLB：flush或使用ASID\n\n5. 恢复执行\n\n切换到用户态\n跳转到进程B的PC指向的指令\n进程B开始执行\n\n缺页中断处理\n参考：按需分页\n场景：进程访问未映射的虚拟地址\n1. 触发page fault\n\n进程访问某个虚拟地址\nMMU查页表，发现valid bit为invalid\nCPU触发page fault异常\n切换到内核态\n\n2. 检查合法性\n\n内核检查地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n如果非法，终止进程；如果合法，继续\n\n3. 分配物理帧\n\n检查是否有空闲帧\n如果有，直接使用\n如果没有，执行页面置换算法\n\n4. 调入页面\n\n如果是首次访问：分配新的零页\n如果被swap out：从磁盘读取页面内容\n\n5. 更新页表和TLB\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n6. 重新执行指令\n\n返回用户态\n重新执行触发page fault的指令\n这次可以正常访问\n\n页面置换流程\n参考：页面置换\n场景：物理内存不足时的处理\n1. 选择victim frame\n\n使用页面置换算法（LRU、FIFO等）\n找到要被换出的页面\n\n2. 检查dirty bit\n\n如果dirty bit为1（页面被修改过）\n\n需要将页面写回磁盘\nI/O操作\n\n\n如果dirty bit为0\n\n可以直接丢弃\n\n\n\n3. 更新victim页面的页表\n\n将valid bit设置为invalid\n记录页面在磁盘的位置\n从TLB中删除对应条目\n\n4. 调入新页面\n\n将需要的页面从磁盘调入到victim frame\n更新新页面的页表项\n设置valid bit为有效\n\n5. 继续执行\n\n返回用户态\n重新执行触发page fault的指令\n\nI/O操作流程\n参考：中断interrupts、中断驱动的调度\n场景：进程读取文件\n1. 进程发起I/O请求\n\n调用read()系统调用\n触发软中断（trap）\n切换到内核态\n\n2. 内核处理I/O请求\n\n检查文件权限\n发起I/O操作（向设备控制器发送命令）\n将进程状态改为Waiting\n将进程PCB移入I/O等待队列\n\n3. CPU调度其他进程\n\n从Ready Queue选择其他进程\n进行上下文切换\n其他进程开始执行\n\n4. I/O完成\n\n设备控制器完成I/O操作\n发起I/O中断\n\n5. 中断处理\n\nCPU保存当前进程上下文\n跳转到I/O中断处理程序\n处理I/O数据\n唤醒等待该I/O的进程\n将进程从Waiting改为Ready\n将进程PCB移入Ready Queue\n\n6. 可能的调度\n\n如果被唤醒的进程优先级更高\n可能发生进程切换\n\n进程同步示例\n参考：03.1 进程同步及其工具\n场景：生产者-消费者问题\n基本设置\n\n共享缓冲区（有界）\n信号量机制保护\n\n生产者进程\n\n等待空闲位置（P操作/wait）\n如果缓冲区满，进入Waiting状态\n有空位时被唤醒，进入Ready状态\n获得CPU后向缓冲区写入数据\n通知消费者（V操作/signal）\n可能唤醒等待的消费者\n\n消费者进程\n\n等待可用数据（P操作/wait）\n如果缓冲区空，进入Waiting状态\n有数据时被唤醒，进入Ready状态\n获得CPU后从缓冲区读取数据\n通知生产者（V操作/signal）\n可能唤醒等待的生产者\n\n关键机制的联系\n进程与内存\n\n进程是资源分配的单位：每个进程拥有独立的虚拟地址空间\n内存是进程运行的基础：代码、数据、堆栈都存储在内存中\n页表是进程的”身份证”：建立虚拟地址到物理地址的映射\nPCB是进程的”档案”：记录进程的所有信息，包括内存管理信息\n\n中断驱动系统\n\n硬件中断：Timer、I/O设备产生中断，触发调度\n软中断：系统调用、异常触发中断，进入内核态\n中断处理：内核处理中断，可能改变进程状态，触发调度\n\n调度与切换\n\n调度决策：选择哪个进程运行（软件策略）\n上下文切换：如何切换进程（硬件+软件机制）\n内存隔离：通过页表和MMU保证进程间隔离\n\n性能考虑\n时间开销\n\n上下文切换：约10μs\n系统调用：进入/退出内核态的开销\nTLB miss：需要访问内存中的页表\nPage fault：可能需要磁盘I/O\n\n优化策略\n\n减少上下文切换频率：合理的时间片大小\nTLB优化：使用ASID避免频繁flush\n页面置换：选择合适的算法减少page fault\nCOW机制：延迟复制，节省内存\n\n相关概念\n\n01 系统启动与进程创建 - 系统启动、进程创建机制\n02 内存管理 - 虚拟内存、分页、地址转换\n03 进程调度与切换 - 进程状态、调度、上下文切换\n01 introduction - 操作系统概述、中断、系统调用\n02.1 进程 - 进程概念、PCB\n02.2 调度 - 调度算法、队列管理\n04.1 主存 - 内存管理细节\n04.2 virtual memory - 虚拟内存细节\n"},"课程笔记/操作系统/流程总览/进程与内存流程总览":{"slug":"课程笔记/操作系统/流程总览/进程与内存流程总览","filePath":"课程笔记/操作系统/流程总览/进程与内存流程总览.md","title":"进程与内存流程总览","links":["Public/课程笔记/操作系统/01-introduction","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"进程与内存流程总览\n本文档从系统上电开始，完整梳理操作系统如何启动、创建第一个用户进程、管理内存，以及如何进行进程切换的整个流程。\n一、系统启动：从硬件到内核\n1.1 上电与引导\n计算机上电后，CPU首先执行存储在**ROM（只读存储器）**中的引导加载器（bootstrap loader）。这个程序是开机后执行的第一个软件，位置固定且已知。\n引导加载器的任务：\n\n进行硬件自检（POST）\n定位磁盘上的操作系统内核镜像\n将内核加载到**主内存（RAM）**中\n切换CPU模式为内核态，开始执行内核代码\n\n1.2 内核初始化\n内核被加载到内存后，开始初始化工作：\n\n初始化中断系统\n\n设置中断向量表（interrupt vector table），建立中断号到中断处理程序的映射\n配置中断请求线（interrupt-request line）\n初始化计时器（timer），用于时间片管理\n\n\n初始化内存管理\n\n建立物理内存的帧表（frame table），记录每个物理帧的使用情况\n初始化内核的页表结构\n设置内存保护机制（base和limit寄存器，或页表保护位）\n\n\n初始化进程管理\n\n创建初始的内核数据结构\n准备就绪队列（ready queue）和等待队列（wait queue）\n\n\n\n二、第一个用户进程的创建\n2.1 内核态到用户态的转换\n内核初始化完成后，需要创建第一个用户进程。在Linux系统中，这个进程通常是init（旧版）或systemd（新版），其进程ID（PID）为1。\n创建第一个用户进程的步骤：\n\n分配进程控制块（PCB）\n\n操作系统为每个进程维护一个PCB，包含进程状态、程序计数器、CPU寄存器、内存管理信息等\n第一个进程的PCB被初始化为初始状态\n\n\n建立虚拟地址空间\n\n每个进程拥有独立的虚拟地址空间\n虚拟地址空间分为两部分：\n\n用户部分：包含text（代码）、data（全局变量）、heap（堆）、stack（栈）\n内核部分：存储PCB等内核数据结构\n\n\n\n\n建立页表映射\n\n为进程创建页表，建立虚拟地址到物理地址的映射\n初始时，只有必要的页面被映射到物理内存\n页表基地址存储在PTBR（Page-Table Base Register）中\n\n\n加载可执行文件\n\n通过加载器（loader）将可执行文件从磁盘加载到内存\n可执行文件经历了编译（.c → .o）、链接（.o → .exe）、加载的过程\n加载器将逻辑地址通过地址绑定（Address Binding）转换为物理地址\n\n\n切换到用户态\n\n通过上下文切换（context switch），将CPU从内核态切换到用户态\n设置CPU的mode bit为1（用户态）\n跳转到用户程序的入口点开始执行\n\n\n\n2.2 地址绑定过程\n程序从源代码到内存中的完整过程：\n\n编译阶段：编译器将符号地址转换为可重定位地址（relocatable address）\n链接阶段：链接器将多个目标文件合并，生成可执行文件，地址相对于整个程序\n加载阶段：加载器将可执行文件加载到内存，完成地址绑定，得到绝对地址\n\n三、内存管理机制\n3.1 虚拟内存的基本原理\n每个进程拥有独立的虚拟地址空间，CPU使用虚拟地址，由MMU（内存管理单元）自动转换为物理地址。\n虚拟地址空间的结构：\n\n用户空间（User Portion）：0 ~ 3GB（32位系统）\n内核空间（Kernel Portion）：3GB ~ 4GB（32位系统）\n所有进程的内核空间映射到同一块物理内存\n\n3.2 分页机制\n现代操作系统使用分页（Paging）机制管理内存：\n\n物理内存分帧：将物理内存切分为等大小的帧（frame），通常为4KB\n虚拟内存分页：将虚拟地址空间切分为等大小的页（page），大小与帧相同\n页表映射：通过页表建立页到帧的映射关系\n\n地址转换过程：\n\nCPU生成逻辑地址（page number + offset）\nMMU根据页表将page number转换为frame number\n物理地址 = frame number + offset\n\n3.3 页表的硬件实现\n页表存储在内存中，通过PTBR指向页表基地址。为了加速地址转换，使用TLB（Translation Look-aside Buffer）作为页表的高速缓存：\n\nCPU访问虚拟地址时，首先查询TLB\n如果TLB命中，直接获得物理地址（一次内存访问）\n如果TLB未命中，访问内存中的页表（两次内存访问），并将结果存入TLB\n\n3.4 按需分页（Demand Paging）\n操作系统采用延迟分配（Lazy Allocation）策略：\n\n进程申请内存时，操作系统只扩大虚拟地址空间，不立即分配物理内存\n当进程首次访问该虚拟地址时，触发缺页中断（page fault）\n操作系统处理缺页中断：\n\n从空闲帧列表中找到空闲的物理帧\n将页面映射到该物理帧\n更新页表项\n重新执行被中断的指令\n\n\n\n3.5 页面置换\n当物理内存不足时，需要将某些页面换出到磁盘（backing store）：\n\n选择victim frame：使用页面置换算法（如LRU）选择要换出的页面\n写回磁盘：如果页面被修改过（dirty bit=1），将其写回磁盘\n调入新页面：将需要的页面从磁盘调入到victim frame\n更新页表：将页表项的有效位设置为无效，记录页面在磁盘的位置\n\n当再次访问被换出的页面时，会触发page fault，操作系统将其重新调入内存。\n四、进程的创建与执行\n4.1 进程创建（fork）\n进程通过fork()系统调用创建子进程：\n\n系统调用：用户程序调用fork()，触发软中断（trap），切换到内核态\n创建子进程：\n\n分配新的PCB\n复制父进程的地址空间（使用Copy-on-Write（COW）优化）\n子进程获得新的PID，PPID指向父进程\n\n\n返回用户态：\n\n父进程：fork()返回子进程的PID\n子进程：fork()返回0\n两个进程从fork()的下一行代码继续执行\n\n\n\nCopy-on-Write（COW）机制：\n\n父子进程最初共享同一份物理页\n当任一进程尝试写入共享页时，才真正复制该页\n节省内存，提高fork效率\n\n4.2 进程执行（exec）\nexec()系统调用用新程序覆盖当前进程的地址空间：\n\n加载新的可执行文件到内存\n建立新的页表映射\n重置程序计数器，从新程序的入口点开始执行\n\n通常的用法是fork()后立即调用exec()，创建新进程并执行新程序。\n五、进程调度与切换\n5.1 进程状态\n进程在运行过程中会经历以下进程状态：\n\nNew：进程正在创建\nReady：进程已准备好，等待CPU资源\nRunning：进程正在使用CPU执行\nWaiting：进程等待某个事件（如I/O完成）\nTerminated：进程已结束\n\n状态转换规则：\n\nRunning → Ready：时间片用完或被抢占\nRunning → Waiting：主动等待（如系统调用、I/O请求）\nWaiting → Ready：等待的事件发生\nReady → Running：被调度器选中，获得CPU\n\n5.2 调度时机\n非抢占式调度：进程主动释放CPU（进入waiting状态或终止）\n抢占式调度：\n\n时间片用完（timer中断）\n更高优先级的进程变为ready状态\n当前进程被中断打断\n\n5.3 上下文切换的完整过程\n当调度器决定切换到另一个进程时，执行上下文切换：\n\n\n保存当前进程的上下文：\n\n保存CPU寄存器（PC、通用寄存器等）到当前进程的PCB\n保存进程状态\n保存内存管理信息（页表指针等）\n\n\n\n更新进程状态：\n\n将当前进程从running状态改为ready状态（或被抢占）或waiting状态\n将当前进程的PCB移入相应的队列\n\n\n\n选择下一个进程：\n\n调度器从ready queue中选择下一个要运行的进程\n根据调度算法（如RR、优先级调度等）进行选择\n\n\n\n恢复下一个进程的上下文：\n\n加载新进程的PCB中的寄存器值\n更新PTBR指向新进程的页表\n如果使用TLB，需要flush TLB或使用ASID\n更新进程状态为running\n\n\n\n切换到用户态：\n\n设置CPU的mode bit为用户态\n跳转到新进程的PC指向的指令继续执行\n\n\n\n上下文切换的开销：\n\n需要保存和恢复大量寄存器\n需要切换页表（可能flush TLB）\n需要更新各种内核数据结构\n典型的context switch时间约为10μs\n\n5.4 中断驱动的调度\n现代操作系统是中断驱动的：\n\n\nTimer中断：\n\n计时器定期产生中断（如每10ms）\n中断处理程序检查当前进程的时间片是否用完\n如果用完，触发调度，将当前进程切换为ready状态\n\n\n\nI/O中断：\n\n当I/O操作完成时，设备控制器发起中断\n中断处理程序唤醒等待该I/O的进程\n将进程从waiting状态切换为ready状态\n\n\n\n系统调用：\n\n用户程序调用系统调用，触发软中断\n切换到内核态执行系统调用\n如果系统调用需要等待（如read），进程进入waiting状态\n\n\n\n六、内存与进程的协同工作\n6.1 进程切换时的内存管理\n进程切换时，内存管理相关的操作：\n\n\n页表切换：\n\n更新PTBR指向新进程的页表\n不同进程的虚拟地址空间被隔离\n\n\n\nTLB管理：\n\n方法1：flush TLB（清空所有TLB条目）\n方法2：使用ASID（Address-Space Identifier），TLB同时匹配page number和ASID\n\n\n\n内存保护：\n\n每个进程只能访问自己的虚拟地址空间\n通过页表的保护位（valid-invalid bit、读写权限位）实现\n\n\n\n6.2 缺页中断的处理流程\n当进程访问的虚拟地址对应的页面不在物理内存中时：\n\n触发page fault：\n\nMMU在页表中查找，发现valid bit为invalid\nCPU触发page fault异常，切换到内核态\n\n\n检查页面合法性：\n\n检查虚拟地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n\n\n分配物理帧：\n\n如果有空闲帧，直接使用\n如果没有空闲帧，执行页面置换算法选择victim frame\n\n\n从磁盘调入页面：\n\n如果页面在磁盘上（被swap out），从backing store读取\n如果页面是首次访问（lazy allocation），分配新的零页\n\n\n更新页表：\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n\n重新执行指令：\n\n返回到用户态\n重新执行触发page fault的指令\n\n\n\n6.3 进程间内存共享\n多个进程可以共享同一块物理内存：\n\n共享代码：\n\n多个进程执行同一程序时，可以共享text段\n页表中不同的虚拟页映射到同一物理帧\n代码必须是可重入的（reentrant code）\n\n\n共享内存（IPC）：\n\n通过系统调用建立共享内存区域\n多个进程的虚拟地址空间映射到同一物理内存\n需要同步机制（如信号量）保护共享数据\n\n\n\n七、完整流程示例：从fork到exec到调度\n7.1 创建新进程并执行新程序\n\n\n父进程调用fork()：\n\n触发系统调用，切换到内核态\n内核创建子进程的PCB\n使用COW机制共享父进程的地址空间\n返回用户态，父子进程并发执行\n\n\n\n子进程调用exec()：\n\n触发系统调用，切换到内核态\n内核加载新的可执行文件\n建立新的页表映射\n覆盖原有的地址空间\n返回用户态，从新程序的入口点开始执行\n\n\n\n7.2 进程切换的完整场景\n假设进程A正在运行，时间片用完：\n\nTimer中断：\n\n硬件计时器产生中断\nCPU保存当前指令的上下文，跳转到中断处理程序\n\n\n中断处理：\n\n内核的中断处理程序执行\n检查发现进程A的时间片已用完\n将进程A的状态改为ready，移入ready queue\n\n\n调度决策：\n\n调度器从ready queue中选择进程B（根据调度算法）\n进程B可能是：\n\n之前被抢占的进程\n等待I/O完成的进程\n新创建的进程\n\n\n\n\n上下文切换：\n\n保存进程A的寄存器到PCB\n加载进程B的寄存器从PCB\n切换页表（更新PTBR）\nFlush TLB或使用ASID\n\n\n恢复执行：\n\n切换到用户态\n跳转到进程B的PC指向的指令\n进程B开始执行\n\n\n\n7.3 内存不足时的处理\n当系统内存不足，新进程需要内存时：\n\n\n触发page fault：\n\n进程访问未映射的虚拟地址\nMMU发现页表项无效\n\n\n\n检查空闲帧：\n\n如果没有空闲帧，执行页面置换\n\n\n\n页面置换：\n\n使用LRU等算法选择victim frame\n如果victim page被修改，写回磁盘\n将victim page的页表项标记为无效\n\n\n\n调入新页面：\n\n从磁盘读取需要的页面到victim frame\n更新页表，建立映射\n更新TLB\n\n\n\n继续执行：\n\n重新执行触发page fault的指令\n进程继续正常运行\n\n\n\n八、总结：关键机制的联系\n8.1 进程与内存的紧密关系\n\n进程是资源分配的单位：每个进程拥有独立的虚拟地址空间\n内存是进程运行的基础：进程的代码、数据、堆栈都存储在内存中\n页表是进程的”身份证”：通过页表实现虚拟地址到物理地址的映射\nPCB是进程的”档案”：记录进程的所有信息，包括内存管理信息\n\n8.2 中断驱动的系统\n\n硬件中断：Timer、I/O设备等硬件产生中断，触发调度\n软中断：系统调用、异常等软件事件触发中断，进入内核态\n中断处理：内核处理中断，可能改变进程状态，触发调度\n\n8.3 虚拟内存的优势\n\n隔离性：每个进程拥有独立的虚拟地址空间，互不干扰\n灵活性：进程可以使用比物理内存更大的虚拟地址空间\n效率：通过按需分页和页面置换，提高内存利用率\n共享性：多个进程可以共享同一块物理内存（代码、数据）\n\n8.4 进程切换的本质\n进程切换本质上是：\n\n保存当前执行环境：寄存器、状态、内存映射\n恢复另一个执行环境：加载另一个进程的上下文\n继续执行：从另一个进程的断点继续\n这一切都依赖于：\n\n\n中断机制：提供切换的时机\n内存管理：保证进程间的隔离和正确映射\n调度算法：决定切换哪个进程\n\n\n相关概念索引\n\n01 introduction - 操作系统概述、中断、特权模式\n02.1 进程 - 进程概念、PCB、进程创建与终止\n02.2 调度 - 进程状态、调度算法、上下文切换\n04.1 主存 - 内存分配、分页、页表、TLB\n04.2 virtual memory - 虚拟内存、按需分页、页面置换\n"},"课程笔记/计算机组成/02-Instructions":{"slug":"课程笔记/计算机组成/02-Instructions","filePath":"课程笔记/计算机组成/02 Instructions.md","title":"02 Instructions","links":["tags/flashcard","ABI-(Application-Binary-Interface)"],"tags":["flashcard"],"content":"DECK: CS::CO\nsummary\n\n\n寄存器 registers flashcard\n\nRISC-V architecture 提供 32 个数据寄存器，分别命名为 x0 ~ x31 ，每个寄存器的大小是 64 位。\n\nx0 的值恒为 0\nPreserved on call 意为是否保证调用前后这些寄存器的值不变。\n\n\n也提供一系列浮点数寄存器 f0 ~ f31。\n之所以寄存器的个数不多，是因为过多的寄存器会增加电子信号的传播距离，从而导致时钟周期的延长。\n将不常用的（或之后用到的）变量存入内存的过程被称为溢出寄存器 (Spilling Register)\n寄存器存储空间小，内存存储空间大 因此小规模的数据会放在寄存器内，而更大规模的数据则会存储在计算机的内存(memory) 中\n各种操作与运算都只能在寄存器内完成\n寄存器有着更快的运行速度和更高的吞吐量，使得访问寄存器内的数据更加迅速和方便，且访问寄存器的能耗更低；而访问内存需要 load 和 store 指令，那么就需要执行更多的指令\n\n\n字节地址 flashcard\n\n\n==在 RISC-V architecture 中，一个 word 为 32 位（4Bytes ），一个 doubleword 为 64 位（8Bytes ）。==\nRISC-V architecture 的地址是 64 位的，地址为字节地址，因此总共可以寻址2的64次方个字节，即2的61次方个 dword ，因为一个 dword 占3位（8Bytes用3个字节地址位表示）\n\n如果想操作某一个 bit（比如把第 3 个 bit 从 0 改成 1 ），CPU 必须：\n\n读取 (Read)：先把这个 bit 所在的整个字节（整个房间）的数据（8个 bits）全部取到 CPU 寄存器中。\n修改 (Modify)：在 CPU 内部，使用位运算（比如 OR 运算）来单独修改那 1 个 bit，而其他 7 个 bit 保持不变。\n写回 (Write)：把修改后的整个字节（8个 bits）再存回到原来的内存地址\n\n\n\n\n\n\n寻址 flashcard\n\n在一些 architecture 中，word 的起始地址必须是 word 大小的整倍数，dword 也一样，这种要求称为 alignment restriction。\n\nRISC-V 允许不对齐的寻址，但是效率会低。\n一次只能读出4字节内存中的一行\n\n\nRISC-V 支持\n\n立即数寻址 ( lui )\n间接寻址 ( jalr )\n基址寻址 ( 8(sp) )：\nPC relative 寻址：分支地址为PC和分支偏移量（立即数的2倍）之和\n\n因为所有合法的指令必须存放在偶数内存地址【指令：16bit（压缩指令）/32bit 】因此最低位始终为0，因此为了优化，指令中会略去最后一个0\n把存储的 immediate 还原成真正的 Branch offset\n\n\n\n\n\n\n\n大小端 flashcard\n\nRISC-V 使用 little endian 小端编址。也就是说，当我们从 0x1000 这个地址读出一个 dword 时，我们读到的实际上是 0x1000~0x1007 这 8 个字节，并将 0x1000 存入寄存器低位，0x1007 存入高位。\n\n存储字节 0x88 就是 bit：10001000\n大小端只关心字节的顺序，不关心字节内部bit的顺序\n\n\n\n\n补码 2’s complement flashcard\n\n因此在将不足 64 位的数据载入寄存器时\n\n如果数据是无符号数，只需要使用 0 将寄存器的其他部分填充 (zero extension)\n\n指令中的lwu , lhu , lbu 使用zero extension。\n\n\n而如果是有符号数，则需要用最高位即符号位填充剩余部分，称为符号扩展 (sign extension)。\n\n指令中的 lw , lh , lb 使用sign extension\n\n\n\n\n\n对于补码先看符号位，负数的话就对数字部分做补码还原，还是取反加一。\n1’scomplement是反码，先看符号位，负数就对数字部分做反码还原，取反即可\n\n\n指令\n设计准则\n正则化 simplicity favors regularity 简化规范\n越小越快 smaller is faster 32个通用寄存器 32*64bit\n指令\n\nArithmetic\n\n加法\n\nadd：寄存器 1 + 寄存器 2\n|add reg1, reg2, reg3    // (in C) reg1 = reg2 + reg3|\naddi(Add Immediate)：寄存器 + 常量\n|addi reg1, reg2, const  // (in C) reg1 = reg2 + const|\n\n\n减法\n\nsub：寄存器 1 - 寄存器 2\n|sub reg1, reg2, reg3    // (in C) reg1 = reg2 - reg3|\n==注意：没有subi，但是可以通过addi一个负常数来实现==\n\n\n\nLogical Operations\n\n\nsll/slli，srl/srli 分别为逻辑左移/右移\n\n左移i位相当于乘以2的i次方，右移i位相当于整除2的i次方 \n逻辑右移时最左边补 0\n不带i的指令表示根据寄存器的值确定移动位数，带i的指令表示用立即数确定移动位数\n|slli x11, x19, 4    // reg x11 = reg x19 &lt;&lt; 4 bits|\n\n\nsra/srai 为算术右移，最左边补符号位\n\nBit Operations\n|and reg1, reg2, reg3    // (in C) reg1 = reg2 &amp; reg3`|\n\n|or reg1, reg2, reg3    // (in C) reg1 = reg2 | reg3`|\n\nAND、OR、XOR 也有立即数版本的指令，分别为：andi、ori和xori\n\n|xor reg1, reg2, reg3    `|\n\nRISC-V 中没有 NOT 指令，因为它可以通过异或表示出来：任何数与 111…111 异或的结果即为该数取反后的结果\n\nMaking Decisions\n计算机与计算器的一大不同之处在于计算机具备决策的能力：它能够执行分支（条件）语句、循环语句等。\n在 RISC-V 汇编语言中，关于决策的指令格式均为：inst rs1, rs2, L1\n\n其中rs1、rs2是寄存器\nL1是标签（跳转位置，也可以是立即数 imm，表示跳转到 PC+imm 的指令）\ninst是指令，比较的是补码值。/0\n\n其分类如下：\n\n条件分支(conditional branch)：先检测值，根据检测结果决定是否将控制权转交给新地址上的语句的一类指令\n无条件分支(unconditional branch)：条件恒为真的条件分支，因此该语句一定会执行\n\n有以下几种可用指令：\n\nbeq(Branch If Equal)：如果寄存器rs1和rs2的值相等，那么跳转至带标签L1的语句\nbne(Branch If Not Equal)：如果寄存器rs1和rs2的值不相等，那么跳转至带标签L1的语句\nblt(Branch If Less Than)：如果寄存器rs1的值小于rs2的值，那么跳转至带标签L1的语句\n\nbltu：无符号版本 unsigned 比如存的是地址，就只能用bltu当作无符号数来比较，否则会引入符号位。【如果高位地址用不上也不容易出错，如果地址比较大就一定要bltu】\n\n\nbge(Branch If Greater Than or Equal)：如果寄存器rs1的值大于等于rs2的值，那么跳转至带标签L1的语句\n\nbgeu：无符号版本 unsigned\n\n\n\nif\n\nif-else\n\ncase-switch\n对于case/switch语句，我们可以使用一张放有可选指令序列地址的表格（称为分支地址表，Branch Address Table），这样的话程序就可以根据条件判断的结果，通过表格的索引找到合适的指令序列。\n\n\n\nloops\n\n循环访问数组\nwhile\n\nset on less than\nslt x5, x19, x20\n\n如果 x19&lt;x20，那么将 x5 赋值为 1\n\nData Transfer Instructions\n由于对数据的各种操作只能在寄存器内完成，而无法在内存中实现，因此数据需要再寄存器和内存之间来回传递，来完成这一传递操作的指令被称为数据传输指令\nRISC-V 有以下数据传输指令：\n\nld（Load Doubleword）：加载指令，将数据从内存拷贝到寄存器当中\n|ld reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 一个保存内存基础地址的寄存器（可以理解为能访问到整个内存的头指针）\noffset: 偏移量，是一个常数\n内存数据的实际地址 = mem_base_addr + offset\n\n\nsd（Store Doubleword）：存储指令，将寄存器的数据拷贝到内存中\n|`sd reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 内存基础地址寄存器\noffset: 偏移量\n\n\nlbu(Load Byte Unsigned)：加载 1 字节的数据，并看作无符号数\nlb(Load Byte)：lbu的有符号数版本\n\n\n在 RISC 指令集中，只有 load 系列和 store 系列指令能够访问内存。\n\n\n立即数 Constant or Immediate Operands\n\n一般的做法是将常数保存在一个寄存器当中，通过一个地址指针指向这个寄存器，然后通过 add 指令实现加法操作\n|ld x9, AddrConstant4(x3) //x9 = constant 4 add x22, x22, x9|\n实际上我们可以引入一个新的概念：立即数（Immediate），这样就避免了加载指令（即通过操作 addi x22, x22, 4 即可实现）\n\n同步Synchronization in RISC-V\n假设两个处理器在同一片内存空间中工作，并且它们的工作顺序为：P1写入数据后，P2再读取数据。没有同步（Synchoronize）好，那么就会产生数据竞争（Data Race）的问题（结果取决于访问顺序，因此这个结果就是不确定的）。\n避免这一问题的方法是原子读取 / 写入 (Atomic Read/Write) 内存操作，这种操作确保读和写之间不会有任何访问这块内存空间的行为。\n有些处理器有专门实现原子操作的指令，比如原子交换 (Atomic Swap/Exchange)（实现寄存器和内存数据的交换）等。而 RISC-V 提供了一个指令对 (Instruction Pair) lr.d和sc.d：\n\nlr.d（Load-Reserved Doubleword）：\n\nlr.d rd, (rs1) 将存储在寄存器rs1的内存地址上的数据加载到寄存器rd上，同时保留这块内存地址，除sc.d的其他指令不应该访问这块地址\n\n\nsc.d（Store-Conditional Doubleword）：\n\nsc.d rd, rs1, (rs2) 将寄存器rs1上的数据放入存储在寄存器rs2的内存地址上，并且由寄存器rd指示该指令是否成功：若成功，则rd = 0，否则rd为一个非零值（表示有其他指令访问过这块内存空间）\n\n\n\n\n其他\n\n拓展指令集内容：\n\nM：与乘除法相关的指令\nA：原子运算，包括前面提到过的lr.d和sc.d指令，以及它们的 32 位版本lr.w和sc.w等\nF：单精度浮点运算相关指令\nD：双精度浮点运算相关指令\nC：压缩的指令，只有 16 位宽\n\n\n伪指令\n\n过程（Procedure）或函数（Function）\n调用过程Procedure Call Instructions flashcard\n\n\njal与jalr\n\njalr是基于【寄存器地址+12位立即数偏移量】\njal是基于pc相对地址【20位立即数】，jal rd，offset\n\n\n对于调用者：调用某个程序地址后，将返回地址（跳转的下一条地址PC+4）存入x1（ra）中\n对于被调用者，x0无法被写入，表示不保存任何返回地址，仅作跳转。\n\n调用过程中的寄存器Registers for procedure calling\nRISC-V寄存器 flashcard\nLocal Data on the Stack\n栈与栈帧 flashcard\nMemory Layout\nMemory Layout flashcard\nRICV-V指令格式 flashcard\n指令编码32bit, 记其为机器码（Machine Code）。我们可以把每条指令当作一块块二进制数字构成的组合，而这单块的数字被称为字段（Field）。我们为字段赋予了一些名称，每个字段有不同的功能：\n\nopcode：指令要做的运算，可用这个字段区分各种类型的指令格式(instruction format)\nfunct3：额外的opcode字段\nfunct7：额外的opcode字段\nrd：寄存器目标操作数，保存运算的结果\nrs1：第一个寄存器源操作数\nrs2：第二个寄存器源操作数\nimmediate：立即数，即常数\n根据不同的 opcode 我们可以将指令分为 6 种类型，它们的字段构成如下：\n\n\nR 型指令一般用于算术、逻辑运算\nI 型指令一般用于加载操作、涉及立即数的算术逻辑运算、jalr指令\n\n因为寄存器的大小为 64 位，也就是说对于移位操作 slli，srli和srai，它们最多只能移位 64 位，因此移位操作中immediate字段只有后 6 位能实际被用来存储移位的步数，前 6 位用来存储额外的opcode字段（funct6）\n关于 jalr 指令，如果跳转地址（立即数）过大，超过了 20 位，那么可以先用 lui 指令将高 20 位数字放入临时寄存器中，然后再用 jalr 指令跳转到地址剩余的低位数字(临时寄存器)上\n\n\nS 型指令一般用于存储操作\nU 型指令一般用于与高位立即数相关的操作\n\n在大多数情况下，立即数不会很大（），能够直接存在指令中；但如果超过 12 位，RISC-V 会用 lui (load upper immediate) 指令来处理这类较大的立即数。\n它可以加载立即数的高 20 位，将其放入寄存器中间的第 12 位到第 31 位，寄存器的低 12 位用 0 填充，高 32 位用第 31 位上的数字填充。\n例如，要将 32 位立即数赋给寄存器，可以先用lui指令将高 20 位赋给寄存器，之后用addi 指令将剩余的 12 位加到寄存器中。\n\n\nSB 型指令一般用于条件分支语句\n\n可表示的地址范围为 -4096-4094，且都是 2 的倍数（因为立即数第一位恒为 0）\n\n\nUJ 型指令一般用于无条件分支语句（jal）\n\nrd用于存放链接地址（即返回地址）\n\n\n\n\n\n另外，为什么 SB 和 UJ 不存立即数（也就是偏移）的最低位呢？（关注表格，可以发现只包括 i[12:1] 或者 i[20:1]，缺失 i[0]）因为，偏移的最后一位一定是 0，即地址一定是 2 字节对齐的，因此没有必要保存。\n\n\n数组和指针\n事实上，用指针访问数组元素比用索引访问数组元素更快一些。它们分别具有如下特点：\n\n数组索引\n\n需要根据数组基地址、当前索引和元素大小计算出数组元素的地址，而且每趟循环都需要更新和重新计算，有些麻烦\n虽然从理论上来说效率不高，但实际上编译器已经为我们做了一定的优化，比如用移位运算替代乘法运算，避免在循环内进行数组地址计算等\n\n\n指针\n\n它直接指向内存地址（可以看到，在循环开始前就已经算好了），无需多余的计算步骤\n\n\n\n例子\nRISC-V 汇编语言来翻译一个用 C 语言写的冒泡排序函数\nC 语言翻译成汇编语言步骤\n\n为程序的每个变量分配相应的寄存器\n为过程的主体部分书写代码\n在过程调用期间保留要用的寄存器\n\nswap函数\nvoid swap(long long int v[], size_t k) {\n    long long int temp;\n    temp = v[k];\n    v[k] = v[k+1];\n    v[k+1] = temp;\n}\nswap:\n    slli x6, x11, 3      // reg x6 = k * 8 -》变成byte字节地址\n    add  x6, x10, x6     // reg x6 = v + (k * 8)\n    ld   x5, 0(x6)       // reg x5 (temp) = v[k]\n    ld   x7, 8(x6)       // reg x7 = v[k + 1]\n    sd   x7, 0(x6)       // v[k] = reg x7\n    sd   x5, 8(x6)       // v[k+1] = reg x5 (tmp)\n    jalr x0, 0(x1)       // return to calling routine\nsort函数\nvoid sort(long long int v[], size_t int n) {\n    size_t i, j;\n    for (i = 0; i &lt; n; i++) {\n        for (j = i - 1; j &gt;= 0 &amp;&amp; v[j] &gt; v[j + 1]; j--) {\n            swap(v, j);\n        }\n    }\n}\n// Saving registers\nsort:\n    addi sp, sp, -40      // make room on stack for 5 registers\n    sd   x1, 32(sp)       // save return address on stack\n    sd   x22, 24(sp)      // save x22 on stack\n    sd   x21, 16(sp)      // save x21 on stack\n    sd   x20, 8(sp)       // save x20 on stack\n    sd   x19, 0(sp)       // save x19 on stack\n \n// Procedure body\n// Move parameters\n    mv   x21, x10         // copy parameter x10 into x21\n    mv   x22, x11         // copy parameter x11 into x22\n \n// Outer loop\n    li   x19, 0           // i = 0\nfor1tst: \n    bge  x19, x22, exit1  // go to exit1 if i &gt;= n\n \n// Inner loop\n    addi x20, x19, -1     // j = i - 1\nfor2tst:\n    blt  x20, x0, exit2   // go to exit2 if j &lt; 0\n    slli x5, x20, 3       // x5 = j * 8\n    add  x5, x21, x5      // x5 = v + (j * 8)\n    ld   x6, 0(x5)        // x6 = v[j]\n    ld   x7, 8(x5)        // x7 = v[j + 1]\n    ble  x6, x7, exit2    // go to exit2 if x6 &lt; x7\n \n// Pass parameters and call\n    mv   x10, x21         // first swap parameter is v\n    mv   x11, x20         // second swap parameter is j\n    jal  x1, swap         // call swap\n \n// Inner loop\n    addi x20, x20, -1     // j for2tst\n    j for2tst             // go to for2tst\n \n// Outer loop\nexit2: \n    addi x19, x19, 1      // i++\n    j for1tst             // go to for1tst\n \n// Restoring registers\nexit1:\n    ld   x19, 0(sp)       // restore x19 from stack\n    ld   x20, 8(sp)       // restore x20 from stack\n    ld   x21, 16(sp)      // restore x21 from stack\n    ld   x22, 24(sp)      // restore x22 from stack\n    ld   x1, 32(sp)       // restore return address from stack\n    addi sp, sp, 40       // restore stack pointer\n \n// Procedure return\n    jalr x0, 0(x1)        // return to calling routine\n指令集架构\n谬误\n\n更多强大的指令会带来更高的性能\n\n虽然更强大的指令意味着执行相同功能所需指令数更少，但同时也意味着这些指令会更加复杂，难以实现，这样反而影响所有指令的效率\n\n\n直接用汇编语言编写的程序性能更高\n\n在现代的处理器中，编译器可能比人脑更擅长将高级语言代码转换为性能更优的汇编语言代码\n而且，对于人类来说，因为汇编代码量较大，所以会带来更多犯错的机会，且编写效率实在不高\n\n\n指令集的向后兼容意味着无需改变现有的指令集\n\n以 x86 为例，虽然它做到了向后兼容，但它的指令数还是呈上升趋势\n\n\n用字节表示地址的机器内，连续的字地址的间距不是 1 而是 4（字节）\n\n一个地址只能放一个字节\n双字地址间距就是8字节\n\n\n使用指向在定义过程外的自动变量的指针\n\n典型例子：某个过程返回一个指向局部数组的指针，但这个过程在返回后就没了，包括这个局部数组，因此这个指针指向一个没有任何意义的地方，如果动用这个指针，很可能会让整个程序崩溃\n\n\n\n指令集架构 instruction set architecture flashcard\n目前世界上主流的 ISA 主要分为两大类：\n\nCISC (复杂指令集)：一条指令可以完成很复杂的操作。\n\nx86 电脑、笔记本、服务器\n\n\nRISC (精简指令集)：指令都很简单、统一，通过组合简单指令来完成复杂任务。\n\nRISC-V\nARM  手机 平板 嵌入式设备 苹果电脑\nMIPS\n当下计算机建立在两个关键原则（即存储程序概念，Stored-Program Concept）：\n\n\n指令用数字来表示\n程序就像数字一样存储在内存中，可用来被读取或写入\n\n\nMIPS\n\n32 位指令\n32 个通用寄存器，其中一个寄存器的值始终为 0\n只能通过加载和存储指令来访问内存数据\n没有能够批量加载 / 存储多个寄存器的指令\n寻址模式适用于各种大小的数据\n\nRISC-V 和 MIPS 的不同之处有：\n\n条件分支（除了相等和不等）：\n\nRISC-V 仅仅比较两个寄存器的大小，而 MIPS 还会用一个寄存器存储比较结果（1 或 0，对应真值）\nMIPS 只有“小于”分支指令，该指令有符号数（slt）和无符号数（sltu）版本\n\n\n\n指令格式的区别\n\nx86\n8086 指令集仅支持字节（8 位）和字（16 位，注意 RISC-V 的字是 32 位）类型的数据，而 80386 增加了 32 位地址和数据（双字，注意 RISC-V 的双字是 64 位）。\nx86 指令与 RISC-V 的不同之处在于：\n\nx86 指令的算术和逻辑指令中，有一个操作数同时充当源和目标；而 RISC-V（以及 MIPS）会将源寄存器和目标寄存器区分开来\nx86 指令的其中一个操作数可以是内存，下面的表格展示了 x86 中所有可能的操作数搭配\n\n寄存器\n80386 指令集有 14 个寄存器，如下图所示：\n\n寻址模式\n80386 的寻址模式如下图所示：\n\n指令格式\n下图为典型 x86 指令格式- 每条指令的开头（左侧）指明了指令要做的操作\n\n有些指令存在一个 Postbyte 字段，它用来指明寻址模式\nx86 的整数指令有以下几类：\n数据传送指令\n算术和逻辑指令\n控制流\n字符串指令\n分别对应的常见指令有：\n\n\nTranslating and starting a program\n一个 C 语言的程序（源代码）转化为存储在内存中的一个文件的过程\n\n\n编译器 (Compiler)：高级编程语言 → 汇编语言\n\n有的编译器兼具汇编器的功能\n\n\n汇编器 (Assembler)：\n\n伪指令 → 指令\n\n伪指令(Pseudo Instruction)：可以理解为汇编指令的扩展（或者缩写），形式上看似指令，而实际上并不存在这种指令，但汇编器会将其自动转化为实际存在的指令\n\n\n可接受各种进制的数\n用符号表(symbol table) 存储标签名称和内存地址的对应关系，便于将标签转化为实际的地址\n基本的功能：汇编语言 → 机器码，即汇编程序 → 目标文件(Object File)。在 UNIX 系统中，目标文件包含以下内容：\n\n目标文件头 (Object File Header)：描述目标文件中其他区域的大小和位置\n文本段 (Text Segment)：包含机器码\n静态数据段 (Static Data Segment)：包含程序生命周期中分配的数据（在 UNIX 中这个区域同时存放静态和动态数据）\n重定位信息 (Relocation Information)：根据程序被加载至内存的绝对地址来区分指令和数据\n符号表 (Symbol Table)\n调试信息 (Debugging Information)：简要描述模块的编译情况，使调试器能够将机器指令和 C 源文件关联起来，且能够读取其中的数据结构\n\n\n\n\n链接器 (Linker)\n\n对于多文件的编译，采取的做法是先编译、汇编单个的文件，然后将这些机器语言程序链接起来，这样可以尽可能减少重编译和重汇编的情况\n工作流程：\n\n将代码和数据模块以符号化的形式存在内存中\n弄清数据和指令标志对应的地址\n补充好内部和外部的引用\n\n\n经链接器加工后，最终生成一个可执行文件 (Executable File)，它与目标文件的区别在于后者存在不确定 (Unresolved) 的引用\n\n\n加载器 (Loader)：将可执行文件放入内存或磁盘中，工作流程为：\n\n读取可执行文件头，得到文本段和数据段的大小\n创建一个指向足够容纳文本和数据的空间的地址\n将可执行文件的指令和数据拷贝到内存中\n将主程序的参数（如果有的话）放入栈中\n对寄存器进行初始化操作，并将栈指针指向第一个空闲的位置上\n跳转到启动例程，将参数拷贝到参数寄存器中，并调用程序的主例程。让主例程返回时，启动例程中止整个程序，附带exit系统调用\n\n\n\nDynamic Linking\n前面介绍的链接方法属于静态链接，虽然它能快速调用库函数，但它具有以下缺陷：不能及时更新库函数，会一次性加载所有库函数（即使很多库函数没被用到）。因此我们更多地会用到动态链接库(Dynamically Linked Libraries, DLL) 来克服这些缺陷——这种库可以在程序运行时被链接到程序里。\n动态链接库有如下特征：\n\n需要可重定位的过程代码\n能够避免由静态链接获取所有库函数带来的占用存储空间过大的问题\n能够自动获取最新版本的库\n\nLazy Linkage\n在原始版本的 DLL 中，程序和库都需要保留额外的信息，用于定位非局部的过程；加载器会运行一个动态的链接器，使用这些额外的信息找到合适的库并更新所有的外部引用。这种 DLL 的缺点是它仍然会一次性加载所有库函数。一种改进方法是使用懒过程链接(Lazy Procedure Linkage) 版本的 DLL，它能保证只有当程序调用库函数时，对应的库才会被链接到程序里。下图展示了这种版本的 DLL：\n\n数据类型\ngo\n\nc\n\n无论是 32 位还是 64 位系统，long long 类型的大小都是 8 字节\nlong 在 32 位系统上是 4 字节，在 64 位系统上是 8 字节\n"},"课程笔记/计算机组成/06-IO":{"slug":"课程笔记/计算机组成/06-IO","filePath":"课程笔记/计算机组成/06 IO.md","title":"06 IO","links":[],"tags":[],"content":"硬盘存储与性能计算\nRAID技术对比(冗余磁盘阵列)\n\n三种IO通信方式\n\n轮询Polling cpu参与度极高\n中断 cpu参与度中等,设备好了会通知cpu 但是又频繁上下文切换开销\nDMA cpu参与度极低,仅在开始和结束的时候介入,数据直接在IO与内存间传输.适用于硬盘\\网卡等大数据量设备\n\nDMA\n直接内存访问,设备控制器直接向/从内存传输数据，不需要处理器的介入\n\n首先处理器通过提供一些信息来设置 DMA 模式，具体包括：设备 ID、操作、待传输数据的内存源地址和目标地址、需要传输的字节数等\nDMA 开始执行操作，并对总线进行仲裁。若某个请求需要在总线上多次传输数据，那么 DMA 单元生成下一个内存的地址，并发起下一次传输\n一旦 DMA 传输完成，控制器向处理器发起中断，随后检查是否发生错误\n\nI/O Performance Measures"},"课程笔记/计算机组成/划重点":{"slug":"课程笔记/计算机组成/划重点","filePath":"课程笔记/计算机组成/划重点.md","title":"划重点","links":[],"tags":[],"content":"16不怎么考\n2.4.5.考得多\n第一章末尾计算题相对性能\n第二章 表会给出来的 但是转换一定会考的 c语言 汇编 二进制转换\n第三章 浮点数计算"},"课程笔记/计算机网络/01-Introduction":{"slug":"课程笔记/计算机网络/01-Introduction","filePath":"课程笔记/计算机网络/01 Introduction.md","title":"01 Introduction","links":[],"tags":[],"content":"TCP/IP 网络模型\n**发送方（不停地穿衣/套娃）\n\nChrome (应用层) 产生数据（比如 “GET /index.html”）。它只管内容，不知道怎么发。把数据直接丢给下一层 。\n\n此时手里拿的是：Data (数据)\n\n\n操作系统 (TCP层) 收到 Data。它不管数据是网页还是邮件，它只负责**“端口到端口”。给数据加一个 TCP 头（贴上源端口、目的端口）\n\n此时手里拿的是：Segment (段) 。\n\n\n操作系统 (IP层) 收到 Segment。它不管里面是 TCP 还是 UDP，它只负责“主机到主机”。给 Segment 加一个 IP 头**（贴上源IP、目的IP）。\n\n此时手里拿的是：Packet (包) 。\n\n\n网卡 (链路层) 收到 Packet。它不管你要发到美国还是北京，它只负责**“发给网线那头的下一站”。给 Packet 加一个 MAC 头（源MAC、目的MAC）再加一个 FCS 尾（用于以后检查数据坏没坏）\n\n此时手里拿的是：Frame (帧)\n\n\n\n接收方（不停地剥皮）：\n\n网卡收到 Frame，检查帧尾 FCS。没问题？把头和尾扔掉，取出中间的 Packet 给 IP 层。\n操作系统(IP层) 收到 Packet，检查 IP 地址。是给我的？把 IP 头扔掉，取出中间的 Segment 给 TCP 层。\n操作系统(TCP层) 收到 Segment，检查端口。是给 Chrome 的？把 TCP 头扔掉，把纯数据给 Chrome。\n\n重点： 每一层只看自己的头，根本不看（也不懂） 里面包着什么。链路层看到 IP 头时，它只觉得那是“数据”的一部分。\n\n核心概念: 封装与解封装.\n\n\n应用层数据被 TCP 装进箱子（Segment)\n\n\nTCP 箱子被 IP 装进集装箱（Packet）\n\n\nIP 集装箱被网卡装进货车（Frame）\n\n\n每一层只读自己那一层的“快递单”（ Header）根本不看里面的内容\n\n\n\n\n\n应用层\n\nmessage报文. 核心任务是具体的业务逻辑.\n专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等\n当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层\n应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态\n\n\n\n传输层\n\n关心segment 段.进程到进程(端口),比如chrome到对方服务器的nginx\n只有这一层在真正负责数据不丢不乱.ip只管发,丢了不管,如果ip把包弄丢了 tcp负责重传.\n\n\n\n网络层\n\n关心packet,包/分组.端到端(实际的设备间传输的功能)\n核心任务是路由和寻址(ip地址).ip协议负责把数据包从一个网段跳到另一个网段\nip地址计算\\路由算法\\ip协议\nip地址: 网络号标识子网.主机号负责标识同一个子网下的不同主机\nip地址和子网掩码进行按位与就可以得到网络号.\n\n\n\n数据链路层(交换机通过自学习知道哪个mac地址在哪个口)\n\n关心frame 帧。相邻节点之间（交换机拿到frame,会根据mac头进行转发.)(网卡只认识mac地址)(路由器收到frame,就拆开给网络层看ip确认,然后重新组装一个frame加上新的mac地址,给二层去发送)\n核心任务是在直接相连的两个设备之间，保证数据可以送过去，别撞车。\n这里的纠错就是负责这段路上不出错（CRC校验、海明码之类的）\n防撞车： CSMA\\CD检测\n\n\n数据链路层的交换机搞不定（因为它只认识局域网内的 MAC）它只能把包交给网络层的路由器(处理不同子网)\n\n\n\n\n\n\n注意路由器里面也是会经历：物理层 -&gt; 链路层 -&gt; 网络层 (处理/决策) -&gt; 链路层 -&gt; 物理层这么一个过程. 交换机是处理到链路层,不到达网络层\n\n\n物理层\n\n只关心bit。\n核心任务是怎么把01变成电信号发送出去。眼里没有包，只有电流\n\n\n\n键入网址到网页显示，期间发生了什么\n应用层 HTTP\n\n\n\nURL解析\n所以图中的长长的 URL 实际上是请求服务器里的文件资源。\n当没有路径名的时候,就访问根目录下事先设置的默认文件.\n对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。\n生成HTTP请求信息\n\n\n真实地址查询—DNS\n\n\n通过浏览器解析URL并生成HTTP消息后,需要委托操作系统将消息发送给Web服务器.在这之前,需要查询服务器域名对应的IP地址.\n\n\nDNS服务器就专门保存了Web服务器域名与IP的对应关系\n\n\nDNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的界限。\n\n\n在域名中，越靠右的位置表示其层级越高。\n\n\n实际上域名最后还有一个点，比如 www.server.com.，这个最后的一个点代表根域名。\n\n\n也就是，. 根域是在最顶层，它的下一层就是 .com 顶级域，再下面是 server.com。\n\n\n\n根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。\n域名解析的工作流程\n\n客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）\n本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。\n根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”\n本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”\n顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。\n本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。\n权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。\n本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。\n\n\n浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」\n\n协议栈\n获取到IP之后, 将HTTP的传输工作交给操作系统中的协议栈\n\n应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。\n\n协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。\n协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。\n\nARP 用于根据 IP 地址查询相应的以太网 MAC 地址。要么是[ 以太网头 | IP 头 | TCP 头/udp/icmp| 数据 ] 要么是[ 以太网头 (Type=0806) | ARP 头 | 数据 ] 就是说arp和ip是平级的\n\n\n\n\n因为arp就是因为只知道ip不知道mac 所以需要问.所以绕过ip层作为以太网负载发出去,问某个ip对应的mac\n\n\nIP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。就是主要负责数据链路层和物理层\n\n可靠传输TCP\n\nTCP建立连接:三次握手\n所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。\n\n一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。\n然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。\n服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。\n客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。\n服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。\n所以三次握手目的是保证双方都有发送和接收的能力。\n\n查看TCP的连接状态，在linux可以用netstat -napt命令查看\n如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。\n\n\n\nMTU：一个网络包的最大长度，以太网中一般为 1500 字节。\n\n\nMSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。\n\n\nTCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。\n\n\n\n经过网络层和传输层之后就是这个样子了\nip将数据封装成网络包：网络层\n\n\n源地址IP，即是客户端输出的 IP 地址；\n目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。\n因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。这样才知道拆开之后的文件属于tcp\n\nTCP: [ IP 头 | TCP 头 | 数据 ]\nUDP: [ IP 头 | UDP 头 | 数据 ]\nICMP: [ IP 头 | ICMP 头 | 数据 ]  但是实际上 icmp属于网络层,tcp/udp属于传输层 icmp就是报错,是由中间的路由器发回给源主机的,不需要什么端口什么的,但是因为是路由器发的,所以被封装进一个ip包.而且发icmp一般都是tcp连接断掉了,那如果还用tcp发那肯定不行的.\n网络层协议: icmp/ip/arp 但是imcp一般是包裹在ip头里面的.arp头则是替代ip头\n\n\n\n\n当存在多个网卡的时候,就需要判断应该写哪个作为源ip地址,就是决定应该用哪个网卡来发送包.这时候就需要根据路由表规则来判断.\n在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。\n\n第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\n\n\nmac\n实际上是由操作系统CPU来填写的\n\n一般在 TCP/IP 通信里，MAC 包头的协议类型只使用：\n\n0800 ： IP 协议\n0806 ： ARP 协议\n//这就是网络层协议\n\n发送方的 MAC 地址获取比较简单，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。\n接收方的 MAC 地址就有点复杂了，\n得先搞清楚应该把包发给谁，需要查一下路由表。\n\n\n如果在一个局域网,那么直接发到ip就可以了\n如果不在就会匹配到最后一个条目 发送到默认网关做转发.\n\n知道发送给谁之后,要如何获取对方的mac地址呢?此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\n\nARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。\n然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。\n如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。\n在后续操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。\n也就是说，在发包时：\n\n先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。\n而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。\n在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。\n\n最终生成的报文长这个样子\n\n网卡\n网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。\n负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。\n网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。\n\n\n起始帧分界符是一个用来表示包起始位置的标记\n末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏\n\n最后网卡会将包转为电信号，通过网线发送出去。\n交换机\n交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。\nmac层:（介质访问控制层）是数据链路层的一个“子层”。\n包接收\n首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。\n然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。\n计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。\n将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n\n一个是设备的 MAC 地址，\n另一个是该设备连接在交换机的哪个端口上。\n\n举个例子，如果收到的包的接收方 MAC 地址为 00-02-B3-1C-9C-F9，则与图中表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 3 号端口上，然后就可以通过交换电路将包发送到相应的端口了。\n所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。\n\n如果MAC地址表查找不到指定的MAC地址\n只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。\n这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。\n发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。\n此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。\n以下两个属于广播地址：\n\nMAC 地址中的 FF:FF:FF:FF:FF:FF\nIP 地址中的 255.255.255.255\n\n路由器\n网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。\n这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。\n不过在具体的操作过程上，路由器和交换机是有区别的。\n\n因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；\n而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。\n\n基本原理\n\n路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。\n当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。\n\n包接收\n\n首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。\n如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。\n总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃\n\n查路由表\n\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。\nMAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。\n转发操作分为几个阶段\n\n\n首先是查询路由表判断转发目标。\n\n进入包的发送工作\n首先需要根据路由表的网关列判断对方的地址\n根据路由表的网关列判断对方的地址\n\n\n如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。\n如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。\n\n知道IP地址之后,就需要通过ARP协议根据IP地址来查询MAC地址,并将查询的结果作为接收方的MAC地址.\n路由器也有ARP缓存,所以会先在ARP缓存中查询,如果找不到则发送ARP查询请求\n\n发送方MAC地址就填写输出端口的MAC地址.还有一个以太类型字段填写IP协议\n网络包完成之后就转换成电信号通过端口发送出去,然后通过交换机到达下一个路由器,经过层层路由转发,就可以到达最终的目的地.这之间,源ip地址和目标ip地址是不会发生变化的,一直变化的是MAC地址\n\n服务器\n\n\n数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。\n接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。\n于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。\n于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。\n服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。\nHTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。\n穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。\n最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。\n客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！\n于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！\n最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。\n"},"课程笔记/计算机网络/02-物理层-the-physical-layer":{"slug":"课程笔记/计算机网络/02-物理层-the-physical-layer","filePath":"课程笔记/计算机网络/02 物理层 the physical layer.md","title":"物理层 the physical layer","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::CN\n物理层的主要任务\n\n网络中硬件设备和传输介质的种类繁多，通信方式也各不相同。物理层应尽可能屏蔽这些差异，让数据链路层感觉不到这些差异。\n\n发送方的数据链路层将需要发送的帧交给物理层\n传输后接收方的物理层将这些帧传递给接收方的数据链路层。\n具体地说，物理层确定与传输媒体接口有关的一些特性：\n\n\n机械特性：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。\n电气特性：指明在接口电缆的各条线上出现的电压的范围。\n功能特性：规定物理接口上各条信号线的功能分配和确切定义（各条线上出现各种电压表示何种意义）。\n规程特性 / 过程特性：定义了各信号线的工作顺序和时序，使得比特流传输得以完成。\n\n2 基本概念\n\n数据是需要传送的信息，信号是数据在传输过程中的存在形式。\n\n2.1 link/channel/data rate/baud rate\n链路和信道 flashcard\n\n(物理) 链路 link；承载信号的 physical path\n一条物理链路可以通通过分时、分频等方式容纳多个 信道 channel (也称为逻辑链路)，每条信道对应着一个发送方和一个接收方。\n\n\n比特率 bit rate flashcard\n\n也可以叫data rate数据率 - 单位时间内传输的信息中 bit 的数目，即 (数据量 / 时间)。\n\n单位是 b/s Kb/s Mb/s Gb/s\n也可以写成 bps Kbps Mbps Gbps\n注意是 bit/s 不是 Byte/s\n就算实际发送的比特比数据多【譬如用1111表示1 】，但是data rate不变.也就是说冗余的比特我们不算在内\n\n\n\n\nsymbol rate flashcard\n\n码元 / 符号 symbol - 用一个数字脉冲表示的一个 k 进制数字。就是一次采样得到的结果，可能包含不同数量的bit。\n\n比如假设电平有4档分别编码00，01，10，11，那么一次采样就是2bit数据。那么分辨8个电压的话一次采样的结果就有3bit。\n\n\nsymbol rate / baud rate - 单位时间内传输的 symbol 数目，即单位时间内可能发生的信号变化次数。就是单位时间采样次数。symbol/second就是baud\n\n\n例如一个四进制码元（0123，四个）可以携带2bit（log24）信息，那么如果数据率是64kb/s，那么symbolrate是32kbaud（因为2bit/symbol）。当然也存在0.5bit/symbol的情况。\n\n\n2.2 带宽\n带宽相关原理/谐波拟合方波 flashcard\n\n\n用一个一倍基频的谐波（傅里叶分量）拟合方波\n用一个一倍基频和一个二倍基频的谐波拟合\n用一个一倍基频和一个二倍基频和一个四倍基频的谐波拟合\n……\n谐波越多，拟合方波越成功。但是物理媒体有限制：截止频率fc，超过这个频率的波会有不同的减弱。所以只能使用0-fc频率【带宽/频带宽度】\n\n周期：b（需要传输b bit信号）/r（data rate）\n频率：r/b 周期的倒数\n那么N*r/b⇐fc N为可以接受的谐波个数，N倍基频不能大于截止频率。可以得到N⇐b*fc/r。\n因为N越大，信号质量越好，所以r过大时信号质量就会不好。因此在信号质量有一定要求的情况下，带宽越大，数据率就越大。因此数据率的最大值也可以称为带宽\n\n\n\n\n带宽的辨析 flashcard\n\n(数字) 带宽 (digital) bandwidth：最大可能的 data rate，用来表示通信线路传输数据的能力，频带宽度越大，数据率越大，因此把数据率最大值也叫做带宽。单位与 data rate 一致。\n(模拟) 带宽 (analog) bandwidth：信道的频带宽度，单位是 Hz。带宽是传输介质的一种物理特性，滤波器可以通过过滤掉某些频率的信号来进一步限制信号的带宽。\n\n带宽指的是一段频率范围，它并不要求这段频率一定从 0 开始；事实上对于无线信道来说，发送低频率的信号也是不可能的，因为波长会很大，天线长度要跟波长一样长。\n\n我们称之前所说的频率为 0∼B Hz 的信号为基带信号 (baseband signal)\n而将其搬移到 S∼S+B Hz 的信号为通带信号 (passband signal)。\n\n\n\n\n\n\n2.3 采样定理\nNyquist’s theorem 奈奎斯特定理 flashcard\n\n条件：在理想 (无噪声) 低通 (带宽有限) 信道中\n\n【有噪声也可以适用】，因为提出的是理论上限，有噪声只会更低\n\n\n极限码元传输速率（采样频率）是 2W Baud，其中 W 是理想低通信道的 (模拟) 带宽，大于这个极限码元速率也采不出更多了就浪费了。\n\n若用 V 表示每个码元离散电平的数目 (即其可以取值的离散值的个数；即其进制数)，则极限数据速率为 2W log₂(V) (b/s)。\n8级电平，用log28个bit可以表示一个symbol，即3bit/symbol\n\n\n\n\nShannon’s theorem 香农定理 flashcard\n\n条件：在受高斯白噪声干扰的信道中\n用 W 表示信道的 (模拟) 带宽，S 表示信号平均功率，N 表示高斯噪声功率，则极限数据速率是 W log₂(1 + S/N) (b/s)。\n\n信噪比 Signal-to-Noise Ratio, SNR：公式中的 S/N 就是信噪比，没有单位；但为了方便表示更大的范围，也用 10lg(S/N) 表示信噪比，单位为分贝 dB（比如用50分贝来表示10的五次方的信噪比）。就是说如果看到分贝单位的信噪比需要进行换算之后还原成普通信噪比代入公式.\n\n\n\n\n\n\n                  \n                  求极限数据速率例题 flashcard\n                  \n                \n\n\n对于给出了 V (信号电平数) 的情况，无论是否说明无噪声都应使用 Nyquist’s theorem 确定 data rate 的一个上界。\n对于给出了 SNR (信噪比) 的情况，也应根据 Shannon’s theorem 确定另一个上界。\n\n示例一：电话系统\n电话系统的典型参数是信道带宽为 3000Hz，信噪比为 30dB，则该系统的最大数据传输速率为： 3k×log2​(1+10^(30/10)) b/s≈30kb/s\n示例二：结合两种定理\n二进制信号在信噪比为 127:1 的 4kHz 信道上传输，求最大数据传输速率。【2进制信号可以理解成2元信号】\n\n根据 Nyquist’s theorem，最大数据速率为2×4k×log2​(2) b/s=8kb/s\n根据 Shannon’s theorem，最大数据速率为4k×log2​(1+127) b/s=28kb/s\n结论： 二者均为上界，应取其中较小的一个，因此该信道的最大数据传输速率为 8kb/s。\n\n示例三 无意义信息\n\n一条无噪声的 8kHz 信道，每个信号包含 8 级，每秒采样 24k 次，那么可以获得的最大传输速率是？\n\n无噪声 - Nyquist, data rate = 2 * 8kHz * log₂(8) bit/symbol = 48kbps\n“题目中给出的每秒采样 24k 次是无意义的，因为超过了波特率的上限 2W = 16 kBaud，所以 72kbps 是错误答案”\n\n\n\n示例四 不乘2的情况\n\n一个信道每 1/8s 采样一次，传输信号共有 16 中变化状态，最大数据传输速率是？【最大采样是带宽的2倍，这里已经告诉我们采样频率了就不乘2了】\n\n8Baud * log₂(16) bit/symbol = 32bps\n\n\n\n\n\n\n\n3 信息交互方式 flashcard\n\n单工链路 simplex link - 1条信道，固定单向通信。【 广播】\n半双工链路 half-duplex link - 2条信道，双向可通信但不能同时。【 对讲机】\n全双工链路 full-duplex link - 2条信道，两边可以同时收发。【 打电话】\n\n注意2条 channel 不一定需要2条物理链路，一条通过一些复用方式或者双向传输也可以实现。\n\n\n\n\n4 传输介质 / 传输媒体 flashcard\nTransmission media，数据传输系统中发送设备和接收设备之间的物理通路。\n\n导向传输介质 Guided trans media\n\n双绞线 twisted pair：绞合以【减少相邻导线的电磁干扰】。\n\n在双绞线外加一层金属丝编织的屏蔽层，可以进一步【提高抗电磁干扰的能力 】，称为屏蔽双绞线 STP, Shielded Twisted Pair\n没有屏蔽层的称为非屏蔽双绞线 UTP, Unshielded Twisted Pair。\n\n\n同轴电缆 coaxial cable\n光纤 fiber optics\n\n\n非导向传输介质 / 无线传输 Wireless transmission\n\n无线电波 Radio：有较强的穿透能力，不需对准某个方向；无线手机通信、WLAN (wireless local area network) 等。\n微波、红外线、激光：有很强的方向性，直线传播。\n\n\n\n\n5 数字调制 / 数字数据到模拟信号\n数据与代表它们的信号之间的转换过程称为数字调制 digital modulation。\n5.1 基带传输 Baseband Transmission flashcard\n\n直接将数据转换为数字信号，数字信号是离散的，占用传输介质上的全部频率，用于有线介质 (光纤不是基带传输) 【编码】\n\n**Non-Return to\n\n\nZero\n- 用正电压 / 有光表示 1，负电压 / 没有光表示 0。\n- 问题是如果 0 和 1 交替，接收端可以在每一次变化时校准；但是如果一直是 0 或者 1 的话过一段时间可能就数错了会失去同步。\n\nManchester (以太网 Ethernet 的编码方式)\n\n用一个高和一个低表示1，一个低一个高表示0 (实际上就是与一个时钟信号做了 XOR，如图)。解决了时钟信号的问题，即每个码元中间一定有电平跳变。\n问题是带宽开销增大了—倍。\n\n\nNRZI NRZ Invert (USB 2.0 的编码方式)：\n\n用信号翻转表示 1，信号不变表示 0。没有带宽开销的增加；\n解决了一长串都是 1 的问题；但是如果一长串都是 0 还是不行。\n\n\n4B/5B mapping：\n\n把4bit的data重新映射到一套新的5bit编码\n经过设计的新编码保证映射结果最多只会出现连续 3 个 0，就能解决NRZI NRZ Invert的问题。虽然增加了 25% 的开销，但是比 Manchester 好一些。\n\n\n扰频/倒频 scrambling：\n\n尝试解决一长串 0 和 1 的问题。发送数据之前，用一个伪随机序列 XOR 数据，接收器用同样的序列 XOR 后得到结果。\n但是其实不太靠谱如果信号和xor数据一模一样的话异或完全是0，而且容易被截获\n\n\n双极编码 bipolar encoding / AMI, Alternate Mark Inversion：\n\n这种编码方式关注信号的平衡性；短时间内正电压和负电压一样多的信号称为平衡信号 balanced signal。这样的信号均值为0，即没有直流分量；由于传输介质的物理性质，没有直流分量是一个优点。\n这种编码方式用 +1 或者 -1 表示 1，每次的 1 与前一次的 1 表示法相反，保证最多只差 1 个；用 0 表示 0。\n\n\n8B/10B 编码模式：\n\n同时考虑这些问题，通过映射保证没有超过 5 个连续的 0 或  1，同时保持 0 和 1 数目相对均等；其额外带宽消耗也只有 25%\n\n\n\n5.2 通带传输 Passband Transmission flashcard\n通过调节载波信号的幅值、相位或频率来运载数据，占据载波信号频率为中心的一段频带，用于无线和光纤信道。【 调制】\n\n\n幅移键控 ASK, Amplitude Shift Keying：\n\n通过两个不同的振幅分别表示 0 和 1；可以用更多的幅值等级表示更多的信息。\n\n\n频移键控 FSK, Frequency Shift Keying：\n\n类似地，通过不同频率表示不同的码元。\n\n\n相移键控 PSK, Phase Shift Keying：\n\n将载波波形偏移—定的相位。\n\n二进制相移键控 BPSK, Binary PSK：将波形偏移 0° 和 180°。\n正交相移键控 QPSK, Quadrature PSK：将波形偏移 45°, 135°, 225° 和 315°。\n\n\n\n\n\n叠加综合\n\n星座图 constellation diagram：为了让每个码元传输更多 bit 的信息，也可以将这些方式综合起来使用。下面的星座图用黑点表示一个合法的振幅和相位的组合，每一个symbol可能是这n个黑点中的一个\n\n其中每个黑点到原点的距离表示振幅，\n和 x 轴正方向所成角度表示相位偏移。\n\n\n正交调幅 QAM, Quadrature Amplitude Modulation：上图 (a) 即为前述 QPSK，而后面两个图是 QAM 【正交相移键控x调幅】的两个实例，它们的每个 symbol 分别携带 4 bit 和 6 bit 的信息。\nGray code：为星座图分配每个黑点代表的 bit 时，需要考虑少量的突发噪音不会导致很多 bit 出错。可以使用 Gray code 解决这一问题（相邻点的 bit 码仅相差一位）。\n\n\n6 多路复用\n频分复用 FDM, Frequency Division Multiplexing flashcard\n经过调制后，要传输的信号所占带宽是有限的；而线路可使用的带宽远大于这一宽度。\n我们可以对多路信号采用不同频率进行调制，使得调制后各路信号频率不同，不会互相干扰；即将信道带宽分割为多种不同频带的子信道，实现多路复用。\n\n每个频带之间保留足够宽的距离，保证相邻的频带不会相互重叠。这一部分保护间隙称为保护频带 guard band。 \n正交频分复用 OFDM, Orthogonal FDM：基本思想是：每个子载波相互正交；即每个子载波在其子载波的中心频率处能量为0。这样在每个子载波中心频率处取样，就不会被其他子载波干扰了。这样的方式不需要 guard band，且频带利用率很高。\n\n\n时分复用 TDM, Time Division Multiplexing flashcard\n每个用户周期性地轮流工作，每次在一个非常短的时间内获得整个带宽。类似于频分复用，时分复用也可能会需要增加保护时间 guard time，保证不重叠\n\n\nTDM 的调度方式是机械的，一种动态按需分配时间片的方式是统计时分复用 STDM, Statistical TDM。但是需要额外的信息来标识可能效率反而会变低\n\n\n码分复用 CDM, Code Division Multiplexing/码分多址CDMA, Code Division Multiple Access#flashcard flashcard\n\n\n若干由 1 或 -1 组成的序列S, Sˉ 表示其反码 (序列中的每个数取其相反数)。\n对于任意两个序列 S 和 T，其归一化内积 (normalized inner product) =内积（对应位置相乘的积相加）/m，其中 m 是序列的长度，此处为 8。\n\n容易理解，有 S⋅S=1，S⋅Sˉ=−1。若 S⋅T=0，我们称这两个序列是正交 (orthogonal) 的； 显然此时 Sˉ⋅T=S⋅Tˉ=Sˉ⋅Tˉ=0。根据这一定义，图中 (a) 的 4 个序列ABCD是两两正交的。\n\n\n现在我们尝试利用这些序列发送信号。每个发送端（ABCD）被分配了一个序列；\n\n每一个周期中，发送端可以选择发送 1 (通过发送这个序列)，或者发送 0 (通过发送这个序列的反码)，或者什么都不发送。当多个站同时发送时，它们发送的信号会叠加起来；\n但是由于序列的正交性，我们可以将每个站发送的信息单独解码出来。假设在某一个周期中，A 和 D 发送了 0，B 发送了 1，C 什么都没有发送，那么叠加出的信号就形如 S=Aˉ+B+Dˉ=(1,−1,3,−1,1,3,−1,−1)。我们将这个信号与 B 作归一化内积：\nS⋅B=8−1+1+3+1+1+3−1+1​=1\n\n\n即 B 发送的是 1。如果与 C 作归一化内积，则结果为 0，表示 C 什么都没有发送。如果与 A 或 D 做归一化内积，则结果为 -1，表示发送的是反码 (即 0)。这是因为，归一化内积满足分配律，S⋅D=(Aˉ+B+Dˉ)⋅D=Aˉ⋅D+B⋅D+Dˉ⋅D，而前两项由于正交性为 0，第三项为 -1，因此最终结果为 -1；其他的情况也是类似的。\n下面回顾我们做了什么。我们==在原本需要发送 1个 bit 的时间发送了 m 个 bit 组成的序列==，这样的序列可以有 m 个且两两正交 (考虑正交矩阵)，==从而满足 m 个发送方同时互不干扰地传输的需要==。同时由于我们在单位时间内传输的 bit 数是原来的 m 倍，因此==所需要的带宽也是原来的 m 倍==。如此我们将一个窄带信号扩展到了一个很宽的频带上，这样更能容忍干扰，同时允许多个用户共享同一个频带。\n\n\n7 公共电话交换网络 The Public Switched Telephone Network, PSTN flashcard\n\n\n7.1 本地回路 Local Loop flashcard\n\n调制解调器 modem: 调制器 modulator 和 解调器 demodulator 的缩写，数字信息和模拟信号流之间的转换。\n非对称用户线 ADSL Asymmetric Digital Subscriber Line: 使用 FDM。在过去，整个电话系统中的传输都是模拟的，实际的语音信号以电压的形式从源端传输到接收方。\n\n\n7.2 中继线 Trunk flashcard\n\n编码解码器 codec: coder-decoder，模拟信号转为数字信号，使用脉冲编码调制 PCM, Pulse Code Modulation。\n波分复用 WDM, Wavelength Division Multiplexing：感觉和频分复用差不多，毕竟频率和波长没啥区别。可能 FDM 用来说电，WDM 用来说光这个样子。\n\n\n7.3 交换 Switching flashcard\n\n\n电路交换 Circuit Switching:\n\n先建立连接，然后直接发，最后释放连接；过程中路径被独占。路径的结点收到就立刻发给下一个结点，不储存。\n\n\n报文交换 Message Switching\n\n不需要建立连接。报文携带目的地址和源地址，途中每个结点在收到整个 message 以后再找下一条路进行传输。\n这样可以动态选择合适空闲的线路，增加线路的可靠性和利用率。但是会引起转发时延，并需要缓存空间。\n\n\n分组交换 / 包交换 Packet Switching\n\n将报文合理分块，增加携带分组编号等信息。\n在报文交换的基础上，缩短了时延，减少了期望的出错重发数据量，同时由于 packet 的长度有所限制，存储管理也方便了很多；动态寻找线路时各个 packet 也可以选择不同路径 (因此，packet 的数据不一定按序到达)。问题是额外信息量进一步增加，且发送前和接收后的工作量也会增加。\n\n\n"},"课程笔记/计算机网络/03-数据链路层-the-link-layer":{"slug":"课程笔记/计算机网络/03-数据链路层-the-link-layer","filePath":"课程笔记/计算机网络/03 数据链路层 the link layer.md","title":"数据链路层 the link layer","links":[],"tags":[],"content":"只关心点到点\n数据链路层的功能\n主要任务\n\n发送方的网络层将数据包发给数据链路层，数据链路层通过物理层提供的服务将数据传输给接收方的数据链路层，接收方的数据链路层再将数据提供给网络层。\n在这个过程中，数据链路层需要考虑的问题有：\n\n物理层传输的是比特流，因此需要区分不同的数据包的界限\n传输过程中可能发生的错误\n发送方和接收方处理数据速率的不同\n\n\n\n\n为了方便解决这些问题，数据链路层将网络层提供的每个数据包通过一些增加和修改封装成 帧 frame（也有可能拆分并封装成多个帧），在接收方的数据链路层，这些修改被还原。\n\n头部 尾部信息\npayload field就是packet具体的内容\n\n\n需要说明的是，我们可以想象在两个 host 之间的数据链路层直接通信。这是因为，数据链路层无需关心物理层是怎么传输这些信息的；这种“不关心”也是有好处的，因为这说明物理层保证实现方式的任何修改不会影响到数据链路层。\n\n数据链路层在哪里实现\n\n路由器router中的线路卡line card\n大部分在主机host的硬件hardware上，一部分在 software that runs on the host’s CPU\n在大多数情况下，链路层由网络适配器network adapter实现，有时也称为网络接口卡network interface card（NIC ）。\n\n网络适配器的核心是链路层控制器，通常是一个单独的专用芯片，负责实现许多链路层服务（帧、链路访问、流量控制、差错检测等）。\n\n\n\n提供给网络层的服务\n检错在哪个层都可以做,但是越晚做成本越大.但是过早检错本身也有一个成本.所以就要平衡早晚.\n因此数据链路层可以根据需要设计不同的协议，提供的具体服务根据不同的协议有所差异。\n\n物理层提供给数据链路层的服务是单一的：将发送方数据链路层发来的帧想办法发送给接收方的数据链路层\n\n通常，数据链路层可能会提供如下 3 种服务之一：\n无确认的无连接服务\nUnacknowledged Connectless Service\n这种服务不会尝试对丢帧情况进行检查，因此也不可能试图对丢失的数据进行恢复。这种服务适合错误率很低的情况（如光纤传输），或者即时通讯、直播等对即时性要求很高，且偶尔的丢失和错误关系不大的情况。\n有确认的无连接服务\nAcknowledged Connectless Service\n这种服务发送的每一帧需要单独确认；如果发送方发送一个帧后在指定的时间内还没有得到确认，则重新发送该帧。适用于不可靠信道，比如无线系统（802.11 WiFi）。\n有确认的面向连接服务\nAcknowledged Connect-Oriented Service\n这种服务在传输数据前在发送方和接收方之间建立一个连接，保证每个帧都按序、不重复地被接收方接收，传输结束后连接和维护连接的资源被释放。为了保证正确性，双方需要维护一些变量和计数器，记录哪些帧已经收到，哪些还没有收到。适用于长距离且不可靠的链路，如卫星信道和长途电话电路。\n成帧\n\n成帧 Framing 的核心任务是设计一种方案将比特流划分为帧\n\n使得接收方很容易找到每个帧的开始，从而将比特流还原成一个个帧；\n同时不能占用太多带宽。\n我们考察 4 种定界方式。\n\n\n\n字节计数法 byte count\n\n\n如图所示，这种方式在每个 frame 的开头用一个 byte 保存这个 frame 的 byte 数目。\n但是当这个计数值出现错误时，即使接收方通过错误检验发现了错误，也再也无法知道下一帧的开始位置（失去同步 get out of sync）。因此，字节计数法一般不会被采用。\n\n标志字节法 Flag bytes\n\n\n这种方式用一个固定的特殊字节标明帧的头部和尾部，如上图 (a)。这个字节称为 flag byte (FLAG)。\n当传输的数据内部出现 FLAG 时，用一个转义字节 escape byte (ESC) 在其前面进行标识；同时需要发送 ESC 本身时也在其前面增加一个 ESC，如上图 (b)。这种技术也称为 字节填充 byte stuffing。\n但是如果要发的数据全都是esc,那就会有百分之百的overhead\n\n标志比特法 Flag bits\n\n\n考虑到帧的划分也可以是比特级的，这种标志和填充也可以精确到比特级。例如 HDLC 的标志方式是：每个帧的开始和结束用序列 01111110 (0x7E 连续的6个1) 标识\n同时发送方的数据链路层在数据中每发现连续的 5 个 1，发送时就在其后面添加一个 0；接收方的数据链路层在发现 111110 时将最后一个 0 舍弃。这种技术称为 比特填充 bit stuffing。\n即使发的全是1也只有百分之二十的overhead\n不太好用软件(字节单位)实现,但是用硬件好实现\n\n物理层编码违禁法 Physical layer coding violations\n\n对于 4B/5B 编码方式或者 Manchester 编码，有相当一部分信号组合是不可能出现的。我们可以使用这样的信号组合作为帧的开始和结束。相对于上面两种填充方法，这种方法不再需要填充数据。IEEE 802 标准就采用了这种方法。\n违反分层原则:下层改变实现细节,不能影响上层调用.但是这个方法的话如果下层修改了编码方式就不行了.但是性能实在优越所以还算常用\n\n检错和纠错\n\n信号在传输中有可能出现错误或者丢失。\n确认:如果我们需要排除丢失的情况，我们可以在协议中要求接收方在收到帧后发回一个确认；发送方得到确认后才可以发下一帧，如果一段时间内没有收到确认则需重新发送。\n检错与纠错:如果我们需要排除错误的情况，我们可以尝试直接对错误进行恢复[比如wifi]；也可以尝试只检查错误，如果发现错误则要求发送方重传。\n无论是纠错码还是检错码都无法处理所有可能的错误，因为提供保护的冗余位与数据信息位一样，有可能被接收成错误。\n\n基本定义和原理\ncodeword码字\n如果想要检查一串数据是否出现过错误，我们显然需要一些额外的信息。\n\n如果一帧有 m 个数据位存储信息\n有 r 个冗余位 (redundant / check bits) 用来校验\n那么这个包含了数据位和冗余位的 n = m + r 位数据块就称为一个 n 位 码字 codeword。\n\ncode rate 码率\n\n码率 code rate 为 codeword 中数据位所占的比例，即 m/n。通常在越高质量的信道上设计的 code rate 越高，因为相比于有噪声的信道，高质量的信道通常需要更少的冗余位用来检错或纠错。\n比如光纤这种可能只需要奇偶校验就能检查出来\n\nHamming distance d海明距离\n\n两个等长的码字中不相同的位的个数称为这两个码字的 海明距离 Hamming distance d，代表一个码字需要出现 d 个 1bit 的错误才会变成另一个码字。\n\n\n如果我们想可靠地检测可能的 e 个错误，我们需要一个海明距离为 e + 1 的编码方案（即，任意两个合法码字之间的距离不小于 e + 1）。**\n\n因为这样任意 e 个错误不可能将一个合法码字变成另一个合法码字**；\n当我们发现一个非法码字时，我们就知道出现了错误。\n\n\n如果我们想可靠地纠正可能的 e 个错误，我们需要一个海明距离为 2e + 1 的编码方案。\n\n因为这样任意的 e 个错误发生后，原来的码字仍然是离现在的码字距离最近的那一个。\n\n\n\n\n海明距离为3的编码方案,可不可以纠正1个可能错误的同时检测可能的2个错误? 不能\n\n其他概念\n纠错码方案的不同特征:\n\n\n块码 block code 是指 r 个校验位是由 m 个数据位按块处理得到的,一次性拿到m个数据,输出n个码字.\n\n\n系统码 systematic code 是指数据位和校验位是分开而没有交叉的；在最终的n位码字中,数据本身是不被改变的\n\n\n线性码 linear code 校验位是对数据位做线性组合得到的\n比如汉明码就同时满足上述三种特征.\n\n\n现实中常见的错误有两种。\n\n\n\n第一种是偶现的问题导致单个比特错误；\n另一种是突发的问题导致一段信息发生错误（不一定每个比特都发生错误）。\n其他类型错误 \n\n纠错码\n\n除了卷积码是线性码不是块码以外，其他三种编码都是线性块码。\n纠错码广泛运用于无线链路。无线链路容易出错，如果没有纠错码很可能获得不到任何完全正确的信息。另外对于单工信道(广播站)的情况，接收方如果检测到了错误也没有办法发回一个重发请求，因此也适用纠错码。\n\n海明码 Hamming codes\n\n假设我们需要设计一种编码方案，每个码字有 m 个信息位和 r 个冗余位，并且能够纠正所有的 1bit 错误。加起来应该是n位(m+r)\n那么对于 2^m 种合法的信息(因为m位信息)，每个信息都应唯一对应 n 个非法码字，它们与该信息的距离为 1。\n\nn种错误情况+自己本身1种合法情况=n+1种情况,是归给合法信息管辖.因为1bit错误,所以距离为1\n如果2位:\n要注意的是,是一串码字表示一个信息,而不是一个位表示一个信息.\n\n\n因此这里就共有 (n+1)2^m 种情况，因此有 (n+1)2^m≤2^n，亦即 (m+r+1)≤2^r。在 m 给定的情况下，我们可以通过这一不等式确定 r 的下界[至少要多少个冗余位才能够满足条件]。海明码给出了这一下界的一个获得方式。编码方式见下图。\n\n2的幂次方位置上有1的数进行异或,正好得到1101.再跟非2的幂次方位置的数字异或,一定得到0[自己异或自己]\n如果不是0,疑惑得到的结果就是错误的哪一位.谁翻转了,异或的时候就会露出马脚\n\n一般见到的是偶校验海明码,奇校验海明码就是异或完之后反一下再填到2的幂次方位置\n卷积码 convolutional codes\n\n\n\n卷积码的输出由当前输入和之前若干位输入决定，影响当前输出的此前输入位数称为 约束长度 constraint length。\n\n\n如图这种卷积码的约束长度为 6[就是图上的s1~6]，每个输出 bit 会带来 2 bits 的输出，\n\n其中第一个是第 0, 2, 3, 5, 6 位的模二加法[就是异或]（0 指输入位，16 指 S1S6 的值），\n第二个是第 0, 1, 2, 3, 6 位的模二加法。\n\n\n\n比如输入序列为 111，输入第一个 1 时 06 位是 1000000，因此输出是 11，然后 S1S6 右移一位变成 100000；输入第二个 1 时为 1100000，因此输出是 10；输入第三个 1 时为 1110000，因此输出是 01。因此编码后为 111001。\n\n\n一个输入码可以得到两个输出结果,3bit可以得到6bit的冗余数据.\n\n\n卷积码的解码是通过最大似然法。在所有可能的输出序列中找出与接收到的序列最相近的那一个，解码为这个序列对应的输入序列。\n\n\n\n\n\n里所罗门码 Reed-Solomon codes\n低密度奇偶校验码 LDPC, Low-Density Parity Check\n检错码\n\n光纤和高品质铜线的错误率较低，因此对偶现的错误进行检错和重传更加有效。下面介绍三种检错码，它们都是线性的系统块码。\n\n奇偶校验位 parity bit\n\nn-1 位信息，1 位冗余。\n\n奇校验码：在加上该位后 ,1的个数为奇数；\n偶校验码:  在加上该位后,1的个数则为偶数。\n\n\n交错校验 interleaving 技术可以一定程度上防止突发的若干比特范围内[如果发生偶数个反转,就检测不出来了]的错误。将数据块作为 k 行 n 列处理，每列计算一个 parity bit 后附在数据块最后发送。这样除非突发错误持续 n 个 bit 以上，否则仍然可以被检测出来。\n横着发,竖着验,可以避免一行连续错误.这里考虑的是单次干扰,不考虑一个错了之后隔了n个又错一个的这种情况\n\n校验和 checksum\n\n对数据进行一些求和运算。然后得到结果后,到那边看看结果还一不一样.\n\n奇偶校验位也可以看做校验和的一个例子。\n\n\n另一个实际例子是 Internet Checksum。规则是：\n\n首先将数据分割成 16 bit 的若干段（最后一段不足 16 bit 则在末尾补 0）；\n然后将这些段相加，最高位进位 wrap around[最高位的进位再加回最低位]\n最后将结果按位取反 (?) 作为校验。\n检查时再次计算数据之和，加上校验，如果结果不为全 1 则发生过错误。[取反之后加上原数字,当然全为1了] [如果传输过程中哪个位翻转了,那么当然破坏了完美的互补]\n\n\n解释 wrap-around carry bit (src)\n\n1001+1100=10101=0101+1=0110\n0110+1010=0001\n0001+0011=0100 这个得到的就叫checksum,但是放到帧里去用的时候需要取反\n\n循环冗余码 CRC, Cyclic Redundancy Code\n\n又称 多项式码 polynomial code，计算方式见下图。其中 G(x) 是发送方和接收方预先商定的一个多项式，称为 生成多项式 generator polynomial，其最高位和最低位一定是 1。\n\n将除数转换成多项式,n位除数,最高次项就是n-1,然后给被除数末尾添上n-1个0.然后正式开始除法之后,加法和减法全都视为异或进行计算.\n\n\n由于模 2 除法的一些性质，这种方法有优秀的检测能力，具体可以参看中文课本 166~167 页。\n\n\n\n                  \n                  例题 \n                  \n                \n\n\n一个比特流 10011101 使用文中描述的标准 CRC 方法进行传输。生成多项式为 x^3 + 1。\n展示实际传输的比特串。\n假设在传输过程中，从左边数的第 3 个比特发生了反转（0变1，或1变0）。证明接收端能检测出这个错误。\n给出一个接收端无法检测到的比特错误示例。\n\n\n\n实际传输的比特串 = 原始数据 + 余数 = 10011101 + 100 = 10011101100.\n\n也就是说 最终的比特串是可以整除除数的.那么发生了错误之后自然不能整除.\n\n\n如果比特串错误的部分正好可以符合整数倍除数,那就不能被检测出来\n\n\n\n流量控制与一些基本协议\n考虑单工停等协议:单工simplex,停等stop and wait\n这里的单工是只发消息,那边往回发一个确认,发送方得到确认后才会发下一个帧.\n一些单工协议\n一个乌托邦式的单工协议\nA Utopian Simplex Protocol\n\n发送方不断地从网络层获取数据包并构造一个帧，通过物理层发送该帧；\n接收方不断等待唯一可能的事件 FRAME_ARRIVAL 发生，将该帧从物理层取得，处理后将数据部分发送给网络层。这种方案的问题是，如果发送方发送帧的速度大于接收方处理的速度，接收方就会被淹没 (flood)。\n\n无错信道上的单工停-等协议\nA Simplex Stop-and-Wait Protocol for an Error-Free Channel\n\n接收方每当接收一个帧并处理完成后，发回一个确认帧；\n发送方在收到确认帧后（不需要处理，因为此时唯一的可能就是确认帧），则可以发送下一帧。这种协议在数据传输上是单工[发”数据消息”确实是单向的]的，但是接收方需要发回消息，因此需要使用半双工信道。\n这种方案的实际问题在于，没有考虑出现错误的情况。\n\n有错信道上的单工停-等协议\nA Simplex Stop-and-Wait Protocol for a Noisy Channel\n这种协议在上一种的基础上考虑 3 种可能的错误\n\n接收到的帧检出错误\n\n为了解决第 1 种错误，我们引入一个新的事件 CKSUM_ERR 表示校验和有误；\n因而接收方在收到一个帧后应当校验正确性，发回一个表示正确或者错误的确认帧；\n如果检出错误，则直接抛弃该帧等待重传。如果发送方收到了表示错误的确认帧导致事件 CKSUM_ERR 发生，那么发送方将重新发送上一帧。\n\n\n发送方发送的帧完全丢失\n\n对于第 2 种错误，接收方完全没有接到一个帧，因而也不可能对此作出确认。\n为了避免这种情况，发送方每次发送一个帧后启动或重置一个计时器，这个计时器的时间应当长于预期正常情况下收到确认帧的时间。\n如果计时器超时发送方仍未收到确认帧（事件 TIMEOUT），那么第 2 种错误有可能发生，此时发送方会将（缓存下来的）刚刚发出去的那一帧重新发出一次。\n直至发送方收到一个积极的确认帧，此时发送方再加载下一帧，上一帧的缓存即可以被覆盖掉。\n\n\n接收方的确认帧丢失\n\n但是需要考虑的是，除了第 2 种错误，这种问题也可能导致发送方没有收到确认帧，因此可能会将一个正确收到（没有被抛弃）的帧重发，导致接收方收到两个该帧；如果不加限制，接收方的网络层则可能收到重复两次的该数据段，引起错误。\n我们需要防止这种重复的发生。考虑到发送方发送第 i + 1 帧的充要条件是第 i 帧已经收到了正确的确认，而这一确认的必要条件是接收方已经正确收到了第 i 帧。因此我们只需记录每一帧序号的奇偶性，并将其包含在帧头中（称为字段 seq ）。\n如果接收方接收到了预期的（与前一帧相反的）奇偶标记，那么就将其保存；否则就说明前一帧被重复发送了，此时则直接抛弃该帧，同时发回一个确认（作为对前一个丢失确认帧的补充）。\n\n\n\n\n这种在接收到肯定确认之前定时重传的协议也称为 自动重复请求 ARQ, Automatic Repeat reQuest 或 带重传的肯定确认 PAR, Positive Acknowledgement with Retransmission。\n\n捎带确认 piggybacking\n\n需要注意的一个问题是，前面两种带有确认的协议都需要使用半双工传输，而这种传输和全双工传输一样都需要往返两条信道；因此实际上同一条链路最好用来往返传输数据。这种情况下，某一帧的接收方就可以把该帧的确认包含在它发回的另一帧的帧头中，这种方式就称为捎带确认[驮运]。\n捎带确认引入的另一个问题是，需要发回确认的那一方并不知道网络层什么时候会让它发送下一个数据包，以便它将确认包含在其帧头中（称为字段 ack）。[打不到车]\n\n为了解决这个问题，发回确认的那一方也可以设置一个计时器，在计时器结束前如果网络层交付了一个数据包让它发送，那么就将确认包含在其中；否则就直接发送一个单独的确认帧。\n\n\n一个捎带确认的双工停-等协议\n\n收到0 就发一个ack0表示希望下一个是1\n\n\n\n滑动窗口协议 Sliding Window Protocols\n基本思想\n\n在现实世界中，帧送往接收方途中和确认帧返回发送方的时间[两个灰色]可能比发出一个帧[仅指推上传送带的过程,绿色]的时间长出很多\n\n这会导致带宽的利用率很低。因此我们引出滑动窗口协议。\n\n\n\n滑动窗口协议的基本思想\n\n发送窗口 sending window任意时刻发送方维护一组允许发送的帧的序号（同样用 seq 字段保存，但这时可能不止 1 个 bit）\n接收窗口 receiving window接收方维护一组允许接收的帧的序号.\n这两个窗口的大小不必相同，但是是固定的。\n\n\n发送方一个每收到确认帧，就将发送窗口向前滑动一个位置；如果没有可以发送的帧（即发送了窗口大小那么多的帧但是还没有收到确认）就停止发送（定时重发）\n接收方每收到一个帧，如果在接收窗口内则接收，否则丢弃。\n事实上，stop-and-wait 协议就可以视为是发送和接收窗口大小均为 1 的滑动窗口协议。\n需要再次注意的是，接收方的数据链路层需要尽可能将数据包按正确的顺序传递给网络层。\n关于窗口大小的理论分析（更正：ACK 0 应当是 ACK 1）\n\n根据上面的理论分析，我们定义 链路利用率 Line Utilization = Frame Length / (Frame Length + 2 * Bandwidth * Propagation Delay)更常见的表述是 Line Utilization = Frame Length / (Frame Length + Bandwidth * Round-Trip Delay)。\n进一步我们定义 链路吞吐率 Throughput = Utilization * Sending Data Rate\n\n回退 N 协议 GBN, Go-Back-N\n\n回退 N 协议是一种滑动窗口协议；其中 N 代表 sending window 的大小，而这种协议中 receiving window 的大小始终为 1。当当前 sending window 的第一帧的计时器（实际上每一帧发出后都启动一个独立的计时器）超时仍未得到 ACK 时，回退 N 位到 sending window 的开头重新发送这 N 帧；而由于 receiving window 的大小是 1，因此提前到达的帧都会被抛弃。如下图。\n\n另外引入一种确认方式：累计确认 cumulative acknowledgement，这种确认方式为：当接收方发回 ACK n 的确认，其中表示 n 和 n 之前的所有帧都已经收到；如果 n 之前有任何没有收到的帧，则 ACK n 不会被发出。\n考虑 GBN 中 seq 段 bit 数和 N 的关系。如果 seq 的取值为 0~MAX_SEQ，即共有 1 + MAX_SEQ = 2^size_in_bit(seq) 种取值，那么 N 最大为 MAX_SEQ 而不能是 1 + MAX_SEQ。\n\n考虑这样的一个情况。假如 MAX_SEQ 是 7，而 N (i.e. sending window size) 是 8；发送方一次性发出了 0~7 这 8 个帧，而接收方发回的 8 个确认帧全部丢失了；那么发送方认为得超时重传0号帧,接收方认为刚才都确认了,要等全新的0号帧\n接着发送方重发了这些帧，而此时接收方以为这是全新的 8 个帧，导致了传递给网络层的数据出现了重复。因此 N 不能是 8。\n\n\n\n选择重传协议 SR, Selective Repeat\n\n如果错误很少发生，那么 GBN 是一个良好的策略；而当错误频繁发生，GBN 的重发方式会浪费大量的带宽。GBN 协议可以有两种思路的优化。\n\n\n当接收方发现了发来的帧有错误或者不是所期待的那个帧时，发送一个否定的确认信息 NAK, Negative Acknowledgement 并说明想要的下一帧，这样可以不用等到 timeout 再回退重发；\n增大 receiving window size，这样当错误发生时可以先缓存一部分发来的后面的帧，这样发送方只需重发 NAK 的帧即可。\n\n\n综合上述两种优化和累计确认的一个例子如下；这就是 选择重传协议。\n\n选择重传协议对每一帧只发送一个 NAK，防止一次性发送大量相同 NAK 的情况。但是，这也有可能带来问题。解决方法: 当接收方收到“非预期”的帧（比如我要 7，你给我 0），并且发现自己已经发过 NAK 了，它就启动一个 辅助计时器。如果计时器时间到了（Expires），还没收到 7，接收方就会强制再发一次 ACK/NAK。\n接收窗口的大小不能大于 (MAX_SEQ + 1) / 2。一般来说，选择重传协议的接收窗口和发送窗口的大小是一样的。如果窗口跨度太大,就会把旧帧当作下一轮的新帧缓存起来,导致数据错乱,所以SR大小必须减半,保证新旧序号在窗口中绝对不会重叠.\n\n点对点传输协议实例\n高级数据链路控制 HDLC, High-Level Data Link Control\n\nHDLC 是一种 bit-oriented protocol，使用全双工通信；有顺序编号和校验，传输可靠性高。其帧结构如下图\n\n每个帧的开始和结束用序列 01111110 (0x7E) 标识。\n同时发送方的数据链路层在数据中每发现连续的 5 个 1，发送时就在其后面添加一个 0；\n接收方的数据链路层在发现 111110 时将最后一个 0 舍弃。\n这样整个帧中只会有头和尾的 FLAG 有 01111110 这样的序列了。\n当链路上没有需要传输的内容时，HDLC 也会通过不断发送形式为 01111110 的帧以保持双方的同步。（实际上，HDLC 最开始是作为 SDLC, Synchronous Data Link Control 被提出的。）\n按照 Control 字段的前 2 个 bit 可以将 HDLC 帧划分为 3 类：\n\n信息帧 Information frame，第 1 位是 0，用来承载正常的信息；\n管理帧 Supervisory frame，前两位是 10，用来进行流量控制和差错控制，如单独的 ACK、NAK 等；这种帧没有 Information 字段；\n无编号帧 Un-numbered frame，前两位是 11，用来进行其他的功能，如链路管理等。\n\n\nFCS 是根据 Address, Control 和 Information 字段计算 CRC 的结果。\n\n点对点协议 PPP, Point-to-Point Protocol\n\nPPP 是一种 byte-oriented protocol。HDLC 提供了可靠的数据传输；而 PPP 通常不编号、提供一种无连接无确认的服务。\nPPP 协议有 3 个组成部分：\n\n\n一种成帧方法。\n链路控制协议 LCP, Link Control Protocol，用于启动、测试、配置（协商参数）、关闭链路。\n网络控制协议 NCP, Network Control Protocol。\n\nPPP 是由 SLIP 发展而来的；\nSLIP 的问题在于它只能用于传送 IP Packet；\nPPP 则支持对于网络层运行其他协议以及两端网络层运行的协议不同的情况下仍使用 PPP 进行传输。\n对于每一个支持的网路层协议，都有一个相应的 NCP 进行配置。其帧结构如下：\n\n\n前后的 FLAG 都沿用 HDLC 的 0x7E，但填充方式有所不同。PPP 是 byte-oriented 的，因此使用 byte stuffing。\n在数据中发现的 0x7E 将被替换为 0x7D 0x5E 两个字节；\n而 0x7D 将被替换为 0x7D 0x5D。这样可以保证唯一出现 0x7E 的地方就是帧的开始和结束。\nAddress 段始终为 0xFF，表示广播，即所有计算机都接收；\nControl 的值为 0x03，表示这是一个无编号帧；由于这两个字段的值始终为定值，因此可以通过 LCP 协商省略这两个字段。\nProtocol 包含关于 LCP 和 NCP 的信息，默认 2 byte，但是可以通过 LCP 协商为 1 byte；\nInformation 的默认长度是 1500 byte，但是也可以通过 LCP 协商，可能利用 Padding 进行填充以满足长度要求；\nFrame Check Sequence 默认 2 byte，但是也可以协商使用 4 byte，也是 CRC。\n\nPPP 协议在用于不同链路上时可能也有不同的成帧方式。例如 PPP 用于 SONET 等同步链路时会使用 HDLC 那样的 bit stuffing 而不是 byte stuffing；用于 SONET 时还需要进行链路的建立以及扰码 (scrambling)。\n\n"},"课程笔记/计算机网络/04-介质访问控制子层MAC,-Medium-Access-Control-Sublayer":{"slug":"课程笔记/计算机网络/04-介质访问控制子层MAC,-Medium-Access-Control-Sublayer","filePath":"课程笔记/计算机网络/04 介质访问控制子层MAC, Medium Access Control Sublayer.md","title":"介质访问控制子层MAC, Medium Access Control Sublayer","links":[],"tags":[],"content":"广播信道传输协议\nMAC 子层\n\n我们讨论过的协议都是针对 点对点连接 point-to-point connections 的；但是在 LAN 等场景下，我们需要使用 广播信道 broadcast channels。\n\n也称为 多路访问信道 multiaccess channel 或 随机访问信道 random access channel。\n对于广播信道，关键的问题是保证在多方争用信道时确定谁可以使用信道，从而让他们都成功发送信息。用来确定多路访问信道的下一个使用者的协议属于 Link Layer 的一个子层 介质访问控制子层 MAC, Medium Access Control Sublayer。我们关注低负载情况下的延迟以及高负载情况下的链路利用率。\n\n\nOSI 七层模型将 Data Link Layer 分为了 LLC (Logical Link Control) 和 MAC 两个子层：\n\n将信道分配问题形式化，我们提出下面 5 个关键假设：\n\nIndependent Traffic，每个站中帧的到达率相互独立；每个帧发送出去前该站阻塞。\nSingle Channel，所有的通信都发生在同一个信道上；所有的站都能在这个信道上发送和接受数据。\nObservable Collision，所有的站都能检测到冲突事件的发生。\nContinuous or Slotted Time，可以约定任何时候都可以开始传输帧，或者将时间分槽，规定只能在时间槽开始时开始传输帧。\nCarrier Sense or No Carrier Sense，可以让站在发送前侦听载波，如果信道忙就暂缓传输防止冲突。\n\n\n\nStatic FDM / TDM\n\nN 变化时很麻烦；不变化也很浪费\n\nALOHA, Additive Links On-line Hawaii Area\nPure ALOHA\n\n基本思想很简单：每个用户有数据需要发送时就传输。问题在于，当两个用户发送的信号发生重叠（称为 冲突 collision）时，冲突的帧就会损坏。ALOHA 要求发送方可以知道所发送的信号是否发生了冲突。这种采用了可能引起冲突的共享信道方法的系统称为 竞争系统 contention system。\n在 ALOHA 最初的应用场景中，中央计算机会将受到的帧广播发回，发送方侦听发回的帧就可以知道有没有发生冲突。在其他系统中，发送方可以直接侦听发送的帧是否发生过冲突；或者等待接收方发回 ACK 或 NAK。\n当发送方侦测到冲突、收到一个 NAK 或者一段时间没有收到回复时，它在等待一段 随机 时间后再次发送该帧。如果等待时间不是随机的，那么发生冲突的帧会一次又一次发生冲突。\n\n最好情况下，Pure ALOHA 的信道利用率期望约为 1/2e ≈ 18%，这是很低的。\n\nSlotted ALOHA\n\n在这种优化了的协议中，时间被分成了离散的 slot，用户只能在每个 slot 的开始时刻才能发送帧。每次传输帧的用时必须小于或等于一个 slot 的长度。\n阴影表示冲突 (src)\n这种方式可以达到的最佳利用率是 1/e ≈ 36%。\n载波侦听多路访问 CSMA, Carrier Sense Multiple Access\n\n1-persistent CSMA\n\n每个站点需要发送数据时，首先侦听信道：如果信道空闲则立即发送数据；如果信道忙，则不断侦听直至信道空闲时发送数据。如果冲突（比如一段时间内没收到 ACK 或者收到了 NAK），则随机等待一段时间后重复上述策略。\n问题：\n\n首先，如果信道忙时两个站点同时侦听，信道空闲的时候两个信道就会同时试图发送，从而出现冲突。\n另外，我们还需要考虑信道上的传播延时 propagation delay：如果 A 已经开始发送数据，但是数据暂时没有传播到 B，此时 B 侦听到的信道是空闲并开始发送数据，也会引起冲突。\n\n\n（即便如此，这种方案的信道利用率也比 ALOHA 好）\n\nnonpersistent CSMA\n\n这种方式的关键区别是：如果侦听到信道忙，则放弃侦听，等待一段随机时长后再进行侦听，直到侦听到信道空闲并成功发送。\n\np-persistent CSMA\n\n这种方式用于 slotted channels。当站点需要发送数据时侦听信道：如果信道忙，到下一个 slot 再侦听；如果信道空闲，则以 p 的概率发送数据，以 1-p 的概率到下一个 slot 再侦听。\n\nCSMA/CD, CSMA with Collision Detection\n\n\n前述几种 CSMA 对冲突的发现都是通过确认帧进行的，对于链路过长的情况，等待的时间可能较长。我们考虑对信道不断侦听实现冲突的检测，这要求返回的信号不能比发出的信号弱太多（如无线传输就不行），而且冲突必须在发送过程中就可以被检查到。如果一个站检测到冲突，它会立即停止传输，并等待一个随机时间后再尝试发送。\n\n\n考察冲突检查花费的最长可能时间：在 CDMA 中，冲突的可能性是某个站开始发送前进行侦听时，另一个站虽然已经开始发送，但是信号尚未传播到这个站。因此如果最远的两个站之间传播用时是 t，那么一个站发送后 0~t 秒内冲突才有可能会发生；而这个冲突会花费同样多的时间传播回去。也就是说，如果一个站发送信息后 2t 时间仍然没有侦测到冲突，那么它发送的这一帧就不再可能出现冲突了。\n\n\n无冲突协议 collision-free protocols\n\n\n基本位图协议 Basic Bit-map Protocol\n\n\n\n\n\n这种在发送数据之前先广播发送意愿的协议称为 预留协议 reservation protocol。\n\n\n令牌环协议 Token Ring Protocol\n\n\n\n\n\n二进制倒计数协议 Binary Countdown Protocol\n\n\n\n\n\n有限竞争协议 limited-contention protocols\n\n\n自适应树遍历协议The Adaptive Tree Walk Protocol\n\n\n以太网\n经典以太网 Classic Ethernet\n\n一个 10Mbps 的以太网标准在 1978 年被制定出来，称为 DIX standard。1983 年它被修订并成为了 IEEE 802.3 标准。\n物理层 \n上图显示了经典以太网的 物理层。以太网的每个版本都有电缆长度的限制；超过这个限制的网络可以用 中继器 repeater 将多条线缆连接起来。但是收发器 transceiver 之间仍然有最大距离 2.5 km 和最大经过中继器数目 4 个的限制。在这些电缆上，信息的发送采用 Manchester 编码。\n\n集线器 Hub\n\n\n传统的接线模式不太方便设备的增减；出现断裂等情况也很难定位。因此人们开发出了一种设备 Hub，这种设备有很多接口，每个接口之间简单地连接起来，这样任何一个接口发送来的帧会被传播到其他所有端口。端口的设置也方便了设备增减和定位问题。\n之所以说 Hub 是一个物理层设备，就是因为它不会试图理解和使用任何数据链路层以及更高层添加的信息；比如它并不知道这个帧是从谁发给谁的。它做的事情就只是完成转发（实际上，只是信号的传播）而已。 也正因为 Hub 实际发挥的作用只是信号的传播，因此 Hub 并没有缓存；各个端口上的线路也必须以同样的速度运行。\n\n传输协议\n\n以太网是无连接的，也并不提供确认，使用 1-persistent CSMA/CD 算法进行传输；它通过侦听有没有冲突来判断是否发送成功。如果站侦听到了冲突，则发一个短的冲突加强信号 (short jam signal) 确保另一个发送站也听到了冲突；如果没有侦听到冲突则假设这个帧发送成功。传输过程中发生的错误只会通过校验和检出并由高层负责恢复。\n考虑这种冲突侦听的可靠性。假设两个最远的站 A, B 之间需要的传播时间为 τ，A 站开始发送一个帧后的 τ-ε 时间，即即将到达 B 站时，B 发送了一个帧并产生了冲突；这个冲突在 2τ-2ε 时间被 A 侦听到。那么，我们必须保证 2τ-2ε 时间时 A 还没有发送完这个帧；否则如果它就有可能已经发送完前一个帧并开始发送下一个帧，并且会不知道这个冲突信号代表哪一帧发生了冲突。即，我们需要让帧时间不低于 2τ。根据物理层中我们规范的 2.5km、4 个中继器的最大限制，往返时间 2τ 大约是 50μs；在 10Mbps 的速率下可以发送 500bit。考虑一个安全余量，我们规定最小帧时间为 51.2μs，最小帧长为 512bit，即 64 字节。（这个推导过程换个参数可以考计算题）\n以太网通过 二进制指数后退 binary exponential backoff 算法确定每次冲突后的等待时间。我们将时间按照 51.2μs 分块；在第 i = 1 ~ 15 次冲突发生后，站等待 0 ~ min((2^i-1), 1023) 个时间槽后再次尝试发送；在发生 16 次冲突后，它放弃发送并给上层返回一个失败报告；高层协议负责进一步的恢复工作。这种算法的考量是，如果等待时间的上限较低，那么多个站发生冲突的时候很可能再次发生冲突；而如果上限较高，则很有可能发生很多无意义的延迟。这种算法可以保证：如果只有少量站发生冲突，则可以保证较低的延迟；当许多站发生冲突时，它也可以保证在一个相对合理的时间内解决冲突。\n\n帧结构 \n\n\n在 MAC 子层，标准规定了以太网的帧结构，如上图所示。可以看到，DIX 和 IEEE 802.3 是略有区别的。\n\n\n前 8 个字节是前导码 Preamble，其中前 7 个字节是 10101010 用来同步，第 8 个字节是 10101011 (SOF, Start of Frame) 提示帧的开始。\n\n\nDest addr 发送出去的第一个 bit 是 0 表示 单播 unicasting，1 表示 组播 multicasting；全 1 表示 广播 boardcasting。\n\n\nSrc addr 是全球唯一的；由 IEEE 统一分配。前 3 个字节称为 OUI, Organizationally Unique Identifier，分配给网络设备制造商；网络设备制造商再分配到网络设备，并写入 网络接口卡 NIC, Network Interface Card，即网卡。\n\n\n接下来的 2 个字节，在 DIX 中表示类型，因为接收方的操作系统需要知道用哪个网络层协议来处理数据包；而在 IEEE 802.3 中这两个字节存储 Data 的长度（在 DIX 中，这个长度只能保存在 Data 中；但这违反了分层的思想），具体的类型则存储在 Data 中的 逻辑链路控制 LLC, Logical Link Control 协议头 中。但是实际上在 IEEE 802.3 提出时，DIX 设备已经在使用了；因此最终选择了兼容：值不大于 0x600 的字段解释为 Length，而大于 0x600 则解释为 Type。\n\n\n接下来是 Data 段。在指定 DIX 标准时，考虑到内存很贵，所以设置了 1500 字节的上限（因此最大帧长是 1518 字节）。下面是 Padding，即填充。填充是为了保证帧长度（不算 preamble）不少于 64 个字节；这一规定的原因在前面已经讨论过了。\n\n\n最后一个字段是校验和，它使用的就是 32 位的 CRC。\n\n\n10Base2, 10Base5 用的是同轴电缆；Base 指基带传输，前面的数字表示是多少 Mbps（除了 10GBaseT 这样的表示 10Gbps）；BaseT 或者 BaseC（比如 100BaseT4, 1000BaseCX）差不多都是双绞线；其他的差不多都是光纤\n\n\n网桥 bridge\n引出\n\n\n假如现在有若干个 LAN，例如一个大学的多个学院，分别发挥其效用。但是此时，这几个 LAN 希望相互之间有一些信息交流。最简单的解决办法就是再用一根电缆连接这些 LAN；但是这种做法有若干问题：\n\n\n首先，每个原来的 LAN 中可能包含大量交流于自己学院内的信息，只有很少的一部分需要与其他 LAN 交流。如果简单地将这些 LAN 连接在一起，那么每个信息都会被广播到所有 LAN，这会极大程度上增加网络的负载，同时也带来了安全性问题。\n\n\n其次，IEEE 802.3 的限制决定了最长的线路长度是 2.5km；而如果这些 LAN 的物理地址相距较远，我们就不能将其直接连接起来。\n\n\n而且，原先的各个 LAN 也有可能使用着不同运行速度的线路，甚至是不同的网络类型。这种情况下，直接将其连接是无法正常工作的。\n\n\n解决这些问题的一个不错的思路是，仍然保持这些 LAN 相互隔离的状态，但是给它们提供途径向其他 LAN 发送消息。这个途径应当足够简单；LAN 内部的信息交流不应感知到有没有这个途径之间的区别。为此，人们开发出了 网桥 bridge。\n\n\n工作原理\n\n\n网桥工作在 混杂模式 promiscuous mode 下；也就是说，它捕获所有发给它的数据。如果发送方和接收方连接在网桥的同一个端口上，那么网桥立刻丢弃该包（如 A 发给 C）；如果不在一个端口，那么网桥将这个帧从接收方对应的端口转发出去。\n这种转发的前提是，网桥应当知道每一个站点连接在哪个端口。因此，网桥中配备了一个哈希表，包含了每一个可能的目的站点以及它对应的端口。当网桥的某个端口接收到一个帧，它查看这个帧的发送站点，这样它就得知通过这个端口能够联系到这个站点（这种自学习方法称为 后向学习法 backward learning）。同时，它检查这个帧的目的站点是否在表中；如果在，则如前述那样转发或丢弃；如果不在，则网桥使用 flooding algorithm，将这一帧发送给除了发送端口以外的所有端口。\n\n当机器或网桥被打开、关闭或移动时，网络的拓扑结构会发生变化。为了处理这种动态的拓扑结构，表中还保存了这一项产生或更新的时间（亦即这一帧到达的时间）。网桥中还有一个进程定期扫描这个表，并将那些时间值在几分钟以前的表项清除。\n查找和更新表项的工作在每个帧到来时都需要进行一次；因此网桥使用了专用的大规模集成电路芯片完成这一工作，每次只需要几微秒就能完成。网桥一看到目的 MAC 地址就知道如何转发帧；因此一旦其看到目的地址字段就可以开始转发，此时帧的其余部分可能还在输入。这种方式降低了帧通过网桥的延迟，也降低了网桥需要缓冲的帧数。这种转发方式称为 直通式交换 cut-through switching 或 虫孔路由 wormhole routing。\n不同类型的线缆都可以连接到一个网桥上；各个端口上的线路可以以不同的速度运行，甚至可以是不同的网络类型。网桥内部有缓存，如果需要发送的信道忙，或者其速度慢于发送方的速度，网桥就会缓存这些帧，等到合适的时机再发送。当然，网桥也有可能因为缓冲空间耗尽而不得不丢弃帧。\n\n为了提高效率，我们也可以让网桥的每个接口独立地连接一个站点；上图展示了除了仍有一个 Hub 以外其他的站点都直接连接在了网桥上。对于每个端口，如果它连接的是全双工的点到点链路，那么它就不再需要 CSMA/CD 等冲突处理算法，因为它不会发生冲突。\n\n冗余链路 redundant links / parallel links\n\n\n\n\n\n为了提高可靠性，网桥之间可以使用冗余链路，防止在一条链路出现故障时两边不会无法联系。\n\n\n但是，这样的冗余引入了拓扑环路。考虑这样的情形：如上图，刚开始，B1 和 B2 的哈希表都是空的。此时 A 给 B1 发送了一帧 F0，B1 将帧从它的所有端口发送了出去，但是由于它到 B2 有两条链路，因此它在这两条链路上分别发送了帧 F1 和 F2。此时 B2 收到了这两个帧，并不知道这两个帧是同一个帧的副本，因此它分别对这两个帧进行 flooding；这样就会导致 F1 的副本从 F2 的链路被发回 B1，F2 的副本从 F1 的链路发回 B1，从此造成这个循环无线进行下去。\n\n\n解决这种问题的方法是生成树算法 Spanning Tree Algorithm；我们通过不使用一些链路让图简化成一个无环的连通结构，即生成树。\n\n\n\n\n\n这种算法的流程是这样的：每个网桥周期性地从它的所有端口广播一个配置信息 configuration message，同时处理来自其他网桥的信息。这些信息不会被转发。首先，全体网桥必须选择一个网桥作为生成树的根。这一选择是通过在自己的配置消息中包含一个基于 MAC 地址的标识符；网桥选择具有最低标识符的网桥作为生成树的根；通过足够的消息交换，所有网桥都将同意这个根。下面，我们选择所有与根直接连接的网桥，它们到根的最短路径都是一跳。此后，我们每次选择上一次选出的网桥通过一跳可以到达的未被选中的所有网桥，直到全部网桥都被选中。如果过程中两个或多个网桥都试图扩展到一个新的网桥，那么其中标识符最低的那个网桥获得这个新的网桥的扩展权。在过程中，网桥在它们的配置信息中还会包括与根的距离。每个网桥记住它找到的到根的最短路径，然后关闭不属于这条路径的端口。\n\n\n在网络正常操作期间，该算法仍需要继续运行，以便自动检查拓扑结构的变化，并更新生成树。生成树算法随后被标准化为 IEEE 802.1D。\n\n\n讨论\n\n\n\n\n\n考察上图这种情况发生冲突的可能。容易发现，此时 ABC 三个站以及网桥的端口 1 之间是有可能互相冲突的；DEFG 和网桥的端口 2 之间也可能冲突。但是，由于网桥的转发作用，这些站被隔离为左右两边，它们之间不会发生冲突。我们称可能会相互冲突的节点的集合称为 冲突域 collision domain。可以看到，网桥也有隔离冲突域的作用；连接在网桥同一端口上的所有站属于一个冲突域。\n\n\n网桥工作在数据链路层。这么说的原因是，网桥会查看 MAC 子层的源和目的地址信息，但不会查看更高层的信息。之所以我们说不同的设备工作在不同的层上，就是因为这些设备根据不同的信息决定如何交换。下图显示了网桥上的协议栈处理。\n\n\n\n\n\n网桥最初被用来连接不同种类的局域网，例如将一个以太网和一个令牌环网连接在一起。但是，由于不同局域网之间的差异，这些工作并不都能完美地完成。不同的帧格式需要重新处理，会引入额外的用时和新的错误可能。有些帧也可能过大无法转发因而不得不丢弃。有的局域网如 WLAN 提供了一些安全机制和服务质量，但以太网等局域网并没有这些概念；因此这些期待也不能得到保证。因此，线代网桥一般都工作在一种网络类型上，连接不同类型网络的责任交给路由器来完成。\n\n\n\n\n\n交换机性能上的优越性，除了在隔离冲突域甚至在点对点、全双工的情况下消除冲突的可能之外，也在于其较高的并发性。端口 1 向端口 2 发送的帧和端口 3 向端口 4 发送的帧可以被互不影响地并行发送出去；这是集线器所不能做到的。\n\n\n交换式以太网 Switched Ethernet\n\n交换机 switch 是现代网桥的另一个称呼；它是交换式以太网的核心。现在的以太网交换机都是全双工、点对点的，因此冲突不可能发生，也不再需要 CSMA/CD 算法了。如下图所示，以太网交换机仍然可以连接集线器，集线器的各个端口希望发送的消息通过竞争后送达以太网交换机；但以太网对此并不需要知情。不过由于交换机的价格在不断下降，传统的集线器也渐渐成为历史。\n\n\nVLAN, Virtual Local Area Network\n\n在关于网桥的讨论中，我们讨论了同一组织的多个 LAN 互相连接的必要性。另外我们也应注意到，同一组织的多个 LAN 也可能发挥不同的作用因而有不同的需求。例如，从 安全性 出发，有的 LAN 部署着 Web 服务器供其他计算机访问，但有的 LAN 存储着不应流传到组织外的信息；又如不同的 LAN 可能有不同的 负载，但诸如用于实时通讯的 LAN 可能不愿意分享它的带宽等。因此，我们在一个组织中也想要维护若干不同的 LAN。但是，我们希望将物理拓扑与逻辑拓扑分离开，这样就能避免由于人事变动或者某个员工更换办公室等情况下导致需要频繁更改线路的物理结构等情况，提高网络的灵活性。因此我们希望能够有一种技术，通过逻辑而不是物理的层面划分 LAN。因此我们提出 VLAN。\n\nVLAN 基于 VLAN-aware switches，我们用不同的颜色标识不同的 VLAN，例如在上面这个图中有白色 W 和灰色 G 两个 VLAN。当一个来自灰色端口的帧发送给交换机时，它将这一帧转发给所有标记为 G 的端口。需要注意的是，一个端口可能被标记为多个颜色。这样简单的思路可能带来一些问题。例如，来自图中 Hub 的帧连接在 B2 一个标为 GW 的端口，那么交换机应当如何转发这一帧？类似地，如果 B1 收到了来自 B2 的一个帧，又应该如何转发？我们可以认识到，为了解决这些问题，我们必须传递一些附加的信息。\n我们希望 VLAN 使用在以太网上，但是以太网的帧结构没有什么空闲的字段可供我们附加一个帧的 VLAN 信息。因此一个新的帧结构被提出了，发表于 IEEE 802.1Q 标准中；同时为了适应这个帧结构，帧长的上限被调整到了 1522 字节：\n\n在讨论这个帧结构的细节之前，我们首先需要明确的是，在这种标准下 VLAN-aware 的和传统的交换机和计算机可以比较好地并存。这一特性的实现方式是，在任一路径上的首个 VLAN-aware 设备负责添加上 VLAN 的额外字段，路径上最后一个这样的设备负责将额外字段删除。因此，只有 VLAN-aware 的设备会看到这些额外的字段：\n\n\n\nVLAN protocol ID (2 Bytes), always has the value 0x81002. VLAN Identifier (12 bits), the color(Pri 5 bits, CFI 1 bit 与 VLAN 无关)\n\n\n颜色按端口为单位划分。With 802.1Q, frames are colored depending on the port on which they are received. For this method to work, all machines on a port must belong to the same VLAN, which reduces flexibility.\n用高层协议决定颜色。Additionally, the bridge can use the higher-layer protocol to select the color. In this way, frames arriving on a port might be placed in different VLANs depending on whether they carry IP packets or PPP frames.\n其他例子：用 MAC 地址决定颜色。Other methods are possible, but they are not supported by 802.1Q. As one example, the MAC address can be used to select the VLAN color. This might be useful for frames coming in from a nearby 802.11 LAN in which laptops send frames via different ports as they move. One MAC address would then be mapped to a fixed VLAN regardless of which port it entered the LAN on.\nQ: 计网教材第四章中讲解的VLAN是不是就是实现了一种组播的效果？那为什么不用组播MAC地址实现呢？又，MAC地址的组播是怎么实现的？A: (by @陈宇) VLAN 和组播 MAC 地址是出于完全不同的目的而设计的。VLAN：由交换机控制，将属于不同 VLAN 的主机进行 网络隔离，所有数据包只在 VLAN 内部互通，不同的 VLAN 之间的数据包是不互通的。组播 MAC 地址：虽然名义上划分了不同的组，但带有组播 MAC 地址的包实际上会被转发给同一内网下 所有主机，无论它们是否属于这个组。所有的主机需要 自己决定收不收这些包。这就无法防止有人故意窃听不属于自己的包，也无法防止有人向其它组恶意发送数据包，其安全性不如 VLAN。因此，VLAN 不是组播，VLAN 的目的是隔离和安全性，而不是为了更方便地在组内传输数据。组播也不能代替 VLAN。\n\nWLAN\n\n\n一些问题\n\n\n无线通信系统通常不能检测出正在发生的冲突，因为它收到的信号比发出的信号微弱得多。无线通信系统的传输范围也有限，因此一个站发出的信号可能不能到达其他所有站；这也会引起下面两种问题：\n\n\n隐藏终端问题 hidden terminal problem如下图 (a)，如 C 想要给 B 发送数据，实际上此时 A 正在给 B 发送数据；但由于 C 在 A 的无线传播距离之外，并没有监听到 A 发送的信号，因此它发送出数据并在 B 处与 A 的数据冲突，双方发送失败。The problem of a station not being able to detect a potential competitor for the medium because the competitor is too far away.\n\n\n暴露终端问题 exposed terminal problem如下图 (b)，B 正在给 A 发送消息；此时 C 试图给 D 发送消息，但是它侦听到了来自 B 的信号，认为此时应该等待。而事实上，此时 C 给 D 发送信号并不会受到干扰；因此这种等待引发了无意义的时延。\n\n\n\n\n\n这两个问题的根本原因在于，发送端只能知道发送处是否有其他无线电信号；但是实际上影响信号接受结果的是接收端附近有无其他无线电信号干扰。在有线通信中，由于不存在传播范围这个限制，这两个概念是等同的；但是在无线通信中只要接收方互不干扰，多个传输可以同时发生。我们也应当利用这种并发性。\n\n\n冲突避免多路访问 MACA, Multiple Access with Collision Avoidance\n\nA 想要给 B 发送数据前，先发送一个 RTS, Request to Send，并在其中包含目标 B 和想要发送的数据帧的长度；B 在收到这个 RTS 后，回复一个 CTS, Clear to Send，其中也包含从 RTS 中得知的这个长度；A 在收到 CTS 后开始传输。需要注意的是，A 的传播范围内的所有站都会听到这个 RTS；听到 RTS 的站就会得知：它们离 A 足够近，因此为了避免与 A 收到的 CTS 发生冲突，它必须保持沉默，直到 A 开始发送信息。同样的，听到 CTS 的所有站都将会知道：在未来的一段时间（可以从 CTS 中的长度推测）内，它们必须保持沉默，否则就会与 B 收到的信息发生冲突。\n\n\nIEEE 802.11\n\n\nArchitecture, Protocol Stack &amp; Phy Layer\n\n\n\n\n\n\n\n\nU-NII：无需许可的国家信息基础建设\n\n\n使用的频带。All of the 802.11 techniques use short-range radios to transmit signals in either the 2.4-GHz or the 5-GHz ISM (Industrial, Scientific, Medical) frequency bands, which are unlicensed and hence freely available to any transmitter willing to meet some restrictions, such as radiated power of at most 1 W (though 50 mW is more typical for wireless LAN radios).The 2.4-GHz band tends to be more crowded than the 5-GHz band, so 5 GHz can be better for some applications even though it has shorter range due to the higher frequency.\n\n\n速率自适应。All of the transmission methods also define multiple rates. The idea is that different rates can be used depending on the current conditions. If the wireless signal is weak, a low rate can be used. If the signal is clear, the highest rate can be used. This adjustment is called rate adaptation. Since the rates vary by a factor of 10 or more, good rate adaptation is important for good performance. Of course, since it is not needed for interoperability, the standards do not say how rate adaptation should be done. 速率越低就可以用越好的调制方法。\n\n\nMAC Sublayer Protocol\nCSMA/CA\n\n无线电几乎总是半双工的，所以做不到错误检测。因此，802.11 尝试使用协议 CSMA/CA (CSMA with Collision Avoidance) 来避免冲突。This protocol is conceptually similar to Ethernet’s CSMA/CD, with channel sensing before sending and exponential back off after collisions. However, a station that has a frame to send starts with a random backoff (except in the case that it has not used the channel recently and the channel is idle)\n发送前侦听。The station waits until the channel is idle, by sensing that there is no signal for a short period of time (called the DIFS), and counts down idle slots, pausing when frames are sent.\n确认。If the frame gets through, the destination immediately sends a short acknowledgement. Lack of an acknowledgement is inferred to indicate an error, whether a collision or otherwise.\n\n和以太网的区别。1. 以后退开始。 Starting backoffs early helps to avoid collisions. This avoidance is worthwhile because collisions are expensive, as the entire frame is transmitted even if one occurs.2. Acknowledgements are used to infer collisions because collisions cannot be detected.\nThis mode of operation is called DCF (Distributed Coordination Function) 分布式协调 because each station acts independently, without any kind of central control. The standard also includes an optional mode of operation called PCF (Point Coordination Function) in which the access point controls all activity in its cell. However, PCF is not used in practice because there is normally no way to prevent stations in another nearby network from transmitting competing traffic.\n\nVirtual channel sensing\n\n802.11 defines channel sensing to consist of both physical sensing and virtual sensing. Physical sensing simply checks the medium to see if there is a valid signal. With virtual sensing, each station keeps a logical record of when the channel is in use by tracking the NAV (Network Allocation Vector). Each frame carries a NAV field that says how long the sequence of which this frame is part will take to complete. Stations that overhear this frame know that the channel will be busy for the period indicated by the NAV, regardless of whether they can sense a physical signal.\n\nHowever, while RTS/CTS sounds good in theory, it is one of those designs that has proved to be of little value in practice.1. It does not help for short frames or for the AP.2. It does not help with exposed terminals as MACA did, only with hidden terminals. 因为要等到 ACK 结束。Most often there are few hidden terminals, and CSMA/CA already helps them by slowing down stations that transmit unsuccessfully\n\n一些其他机制\n\n\nReliability无线网络环境嘈杂，需要增加传输成功的概率\n\n\nlower the transmission rateSlower rates use more robust modulations that are more likely to be received correctly for a given signal-to-noise ratio. If too many frames are lost, a station can lower the rate. If frames are delivered with little loss, a station can occasionally test a higher rate to see if it should be used. (Rate adaption)\n\n\nsend shorter frames如果每个 bit 出错概率一致，帧越短则无错发送的概率越大1. reducing the maximum size of the message that is accepted from the network layer2. 802.11 allows frames to be split into smaller pieces, called fragments, each with its own checksum. The fragment size is not fixed by the standard, but is a parameter that can be adjusted by the AP. The fragments are individually numbered and acknowledged using a stop-and-wait protocol. Once the channel has been acquired, multiple fragments are sent as a burst. They go one after the other with an acknowledgement (and possibly retransmissions) in between, until either the whole frame has been successfully sent or the transmission time reaches the maximum allowed.\n\n\nSaving Power移动无线设备需要考虑电池的寿命\n\n\nBeacon Frames. Beacons are periodic broadcasts by the AP (e.g., every 100 msec). The frames advertise the presence of the AP to clients and carry system parameters, such as the identifier of the AP, the time, how long until the next beacon, and security settings. Clients can set a power-management bit in frames that they send to the AP to tell it that they are entering power-save mode. In this mode, the client can doze and the AP will buffer traffic intended for it. To check for incoming traffic, the client wakes up for every beacon, and checks a traffic map that is sent as part of the beacon. This map tells the client if there is buffered traffic. If so, the client sends a poll message to the AP, which then sends the buffered traffic. The client can then go back to sleep until the next beacon is sent.\n\n\nAPSD (Automatic Power Save Delivery). The AP buffers frames and sends them to a client just after the client sends frames to the AP. The client can then go to sleep until it has more traffic to send (and receive). This mechanism works well for applications such as VoIP that have frequent traffic in both directions. For example, a VoIP (Voice over Internet Protocol) wireless phone might use it to send and receive frames every 20 msec, much more frequently than the beacon interval of 100 msec, while dozing in between.\n\n\nQuality of Service\n\n\nWhen the VoIP traffic competes with peer-to-peer traffic, the VoIP traffic will suffer. It will be delayed due to contention with the high-bandwidth peer-to-peer traffic, even though the VoIP bandwidth is low. These delays are likely to degrade the voice calls. To prevent this degradation, we would like to let the VoIP traffic go ahead of the peer-to-peer traffic, as it is of higher priority.扩展了 802.11，作为 802.11e 被引入。\n\n\n\n\n\nSIFS, Short InterFrame Spacing - ACK/RTS/CTS/Burst of fragmentsAIFS, Arbitration IFS - 特别设定的较高或者较低优先级（一般有四个）DIFS, DCF (Distributed Coordination Function) IFS - RegularEIFS, Extended IFS - Bad frame recovery\n\n\nTXOP, Transmission Opportunity\n\n\nThe original CSMA/CA mechanism let stations send one frame at a time. This design was fine until the range of rates increased. With 802.11a/g, one station might be sending at 6 Mbps and another station be sending at 54 Mbps. They each get to send one frame, but the 6-Mbps station takes nine times as long (ignoring fixed overheads) as the 54-Mbps station to send its frame. This disparity has the unfortunate side effect of slowing down a fast sender who is competing with a slow sender to roughly the rate of the slow sender. For example, again ignoring fixed overheads, when sending alone the 6-Mbps and 54-Mbps senders will get their own rates, but when sending together they will both get 5.4 Mbps on average. It is a stiff penalty for the fast sender. This issue is known as the rate anomaly.\n\n\nWith transmission opportunities, each station gets an equal amount of airtime, not an equal number of frames. Stations that send at a higher rate for their airtime will get higher throughput.\n\n\nFrame Structure\n\n\n\n\n\nFrame Control- Protocol Version, temp. 00- Type, Data (Fig., 10) / Control / Management- Subtype, e.g. RTS / CTS- To / From DS (Distributed System)- More frag., More fragments- Retry, retransmission- Power management: sender is going into power-saving mode- More data, More frames- Protected, frame body has been encrypted- Order, higher layer expects the sequence of frames to arrive strictly in order\n\n\nDuration - NAV (μs), used in all types of frames.Address - 1. Receiver Addr, 2. Transmitter Addr, 3. Destination Addr.Sequence - 4 for fragments and 12 for frames.Data - the payload, up to 2312 bytes. The first bytes of this payload are in a format known as LLC (Logical Link Control). This layer is the glue that identifies the higher-layer protocol (e.g., IP) to which the payloads should be passed.Check sequence - 32 bit CRC\n\n\n(src)\n\n\nManagement Frame 的格式与此相同；Control Frame 只有 Frame Ctrl, Duration, Address1, CRC 字段。\n\n\nServices\n\n\n暂时懒得学……\n\n"},"课程笔记/计算机网络/05-网络层":{"slug":"课程笔记/计算机网络/05-网络层","filePath":"课程笔记/计算机网络/05 网络层.md","title":"网络层","links":[],"tags":[],"content":"网络层 Network Layer\n主要任务\n链路层完成的是在一个网络中如何将帧从一个结点传输给另一个结点；或者说是从线路的一边传递到另一边。而网络层则考虑如何将数据包从发送方一路送到接收方[host to host]。在这个过程中，数据包可能会跨越不同的网络（这也是 inter-net 的名字来源）。\n\n使用一些中间设备（或称中间系统、中继系统）可以将两个计算机网络连接起来。\n\n我们之前学到的物理层的中继器 (Repeater)、集线器 (Hub)，以及链路层的网桥 (Bridge)、交换机 (Switch) 都属于中间设备。\n我们之前也提到，虽然网桥最初设计被用来处理异构网络之间的互联，但最终这部分任务被留给了网络层；即，我们认为上述设备只是扩大了网络，并没有连接不同的网络。\n\n\n因此我们引入网路层的中间设备：路由器 (Router)\n\n它负责连接不同的网络，为到来的跨网络的数据包根据其目的地找到一条路径，并对应地将其转发。\n\n\n在更高层还有网关 (Gateway) 这一中间设备。由于一些历史原因，路由器有时也被称为网关。\n\n我们说，网络层是处理端到端数据传输的最底层。这是因为，链路层考虑的只是将数据从网络上的一个结点发给另一个结点，而我们实际上需要做的是将一个进程的数据传递给另一个进程。如下图所示，发送方 H1 上的进程 P1 将信息传递给 ISP（网络应用提供商）提供的设备 A，ISP 的路由器为数据包找到一条通路并转发给接收方的路由器 F，最终由接收方 H2 的进程 P2 接受。网络层首先完成了从主机到主机的数据传输。\n具体的过程是， A host with a packet to send transmits it to the nearest router, either on its own LAN or over a point-to-point link to the ISP. The packet is stored there until it has fully arrived and the link has finished its processing by verifying the checksum. Then it is forwarded to the next router along the path until it reaches the destination host. This mechanism is store-and-forward packet switching.\n除了将异构网络互联、通过路由和转发实现任意网络结点间的数据传输以外，网络层还关注拥塞控制 (congestion control) 和服务质量 (quality of service) 等话题。\n提供给传输层的服务\n正如在数据链路层中讨论的那样，我们在网络层也需要考虑提供面向连接的还是无连接的服务。\n\n以 Internet community 为代表的一方认为，无论如何设计网路，本质上它就是不可靠的，因此网络服务应该是无连接的。\n以电话公司为代表的另一方认为，网络应该提供可靠的面向连接的服务。\n实际上，无连接服务获得了成功。但是 Internet 也渐渐朝着面向连接的特性进化，因为服务质量变得越来越重要了。与此相关的两个面向连接技术的例子是 MPLS 和 VLAN。我们在链路层已经讨论过了 VLAN，在网络层中我们会讨论 MPLS。\n\n但无论如何，提供给传输层的服务应当屏蔽不同的路由器技术，以及网络上的路由器数量、类型和拓扑关系。传输层可用的网络地址也应当有一套可以跨越 LAN 甚至 WAN 的统一编址方案。\n无连接服务的实现：数据报网络 datagram network\n\n我们在物理层讨论了三种不同的交换方式，包交换 packet switching 是其中一种。在这里，我们进一步考察包交换的实现方式。我们将每个数据包独立注入网络中，并且为每个数据包独立路由（即，为每个数据包分别进行一次寻路）。在这种方式中，我们称数据包为 数据报 datagram，这种网络称为 数据报网络 datagram network。\n这种方式中，每个数据报的首部需要保存其目的地址；每个路由器根据该地址进行寻路。\n\n\n面向连接服务的实现：虚电路网络 virtual-circuit network\n\n虚电路网络也是包交换的一种实现方式。虚电路不希望给每个数据包选择一条路径，而希望建立一个连接，选择一条固定的路径；所有需要从这个连接上通过的流量都使用这条路径。\n虚电路之所以是“虚”的，是因为这条电路不是专用的，只是逻辑上的。一条链路上可能有多个虚电路通过，一对 host 之间也可能存在多条不同的虚电路。\n如下图所示，每个连接有一个连接标识符 connection identifier；路由器 A 的表中的第一行表示：如果有一个来自 H1 的、标识符为 1 的包，那么 A 将其转发给 C，且标识符为 1。这种方式中，每个数据报不需要保存目的地址，而是保存 connection identifier。\n\n\nMPLS (MultiProtocol Label Switching)\n\n\n\n数据报网络和虚电路网络的比较\n\n\nOne trade-off is setup time versus address parsing time. Using virtual circuits requires a setup phase, which takes time and consumes resources. However, once this price is paid, figuring out what to do with a data packet in a virtual-circuit network is easy: the router just uses the circuit number to index into a table to find out where the packet goes. In a datagram network, no setup is needed but a more complicated lookup procedure is required to locate the entry for the destination.\nA related issue is that the destination addresses used in datagram networks are longer than circuit numbers used in virtual-circuit networks because they have a global meaning. If the packets tend to be fairly short, including a full destination address in every packet may represent a significant amount of overhead, and hence a waste of bandwidth.\nVirtual circuits have some advantages in guaranteeing quality of service and avoiding congestion within the network because resources (e.g., buffers, bandwidth, and CPU cycles) can be reserved in advance, when the connection is established. Once the packets start arriving, the necessary bandwidth and router capacity will be there. With a datagram network, congestion avoidance is more difficult.\n事务处理系统适合数据报，长期的流量连接适合虚电路（手工建立，持续使用）。\nVirtual circuits also have a vulnerability（脆弱性） problem. If a router crashes and loses its memory, even if it comes back up a second later, all the virtual circuits passing through it will have to be aborted. In contrast, if a datagram router goes down, only those users whose packets were queued in the router at the time need suffer (and probably not even then since the sender is likely to retransmit them shortly). The loss of a communication line is fatal to virtual circuits using it, but can easily be compensated for if datagrams are used.\nDatagrams also allow the routers to balance the traffic throughout the network, since routes can be changed partway through a long sequence of packet transmissions.\n\n路由算法\n路由器的功能是 路由 routing 和 转发 forwarding。路由是指根据特定的路由算法构造出路由表，同时不断进行更新维护；而转发是指根据到来的数据包的内容查询路由表并从合适的端口转发出去。\n路由算法\n\n\n虚电路网络只在建立一条新的虚电路时才需要做路由决策，因此这种情形也称为 会话路由 session routing。\n\n\n路由算法可以按是否根据当前网络的流量和拓扑结构调整路由决策分为两大类\n\n\n静态路由 static routing / 非适应性算法 nonadaptive algorithm。简便，开销较小，在拓扑变化不大、路由选择非常清楚的场合很有用；但无法响应故障。\n\n\n动态路由 dynamic routing / 适应性算法 adaptive algorithm。能够改善网络性能，有助于流量控制，收到故障的影响较小。但是算法较为复杂，会增加网络负担。另外如果变化太快容易引起震荡，变化过慢会影响路由的一致性。在 where they get their information (e.g., locally, from adjacent routers, or from all routers), when they change the routes (e.g., when the topology changes, or every ΔT seconds as the load changes), and what metric（度量标准）is used for optimization (e.g., distance, number of hops, or estimated transit time) 等方面有多种选择。\n\n\nSink tree is not necessarily unique\n\n\nShortest Path\n\n\nDijkstra’s Algorithm\n\n\nFlooding\n\nDistance Vector Routing / Bellman-Ford Routing\n\n\nThe settling of routes to best paths across the network is called convergence (收敛). Although Distance Vector Routing converges to the correct answer, it may do so slowly. In particular, it reacts rapidly to good news, but leisurely to bad news.\n(a) After init, A started; (b) After init, A halted\nAt the first packet exchange, B does not hear anything from A. Fortunately, C says “Do not worry; I have a path to A of length 2.” Little does B suspect that C’s path runs through B itself. …However, none of these heuristics work well in practice despite the colorful names. The core of the problem is that when X tells Y that it has a path somewhere, Y has no way of knowing whether it itself is on the path.\nProblems: 1. 发的东西太长了，占带宽； 2. converge 太慢了\n\nLink State Routing\n\n基本过程：与邻居交流，了解其网络地址和交流成本；将这些信息构造成数据包，发给其他所有路由器，也接收其他路由器的数据包；根据这些数据包在本地构造出整个网络的拓扑，并用 Dijkstra’s algorithm 算出到每个结点的最短路。\n\nUse an artificial node N. One designated router on the LAN is selected to play the role of N in the routing protocol\n\n\n\n\n\n\n\n\nHierarchical Routing\n\n拥塞控制\n服务质量\n网络互联\n不同协议的路由策略\n\n具体如何在异构网络之间转发呢？有下面两种思路：\n\n\n\nPacket Fragmentation\n\nEach network imposes some maximum packet size: MTU, Maximum Transmission Unit. 由于路由，源端很难得知路径上的 MTU。\n\n问题：(a) 拆分重组和重复工作、不能分别路由，以及 (b) 判断结尾、额外开销、错误率提升。Nontransparent fragmentation:\n\n\n\nInternet Protocol\nIPv4\n\n\nHeader (20-byte fixed + options) + Body / Payload\n\n\nHeader 格式\n\n\n\n传输顺序。 The bits are transmitted from left to right and top to bottom, with the high-order bit of the Version field going first. (This is a “big-endian” network byte order. On little-endian machines, such as Intel x86 computers, a software conversion is required on both transmission and reception.) In retrospect, little endian would have been a better choice, but at the time IP was designed, no one knew it would come to dominate computing.\n\n\nVersion - 4 (0100) for IPv4\n\n\nIHL (Internet Header Length) - 4 bits, 5~15, in 32-bit words. E.g. IHL = 5 表示头部有 5*32 bits = 20 Bytes，即 Option 字段长度为 0。因此 Option 字段最多 40 Bytes\n\n\nTotal length - 16 bits, in Byte, Head + Body, ⇐65536\n\n\nIdentification - 16 bits, all the fragments of a packet contain the same Identification value.\n\n\nUnused DF (Don’t Fragment) - can be used in path MTU discovery MF (More Fragments) - 0 for the last fragment\n\n\nFragment offset - All fragments except the last one in a datagram must be a multiple of 8 bytes\n\n\nTTL - 设计为按秒计，现在按 hop 计。When it hits zero, the packet is discarded and a warning packet is sent back to the source host. This feature prevents packets from wandering around forever, something that otherwise might happen if the routing tables ever become corrupted\n\n\n\n\n\nChecksum - 之前讨论过的 Internet Checksum，16 bits 划分。注意每一跳后 TTL 都会变所以 the Header checksum is assumed to be zero upon arrival 然后重新算一遍。\n\n\n\n\n\nThe Options field was designed to provide an escape to allow subsequent versions of the protocol 1) to include information not present in the original design, 2) to permit experimenters to try out new ideas, and to 3) avoid allocating header bits to information that is rarely needed. The options are of variable length. Each begins with a 1-byte code identifying the option. Some options are followed by a 1-byte option length field, and then one or more data bytes. The Options field is padded out to a multiple of 4 bytes.\n\n\n\n\n\nIPv4 地址\n\n\nInternet 上的每个 host 和 router 都有 IP 地址。需要注意的是，每个 IP 地址指向的不是一台机器，而是一个 network interface；例如 router 有多个接口，因此每个接口都有一个 IP 地址。\n\n\nIP 地址具有层次性。Each 32-bit address is comprised of a variable-length network portion in the top bits and a host portion in the bottom bits. The network portion has the same value for all hosts on a single network, such as an Ethernet LAN. This means that a network corresponds to a contiguous block of IP address space. This block is called a prefix.Subnet mask. Since the prefix length cannot be inferred from the IP address alone, routing protocols must carry the prefixes to routers. Sometimes prefixes are simply described by their length, as in a “/16” which is pronounced “slash 16”.IP addresses are written in dotted decimal notation.\n\n\n\n\n\n\n\n\nClassful Addressing\n\n\n\n\n\n\n\n\n0.0.0.0：As source addr when booting, this host doesn’t know its IP addr and trying to acquire one (DHCP); As dest addr / socket listening: all, including 127...127...: Loopback. Not actually on the link.\n\n\nSubnet\n\n\n\n\n\n\n\n\nOutside the network, the subnetting is not visible, so allocating a new subnet does not require contacting ICANN or changing any external databases.\n\n\nCIDR, Classless Inter-Domain Routing\n\n\n\n\n\n\n\n\nNAT\n\n\n\n\n\n\n\n\n\n\n\nIPv6\n\n\n\n\nInternet Control Protocols\n\n\nIn addition to IP, which is used for data transfer, the Internet has several companion control protocols that are used in the network layer.\n\n\nARP\n\n\n\n\n\nDHCP\n\n\n\n\n\nICMP\n\n\n\n\n\n路由协议\n互联网路由\n\n问题：不同的路由算法、不同的度量方式、对外保护网络内部细节、太大\n\nWithin each network (OR AS, Autonomous System), an intradomain or interior gateway protocol is used for routing. (“Gateway” is an older term for “router”.) Across the networks that make up the internet, an interdomain or exterior gateway protocol is used. The networks may all use different intradomain protocols, but they must use the same interdomain protocol.\n\nRIP, Routing Information Protocol\n\n一种 Interior Gateway Protocol，基于 Distance Vector Routing，用 hop 计量距离。规定一条路径最多包含 15 个 router（即 15 个 hop），从而防止环路；可见只适用于小型网络。每 30s 在 相邻 的路由器之间交换一次信息，即自己当前的路由表，以维护路由表。\n是一个应用层协议，需要借助 UDP，端口号是 520。\n\nOSPF, Open Shortest Path First\n\n也是一种 Interior Gateway Protocol，直接使用 IP Packet 发送，protocol 字段值为 89。Open 是指该协议发布在公开文献中。\n支持根据 IP Packet 的不同 services 使用不同的路由方式，从而更好地传输实时流量。 支持多种距离度量，支持多路径之间的负载平衡，支持层次系统，提供一定安全性，支持隧道。\n每个 AS 内部也有层次结构：有一个 Backbone Area；其他任意两个区域之间可以通过 Backbone Area 互达。\n基于 Link State Routing。\n\n\nBGP, Border Gateway Protocol\n\nInternet 使用的 Exterior Gateway Protocol。每个 AS 需要选择至少一个 router 作为发言人。基于 Distance Vector Routing；但实际上不一定是最优的，因为考虑优先使用对等网络以及各种限制等实际的政策原因，同时网络太大也不一定能找到最佳。另外还维护到目的地的路径，因此叫 Path Vector Protocol。\n应用层协议，基于 TCP，端口号 179。\n\nIP 组播\n移动 IP\nICMP 的 ROUTER ADVERTISEMENT/SOLICITATION 消息使得主机可以找到附近的路由器。当主机发现路由器不一样的时候，就知道自己跑了。\n主机在新的网络 (foreign / remote agent) 通过 DHCP 获得一个新的 IP 地址，然后告诉自己的老家 (home agent) 自己现在在哪。\nHome agent 需要拦截发给这个跑路了的主机的包，方法是当路由器通过 ARP 询问跑路主机持有的 IP 对应什么 MAC 地址时，回答自己的 MAC 地址。这就是 ARP agent。为了快速更新，home agent 也可以发 Gratuitous ARP（无故 ARP），问跑路主机的 IP 对应的 MAC 并自己回答。\n剩下的步骤如下图："},"课程笔记/计算机网络/06-传输层-Transport-Layer":{"slug":"课程笔记/计算机网络/06-传输层-Transport-Layer","filePath":"课程笔记/计算机网络/06 传输层 Transport Layer.md","title":"传输层 Transport Layer","links":["tags/待解决"],"tags":["待解决"],"content":"传输层的功能\n\n传输层提供端到端的通信；也提供面向连接和无连接的两种服务。\n也有观点认为，网络层提供的并不是真正的端到端（即，进程到进程）的服务，而只是主机到主机的服务，因为它并没有办法找到目标的进程。\n但传输层通过端口来标识应用进程，从而真正实现进程之间的通信。\n\n在网络层已经有了面向连接和无连接的两种通信方式的情况下，为什么传输层还要提供这两种服务呢？\n\n因为网络层提供的服务更多是由 ISP 决定的；主要运行在路由器上\n但传输层的代码运行在用户自己的机器上，因此用户可以在这一层选择协议来提高网络的服务质量。\n\n传输层是面向通信部分的最高层，起着承上启下的作用。每个传输服务会给用户提供一组接口，用户（或者说应用）只需要调用这些接口就能调用相应的功能了。传输服务之于网络服务就像编程语言之于汇编语言：当切换不同的网络服务时，只需要切换一种传输服务到网络服务的库就好了；就像在新的架构上运行原来的 C 语言程序时，只需要换一个编译器就好。同时，网络服务就像汇编语言一样被用的比较少；但传输服务就像高级语言一样会被很多程序员使用。因此，传输服务的接口一定要更加方便、简单。\n怎么实现端到端的通信呢？SAP: Service Access Point. Transport SAP 即 Port，用来指定进程，有 16bit，可以表示 65536 个不同的端口号。\n传输层传输的单位称为 segment。\n\nUDP\nUDP, User Datagram Protocol 是一个无连接的非可靠传输层协议。\n它在 IP 之上只提供 2 个附加服务：\n\n多路复用\n对数据的错误检查（IP 只检查头部的错误）。\n\n\n它不进行流量控制、拥塞控制和重传，所有维护可靠性的工作由应用层完成；它只是提供一个与 IP 协议的接口。\n\n\n\nUDP length 是包含 UDP Header (8 Bytes) 和数据在内的总字节数。最小是 8，即只有头部；最大是 65515，这是 IP 的限制。\n\n\nUDP checksum 是可选的；如果不想检查就写全 0。其算法与 IP checksum 类似，具体参与运算的包含一个 12 Bytes 的 IPv4 pseudoheader、UDP checksum 暂时置零的 UDP header 以及数据部分。\n\n如果数据部分的长度不是 16 bits 的整倍数，则在末尾补 0 用于计算；但补的 0 不会被发送出去。\n\n\n\n\n\n首部\n伪首部\n\n\n\n\n其中，IPv4 pseudoheader 中的长度是和 UDP header 中的长度一致的。同时也可以看到，UDP 在计算时是用到了发送方和接收方的 IPv4 地址的；这有违分层原则。当然，pseudoheader 也有对应的 IPv6 版本。\n\n\nUDP 适合一次性传输较少数据的网络应用，也适合那些可靠性不那么重要但不能容忍延迟的应用。\n\nDNS域名系统\nSSDP简单服务发现协议\n\nRTP 实时传输协议[不怎么考]\n\nRFC3550\n它是一种传输协议，只是碰巧在应用层实现\n\n以数据包形式传输音频和视频\n\n将多个实时数据流复用到单个 UDP 数据包流中。UDP 流可以发送到单个目的地（单播）或多个目的地（多播）。\n\n\n接收方在正确的时间播放音频和视频\n\n\n不保证传递，数据包可能会丢失、延迟、损坏等。RTP 流中发送的每个数据包的编号都比其前驱数据包高一个\n\n目的地确定有数据包丢失,可以跳过（视频帧）或插值（音频数据）[没有确认机制]\n\n\n每个 RTP 负载可能包含多个样本，它们可以按应用程序需要的任何方式进行编码。提供一个头字段来指定编码方.\n为每个数据包中的第一个样本关联一个时间戳。这个机制允许目的端进行少量缓冲，并在流开始后的正确毫秒数后播放每个样本。\n\n减少网络延迟变化的影响\n同步多个流\n\n\n\n3个32bits 以及一些可能的扩展\n\nRTCP 实时传输控制协议\nRTP的配套协议\n\n用于处理反馈\\同步和用户界面\n不传输任何媒体样本\n\nTCP\nTCP, Transmission Control Protocol 是为了在不可靠的 IP 层上实现可靠端到端传输设计的。\n它是面向连接的，且只支持一对一的通信（而 UDP 支持一对多、多对一、多对多），提供全双工点到点通信，解决传输的可靠、有序、无丢失、不重复。\n\nTCP 是面向字节流的，而 UDP 是面向报文的。这就是说，UDP Segment 的长度由应用程序传来的数据决定，而 TCP 只将应用程序传来的数据视为无结构的字节流，segment 的长度由协议动态决定。\n设计宗旨是动态适应互联网的特性[差异很大的拓扑、带宽、延迟、数据包大小和其他参数]，并在面对多种故障时具有强大的鲁棒性。\n\n主要的:RFC2018/2581/3168\n基本TCP协议:具有动态窗口大小的滑动窗口协议\nTCP 服务是由发送方和接收方创建的端点（称为sockets）获得的。\n\nEach socket has a socket number (address) consisting of\nthe IP addressing of the host and a 16-bit number local to\nthat host, called a port\n\nConnections are identified by the socket identifiers at both\nends, that is, (socket1, socket2)\n\nTCP Segment\n限制segent大小的两个条件\n\n每个段包括头部必须适配65515字节ip负载(65535-20IP头)\n每个链路都有一个MTU最大传输单元\n\nTCP 的一个关键特性，也是主导该协议设计的特性，是 TCP 连接上的每个字节都有自己的 32 位序列号。\n\n序列号空间是基于字节的，而不是基于段的\n没有任何数据的段是合法的，通常用于确认和控制消息。\n\nsource port和destination port 连接识别器是一个五元组,包括协议[TCP]\\源ip\\源端口\\目的ip\\目的端口\nSequence number - 4B\n\nTCP 是面向字节流的，因此它的 seq# 是以字节计数的。例如一个 segment 的 seq# 是 301，数据长度是 100B，那么这个 segment 就包含了第 301~400 个字节，下一个 segment 的 seq# 就是 401。\n\n\nAck number - 4B\n\n期望收到的下一个 segment 的 seq#。例如收到了上面说的那个 segment，那发回去的 segment 的 ack# 就应该是 401。\n是一个cumulatie acknowledgement累积确认,因为用一个数字概括了接收到的数据\n\nCarries highest in-order sequence number\nNormally a steady advance\n\n\n\n\nTCP header length - 4bits\n\n以 32 bits / 4 Bytes 计数。由于 header 有变长的 offset 字段，因此 header 的长度也是可变的。这一字段也被称作 data offset，因为它作为 header 的长度同时也表示了 segment 中的数据是从哪里开始的；这个 offset 与 IP datagram fragments 中的 offset 不一样。[里面是字的length 比如8字,实际上就是8*4=32Bytes]\n\n\nReserved - 4bits\n\n设计时用于在发现协议出现设计问题后补充使用；本来有 6 位，只用掉了 2 位，说明设计的不错。目前应当置 0。\n\n\nCWR, Congestion Window Reduced; ECE - Explicit Congestion Notification Echo：\n\n当 TCP 接收端得知网络拥塞[表现为丢包]后，就设置 ECN-Echo (ECE) 从而显式告知发送端网络拥塞，需要放慢发送速率；\n当 TCP 发送端收到 ECE 后就设置 CWR 从而告诉接收端已经放慢速率了，不需要再发 ECE 了[一直发送直到接收到CWR已被设置为止]。\n\n\nURG, URGent bit。\n\n可以看到后面还有一个 16 bits 的 Urgent pointer 字段，只有在 URG = 1 时该字段才有效。此时表示该 segment 中有紧急数据，紧急指针用于指示从当前序列号[字节流]开始的字节偏移量，紧急数据位于该位置范围。\n\n例如，假设当前序列号为 1000，如果紧急指针=10，那么此字节流中紧急数据的端点是 1000+10=1010\n\n\n当紧急数据在目的地被接收时，接收应用程序会被中断，以便它可以停止正在进行的任何操作，读取数据流以查找紧急数据。\n紧急数据的结尾被标记，以便应用程序知道何时结束。紧急数据的开始没有被标记。应用程序需要自己判断。\n\n\nACK。\n\nACK = 1 时 ack# 字段才有效,=0时确认字号字段会被忽略。TCP 规定建立连接后所有 segment 的 ACK 都是 1。\n\n\nPSH, push。\n\nPSH = 1 表示接收端在接收到 segment 后应当尽快交付给应用程序，而并不是等到缓冲区满后再向上交付。\n\n\nRST, reset。\n\nRST = 1 表示 TCP 连接中发生严重差错，例如主机崩溃等，需要重置连接。也用于拒绝无效段或拒绝尝试建立连接\n\n\nSYN, synchronize。\n\nSYN = 1 表示这是一个连接请求或者连接接受 segment。\n\nSYN = 1, ACK = 0[表示32位ack没有意义] 说明这是一个连接request segment\nSYN = 1, ACK = 1 说明这是一个连接reply segment。\n\n\n\n\nFIN, finish。\n\nFIN = 1 表示发送方数据已经发送完毕，要求释放传输连接。SYN和FIN的segment都会有序列号,因此能够保证以正确的顺序进行处理\n\n\nWindow size，2 Byte\n\n表示允许对方发送的数据量（TCP 是全双工的）。例如 ack# 是 701，window size 是 1000，就说明允许对方发送 701~1700 这些字节。\n\nWindow size 可以为 0，表示现在不想要；\n之后想要恢复时只需要发送一个同样 ack# 但是 window size 不为 0 的 segment 就行了。\n\n\n\n\nChecksum，2 Byte，计算方法和 UDP 的一样对报头、数据和概念上的伪报头进行校验，只是需要把 UDP 协议号 17 改为 TCP 协议号 6,且校验和是强制性的\nOptions，0~40 Bytes，选项长度可变，最长可扩展到 40 字节以容纳可以指定的最长 TCP 头.\n\n必须是 4 Bytes 的倍数，不足的用 0 补充。\n允许主机规定 MSS, Maximum Segment Size，即允许对方发来的 TCP segment 中 数据 部分的最大长度。否则默认为536字节的负载,即536+20的TCPsegment\nwindow scale option允许发送方和接收方在连接开始时协商window scale factor\ntimestamp option 携带由发送方发送并由接收方回显的时间戳\nsack 选择性确认选项 补充序号确认\n\n\n\nTCP Connection\nexample\n\n\n\n\n\n注意seq跟字节流序列号有关,seq代表的起始字符也要包括进去.如果发送的是nodata的\n开头的syn segment是占seq的\n\n\nEstablishment\n\n三次握手其实就是双方交换 ISN 的过程\n过程\n\n\nSYN segment 不能携带数据,只有报头（即前两次握手），但是要消耗掉 1 个 seq,以便于明确地被确认。\n\nrequest 客户端向服务器发送请求段\n\n初始序列号[每个主机选择的初始序列号会循环使用但是周期很长.这个规则是为了防止延迟的重复数据包]\n\n因为是每个主机单独生成的所以两边的序列号没有任何关系\n\n\nsyn位为1 指示该segment包含客户端使用的初始序列号\n最大段大小:包含在option字段中 [最大数据块限制]\n接收窗口大小:包含在窗口大小字段中[未确认数据限制]\n\n\nreply 服务器发送应答段来响应客户端\n\n前四条同上\n\n\n确认号,客户端发送的request段中的初始序列号+1作为序列号,表示服务器期望从客户端接收的下一个数据字节的序列号\nack位置1 向客户端标名当前段中的确认号字段是有效的\n\n\n\n\n接收reply段之后\n\n通过发送纯确认来确认服务器的响应[不必要,因为如果客户端立即发送数据包,那么就视为已经被确认,全双工连接已建立,所以其实实际上必要的是2次握手]\n\n\n\n\n对于除请求段以外的所有段,ack位始终置为1\n\nSYN flood attack\n\n由于服务端在第 2 次握手时分配了资源，因此有可能受到 SYN 泛洪攻击\n\n[发reply包的时候需要记住自己发出去的seq,以便于后面检查ack是否等于seq+1.]因此恶意发送者可以通过发送一连串 SYN 段并且从不完成连接来占用主机上的资源\n\n解决办法:用SYN cookies 通过加密算法,用自身的一些信息生成序列号.那么序列号+1被返回的时候,就可以通过相同的加密算法生成正确的序列号再来对比.\n\n\n\n\n\n如何寻找相关字段\n\n\n\n在wireshark里可以找到ip头的totallength为34→换算10进制52=ip头20 tcp头32  待解决\n\n\n\n\n\n\n\n\n\n\n\nRelease\n\n\n2-army problem：理论上无法保证一定能成功释放连接。\n假设客户端和服务端之间已经建立了良好的TCP连接,客户端想要终止连接\n\n为了终止连接\n\n客户端向服务单发送FIN segment FIN位设为1\n客户端进入FIN_WAIT_1状态\n客户端等待来自服务端的确认\n\n\n接收到FIN segment之后\n\n服务器释放其接收缓冲区\n服务端向客户端发送确认\n服务器进入CLOSE_WAIT状态\n\n\n客户端收到确认后进入FIN_WAIT_2状态\n\n客户端到服务端的连接已终止,即单向连接已关闭\n由于服务器缓冲区已释放,客户端无法向服务器发送人恩赫数据\n仍然可以从客户端向服务器发送纯确认(无数据)\n服务器到客户端的连接仍然打开,服务器可以向客户端发送数据和确认信息\n\n\n服务器想要关闭与客户端的连接\n\n服务器向客户端发送一个FIN segment\n等待确认\n\n\n接收到FIN segment之后\n\n客户端释放其接收缓冲区\n客户端向服务器发送纯确认(不必须)\n客户端进入TIME_WAIT状态\n\n允许客户端在最终的确认丢失时重新发送,等待结束后,连接就被正式关闭\n\n\n\n\n\n\n\n建模\n\n\nTCP connection management finite state machine. The heavy solid line is the normal path for a client. The heavy dashed line is the normal path for a server. The light lines are unusual events. Each transition is labeled with the event causing it and the action resulting from it, separated by a slash.\n\n可靠传输机制\nTCP Timer Management\nRTO\n\n超时重传theRTO。TCP 发送方维护一个 Time-Out Timer，如果超过超时重传时间 RTO, Retransmission Time-Out 就重新发送这个 segment。值得讨论的问题是 RTO 的设置，TCP 面临着一个根本不同的环境。TCP 确认返回所需时间的概率分布更大且更具变异性,因此RTO的设置和传输层的不同。\n\n[使用动态算法，根据对网络性能的持续测量，不断调整超时间隔.]这里的算法要用基本四则运算,可以用移位寄存器进行实现,很效率.\n\n先算一个SRTT,用历史值和当前值做一个线性加权和,做一个估计的smoothRTT\n再算一个RTTVAR叫往返时间变异,用RTTVAR和SRTT算一个RTO,然后把这个RTO和1sec取最小值\nkarn算法: 不对任何已被重传的segments更新估计值.此外,每次连续重传的时候超时时间都会加倍直到第一次成功通过为止\n\n\n\n\n\nthe persistent timer\n接收方发送一个窗口大小为 0 的确认，告诉发送方等待。之后，接收方更新窗口，但是包含更新的数据包丢失了。现在发送方和接收方各自等待对方做些什么。\n\n当持久计时器超时时，发送方向接收方发送一个探测。对探测的响应给出窗口大小。\n\n如果仍然为0,再次设置持久计时器\n如果非零就可以发送数据\n\n\n\nthe keepalive timer\n当连接长时间空闲时，保活计时器可能会触发，使一方检查另一方是否仍然存在\nthe TIMEWAIT timer\n在关闭时的timewait状态中使用.运行的时间是 twice the maximum packet lifetime,以确保当连接关闭时,创建的所有数据包都已经消失\n流量控制/滑动窗口\n\n\n\n窗口探测使用的计时器是 persistence timer。\n\nThe Silly Window Syndrome\n当数据以大块形式传递给发送 TCP 实体，但接收端的交互式应用程序每次只读取 1 个字节时，就会出现此问题\n\n\nNagle’s Algorithm\n\n减少接收方对网络造成的负载\n减少发送多个短数据包的发送方使用的带宽\n发一块并缓冲其余所有数据,直到第一块被确认之后,在一个tcp段中发送所有缓冲数据,并开始缓冲直到下一个段被确认\n但是不适合交互式游戏而且可能会和延迟确认相互作用导致死锁\n\n\n\nClark’s Solution\n\n强制接收器等待，直到有足够的可用空间，然后通告该空间\n这两种解决方案都是有效的，可以一起使用。目标是使发送方不发送小段，接收方也不请求小段。\n\n\n\n乱序到达问题\n\n接收方将缓冲数据，直到能够按顺序将其传递给应用层。\n只有当已收到确认字节之前的所有数据时，才能发送确认[cumulative acknowledgement累积确认]\n\n如果接收方收到segments0124567,可以确认sement2中最后一个字节及其之前的所有内容.\n当发送方timesout之后,会重新传输段3.因为接收方已经缓冲了4~7,所以收到3之后,它可以确认分段7末尾的所有字节.\n\n\n\n拥塞控制\n\n\n网络层在路由器队列增长过大时检测到拥塞，并尝试对其进行管理，至少通过丢弃数据包来管理。\n\n\n传输层负责从网络层接收拥塞反馈，并减慢其向网络发送的流量速率。\n\n在互联网中，TCP 在控制拥塞以及可靠传输中都扮演主要角色。\n\n\n\nTCP 拥塞控制基于 AIMD (Additive Increase Multiplicative Decrease) 控制律使用窗口机制，以packet loss作为二进制信号。\n\n\nTCP 维护一个拥塞窗口congestion window (the sending window）和一个流量控制窗口（接收窗口）\n\n拥塞窗口（发送窗口）的大小是指发送者在任何时刻可以在网络中传输的字节数。\n\n拥塞窗口仅为发送者所知，不通过链路传输。\nThe corresponding rate 是窗口大小(两个窗口取最小) 除以连接的往返时间。\nTCP 根据 AIMD 规则调整拥塞窗口的大小\n\n\n流量控制窗口(接收窗口)\n\n指定接收器可以缓冲的字节数。接收器通过 TCP 头向发送器指示其窗口大小(window size)。\n两个窗口并行跟踪，可以发送的字节数是两个窗口中较小的那个。换句话说，发送器处未确认数据的数量 ≤ min(接收器窗口大小，拥塞窗口大小)\n如果拥塞窗口或流量控制窗口暂时满了，TCP 将停止发送数据。\n\n\n所有互联网 TCP 算法都假设丢包是由拥塞引起的，并通过监测超时来判断。但是，使用丢包作为拥塞信号取决于传输错误相对较少\n\n对于无线传输链路来说,通常不成立,丢包一般是传输错误导致的\n大多数电线和光纤的比特错误率较低\n\n\n\n\n\n两个重要问题\n\n发送方将使用的数据包传输速率\n\nAck clock to estimate RTT\n\n\n拥塞窗口的大小so that we can take the most advantage of the network path while at the same time will not induce clog quickly\n\nslow start\n\n\n\n\n\nAck clock\n确认返回到发送方的速率大约与数据包能够在路径中最慢链路上发送的速率相同[就是最瓶颈的那一段]。这正好是发送方想要使用的速率。\n\n慢开始和拥塞避免\n整个思想是让 TCP 连接的拥塞窗口长时间保持在最优值附近——既不会小到导致吞吐量过低，也不会大到引起拥塞。\n\n\n发送方的窗口大小需要考虑两方面因素\n\n接收方缓冲区剩余大小，即协议中发回的 rwnd；\n网络的拥塞情况，发送方应当根据拥塞情况维护一个拥塞窗口 cwnd。\n\n\n发送方的窗口大小应取这二者之间的较小值。下面讨论 cwnd 的算法。\n\n初始 cwnd 为 1（单位为 KB 或者 MSS, Maximum Segment Size）\n每收到一个ACK,就增加一个数据包,也就是一个变两个[指数增长]\n指数增长到小于等于 ssthresh（slow start threshold）后开始两者每次共同 +1[到达阈值之后转变为线性增长]最初，慢启动阈值被任意设置为较高的值，即流量控制窗口的大小，以便不会限制连接。\n直到发现拥塞时(发现丢包) cwnd = 1, ssthresh *= 0.5,然后重新开始.\n将 cwnd 置为 1 的考量是让网络迅速消化掉拥塞在网络中的数据包。\n\n\n\n快重传和快恢复\n\n\nDuplicate ACKnowledgements重复确认\n\n会提示数据未到达的情况.\n\n\n快重传[TCP Tahoe 版本]和快恢复[TCP Reno版本=TCP Tahoe+快恢复]是对前述算法的优化。\n\n快速重传: 此时发送方可以不必等待超时而是一旦收到 3 个重复 ACK，发送方立刻重传 2 号 segment\n\n慢启动阈值仍设置为当前拥塞窗口的一半。通过将拥塞窗口设置为一个数据包可以重新启动慢启动。\n\n\n在快恢复算法中，我们发现 3 个冗余 ACK 时会采取 cwnd *= 0.5，ssthresh *= 0.5 的方式，而不是将 cwnd 置为 1。\n\n对每个额外的重复确认继续发送一个新数据包（假装进一步的重复 ACK 是预期的 ACK）\n为此，对重复 ACK 进行计数（包括触发快速重传的三个 ACK），直到网络中的数据包数量下降到新的阈值[下降到新阈值之前停止发送新数据包,下降到新阈值之后可以每收到一个重复确认就发送一个新的数据包]\n\n当 ACK 跳跃时协调视图采取这一策略的考量是，既然发送方还能收到冗余的 ACK，那么说明网络还没那么拥塞。\n\n\n快速重传之后的一个RTT,丢失的数据包将被确认,那么重复确认流停止,退出快速恢复模式.拥塞窗口将被设置为新的慢启动窗口并线性增长.\nTCP 避免使用慢启动，除非在连接首次启动时和发生超时时。\n\n\n\n\n\n\n其他\nSACK (Selective ACKnowledgements):\n\nlists up to three ranges of bytes that have been received. With this information, the sender can more directly decide which packets to retransmit and track the packets in flight to implement the congestion window.\nWith SACK, TCP can recover more easily from situations in which multiple packets are lost at roughly the same time, since the TCP sender knows which packets have not been received.\n[RFC2883 and RFC3517]\n\nECN (Explicit Congestion Notification)\n\nECN is an IP layer mechanism to 通知主机网络拥塞情况\nThe use of ECN is enabled for a TCP connection when both the sender and receiver indicate that they are capable of using ECN by setting theECE and CWR bits during the connection establishment.\n\nThe TCP receiver uses the ECE (ECN-Echo) flag to signal the TCP sender to tell it to slow down when the TCP receiver gets a congestion indication from the network.\nThe sender tells the receiver that it has heard the signal by using the CWR (Congestion Window Reduced) flag, so that the TCP receiver knows the sender has slowed down and can stop sending the ECN-Echo.\n\n\nIf ECN is used, routers that support ECN will set a congestion signal on packets that can carry ECN flags when congestion is approaching, instead of dropping those packets after congestion has occurred.\nECN requires both host and router support. [RFC 3168]\n\n其他其他: bbr基于拥塞的拥塞控制\n\n\n当瓶颈缓冲区很大时，基于丢包的拥塞控制会将其保持满满状态，导致缓冲区膨胀 buffer bloat。\n\n延迟拥塞事件对发送方的影响（当长网络路径中的网络设备具有过大的缓冲区时，具有大拥塞窗口的 TCP 发送方可以以远超网络容量的速率发送数据，直到收到丢包信号才会做出反应）。\n\n\n当瓶颈缓冲区较小时，基于丢包的拥塞控制会错误地将丢包解释为拥塞信号，导致吞吐量很低。\n\n替代方案:\n首先理解网络拥塞在何处产生以及如何产生\n\n在任何时间，一条全双工 TCP 连接在每个方向上恰好有一条最慢的链路或瓶颈。\n\n瓶颈决定了连接的最大数据传输速率\n它是持久队列形成的地方\n\n\n从 TCP 的角度来看，一条任意复杂的路径表现为具有相同 RTT 和瓶颈速率的单条链路。\n\n两个物理约束，RTprop（往返传播延迟）和 BtlBw（瓶颈带宽）限制了传输性能。\n\n如果网络路径是一条物理管道，RTprop 就是它的长度，BtlBW 就是它的最小直径。\n\n\n\n\n"},"课程笔记/计算机网络/07-应用层":{"slug":"课程笔记/计算机网络/07-应用层","filePath":"课程笔记/计算机网络/07 应用层.md","title":"应用层","links":[],"tags":[],"content":"应用层概述\n\n网络应用不仅仅是应用层协议.包括\n\n客户端\n\n主动与服务器建立联系connect()\n向服务器请求服务\n\n\n服务器端\n应用层协议\n\n应用程序需要哪种运输服务应参考的参数\n\nData Loss\n\n容错loss-tolerant 比如音频视频\n文件传输\\telnet等则需要百分百可靠\n\n\n带宽bandwidth\n\n多媒体需要最大带宽\nelastic: 弹性 可以使用任何可用的带宽\n\n\nTiming\n\n语音通话等需要低延迟才能有效工作\n\n\n\n\n\n重要的应用层协议\nDNS 域名系统\n理论上说，只要我们记住需要访问的资源部署在哪个 IP 地址上，我们就可以借此使用到对应的服务。\n\n但是如果服务更换了一个主机部署，服务提供方就需要将 IP 地址通知到每一个人；\n同时人们也倾向于使用更具有意义的字符串而不是 IP 地址来记忆。\n因此人们希望建立一个从便于记忆的主机名和 IP 地址之间的映射解决这些问题。因此我们引入了 DNS, Domain Name System。\n\n\n本质是基于域名的分层命名方案和分布式数据库\n将名称映射到IP地址,应用程序需要调用一个称为the resolver并将名称作为参数传递给它\n查询和响应消息作为UDP数据包发送\n\n为什么不是中心式\n• Single point of failure 单点故障\n• Traffic volume 流量容量\n• Distant name server means slow response 远距离名称服务器导致响应缓慢\n• Scalability 可拓展性\n层级结构:\nmappings分布在dns服务器中,dns服务器分为三种\n\n根dns服务器\n\n13个逻辑根dns服务器a.root-servers.net to m.root-servers.net\n\n每个服务器实际上是服务器集群\n所有域名服务器都需要根服务器的ip地址\n通过name.ca配置文件处理\n\n\n有1959(root-servers.org 2025.12.9) 个分布式服务器instances\n\nMost servers are reached by IP anycast.(通过IP anycast共享同一个ip地址)\n在任播路由中，数据包被传递到目标地址的最近实例。\n服务器可通过 IPv4 和 IPv6 访问\n\n\n\n\n顶级域名TLD dns服务器\nauthoritative DNS server\n\nThe DNS Name Space\n顶级域名分成两类: generic(通用) and countries(国家).\n\nDNS Zones\n\n\nDomain Resource Records 资源记录\n每个域，无论是单个主机还是顶级域，都可以有一组与之关联的资源记录。这些记录构成了DNS数据库\n单个主机:最常见的资源记录是它的ip地址\n当解析器向DNS提供一个域名时,返回的是与该域名关联的资源记录\nDNS的主要功能是将域名映射到资源记录\n资源记录是五元组\nDomain_name Time_to_live Class Type Value\n\n域名 表示该记录适用的域,每个域存在许多记录,数据库的每个副本保存关于多个域的信息  the primary search key\nttl 指示记录的稳定性\n类字段 对于互联网信息总是IN\n类型字段\nSOA 记录提供了关于名称服务器区域信息的主要来源的名称。\n\nPTR 指向另一个名称。它几乎总是用于将名称与 IP 地址相关联，以允许查找 IP 地址并返回相应计算机的名称。  -反向查询\nMX record, it specifies the name of the host prepared to accept email for the specific domain\nSRV 是一种较新的记录类型，允许在域中识别用于给定服务的主机。该记录是对 MX 记录的一般化，MX 记录执行相同的任务但仅用于邮件服务器。\nSPF（发件人策略框架）也是一种较新的记录类型。它允许域编码关于域中哪些机器将向互联网其余部分发送邮件的信息。这有助于接收机器检查邮件是否有效。\n\n\nDNS Resolution\nDNS 协议让主机能够将任何主机名（域名）解析为 IP 地址\n如果未知，可以从根名称服务器开始并逐级查询各个区域\n递归查询:\n\n递归 DNS 查询是指 DNS 解析器（通常是客户端 DNS 服务器）要求另一个 DNS 服务器处理整个解析过程的查询。客户端 DNS 服务器向递归 DNS 服务器发送单个查询，并等待最终答案。\n它简化了客户端 DNS 解析器的流程。解析器只需发送一个查询并等待响应，无需处理转发或进行多个请求。– 它可以潜在地提供更快的响应，因为递归 DNS 服务器可以通过使用其缓存来优化查询过程。如果它之前已经解析过该域名或其缓存中有相关信息，它可以更快地返回答案。\n如果递归 DNS 服务器收到大量请求，特别是当它们必须为每个查询执行完整的解析过程时，可能会被过载。\n递归 DNS 服务器存在安全风险。如果恶意行为者能够控制递归 DNS 服务器，他们可以操纵 DNS 解析结果，导致网络钓鱼或将用户重定向到恶意网站等问题\n\n迭代查询:\n\n迭代 DNS 查询是 DNS 解析器（通常是客户端 DNS 服务器）向不同的 DNS 服务器进行一系列请求，直到获得所需答案的过程。当 DNS 解析器发送迭代查询时，它从根 DNS 服务器开始。\n假设本地 DNS 解析器想要解析域名”www. cs.washington.edu”。\n\n\n本地 DNS 服务器首先联系根 DNS 服务器。但根 DNS 服务器不直接知道www.cs.washington.edu的 IP 地址，但它知道顶级域（TLD）服务器的 IP 地址（如.edu 服务器）。因此，它用相关 TLD 服务器的 IP 地址响应本地 DNS 解析器。\n本地 DNS 解析器随后联系 TLD 服务器。TLD 服务器依次提供域名”washtington.edu”的权威 DNS 服务器的 IP 地址。\n最后，本地 DNS 解析器联系权威 DNS 服务器，该服务器提供”www .cs.washington.edu”的 IP 地址。\n\n\n它减少了对根服务器和 TLD 服务器之外的 DNS 服务器的负载，因为本地 DNS 解析器在遵循转介方面完成了大部分工作。本地 DNS 服务器可以在一个客户端池上进行缓存以获得更好的性能\n该过程可能会较慢，因为解析器必须发出多个请求并等待来自不同服务器的响应。此外，过程中的每一步都可能引入额外的延迟。\n\n\n\n\n\nFTP\n用于向远程主机传输文件或从远程主机接收文件。百分之百可靠传输\n\n– 1) 用户首先提供远程主机的主机名，导致本地主机中的 FTP 客户端进程与远程主机中的 FTP 服务器进程建立 TCP 连接。\n– 2) 用户随后提供用户标识和密码，这些信息通过 TCP 连接以 FTP 命令的形式发送。\n– 3) 一旦服务器授权用户，用户就可以将存储在本地文件系统中的一个或多个文件复制到远程文件系统中（或反之）。\nFTP 使用两条并行的 TCP 连接来传输文件，一条控制连接和一条数据连接。\n\n控制连接用于在两台主机之间发送控制信息，包括用户识别、密码、更改远程目录的命令，以及”上传”和”下载”文件的命令。\n\nFTP 被称为带外发送其控制信息。（正因为这个控制连接（独立的），FTP 是”带外”的。\n从客户端到服务器的命令和从服务器到客户端的应答通过控制连接以 7 位 ASCII 格式发送。\n\n\n数据连接用于实际发送文件\n\nEmail\n一种异步通信媒介,包括\n– 用户代理（客户端，例如 Outlook、Gmail 网络界面）\n– 消息传输代理（邮件服务器）\n– 简单邮件传输协议：SMTP\n\nSMTP\n– RFC 5321\n– 它利用 TCP 的可靠数据传输服务将邮件从发送方邮件服务器传输到接收方邮件服务器。\n– 与大多数应用层协议一样，SMTP 有两个方面：客户端方面在发送方邮件服务器上执行，服务器端方面在接收方邮件服务器上执行。\n\n首先，客户端 SMTP（运行在发送邮件服务器主机上）通过 TCP 建立连接到服务器 SMTP（运行在接收邮件服务器主机上）的 25 端口。\n\n如果服务器宕机，客户端稍后重试。\n\n\n一旦这个连接建立，服务器和客户端进行应用层握手\n\n在 SMTP 握手阶段，SMTP 客户端指示发件人的电子邮件地址和收件人的电子邮件地址。\n\n\n一旦 SMTP 客户端和服务器相互介绍后，客户端就会发送消息\n\n如果客户端有其他消息要发送到服务器，则会在同一 TCP 连接上重复此过程。\n\n\n否则，它指示 TCP 关闭连接。\n\nEmail Message Format\n– 信封封装了消息。它包含传输消息所需的所有信息，例如目标地址、优先级和安全级别。消息传输代理使用信封进行路由，就像邮局所做的那样。\n– 信封内的消息由两个独立部分组成：头部和正文\nRFC\nMIME\n\nHTTP\nThe HyperText Transfer Protocol超文本传输协议\n\nWeb 的应用层协议，是 Web 的核心。\n是一个简单的请求-响应协议，通常运行在 TCP 上。\nHTTP 与 Web 页面如何被客户端解释没有任何关系。\n\nWeb 页面如何被客户端解释: 浏览器\n\n\n\n网页（也称为文档）由对象组成。对象就是一个文件，如 HTML 文件、JPEG 图像、Java 小程序或视频剪辑，可以通过单个 URL 访问。\n\n\nDomain names can be either absolute or relative. An absolute domain name always ends with a period (i.e. dot) (e.g., eng.cisco.com.), whereas a relative one does not. Relative names have to be interpreted in some context to uniquely determine their true meaning. In both cases, a named domain refers to a specific node in the tree and all the nodes under it.\nTo create a new domain, permission is required of the domain in which it will be included. Once a new domain has been created and registered, it can create subdomains without getting permission from anybody higher up the tree.\n\nName Servers\n\n\n\n都用 recursive query 会导致 root name server 负载过大。\n整个 Internet 依赖于 root name server，因此实际上它们能力超强且有多份冗余；query packet 通过 anycast 找到其中之一。\nName server 有缓存。上面的例子展示的是没有缓存的情况；事实上部分 name server 可能已经将内容缓存起来。由于缓存不一定确保正确，因此 name server 上的 records 也是有时限的。\nDNS 的 query 和 response 采用 UDP 发送；DNS name server 使用 53 号端口。如果很短的时间内没有收到 response，DNS client 就重新发一个；如果重复若干次仍然失败，就尝试另一台 name server。\n\nDomain Resource Records\n\n\n\n\n\nEmail\nArchitecture and Services\n\n\n\n\n\nUA, User Agent: 也叫 Email Reader，是一个 program，给用户看的。\n\n\nMessage Transfer Agent: 负责发送和接收邮件，同时向发送方报告发送情况。有可能在 ISP 上。\n\n\n收发过程\n\n\n发送方用 UA 编辑好了以后通过 SMTP（后面讨论）给 Message Transfer Agent\n\n\n邮件进入 MTA 的缓存\n\n\nSMTP client process 定期扫描 MTA 缓存，发现了以后与接收端 SMTP server process 建立 TCP 连接（可能需要先 DNS），端口号为 25\n\n\nTCP 连接建立好了以后 SMTP 开始发送邮件，发完了以后 SMTP 关闭 TCP 连接\n\n\n接收端 MTA 中的 SMTP 进程收到邮件后就放到收信人的用户邮箱\n\n\n收信人打算收信时，调取 UA，通过 POP3 / IMAP（后面讨论）取回邮件\n\n\nMessage Formats\n\n\n\n\nSMTP, Simple Mail Transfer Protocol\n\n\nSMTP 是一种 ASCII 协议，这样方便调试。\n\nPOP3, Post Office Protocol 3\n\nTCP, port = 110\n下载并保留 or 下载并删除\n\nIMAP, Internet Message Access Protocol\n\nPOP3 的改进版；TCP, port = 143\n\nWWW\nArchitecture Overview\n\nWeb = World Wide Web，由 Web pages 组成。观看它们的程序是 browser\nURL, Uniform Resource Locator，://:/例如 www.yuque.com/xianyuxuan 中 http 说明了访问这个页面的方式，www.yuque.com 经过 DNS 解析后可以得到 IP 地址，xianyuxuan 说明了具体要看的是这个主机上的什么。\n\n\nHTTP, HyperText Transfer Protocol\n\nTCP, port = 80，ASCII 协议。比较通用，不限于 web。\nHTTP request 可以在 TCP 第三次握手就带上\n\n\n\n\nFTP\nFile Transfer Protocol。允许客户指明文件的类型和格式，因此可以在不同架构、操作系统之间的文件传输；允许文件具有存取权限，提供不同用户的权限，因此可以实现远程文件管理和文件共享。\nserver listen port 21, client TCP 连接之。随后建立数据连接，有 2 种方式\n\n主动模式 POST：client 开个端口 N（一般是 ctrl 的端口 + 1），给 server 发 POST N，server 用 port 20 连接 N。问题在于如果 client 有 NAT 之类的可能连不上。\n被动模式 PASV：client 给 server 发 PASV，server 开一个随机端口并且告诉 client，client 连这个端口。问题在于配置复杂而且不利于安全。\n\n关于 OSI 7层模型\nOSI 7层模型中的 会话层 Session Layer, 表示层 Presentation Layer 以及 应用层 Application Layer 对应了五层协议体系结构中的应用层。\nSession Layer 负责管理端到端的会话，具体包括会话的建立、管理和中止。会话提供同步、checkpoint 恢复等功能。\nPresentation Layer 负责将不同机器的不同编码和表示方式进行抽象、统一；同时也提供数据压缩、加密等功能。\nApplication Layer 就是本节介绍的用户界面以及使用的各种协议。"},"课程笔记/计算机网络/HTTP专项":{"slug":"课程笔记/计算机网络/HTTP专项","filePath":"课程笔记/计算机网络/HTTP专项.md","title":"HTTP专项","links":[],"tags":[],"content":""},"课程笔记/计算机网络/Lab/lab7-网络应用协议-and-Socket编程接口":{"slug":"课程笔记/计算机网络/Lab/lab7-网络应用协议-and-Socket编程接口","filePath":"课程笔记/计算机网络/Lab/lab7 网络应用协议&Socket编程接口.md","title":"lab7 网络应用协议&Socket编程接口","links":[],"tags":[],"content":"基本的网络应用软件\n自定义的协议规范\nSocket编程接口\n客户端\n服务端\n程序界面：命令行或者最简单的窗体\n\nIP 地址：IPv4 (32 bits) or IPv6 (128 bits) 地址，一台计算机可以拥有一个独立的IP 地址；一个局域网也可以拥有一个独立的IP 地址（对外就好像只有一台计算机）。\nMAC 地址(48 bits)：每个网卡的MAC 地址在全世界都是独一无二的。多数现实的情况是，一个局域网往往才能拥有一个独立的IP地址；换句话说，IP 地址只能定位到一个局域网，无法定位到具体的一台计算机。\n\n数据包中除了会附带对方的IP 地址，还会附带对方的MAC 地址，当数据包达到局域网以后，路由器/交换机会根据数据包中的MAC 地址找到对应的计算机，然后把数据包转交给它，这样就完成了数据的传递。\n\n\n端口号(16 bits)：一台计算机可以同时提供多种网络服务，例如Web 服务（网站）、FTP 服务（文件传输服务）、SMTP 服务（邮箱服务）等，仅有IP 地址和MAC 地址，计算机虽然可以正确接收到数据包，但是却不知道要将数据包交给哪个网络应用程序来处理。为了区分不同的网络应用程序，计算机会为每个网络程序分配一个独一无二的端口号（Port Number）。端口（Port）是一个虚拟的、逻辑上的概念。可以将某台计算机看成是一个居民楼，而每个网络应用程序是居住在这个楼的居民，为了能把信件投送到家，必须在投送地址上写明房间号。\n\n注意一般0-1023端口是分配给一些特定的网络应用服务，如\n\nhttp (TCP) 服务的端口号是80，https(TCP)服务的端口号是443\nDNS(UDP)服务的端口号是53\nFTP 服务的端口号是21\nSMTP 服务的端口号是25 (POP3 101)\n\n\n我们实验中端口号请选择1024-65535之间的数值（以自己学号的后四位作为服务器端的监听端口号，如果后四位中的第一位为零，则采用1XXXX）。\n\n\n\nsocket\nsocket 的原意是“插座”，在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。\n\n\n                  \n                  UNIX/Linux 中的socket 是什么？ \n                  \n                \n\n\n在UNIX/Linux 系统中，为了统一对各种硬件的操作，简化接口，不同的硬件设备也都被看成一个文件。对这些文件的操作，等同于对磁盘上普通文件的操作。\n\n通常用0 来表示标准输入文件（stdin），它对应的硬件设备就是键盘；\n通常用1 来表示标准输出文件（stdout），它对应的硬件设备就是显示器。\n\n\n为了表示和区分已经打开的文件，UNIX/Linux 会给每个文件分配一个ID，这个ID 就是一个整数，被称为文件描述符（File Descriptor）。\n网络连接也是一个文件，它也有文件描述符！\n我们可以通过socket() 函数来创建一个网络连接，或者说打开一个网络文件，socket() 的返回值就是文件描述符。\n\n有了文件描述符，我们就可以使用普通的文件操作函数来传输数据了\n用read() 读取从远程计算机传来的数据；\n用write() 向远程计算机写入数据。\n\n\n\n\n\n\n\n                  \n                  Window 系统中的socket 是什么？ \n                  \n                \n\n\nWindows 也有类似“文件描述符”的概念，但通常被称为“文件句柄”。\n与UNIX/Linux 不同的是，Windows 会区分socket 和文件，Windows 就把socket 当做一个网络连接来对待，因此需要调用专门针对socket 而设计的数据传输函数，针对普通文件的输入输出函数就无效了。\n\n\n\nsocket的种类\n流格式套接字（SOCK_STREAM）\n\n数据在传输过程中不会消失；\n数据是按照顺序传输的；\n数据的发送和接收不是同步的(流格式套接字的内部有一个缓冲区（是一个字符数组），通过socket 传输的数据将保存到这个缓冲区。接收端在收到数据后并不一定立即读取，只要数据不超过缓冲区的容量，接收端有可能在缓冲区被填满以后一次性地读取，也可能分成好几次读取。)\nExample: HTTP (TCP)\n\n\n数据报格式套接字（SOCK_DGRAM）\n计算机只管传输数据，不作数据校验，如果数据在传输中损坏，或者没有到达另一台计算机，是没有办法补救的。也就是说，数据错了就错了，无法重传。\n\n强调快速传输而非传输顺序；\n传输的数据可能丢失也可能损毁；\n限制每次传输的数据大小；\n数据的发送和接收是同步的\nExample: QQ视频和语音聊天(UDP)\n\n我们所说的socket编程，是在传输层的基础上，所以可以使用TCP/UDP 协议。但是实验要求TCP\nConstructing Message\nByte Ordering\n\nDifferent machines / OS’s use different word orderings\n\nLittle-endian: lower bytes first\nBig-endian: higher bytes first\n\n\n\n注意不同类型的主机字节顺序不同（但是网络传输过程中都是大端的顺序）为了可移植性，需要使用四个函数：\n\ns：16bits的port numbers\nl：32bits的port numbers\nAlignment &amp; Padding\n对齐和置零\nAlignment：把数据放置在内存中地址等于字节倍数的位置，这样可以提高系统性能\nPadding：填充插入额外字节\n\nFraming &amp; Parsing\nFraming\nParsing\n具体的编程\nMany network applications consists of a pair programs ——a client program and a server program ——residing in two different end systems（web or ftp）\n程序执行时会创建一个客户端进程和一个服务器进程，这些进程通过从套接字读取和向套接字写入来相互通信。\n\n决定哪种传输层协议 TCP/UDP\n\n\nTCP是面向链接的，提供一个可靠的字节流信道（TCP是内驻在操作系统里面，我们要写的是网络层的协议）\n\n\nUDP是面向无链接的，将独立的数据包从一个端系统发送到另一个端系统，不保证任何交付性\n\n\n\n\nTCP数据报结构\n• 1) 序号：Seq（Sequence Number）序号占32位，用来标识从计算机A发送到计算机B的数据包的序号，计算机发送数据时对此进行标记。每发一个字节都有一个独立的序号\n• 2) 确认号：Ack（Acknowledge Number）确认号占32位，客户端和服务器端都可以发送，Ack = Seq + 1。确认被接收\n• 3) 标志位：每个标志位占用1Bit，共有6个，分别为 URG、ACK、PSH、RST、SYN、FIN，具体含义如下：\n– URG 紧急指针（urgent pointer）有效。\n– ACK 确认序号有效（1 ）。\n– PSH 接收方应该尽快将这个报文交给应用层。\n– RST 重置连接。\n– SYN 建立一个新连接（1 ）。\n– FIN 断开一个连接。\n\n\nTCP三次握手建立连接\n\n数据在传输前要建立连接 （connect() 函数，为了保证ip地址、端口、物理链路正确），传输完毕后还要断开连接。\nTCP建立连接时要传输三个数据包，俗称三次握手（Three-wayHandshaking）。可以形象的比喻为下面的对话：\n\n[Shake1] 套接字A：“你好，套接字B，我这里有数据要传送给你，建立连接吧。”\n[Shake2] 套接字B：“好的，我这边已准备就绪。”\n[Shake3] 套接字A：“谢谢你受理我的请求。”\n\n\n\n建立连接时需要进行三次握手\n\n建立链接成功后进行数据传输\n\n当数据包在传输的过程中发生丢失的时候，会进行重传。如何发现丢失的呢？RTT：round trip time\nTCP四次握手断开连接\n建立连接非常重要，它是数据正确传输的前提；断开连接同样重要，它让计算机释放不再使用的资源。如果连接不能正常断开，不仅会造成数据传输错误，还会导致套接字不能关闭，持续占用资源，如果并发量高，服务器压力堪忧。\n建立连接需要三次握手，断开连接需要四次握手，可以形象的比喻为下面的对话：\n\n\n[Shake 1] 套接字A：“任务处理完毕，我希望断开连接。”\n\n\n[Shake 2] 套接字B：“哦，是吗？请稍等，我准备一下。”\n\n\n等待片刻后……\n\n\n[Shake 3] 套接字B：“我准备好了，可以断开连接了。”\n\n\n[Shake 4] 套接字A：“好的，谢谢合作。”\n\n5000和7000没关联\n第二个fin包：seq值+1了，但是ack值没有进行变化。因为客户端在ack和fin包之间没有发出新的数据包给服务器端。在这个包里fin会置1。\n第二个ack包：在上一个fin包的seq基础上7001+1\n\n\n客户端最后一次发送 ACK包后进入 TIME_WAIT 状态，而不是直接进入 CLOSED 状态关闭连接，这是为什么呢？\n\nTCP 是面向连接的传输方式，必须保证数据能够正确到达目标机器，不能丢失或出错，而网络是动态、不稳定的，数据随时可能被会毁坏或丢弃，所以机器A每次向机器B发送数据包后，都要求机器B“确认” ，回传ACK包，告诉机器A我收到了，这样机器A才能知道数据传送成功了。如果机器B没有回传ACK包，机器A会重新发送，直到机器B回传ACK包。\n\n\n\n客户端最后一次向服务器回传ACK包时，有可能会因为网络问题导致服务器收不到，服务器会再次发送 FIN 包，如果这时客户端完全关闭了连接，那么服务器无论如何也收不到ACK包了，所以客户端需要等待片刻、确认对方收到ACK包后才能进入CLOSED状态。那么，要等待多久呢？（就是说经过一段时间没发出有问题的信号，才能确认没问题）\n\n数据包在网络中是有生存时间的，超过这个时间还未到达目标主机就会被丢弃，并通知源主机。这称为报文最大生存时间（MSL，Maximum Segment Lifetime）。TIME_WAIT 要等待 2MSL才会进入 CLOSED 状态。ACK 包到达服务器需要 MSL 时间，服务器重传 FIN 包也需要 MSL 时间，2MSL 是数据包往返的最大时间，如果 2MSL 后还未收到服务器重传的 FIN 包，就说明服务器已经收到了 ACK 包。\n\n如果fin包也没送到呢？实际上，ack没达到服务器端的话，会通知客户端重发的，也就不会有服务器发送fin包的问题了。\n\n\n\n\n\n\nlinux的socket例子\n\n函数名和我们用的可能有所不同\nsocket：开洞\nbind：给门洞安门牌号，才能正常收发邮件\nlisten：服务器端使用的\naccept：服务器使用的\nconnect：客户端使用的\nsend：都有的\nreceive：都有的\nclose：都有的\n\n\n在 Linux 下使用 &lt;sys/socket.h&gt; 头文件中 socket() 函数来创建套接字\n\n\n原型为：int socket(int af, int type, int protocol);【因为linux把网络连接当成文件来处理】\n\naf为地址族（Address Family），也就是 IP 地址类型。\n\nAF_INET表示IPv4 地址 (INET是“Internet”的简写)\nAF_INET6表示IPv6地址\nAF_UNIX (local channel, similar to pipes)\nAF_ISO (ISO protocols)\n\n\ntype 为数据传输方式/套接字类型\n\nSOCK_STREAM（流格式套接字/面向连接的套接字 ~ TCP）\nSOCK_DGRAM（数据报套接字/无连接的套接字 ~ UDP）\n\n\nprotocol 表示传输协议，常用的有IPPROTO_TCP 和 IPPROTO_UDP，分别表示 TCP 传输协议和 UDP 传输协议。Usually set to 0 (i.e., use default protocol). 有可能多种协议使用同一种数据传输方式，所以在socket编程中，需要同时指明数据传输方式和协议。（ 提供面向连接的服务，但是有多个协议来支撑面向连接的服务)\n\n\n\n像 connect()、accept() 和 bind() 这样的套接字函数需要使用专门定义的地址结构来保存 IP 地址、端口号和协议类型。\n\n\n困难在于你可以使用套接字用不同的协议来编写网络应用程序。例如，我们可以使用 IPv4、IPv6、本地 Unix 等。问题在于：每种不同的协议都使用不同的地址结构来保存其寻址信息，但它们都使用相同的函数 connect()、accept() 和 bind() 等。\n\n\n因此改成一个通用的地址结构再给这些函数用\n\n\n\nstruct sockaddr\nstruct sockaddr{\nsa_family_t sin_family; //地址族(Address Family)，也就是地址类型\nchar sa_data[14]; //IP地址和端口号\n};\n\n必须传递给所有需要地址结构的 socket 函数的地址结构。\n强制地址转换\n\nIPv4 address structure: struct sockaddr_in\nstruct sockaddr_in{\nsa_family_t sin_family; //地址族(Address Family)，也就是地址类型\nuint16_t sin_port; //16位的端口号\nstruct in_addr sin_addr; //32位IP地址\nchar sin_zero[8]; //不使用，一般用0填充\n};\n \nstruct in_addr{\nin_addr_t s_addr; //32位的IP地址\n};\n\n\nsockaddr是一种通用的结构体，可以用来保存多种类型的IP地址和端口号，而 sockaddr_in是专门用来保存 IPv4 地址的结构体。\n\nconnect(), bind()和accept()函数中第二个参数的类型为 sockaddr\n\n\nsockaddr和 sockaddr_in的长度相同，都是16字节，sockaddr将IP地址和端口号合并到一起，用一个成员 sa_data表示。要想给 sa_data赋值，必须同时指明IP地址和端口号，例如“127.0.0.1:80”，遗憾的是，没有相关函数将这个字符串转换成需要的形式，也就很难给 sockaddr类型的变量赋值，所以使用 sockaddr_in来代替。这两个结构体的长度相同，强制转换类型时不会丢失字节，也没有多余的字节\n\n在服务器端建立一个socket\n\nsocket（） 创建套接字\nbind（）将套接字绑定到一个地址，对于 Internet 上的服务器套接字，地址由主机上的端口号组成。\nlisten（）调用监听连接\naccept（）接受连接。通常是堵塞地，直到有一个客户端与服务器建立连接\n发送和接受数据\n\n简化版：\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;arpa/inet.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;netinet/in.h&gt;\nint main(){\n//创建套接字，it just creates interface\nint serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); //如果serv_sock&lt; 0, 则创建失败，最好有检查\n//将套接字和IP、端口绑定\nstruct sockaddr_in serv_addr; //IPv4地址结构体\nmemset(&amp;serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充\nserv_addr.sin_family = AF_INET;//使用IPv4地址\nserv_addr.sin_addr.s_addr = inet_addr(“127.0.0.1”);//服务器IP地址(这里使用的是本机地址，【最好用这个因为可能本机有很多个网卡要多个套接字，这个的话一个套接字就可以】INADDR_ANY)\nserv_addr.sin_port = htons(1234); //端口//可移植性比较好\nbind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)); //这里地址强制转换\n//进入监听状态，等待用户发起请求\nlisten(serv_sock, 20); //20表示服务器端可容纳队列长度，可以有20个clients等待连接\n//接收客户端请求\nstruct sockaddr_in clnt_addr;\nsocklen_t clnt_addr_size = sizeof(clnt_addr);\nint clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size);\n//向客户端发送数据\nchar str[] = “Hello Client!&quot;;\nwrite(clnt_sock, str, sizeof(str));\n//关闭套接字\nclose(clnt_sock); close(serv_sock); return 0;\n}\nserv_sock 一直监听\nclnt_sock 用于接收\n需要在这个模板上增加做一些创建失败的检查\naccept\nint clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size);\n\naccept() 返回一个新的套接字文件描述符，用于与客户端进行读写。原有的文件描述符通常用于监听新的传入连接。\n它从服务器该套接字的队列中出队下一个连接请求。如果队列为空，该函数将阻塞直到有连接请求到达。\n注意该函数的最后一个参数是一个指针。你不是在指定长度，内核会指定并将值返回给你的应用，同样对于 clnt_addr 也是如此。在与客户端建立连接后，必须将客户端的地址提供给你的服务器，否则你如何向客户端发送响应？因此，accept 函数调用会为你填充地址结构和地址结构的长度以供使用。、\n当服务器接收到（接受）客户端的连接请求时 ⇒ 它会派生（forks）出自身的副本并让子进程处理该客户端。（确保你记住这些操作系统概念）因此在服务器机器上，监听套接字与已连接套接字是不同的。\n\nwrite() and read()\nintwrite(int file_descriptor, const void *buf, size_t message_length);\nintread(int file_descriptor, char *buffer, size_t buffer_length);\n\nwrite() 函数的返回值是写入的字节数，失败时返回 −1\n这个函数所做的是将数据从你的应用程序传输到本机内核中的一个缓冲区，它并不直接通过网络发送数据。TCP 完全控制数据的发送，这在内核内部实现。\nread() 函数返回的是读取的字节数，可能小于缓冲区长度。失败时返回 −1。\nread() 仅将数据从内核中的缓冲区传输到你的应用程序，你并不是直接从远程主机读取字节流，而是由 TCP 来控制并为你的应用缓冲数据。\n\n\n\n把ip地址转化为用于网络传输的二进制数值\n\nintinet_aton(constchar cp, structin_addrinp);\ninet_aton() 转换网络主机地址ip(如192.168.1.10)为二进制数值，并存储在structin_addr结构中，即第二个参数*inp, 函数返回非零值表示cp主机地址有效，返回0表示主机地址无效。\n这个转换完后不能用于网络传输，还需要调用htonl函数才能将主机字节顺序转化为网络字节顺序。\n\n\n将网络传输的二进制数值转化为成点分十进制的ip地址\n\nchar *inet_ntoa(structin_addrin);\ninet_ntoa函数转换网络字节排序的地址为标准的ASCII以点分开的地址,该函数返回指向点分开的字符串地址（如192.168.1.10)的指针，该字符串的空间为静态分配的，这意味着在第二次调用该函数时，上一次调用将会被重写（复盖），所以如果需要保存该串最好复制出来自己管理！\n\n\n\n在客户端建立一个套接字\n\n使用 socket() 系统调用创建一个套接字\n使用 connect() 系统调用将套接字连接到服务器地址\n发送和接收数据。有多种方法可以实现，但最简单的是使用 read() 和 write() 系统调用。\n\n\n注意，客户端需要知道服务器的存在以及服务器的地址，但服务器在连接建立之前无需知道客户端的地址（甚至无需知道客户端的存在）。【 因为accept会自动读入与服务端建立连接的客户端地址信息的】\n另请注意，一旦连接建立，双方都可以发送和接收信息。\n\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;arpa/inet.h&gt;\n#include &lt;sys/socket.h&gt;\nint main(){\n//创建套接字\nint sock = socket(AF_INET, SOCK_STREAM, 0);\n//向服务器（特定的IP和端口）发起请求\nstruct sockaddr_in serv_addr;\nmemset(&amp;serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充\nserv_addr.sin_family = AF_INET; //使用IPv4地址\nserv_addr.sin_addr.s_addr = inet_addr(“127.0.0.1”);//服务器IP地址(这里是本机地址)\nserv_addr.sin_port = htons(1234); //端口\n//connect()函数执行TCP三次握手建立联接\nconnect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));\n//读取服务器传回的数据\nchar buffer[40];\nread(sock, buffer, sizeof(buffer)-1);\nprintf(&quot;Message form server: %s\\n&quot;, buffer);\n//关闭套接字\nclose(sock); return 0;\n}\nwindows的socket例子\n//Windows 不把套接字作为普通文件对待，而是返回 SOCKET 类型的句柄。\nSOCKETsocket(int af, int type, int protocol);\n \n//Linux下socket函数\nintsocket(intaf, inttype, intprotocol);\nGeneric:\nstructSOCKADDR{\nunsigned short sa_family;\nchar sa_data[14];\n};\nIPv4 address struct:\nstructsockaddr_in{\nshort sin_family;\nunsigned short sin_port;\nstructin_addrsin_addr;\nchar sin_zero[8];\n};\nstructin_addr{\nunion {\nstruct{unsigned char s_b1, s_b2, s_b3, s_b4;} S_un_b;\nstruct{unsigned short s_w1, s_w2;} S_un_w;\nunsigned long S_addr;\n} S_un;\n};\n//include部分\n//Windows 下的 socket 程序依赖 Winsock.dll 或 ws2_32.dll，必须提前加载。\n#include &lt;stdio.h&gt;\n#include &lt;winsock2.h&gt;\n#pragma comment (lib, &quot;ws2_32.lib&quot;) //加载 ws2_32.dll\n绿色是与linux不同的部分\n\n\n\n全流程回顾\n\n\nCommunication via sockets necessitates existence of the 4-tuple:\n\nLocal IP address\nLocal Port#\nForeign IP address\nForeign Port#\n\n\nServer\n\nPassively waits for and responds to clients\nPassive socket 被动套接字\n\n\nClient\n\nInitiates the communication\nMust know the address and the port of the server\nActive socket 主动套接字\n\n\n\n\n服务器先执行并等待接收\n客户端后执行并且向服务器发送第一个网络数据包\n建立连接之后，客户端或者服务器都可以发送和接收数据\n\n关于实验\n\n每增加一个功能就调试一次\n\n\nzjucomp.net/docs/Coding/toolchain\n不要使用定长的数据报，协议的定界问题要自己思考\n实验报告：一些控制相关的 客户端有菜单选项，服务端没有菜单选项的话需要考虑\n"},"课程笔记/计算机网络/Lab/lab8":{"slug":"课程笔记/计算机网络/Lab/lab8","filePath":"课程笔记/计算机网络/Lab/lab8.md","title":"lab8","links":[],"tags":[],"content":"URI解析与映射\n\n统一资源标识符URI（Uniform Resource Identifier）为互联网上的资源提供了一种标准化的命名和定位机制，极大地便利了资源的发现与访问过程\nURI是一种用于唯一地标识互联网上资源的字符串，它可以指向任何类型的资源，包括文档、图片、视频流、服务入口点等，URI的设计目的是为了确保每个资源在全球范围内都能被唯一识别，根据其功能和结构的不同，URI中可以进一步划分为URL和URN两种类型：\n\n统一资源定位符URL（Uniform Resource Locator）\n最常见的URI形式，提供了访问特定资源的路径和方法，URL不仅告诉计算机资源是什么，更重要的是说明了如何找到并获取这个资源，一个典型的URL结构是：scheme://host[:port]/path?query#fragment\n\nscheme：指定访问资源时使用的协议类型，如HTTP、HTTPS、FTP等\nhost：资源所在的主机名或IP地址:\n\n可以是一个域名,也可以是一个ip地址.总之背后对应一台运行着web服务器的机器.\n\n\nport：可选字段，指定主机上的端口号，默认情况下，不同的协议会使用不同的端口，例如HTTP默认使用80端口，HTTPS使用443端口\npath：资源在服务器上的具体位置，如path/to/file\nquery：可选字段，用于传递给服务器的查询参数，通常以键值对的形式出现，如key1=value1&amp;key2=value2\nfragment：可选字段，用于指示页面内部的一个特定部分或元素，通常用于页面内的导航，比如通过zjucomp.net/docs/Lab8_page#51-uri解析与映射 访问本文档时，可以直接跳转到第5部分\n\nURL又可以分为绝对URL和相对URL，这和绝对路径/相对路径的差别非常相似，绝对URL指向特定主机上一个特定的资源，而相对URL对于不同的主机可能对应不同的资源，我们在解析请求行中的URI时，实际上得到的是一个相对URL\n统一资源名称URN（Uniform Resource Name）\nURN更关注于资源的身份标识而非物理位置，旨在提供一种持久不变的名字空间，即使资源的实际位置发生变化，其URN仍然保持不变，它的格式通常为：&lt;nns&gt;:&lt;specifics&gt;\n\nnns：命名空间标识符，用于定义URN所属的命名空间\nspecifics：命名空间内的具体标识符，用于唯一确定资源\n\n你可能会问，既然得到的相对URL和相对路径这么相似，那么我们可不可以直接把资源和服务端程序的相对路径当作相对URL用来请求对应的资源呢？答案是“可以，但最好不要”\n尽管这样的命名方式非常简单直接，可以极大降低提供资源访问的难度，但这同时也带来了安全风险，通过对服务器的爆破扫描，脚本小子们可以摸索出服务器上的文件结构，从而针对性地选择潜在漏洞进行渗透，带来较大的安全风险，因此，为了保护服务器的安全，避免泄露不必要的信息，通常不建议直接将服务端程序的相对路径作为相对URL来使用\n根据你编写的程序运行效果，分别解答以下问题：\n\n\nHTTP 协议是怎样对头部和体部进行分隔的？\n\n\n   HTTP 协议使用连续的两个回车换行符(\\r\\n\\r\\n)作为头部（Header）和体部（Body）的分隔标志。\n\n\n浏览器是根据文件的扩展名还是根据头部的哪个字段判断文件类型的？\n\n\n   浏览器主要根据 HTTP 响应头部中的 Content-Type 字段来判断文件类型，服务器会维护一个 MIME_TYPES 映射表, 将文件扩展名（如 .html, .jpg）映射为标准的 MIME 类型\n\n\nHTTP 协议的头部是不是一定是文本格式？体部呢？\n\n\n  HTTP 协议的头部（Header）一定是文本格式（ASCII 编码）。体部（Body）则不一定是文本格式，它可以是文本（如 HTML, JSON），也可以是二进制数据（如图片, 视频）。\n\n\nPOST 方法传递的数据是放在头部还是体部？两个字段是用什么符号连接起来的？\n\n\n  POST 方法传递的数据通常放在 HTTP 请求的体部（Body）中。多个字段之间使用 &amp; 符号连接。\n在 Windows 使用 Wireshark 无法监听到 WSL 内部的本地回环流量,所以学习使用了 Linux 原生的 tcpdump 工具，通过命令将流量保存为抓包文件，再导入 Windows 的 Wireshark 进行分析。\n2. 心得体会：\n\n\n深入理解 HTTP 协议： 通过亲手实现解析器，对 HTTP 协议的无状态性、请求/响应格式、状态码的含义有了更深刻的理解，特别是 Content-Type 和 Content-Length 这两个头部字段的重要性。\n\n\nSocket 编程实践： 巩固了对 socket, bind, listen, accept 等 API 的理解，以及如何使用多线程（std::thread）来处理并发连接。\n\n\n代码健壮性： 认识到网络编程中防御性编程的重要性，例如处理恶意长请求、非法路径访问等情况。\n\n"},"课程笔记/计算机网络/TCP专项":{"slug":"课程笔记/计算机网络/TCP专项","filePath":"课程笔记/计算机网络/TCP专项.md","title":"TCP专项","links":[],"tags":[],"content":"基本认识\nTCP报文格式\n\n\n序列号: 在建立连接时,由计算机生成的随机数作为初始值,通过SYN包传给接收端主机,每发送一次数据就对该字节数+1,用来解决网络包乱序问题\n确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。\n控制位： 标志信息\n\nACK：该位为 1 时，「 确认应答号」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。\nRST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。\nSYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。\nFIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。\n\n\n\n为什么需要 TCP 协议？ TCP 工作在哪一层？\nIP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。\n如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。\n因为 TCP 是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。\n什么是TCP\nTCP 是面向连接的、可靠的、基于字节流的传输层通信协议。\n\n面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；\n可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；\n字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃\n\n什么是TCP连接\n用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。\n\n所以我们可以知道，建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。\n\nSocket：由 IP 地址和端口号组成\n序列号：用来解决乱序问题等\n窗口大小：用来做流量控制\n\n如何唯一确定一个TCP连接\nTCP 四元组可以唯一的确定一个连接，四元组包括如下：\n\n源地址\n源端口\n目的地址\n目的端口\n源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。\n源端口和目的端口的字段（16 位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。\n\n服务端通常固定在某个本地端口上监听，等待客户端的连接请求。\n客户端 IP 和端口是可变的，其理论值计算公式如下:最大TCP连接数=客户端ip数*客户端端口数\n对IPv4,IP数最多为2的32次方,端口数最多为2的16次方.所以总共是2的48次方\n但是服务端最大并发TCP连接数实际上是存在上限的,并不能达到理论最大值.\n\n文件描述符限制，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：\n\n系统级：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看；\n用户级：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看；\n进程级：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看；\n\n\n内存限制，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。\n\nUDP和TCP的区别\nUDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。\nUDP 协议真的非常简，头部只有 8 个字节（64 位），UDP 的头部格式如下\n\n目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。\n包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。\n校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP 包。\n\nTCP 和 UDP 区别：\n1. 连接\n\nTCP 是面向连接的传输层协议，传输数据前先要建立连接。\nUDP 是不需要连接，即刻传输数据。\n2. 服务对象\nTCP 是一对一的两点服务，即一条连接只有两个端点。\nUDP 支持一对一、一对多、多对多的交互通信\n3. 可靠性\nTCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。\nUDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议\n4. 拥塞控制、流量控制\nTCP 有拥塞控制和流量控制机制，保证数据传输的安全性。\nUDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。\n5. 首部开销\nTCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。\nUDP 首部只有 8 个字节，并且是固定不变的，开销较小。\n6. 传输方式\nTCP 是流式传输，没有边界，但保证顺序和可靠。[在逻辑上,可能发生粘包或拆包,发送次数与接收次数无关,程序员必须自己规定消息结束符来区分消息]\nUDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。\n\n7. 分片不同\n\nTCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。\nUDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。\n\nTCP 和 UDP 应用场景：\n由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：\n\nFTP 文件传输；\nHTTP / HTTPS；\n\n由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：\n\n包总量较少的通信，如 DNS 、SNMP 等；\n视频、音频等多媒体通信；\n广播通信；\n\n\n为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？\n原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。\n\n\n为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？\n\n先说说 TCP 是如何计算负载数据长度：\n\n其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。\n大家这时就奇怪了问：“UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算呀？ 为何还要有「包长度」呢？”\n这么一问，确实感觉 UDP 的「包长度」是冗余的。\n我查阅了很多资料，我觉得有两个比较靠谱的说法：\n\n第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 4 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 4 字节的整数倍，才补充了「包长度」字段。\n第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。\n\nTCP 和 UDP 可以使用同一个端口吗？\n答案：可以的。\n在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。\n所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。\n传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。\n当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。\n\n因此，TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。\n关于端口的知识点，还是挺多可以讲的，比如还可以牵扯到这几个问题：\n\n多个 TCP 服务进程可以同时绑定同一个端口吗？\n重启 TCP 服务进程时，为什么会出现“Address in use”的报错信息？又该怎么避免？\n客户端的端口可以重复使用吗？\n客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？\n\n上面这些问题，可以看这篇文章：TCP 和 UDP 可以使用同一个端口吗？\nTCP连接建立\n三次握手\nTCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：\n\n\n一开始,客户端和服务端都处于close状态,先是服务端主动监听某个端口,处于listen状态\n客户端会随机初始化序列号client_isn,然后SYN置1,组成一个SYN报文,发送给服务端,表示发起连接.该报文不包含应用层数据\n\n发送报文后,客户端处于SYN-SENT状态\n\n\n服务端收到客户端的SYN报文之后,服务端也随机初始化自己的序列号(server-isn),确认应答号位置填入client_isn+1,然后ACK和SYN都置1:表示确认应答位有效&amp;&amp;希望建立连接.然后把报文发送给客户端,该报文也不包含应用层数据,之后服务端处于SYN-RCVD状态\n客户端上收到服务端报文之后，还需要向服务端回应最后一个应答报文,首先该应答报文TCP首部ACK标志位置为1,其次,确认应答号字段填入server_isn+1.然后发送.这次报文可以携带客户端到服务端的数据了,之后客户端处于established状态\n服务端收到之后,也进入established状态.此时连接建立完成,客户端和服务端可以相互发送数据了\n\n第三次握手是可以携带数据的，前两次握手是不可以携带数据的\n只有第一个报文不需要ack置1,其他都需要置1.syn是前两个报文需要置1.\n\n\n                  \n                  为什么是三次握手 \n                  \n                \n\n重要的是为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接。\n\n避免历史连接\n如果收到了过期的旧请求,再返回一个包确认是否是正确的(用client_isn+1),客户端发现是错误的之后,就会发一个取消指令,连接就不会成立\n防止资源浪费\n如果SYN在网络中阻塞了,客户端没收到ACK报文就会一直重复发送SYN,然后服务器收到了多个请求,会问是否确认要连接,只有确认之后才会分配资源.不然的话就会根据多个SYN建立多个连接,浪费资源.\n同步序列号\n必须都知道对方的起始序列号,交流才不会乱\n起始序列号-确认.起始序列号-确认 这样三次.\n\n\n\n查看TCP状态\nTCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。\n\n为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？\n主要原因有两个方面：\n\n\n为了防止历史报文被下一个相同四元组的连接接收（主要方面）\n\n\n为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；\n\n\n客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。\n\n\n紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；\n\n\n在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。\n\n\n\n这里的核心在于 一个数据包被阻塞了 以至于发出的时候,他还在上一个连接里,被收到的时候,已经是下一个新的连接了.\n\n初始序列号 ISN 是如何随机产生的？\n起始 ISN 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。\nRFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。\n\nM 是一个计时器，这个计时器每隔 4 微秒加 1。\nF 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。\n可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。\n\n\n就是根据时间和四元组生成的.\n\n既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？\n我们先来认识下 MTU 和 MSS\n\n\nMTU：一个网络包的最大长度，以太网中一般为 1500 字节；\nMSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；\n\n如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？\n当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送[这里是说,算上自己的ip头之后]，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。\n这看起来井然有序，但这存在隐患的，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。\n因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。\n当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。\n因此，可以得知由 IP 层进行分片传输，是非常没有效率的。\n所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。\n发送方会按照按照接收方告知过来的mss来发送.经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。\n握手丢失了，会发生什么？\n谁的数据包没被确认,谁就负责重传.\n1.第一次握手丢失了,那么出发超时重传.达到最大重传次数之后,放弃连接.\n2.第二次握手丢失了,因为同时也是对第一次握手的确认,所以两边的都会重传.同样是达到最大重传次数之后放弃\n3.第三次握手丢失,但是ACK报文本身不会重传.因为服务端还在等ACK,超时未收到,会以为是第二次握手发的报文对方没有收到,所以会重传SYN-ACK,然后客户端收到之后,知道自己上一次发的ACK丢了,于是再次发送ACK,也是看服务端的最大重传次数\n什么是 SYN 攻击？如何避免 SYN 攻击？\n我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的半连接队列，使得服务端不能为正常用户服务。\n在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：\n\n半连接队列，也称 SYN 队列；\n全连接队列，也称 accept 队列；\n我们先来看下 Linux 内核的 SYN 队列（半连接队列）与 Accpet 队列（全连接队列）是如何工作的？\n正常流程：\n当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；\n接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；\n服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；\n应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接对象。\n\n不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。\nSYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。\n避免 SYN 攻击方式，可以有以下四种方法：\n\n调大 netdev_max_backlog；\n增大 TCP 半连接队列；\n开启 tcp_syncookies；\n减少 SYN+ACK 重传次数\n\n\n方式一：调大 netdev_max_backlog\n\n当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：\nnet.core.netdev_max_backlog = 10000\n\n\n方式二：增大 TCP 半连接队列\n\n增大 TCP 半连接队列，要同时增大下面这三个参数：\n\n增大 net.ipv4.tcp_max_syn_backlog\n增大 listen() 函数中的 backlog\n增大 net.core.somaxconn\n\n\n方式三：开启 net.ipv4.tcp_syncookies\n开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。\n\n\n具体过程：\n\n当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 cookie 值；\n将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；\n服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。\n最后应用程序通过调用 accpet() 接口，从「 Accept 队列」取出的连接。\n\n可以看到，当开启了 tcp_syncookies 了，即使受到 SYN 攻击而导致 SYN 队列满时，也能保证正常的连接成功建立。\nnet.ipv4.tcp_syncookies 参数主要有以下三个值：\n\n0 值，表示关闭该功能；\n1 值，表示仅当 SYN 半连接队列放不下时，再启用它；\n2 值，表示无条件开启功能；\n\n那么在应对 SYN 攻击时，只需要设置为 1 即可。\n$ echo 1 &gt; /proc/sys/net/ipv4/tcp_syncookies\n\n\n方式四：减少 SYN+ACK 重传次数\n\n当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。\n那么针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。\nSYN-ACK 报文的最大重传次数由 tcp_synack_retries内核参数决定（默认值是 5 次），比如将 tcp_synack_retries 减少到 2 次：\n连接断开四次挥手\n双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：\n\n\n客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。\n服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。\n客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。\n等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。\n客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态\n服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。\n客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。\n\n你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。\n这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。\n关于FIN_WAIT_2状态\n\n这是第二次挥手后，客户端等待服务端发 FIN 的状态。\n如果用 close() 关闭： 受 tcp_fin_timeout (默认 60s) 控制。超时没收到第三次挥手，内核直接关连接。\n如果用 shutdown() 关闭： 不受 tcp_fin_timeout 控制。如果服务端一直不发第三次挥手，客户端会一直死等在 FIN_WAIT_2，可能导致内存泄漏。\n\n为什么挥手需要四次\n再来回顾下四次挥手双方发 FIN 包的过程，就能理解为什么需要四次了。\n\n关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。\n服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。\n\n从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。\n挥手丢失了会发生什么\n\nACK报文永远不会被重传\n谁发的FIN,谁负责重传.\n\n如果Fin报文丢失了,发送方会触发超时重传\n如果ACK报文丢了,FIN的发送方会以为自己发的Fin对方没有收到,所以还是自己重传\n\n\n重传次数控制在一定次数内,超过了会放弃\n\n1.第一次fin丢失,客户端重传\n2.第二次服务端发ack丢失,客户端重传fin\n3.第三次服务端fin丢失,服务端重传\n4.第四次客户端发ack丢失,服务端重传fin.客户端收到重传的fin之后,重置2MSL定时器并再次发送ACK\n为什么是 2MSL\n只有主动关闭连接的那一方(通常是客户端)才会进入TIME_WAIT\n\nMSL是报文在网络中最长的生存时间\n两倍:允许报文一去一回.既要保证最后的ACK能够传给对方,也要允许对方重传的Fin能传回来.\nLinux 硬编码 MSL = 30秒。,因此两倍就是60s,不可以动态修改.如果在等待期间收到了服务器重传的fin,定时器会重置,重新计时\n\n为什么需要TIME_WAIT状态\n\n防止历史连接中的数据，被后面相同四元组的连接错误的接收,是随机序列号的更进一步保障.\n保证「被动关闭连接」的一方，能被正确的关闭；假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文,比较不优雅\n\nTIME_WAIT 过多有什么危害？\n过多的 TIME-WAIT 状态主要的危害有两种：\n\n第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；\n第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。\n客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。\n如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。\n因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务端建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务端建立连接了。\n\n不过，即使是在这种场景下，只要连接的是不同的服务端，端口是可以重复使用的，所以客户端还是可以向其他服务端发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。\n如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。"},"课程笔记/计算机网络/期末复习-大题":{"slug":"课程笔记/计算机网络/期末复习-大题","filePath":"课程笔记/计算机网络/期末复习-大题.md","title":"期末复习-大题","links":[],"tags":[],"content":"距离向量路由算法(DV算法\n总距离 = 到邻居的距离 + 邻居到目的地的距离\n路由表只要根据接收到的新信息,去选择下一条是哪个路由器的时候,代价最小就可以.如果不是邻居,就不考虑.只要信任邻居发来的信息就可以\n192.168.10.0/24进一步划分成四个等长的子网:\n这个时候前24位是网络号,后八位是主机号.要分四个子网,我们需要从8位主机号里面分2位出来 子网掩码就变成了前26位1\n11000000: 192\n所以十进制掩码就是255.255.255.192\n将256个地址平均分成4份的话,每个子网都要有64个地址,然后需要2位表示子网.也就是2的六次方=64(注意这里是000000111111 确实是2的六次方-1+1哈.)\n针对第四个子网而言,网络地址是192.168.10.192 (也就是该段的第一个地址,代表身份)\n广播地址是192.168.10.255 该段的最后一个地址 用于广播\n掐头去尾,就可以得到193254 是可以用于标志主机的\n网络配置分析与NAT\nOSPF开放最短路径优先是一种让路由器自动计算“怎么走最近”的协议.不是靠邻居之间传递,而是把全网的地图都下载下来，然后用最短路径算法（Dijkstra 算法）自己算出最优路线。\n它不看跳数，它看的是带宽（Cost，代价）。路越宽、网速越快，代价越低。\n==AD 管理距离,是一个可信度指标,OSPF 的默认可信度数值是 110==\nNAT\nNAT网络地址转换,因为全球的公网 IP 不够用了，所以大家在家里、公司里都用内网 IP，出门时统一由路由器转换成公网 IP。\n\n内网 IP（192.168.x.x）： 就像公司内部的分机号，在外面是打不通的，也没法直接上网。\n公网 IP（203.0.x.x）： 就像公司的总机号码，全球唯一，可以上网。\n然后路由器还会记录一个NAT转换条目表,以便于服务器回应的时候可以送达.\n\nOSPF选routerid的顺序是\n1.手动指定\n2.loopback虚拟接口地址中的最大值\n3.物理接口地址中的最大值\n源ip:端口 目的地ip:端口\n经过路由器转换后,将源ip改成路由器自己的公共ip,源端口改成分配的新端口,目的地不变,\n路由器:ip层 负责找路 3\nswitch 能看懂mac地址 是数据链路层设备 2\nhub集线器 只负责把电流传给所有人物理层设备 1\n网络设备cisco\n\nip route &lt;目标网段&gt; &lt;掩码&gt; &lt;下一跳IP或出接口&gt;\n\n作用： 配置静态路由。告诉路由器去往某个网络该怎么走。\n\n\nredistribute &lt;协议&gt; &lt;参数&gt; subnets\n\n路由重分发。将一种路由协议学习到的路由注入到另一种协议中（例如将 OSPF 的路由引入到 BGP 中）。subnets 关键字通常用于 OSPF，表示包含子网。\n\n\n\n\nospf和bgp协议:\n\nOSPF 协议 (内部网关协议)\n\nrouter ospf &lt;进程号&gt;\n\n作用： 启动 OSPF 路由进程。\n\n\nnetwork &lt;网络号&gt; &lt;反掩码&gt; area &lt;区域号&gt;\n\n作用： 宣告网络。告诉 OSPF 在这个接口上运行，并将其所属的网段通告给邻居。注意这里通常用通配符掩码（反掩码）。\n\n\narea &lt;ID&gt; virtual-link &lt;Router-ID&gt;\n\n作用： 配置 OSPF 虚链路。当非骨干区域（非 Area 0）无法直接物理连接到骨干区域时，通过此命令逻辑连接。\n\n\n\nBGP 协议 (边界网关协议)\n\nrouter bgp &lt;AS号&gt;\n\n作用： 启动 BGP 路由进程。AS 是自治系统号。\n\n\nnetwork &lt;网络号&gt; mask &lt;掩码&gt;\n\n作用： 在 BGP 中通告路由。注意 BGP 通常使用正掩码。 注意这里是子网！！！\n\n\nneighbor &lt;IP地址&gt; remote-as &lt;AS号&gt;\n\n作用： 指定 BGP 邻居的 IP 和所在的自治系统号，建立对等体关系。通常ebgp用端口ip ibgp用loopback\n\n\nneighbor &lt;IP地址&gt; update-source &lt;接口&gt;\n\n作用： 指定建立 BGP 邻居连接时使用的源接口。通常在建立 iBGP 邻居时，建议使用 Loopback 接口作为源，以保证连接稳定性。。就是说，设置ibgp是相互的\n\n\n\nloopback\n\n这个虚拟接口非常的稳定，因此routeid一般也会选用这个 因为其他接口有可能发生改变那要重新选routeid就不方便了。\nbgp配置的时候建邻居也最好用loopback建，\n\nrouteid\n用来标识节点身份\n用来选班长副班长\nas路由跳数\n\nospf默认是看带宽的,带宽越大，cost越小，就选这条。\n\n\nFastEthernet (f0/0, f0/1) 的带宽通常是 100 Mbps，OSPF Cost 是 1\nSerial (s2/0) 的带宽（默认 T1 标准）通常是 1.544 Mbps，OSPF Cost 是 64\n\n配置题\n二层交换机是用来连接同一个子网内的设备的.核心任务是隔离不同vlan.[负责把同一个 VLAN 里的电脑连起来，不同 VLAN 之间是绝缘的。]\n\naccess 当电脑插到一个 Access VLAN 10 的口上，交换机就给它打上“我是 VLAN 10”的标签.这是进入vlan的大门,如果没有access,那是真的进入不了网络\ntrunk 是不同交换机之间的运输管道，它保证 VLAN 10 的数据传过去还是 VLAN 10，绝不让它变成 VLAN 20。如果没有开 Trunk，只用一根网线连接两台交换机，那么这条线上只能跑 1 个 VLAN 的数据[默认是vlan1]。其他 VLAN 的数据根本过不去，直接被丢弃。\n路由（路由器/三层交换机）： 只有它们才有能力把 VLAN 10 的数据拿出来，修改标签，转发给 VLAN 20。这叫“三层转发”。\n\nvlan主要是在交换机上配,路由器和服务器也可以配.\n一般配置trunk的情况就是 两台交换机之间,或者一台交换机连以台路由器(单臂路由).总之trunk就是用于通过多个vlan的线路.\naccess就是连接交换机和普通终端的,对他做一个vlan的改造.\n\nABR与area\nABR是在两个area之间的区域边界路由器 area border router\n普通的路由器只属于一个区域,脑子里只有一张地图.ABR必须同时连接骨干区域和一个或者多个非骨干区域,\n脑子里维护着多个完全隔离的数据库LSDB\n关键任务是生成LSA  ABR会阅读area1的所有精确的拓扑信息,然后计算出所有网段的路由,生成Network Summary LSA 发送给Area0 ,就是打包汇总\n虚链路: 原则上所有非骨干区域都要连接到骨干区域,把骨干区域作为中转,不允许非骨干区域自己连通.如果area2到不了area0,那就在area1之间打一个虚拟链路去连接.配置之后,area1中间的路由器只负责转发数据包,而感觉不到这条链路的存在,对于area2来说就相当于直连了area0\n\n要在中间穿越区域的两端路由器上配置\n\n\nR1：连接 Area 0 和 Area 1（Router ID: 1.1.1.1）\nR2：连接 Area 1 和 Area 2（Router ID: 2.2.2.2）\n中间区域：Area 1\n目标：让 R2 穿过 Area 1 连上 Area 0。\n\n\n2. 为什么“直连”可以，“传话”就不行？\n我们回到你的那个链条模型： Area 0 (北京) &lt;---&gt; ABR1 (你的角色) &lt;---&gt; Area 1 (河北) &lt;---&gt; ABR2 &lt;---&gt; Area 2 (内蒙)\n你是 ABR1。你连接着 Area 0 和 Area 1。\n情况 A：把 Area 1 (河北) 的事告诉 Area 0 (北京)\n\n你的视角：因为你的一只脚就在河北（Area 1），你手里拿着的是河北的原始高清地图（1类、2类 LSA）。\n动作：你看着原始地图，亲自写了一份简报（3类 LSA），递交给 Area 0。\n结论：这是允许的。因为是你**“亲眼所见、亲自总结”**的。\n\n情况 B：把 Area 2 (内蒙) 的事告诉 Area 0 (北京)\n\n你的视角：你并不连接内蒙。你是听 ABR2 告诉你的。ABR2 在 Area 1 里发了一条简报（3类 LSA）说：“我有路去内蒙”。\n动作：这时候，你作为 ABR1，在 Area 1 这一侧收到了这条简报。\nOSPF 的死规矩（LSA 转换规则）：\n\nABR 只负责把“原始地图（1类/2类）”转换成“简报（3类）”。 ABR 绝不负责把“别人的简报（3类）”再次转发给 Area 0。\n这就是问题的关键！简报（3类 LSA）不能二手转发进骨干区域。\n\n\n\n下一跳（Next Hop）永远是写“对方路由器的接口 IP 地址”（端口 IP）\nIPv6\n\n以这个为例，前80位是网段号，后48位是主机号。总共128位：\n16禁止，一共8组数字，每组4个16进制数。\n2001 : 0db8 : 0000 : 0000 : 0000 : 0000 : 1428 : 57ab\n每组开头的 0 可以省略，但中间和结尾的不能省。\n\n0064 → 简写为 64\n0db8 → 简写为 db8\n0000 → 简写为 0\n规则二：连续的一串 0，可以用双冒号 :: 代替**\n如果有一连串的 0000:0000:0000，你可以直接把它们压缩成一个 ::。\n注意： 整个地址里只能出现一次 ::（否则路由器不知道你在两个 :: 里分别藏了几个 0）。\n\n默认情况下，BGP根据什么条件决定最佳路由︖\n在默认配置下,BGP最核⼼的判断条件是AS_PATH也就是AS路径长度,BGP会优先选择AS跳数最少的路径,如\n果AS路径长度相同,后续会依次⽐较其他属性.\n看路由表\n\n路由器优先级是由管理距离AD决定的。数值越小"},"课程笔记/计算机网络/期末复习-总纲":{"slug":"课程笔记/计算机网络/期末复习-总纲","filePath":"课程笔记/计算机网络/期末复习-总纲.md","title":"期末复习-总纲","links":[],"tags":[],"content":"大题\n\nIP地址划分、子网掩码与路由聚合 (CIDR)：\n    ◦ 考点：子网划分计算（已知主机数求掩码） CIDR路由聚合、路由表最长前缀匹配（Next Hop选择）\n    ◦ 难点：多级路由表聚合、子网容纳主机数计算（2n−2原则）\nTCP 拥塞控制与窗口管理：\n    ◦ 考点：慢启动 (Slow Start)、拥塞避免 (Congestion Avoidance)、快重传/快恢复 (Tahoe vs Reno)、滑动窗口大小计算（接收窗口与拥塞窗口取最小值）。\n    ◦ 难点：超时或收到重复ACK后阈值 (ssthresh) 和窗口值的动态变化曲线。\n路由算法计算：\n    ◦ 考点：距离向量路由 (Distance Vector) 的更新（Bellman-Ford公式）、链路状态路由 (Link State/OSPF)。\n    ◦ 难点：DV算法中的“坏消息传得慢”问题及其收敛过程计算。\nCSMA/CD 与 以太网性能：\n    ◦ 考点：最小帧长计算（Lmin​=2×RTT×Bandwidth）、有效数据传输速率计算、二进制指数退避算法。\n    ◦ 难点：考虑传播延迟和确认帧后的有效吞吐量计算。\n\n高频选择判断\n\n物理层基础计算：\n    ◦ 考点：奈奎斯特准则 (Nyquist) 无噪声带宽计算、香农公式 (Shannon) 有噪声信道容量、分贝 (dB) 转换。\n    ◦ 注意：若两个公式都可用，取计算结果中较小的一个。\n数据链路层差错控制：\n    ◦ 考点：循环冗余校验 (CRC) 编码与校验过程、海明码 (Hamming Code) 纠错位数计算。\nTCP 连接管理与状态机：\n    ◦ 考点：三次握手（SYN, ACK序号变化）、四次挥手、各阶段状态名称（ESTABLISHED, TIME_WAIT等）。\n应用层协议细节：\n    ◦ 考点：HTTP 状态码（200, 404, 500）、Cookies、持久/非持久连接；DNS 记录类型（A, MX, CNAME）；SMTP/POP3/IMAP 端口号及功能。\n\n低优先级\nP3：低优先级（记忆性知识，基础补充）\n\n网络分层模型：OSI七层与TCP/IP四层/五层模型、各层PDU名称（段、包、帧、比特）、Headers的添加/删除方向。\n网络安全：对称密钥 vs 公钥 (RSA)、数字签名 (Message Digest)、CA 证书验证逻辑、SSL/TLS 握手。\n协议辅助工具：ARP、ICMP（Ping/Tracert）、DHCP、NAT 转换表。\n\n面试导向\n1. TCP/IP 协议栈（重中之重）\n\n三次握手 &amp; 四次挥手：\n\n考点： 为什么要三次？为什么要四次？\n状态机： TIME_WAIT 和 CLOSE_WAIT 状态的区别和产生原因。（这是后端排查服务器连接泄露问题的核心）\nGo 关联： 当你写 defer conn.Close() 时，底层发生了什么？\n\n\nTCP 可靠性保障：\n\n考点： 滑动窗口（流量控制）、拥塞控制（慢启动、拥塞避免、快重传、快恢复）。\n黏包/拆包问题： 为什么会发生？如何在应用层解决（如设计由 Header+Body 组成的协议）？\n\n\nTCP vs UDP：\n\n区别是什么？什么场景用 UDP（直播、HTTP/3、QUIC）？\n\n\n\n2. HTTP 协议\n\nHTTP 版本演变：\n\n1.0 vs 1.1： 长连接 (Keep-Alive)。\n1.1 vs 2.0： 多路复用 (Multiplexing)、头部压缩、服务端推送。Go 的 gRPC 基于 HTTP/2，所以 2.0 的特性必考。\nHTTP/3 (QUIC)： 基于 UDP 解决了 TCP 的队头阻塞问题。\n\n\nHTTPS：\n\nTLS/SSL 握手过程： 对称加密 vs 非对称加密在握手中是如何配合的？CA 证书的作用。\n\n\nGET vs POST： 幂等性、安全性、传参方式的区别。\n\n3. 常见网络攻击\n\nDDoS、SYN Flood（半连接队列）、XSS、CSRF。\n"},"课程笔记/计算机网络/期末复习-选择":{"slug":"课程笔记/计算机网络/期末复习-选择","filePath":"课程笔记/计算机网络/期末复习-选择.md","title":"期末复习-选择","links":[],"tags":[],"content":"chapter1 intro\nOSI\ncentralconcepts\nservices 下层为上层提供的服务\ninterfaces 上下层之间沟通的接口\nprotocols 同一层之间沟通的协议\n\n物理层 (Physical): 比特 (Bits)、网线、光纤。传的是原始的比特流（010101），因为电缆可能会有干扰，传过来的数据可能是乱的（有噪声）。\n数据链路层 (Data Link): 帧 (Frames)、MAC 地址、相邻节点传输、差错检测。负责把这些比特打包成 帧 (Frame)，并进行差错检测（比如 CRC 校验）。如果发现错了，它可能会要求重传或者丢弃，从而给上层提供一个相对靠谱的链路\n网络层 (Network): 包 (Packets)、IP 地址、路由 (Routing)、源到目的。\n传输层 (Transport): 段 (Segments)、端口号、端到端 (End-to-End)、可靠性 (TCP)。\n会话层 (Session): 会话管理 (建立/断开连接)。\n表示层 (Presentation): 语法与语义 (Syntax &amp; Semantics)、加密、压缩、格式转换。\n应用层 (Application): 用户接口、HTTP、Email。\n失败原因：timing technology implementations politics\n主要是复杂性 时机和生态 和price没关系\n\n\nqueuing delay 数据包在路由器里排队等待处理的时间，排队延迟，并不是传输机制\nstore and forward transmission 现代分组交换网络最核心的工作机制\npacket switching 把数据切成packet来传，分组交换网络通常使用存储转发。\npropagation 传播 信号在电线、光纤里跑的时间\n\nEncapsulation\n每层进行封装\nchapter2物理层\n多路复用技术\nFDM frequency division multiplexing 频分复用\n收音机 simultaneous different frequencies复用不同频率\nTDM 时分复用 time 大家共用全部带宽 但是必须轮流讲\nWDM波分服用 专指光信号在光纤中传播。\nCDM (码分复用) 用数学编码区分，大家同时同频说话，但只有特定的解码器能听懂。\n计算channel capacity/maximum data rate\nnyquist 无噪声 或者给了信号级数(如果有16级 就要用4位来表示)\n数据传输率=2B(带宽)*log2V\n香农定理shannon\nC = B \\times \\log_2(1 + S/N) 这里是信噪比\nM是10的6次方\n\n分贝:db=10log10s/n 就是说 如果给了db=30 那么log10s/n就是3 s/n就是一千\n分组交换\n电路交换 老式电话网 打电话前先拨号建立线路\n报文交换 电报时代的产物,整个报文发到中转站,存下来再发给下一站\n数据链路层协议:\n\nHDLC high-level data link control 广域网点对点连接 数据链路层\nSDLC 一般有DLC的都是datalink control\nPPP 属于数据链路层 pointtopoint\n\n网络层:\nIP/ICMP/ARP\n最著名的就是ping命令,是被封装在ip包里的\n信道的数据传输速率也就是capacity (数字带宽就是datarate传输速率,模拟带宽是频带宽度hz)\n一秒钟能并行通过多少辆车（吞吐量/速率） 是由车道数量决定的，而不是车速决定的。\nV (Level) 或 Modulation rate: 调制速率（波特率），它决定了每秒能变多少次，进而影响能传多少 bit\nWhich one can be used as a key component of optical transmission system? 光传输系统的关键组件\nUDP unshielded twistedpair 非屏蔽双绞线 普通网线 电信号\nsemiconductor laser device 半导体激光器才可以发送光源\nHUB 网络连接设备 电信号\nwifi router 无线电设备 发送的是无线电波\nThe Public Switched Telephone Network\nPSTN\nlocal loop 本地回路 连接你家和最近的电话局 铜线 (Twisted Pair) 是有线的\n”Toll office” 和 “End office” 端局就是离你最近的电话局 toll就是汇接局,连接不同电话局的 中间是trunk中继线\n有线的损伤:\nDifferent Fourier components propagating at different speed 不同频率传播速度不同,叫做distortion失真\nthermal noise 热噪声所有电子设备和电线都有这个问题 只要有温度电子就会产生噪音\nCrosstalk between two close wires 线间串扰 也是双绞线感应的问题\n无线:\nmultipath fading 多径衰落\\阴影效应\n载波计算\nT1channel是北美和日本使用的数字通信标准 24复用路数,每路8bit*24路 192bits 每帧加一个bit用来同步 193bits 然后每秒要传8000帧,1.544 Mbps\n中国用的是E1 2.048Mbps\n一路PCM信号的速率是4kbps 也叫DS0\n2.5 Gbps: 光纤网络（如 OC-48）的速率级别\nchapter3 数据链路层\n比特填充\nHDLC (High-Level Data Link Control - 高级数据链路控制) 协议中的透明传输机制\n在 PPP 标准帧中：\n\nAddress 永远是 0xFF (表示广播/所有人)。\nControl 永远是 0x03 (表示无编号帧)。\n所以这两个字段是可以省略的\n\nCRC 循环冗余校验\n注意是异或除法!而且是首位1就可以\nVLAN的构建方法\n\n基于端口\n基于mac地址\n基于网络层协议,比如：“所有发 IPv4 协议的包去 VLAN 10，发 IPv6 协议的包去 VLAN 20”。\n\n海明码\n\n（纠错半径 t=3）： 我最多只能错 3 位，再错我就回不来了。\\rightarrow 这叫纠错能力，也就是“安全半径”。\n书上的定义（最小距离 d=7）： 为了让你错 3 位还能找回来，正确的答案 A 和 正确的答案 B 之间，必须至少隔开 7 步远。 这里需要+1\n然后能检错的位数就是距离-1\n\nGBN\n回退N   其中 N 代表 sending window 的大小，而这种协议中 receiving window 的大小始终为 1\n发送窗口必须比序号总数(2的n次方)少 1 这样能保证序号不重复.因为你发完一轮的下一个发0 和ack丢了导致需要重传0会重复.\n选择重传协议SR\n通常在选择重传协议中，为了效率最大化，发送窗口和接收窗口的大小是相等的，\n接收窗口的大小不能大于 序号总数 2n次方/ 2。\nPiggybacking\nchapter4 网络层\n通过单个新路由器连接的主机\nhub 啥都隔离不了 冲突域相同 广播域相同\n交换机 隔离冲突 冲突域不同（每个端口独立）（广播域相同（能广播的范围是一样的）\n路由器 冲突域不同（每个端口独立） 广播域不同（只能在一个网络内广播 不同网络广播包就会隔离）\n发送方发送了帧0~8 然后结束的时候收到了对帧135的确认 假设是回退n 且确认号表示最后一个正确接受收的帧号，那么重传的下一帧是6 发送678\n无线网络不用cd了,因为无线信号衰弱大,自己听自己的声音太大,会检测不到冲突.因此 会导致隐蔽战问题 hidden terminal AC都发给B,但是AC互相听不见就会在B处撞车.暴露战问题 Exposed terminal B发给A C听到了不敢发给D 其实不影响的\nCSMA/CA是碰撞避免. 既然检测不到冲突就避免冲突\nRTS/CTS\nRTS = Request To Send A 说：“我要发了，长度是 X” (RTS)。\nCTS = Clear To Send B 说：“好的，你发吧，长度是 X” (CTS)。\n周围的人（包括隐蔽站）听到 RTS 或 CTS，都知道由于长度 X，这段时间不能说话（NAV 倒计时）。\n\n如果 X 收到了 A 的 RTS，说明 X 在发送方 A 的附近。虽然 X 可能干扰不到接收方 B，但为了让 A 能顺利收到 B 回复的 CTS，X 应该闭嘴。而且 RTS 里包含了 NAV（网络分配矢量(Network Allocation Vector），告诉周围人“我要占线多久”，听到的人都得更新 NAV 并保持沉默。\n如果 X 收到了 RTS，但没收到 CTS，那么 X 可以发送数据.有争议但理论上可行的场景…X 听到了 A 的 RTS（X 靠近 A），但没听到 B 的 CTS（X 远离 B）这意味着：X 发送数据不会干扰到 B 的接收（因为离得远）。虽然标准协议通常比较保守（听到 RTS 就设 NAV），但在理论分析中，X 确实可以发送数据而不产生冲突。这个选项通常被认为是描述 CSMA/CA 在理想状况下试图解决的问题，或者至少它不是最明显的错误。\n如果 X 没收到 RTS，但收到了 CTS，那么 X 不可以发送数据- 说明 X 在接收方 B 的附近（是 B 的邻居）。 B 马上就要接收数据了。如果 X 这时候说话，信号会直接覆盖掉 A 发给 B 的数据，导致 B 接收失败（这就是隐蔽站干扰）。\n\nVLAN\n当交换机配置基于端口的vlan的时候\naccess线路下 一个物理端口在同一时间只能属于一个vlan 通过这个端口的会被打上vlan标签或者撕掉vlan标签 一般是pc到交换机之间\ntrunk线路就是允许各种vlan的标签通过 也不对vlan做修改.但是他本身也是只有一个vlan的\n交换机转发表\n【动作拆解 - 第 1 帧】：\n\nSource (源地址)： A1（在端口 1）。\nDestination (目的地址)： C1（在端口 3）。\nSwitch’s Reaction (交换机的反应)：\n\nLearning (学习)： 交换机收到帧，看到源 MAC 是 A1，是从 Port 1 进来的。于是它在转发表里记下一笔：A1 -&gt; Port 1。\nLookup (查表)： 交换机看目的 MAC 是 C1。去查表，发现 表中没有 C1 的记录（Unknown Unicast，未知单播帧）。\nForwarding (转发决策)： 因为找不到人，只能 泛洪 (Flood)\nResult (结果)： 帧被复制并发往除来源口（Port 1）以外的所有活动端口。即 Port 2, 3。\n【考试关键词解析】：\n\n\nConfirmation frame： 通常指 ACK 帧，反正就是回信。这意味着角色互换了：C 变成了发送方，A 变成了接收方。\n【动作拆解 - 第 2 帧】：\nSource (源地址)： C1（在端口 3）。\nDestination (目的地址)： A1（在端口 1）。\nSwitch’s Reaction (交换机的反应)：\n\nLearning (学习)： 交换机收到帧，看到源 MAC 是 C1，是从 Port 3 进来的。于是它在表里记下一笔：C1 -&gt; Port 3。（此时表里有 A, B, C 三个人了）。\nLookup (查表)： 交换机看目的 MAC 是 A1。去查表，发现 表中有 A1 的记录！\n\n为什么有？ 因为在“第二句”里，交换机刚刚通过 A 发来的帧学会了 A 在 Port 1。\n\n\nForwarding (转发决策)： 既然认识路，那就 单播 (Unicast)。\nResult (结果)： 帧只会被发往 Port 1。\n\n\n\nchapter5\nWhich is not the private address that will not appear in Internet datagram?“\nprivate address:\n\nClass A: 10.0.0.0 到 10.255.255.255\nClass B: 172.16.0.0 到 172.31.255.255 （注意这个范围！）\nClass C: 192.168.0.0 到 192.168.255.255\n这些范围以外的都是公网地址\n\nipv6地址格式\n\nIPv6 Address： 长 128 位。通常写成 8 组，每组 4 个十六进制数，中间用冒号 : 隔开。例如 ABCD:EF01:2345:6789:ABCD:EF01:2345:6789。\n压缩规则 (Zero Compression)： 如果有一串连续的 0，可以用双冒号 :: 代替，但只能出现一次。\n混合记法： IPv6 也可以兼容 IPv4 的写法，比如 ::192.168.0.1，这叫 IPv4-mapped IPv6 address。\n前96为0 后32位是ipv4\n\n路由协议\n下列都是动态的 dynamic routing protocol\nIGP interior gateway protocol 内部网关协议 在同一个自治系统AS内部使用的协议 包括\n\n\nrouting information protocol 路由信息协议 RIP\n\n\nOSPF\nEGP 外部网关协议\n\n\n距离向量:RIP的算法类型,通过跳数衡量距离 每隔30瞄把自己的整个路由表发给邻居\n\n\nlinkstate OSPF的算法类型 只发链路状态信息来画地图\n\n\n为了让数据包从一个 局域网 (LAN) 传输到 互联网 (Internet)，需要下列哪种设备？\nA. Bridge (网桥) / C. Switch (交换机) / D. Hub (集线器)：\n\n这三个都是 Layer 2 (数据链路层) 或 Layer 1 (物理层) 的设备。\n它们只认识 MAC 地址，只能在同一个网络内部倒腾数据。它们出不了“村”。\n\nrouter才可以连接不同的网络\n链路状态路由的特点\nLink-State (链路状态，如 OSPF)：\n\n每个人都画一张完整的地图（拓扑图）。\n路由器之间交换的是 LSA (链路状态通告)，即“我是谁，我邻居是谁，路费多少”。\n关键点： 我只告诉你我的局部信息，但我会把这个信息告诉全网所有人（泛洪）。\n\nDistance Vector (距离向量，如 RIP)：\n\n谣言路由： 我不画地图，我只听邻居说“去北京只要 3 跳”。\n关键点： 我把我的整个路由表（我知道的所有路）交换给我的邻居。\n\n第一步：打招呼 (Hello)\n刚开，路由器通过发 Hello 包 发现身边的直连邻居。\n结果：我知道谁在我隔壁，以及我和他之间的路况（Cost/Metric）。\n第二步：写日记 (LSA - Link State Advertisement)\n每个路由器写一张“小纸条”（这就是 链路状态通告 LSA）。\n内容：“我是路由器 X，我的邻居有 Y 和 Z，我和 Y 的距离是 10，和 Z 的距离是 5。”\n注意：我只描述我自己的局部视野。\n第三步：泛洪 (Flooding)\n最关键的一步！大家把自己的“小纸条”发给所有人。\n路由器收到别人的 LSA 后，先存一份，然后立即转发给它的邻居（除了发给它的那个）。\n结果：一传十，十传百，只要网络是通的，最终全网所有路由器都会收到所有其他人写的纸条。\n第四步：拼地图 (LSDB - Link State Database)\n每个路由器把收集到的成百上千张 LSA 汇总在一起，形成一个 链路状态数据库 (LSDB)。\n重点：此时，全网所有路由器的 LSDB 是完全一样的（也就是大家都拥有了同一份完整的网络拓扑图数据）。\n类比：每个人手里都拿到了同一个迷宫的完整图纸。\n第五步：算路径 (Dijkstra / SPF 算法)\n有了完整地图（LSDB），每个路由器以自己为根 (Root)，独立运行 Dijkstra 最短路径优先算法 (SPF)。\n计算出从“我”出发，去往网络中每一个节点的最短树。\n最后一步：把算出来的最优路径，填入自己的路由表。\nCIDR(Classless Inter-Domain Routing)无类别域间路由 是一种更灵活的ip地址分配和管理方法\n因为 CIDR 允许我们将很多零散的小网段，聚合 (Aggregate) 成一个大网段告诉全世界。\n\n它消灭了 A/B/C 类：不再看 IP 开头是几来判断类别。\n看掩码/斜线：掩码里有多少个 1（或者斜线后的数字是几），网络号长度就是多少位。\n举例： 如果不适用 CIDR，路由器可能需要记录 4 条路：\n\n\n去 192.168.0.0 的走左边\n去 192.168.1.0 的走左边\n去 192.168.2.0 的走左边\n去 192.168.3.0 的走左边\n有了 CIDR，路由器可以偷懒，把这 4 个 C 类合并成一条记录：\n\n\n“去 192.168.0.0/22 （涵盖了上面 4 个）的全都走左边。”\n\n最长前缀匹配原则 (Longest Prefix Match)\n\n这是路由器的核心法则：如果一个目的 IP 同时匹配了路由表中的多行，路由器会选择子网掩码最长（也就是掩码中 1 更多、网段范围更小更精准）的那一条路由。\n默认路由 0.0.0.0 的掩码长度为 0，是优先级最低的保底选项。\n\nARP是已知ip找mac RARP是反向arp 已知mac找ip\nTraceroute工具\nPath (路径) / Routers along the path\n设计用来查找从主机到目的 IP 地址的 路径上的路由器 (Routers along the path) 的？Traceroute工具\n利用的是IP头里的TTL生存时间,它先发一个 TTL=1 的包，第 1 个路由器收到后 TTL 减为 0，路由器报错“我死了”，发回一个 ICMP 包（暴露了第 1 个路由器的 IP）。- 再发 TTL=2，第 2 个路由器报错。\n\n以此类推，把沿途的路由器一个个“骗”出来。\n\nNetstate (应该是 Netstat)： 用来查看自己电脑上的网络连接状态（开了哪些端口）。\nIP协议特性:\nbest effort\nunreliable\nconnectionless\n尽力而为 不可靠(tcp负责)  ,无链接(tcp负责)\nip最大的本事就是路由\nchapter6\nUDP 性格： 它是一个 不可靠 (Unreliable)、无连接 (Connectionless) 的协议。\n总之什么都不用 什么都不保证\nTCP\n\nStep 1 (A → B): SYN=1, seq = x (这里 x=220)。\n\n意思：A 说“我想连你，我的起始序号是 220”。\n\n\nStep 2 (B → A): （本题考点！）\n\nFlags: 必须回应 SYN=1 (我也想连你) 和 ACK=1 (我收到你的请求了)。\nack (确认号): 必须是 A 的序号 + 1。\n\n公式：ack = x + 1\n计算：220 + 1 = 221。\n意思：“220 我收到了，下次请给我发 221”。\n\n\nseq (序号): B 自己的起始序号 y。通常是随机的。\n\n\nStep 3 (A → B): ACK=1, seq=x+1, ack=y+1。\n\n累计确认\n流量控制:滑动窗口\n\nTCP 头里有一个字段叫 Window Size (RWND, Receive Window)。\n接收方在给发送方回 ACK 的时候，顺便在头里带上：“我的缓存区还能装 X 个字节”。\n发送方看到后，就会控制自己：未确认的数据总量 ⇐ X。\n如果接收方缓存满了，它会发一个 Window Size = 0 的包，发送方就会暂停发送，进入等待状态（这就叫零窗口探测）。\n\n拥塞控制 congesion\n机制：发送方自己维护一个变量叫 CWND (Congestion Window)。发送方实际能发的窗口大小 = min(RWND, CWND)（取接收方能力和网络能力的最小值）。\n四个经典阶段 (Slow Start &amp; Congestion Avoidance)：\n\n慢启动 (Slow Start)：\n\n刚开始不知道路况，只发 1 个包。收到 ACK 后，发 2 个，再发 4 个，8 个…… 指数级增长。现象：窗口从 1 开始，指数级增长 (1, 2, 4, 8…)。\n逻辑：快速试探网络的底线。\n\n\n拥塞避免 (Congestion Avoidance)：\n\n当增长到一个阈值（ssthresh）后，改为线性增长（每次 +1）。\n逻辑：小心翼翼地增加，防止突然堵车。\n\n\n快重传 (Fast Retransmit)：\n\n如果发送方连续收到 3 个重复的 ACK（比如连续 3 次 ACK 200），说明 200 丢了，但网络没断（因为后面的 ACK 还能回来）。\n立即重传 200，不需要等超时定时器。\n\n\n快恢复 (Fast Recovery)：\n\n发生了快重传，说明网络有点堵，但没死透。于是把发送速度减半（而不是归零），然后继续线性增长。\n\n\n\n\n设定阈值 (ssthresh)：根据规则，阈值设为当前窗口的一半。\n\nssthresh = 18 / 2 = 9 KB。\n重置窗口：因为是超时，CWND 直接重置为 1 MSS。\nCWND = 1 KB。\n然后进入阶段：慢启动 (Slow Start)。\n\n\n序列号空间是基于字节的，而不是基于段的\nACK 只能确认“连续收到的最后一位”。\n比如100200丢了  200300收到了 那么接下来发的ack应该是=100的 因为只能确认前面100 不能确认到300\n\n原因：TCP 是 点对点 (Point-to-Point) 的协议。它必须在两个明确的 IP 和端口之间建立连接。\n广播（发给所有人）和组播（发给一组人）是 UDP 的特长，TCP 做不到。\n\n\nchapter7 应用层\nDNS\nDNS记录格式\nA记录 域名到ip地址\nTXT记录 域名到文本字符串\nSOA记录 起始授权机构 后面一大串参数\nMX记录 mail exchange 的标准格式必须包含一个优先级数字 IN MX 10 邮件服务器域名\nresolver 解析器\nclient\nlocal name server 本地域名服务器: 通常由你的 ISP（电信/移动）或者学校网络中心自动分配给你（比如浙大的 DNS），或者你自己指定的（比如 Google 的 8.8.8.8）。\nroot/TLDserver Top-Level Domain 根服务器和顶级域名服务器\nAuthoritative Name Server (权威名称服务器\n\n电脑内部解析器对localnameserver说 查询www.google.com 的 IP.这是recursive query\n然后localname server开始查询,\n这里是迭代的 虽然得知了信息 但下一个级别的dns还是需要local name server去询问\n\n找根服务器 然后从后面开始一部分一部分找:先找.com\n.com顶级域名服务器 找google.com\ngoogle.com的权威服务器:www.google.com的ip是xxxxxx\n\n然后localnameserver再返回给client 同时这个会被记在cache里面\n应用层协议及其对应端口号\n电子邮件类:\nSMTP simple mail transfer protocol 25 TCP 发邮件\nPOP3 post office protocol v3 110 TCP 收邮件特点是“下载并删除”（默认），对多设备同步不友好。\nIMAP internet message access protocol 143 TCP 收邮件特点是“同步”，邮件保存在服务器上，比 POP3 更强。\n远程连接类:\ntelnet telecommunication network 23 TCP 远程登陆明文传输（极不安全），密码会被截获。\nSSH (Secure Shell) 22 TCP 远程登录。加密传输（安全），它是 Telnet 的替代者。\n文件传输类\nFTP file transfer protocol 21/20 TCP传文件。注意它用两个端口！21是control 用来传指令 20是data专门传文件数据\nTFTP trivial FTP 69 UDP 简单文件传输 只传小文件不用握手\n网页与域名\nHTTP 80看网页。明文传输。\nHTTPS 443看网页（加密）。HTTP + SSL/TLS。\nDNS 53  UDP/TCP 查ip,域名解析  查IP。域名解析。通常查询用 UDP，主备服务器同步用 TCP。\n第 91 题：传输技术分为 Point-to-point (点对点) 和 Broadcast links (广播链路)。\n\n记忆点：这是物理层的分类，广播链路指共享介质（如 Wi-Fi、以太网）。\n\n\nARP 的归属层级：luxq 资料指出，ARP 最好被视为介于链路层和网络层边界的协议，但它为网络层提供服务。\nOSI 与 TCP/IP 的对比：OSI 参考模型网络层支持无连接和面向连接，但 TCP/IP 的互联网层仅支持无连接通信（IP协议）。\nSSH 端口误区：务必记住 SSH 是 22 端口，不要和 FTP 的 21 混淆。\nMIME 编码：Base64 编码是将每 24 位（3字节）分割为 4 个 6 位的单元，并映射为 ASCII 字符。\nHTTP 状态码：重点记住 200 (OK)、301 (永久重定向)、404 (找不到页面) 和 500 (服务器内部错误)。\n\nkeep track of a user and its related information by the Web server?”\n\nHTTP 协议本身是 无状态 (Stateless) 的。这意味着你请求了第 1 页，再请求第 2 页，服务器根本不知道你是同一个人。\n为了记住“你是谁”（比如保持登录状态、购物车里的商品），服务器会发给你一个小纸条，让你下次请求时带上。这个小纸条就是 Cookie。\n\n\nCookie 存在哪？：浏览器 (Client)。\nHTML标签语义\n\n\nHTTP是持久连接\n\n无状态 (Stateless)： 描述的是**“记忆能力”**（应用层逻辑）。\n持久连接 (Persistent Connection)： 描述的是**“传输通道”**（传输层/物理连接）。\n\ncontent delivery network\n\nchapter8 网络安全\n目标:保护以下的性质\n\n机密性 confidentiality 被截获\n完整性integrity 被篡改\n认证authentication 假身份\n\n块密码：\nAES DES老掉牙的对称加密\n工具 加密算法\n\n对称加密 symmetric encryption 快 但是有缺陷\n\n加密和解密用同一个密钥,常见算法是AESAdvanced Encryption Standard:块密码 block cipher 把数据切成一块一块做加密\n每一块独立加密:ECB 虽然解不开但是能看到图案和模式：如果两块一样 加密后也一样了\ncipher block chaining CBC 把前一块的加密结果混入下一块加密过程中\n因此:为了防止针对 ECB 的模式分析攻击，AES 必须配合 CBC 模式使用。\n\n\n非对称加密 public-key cryptography 安全但是慢 主要的算法是RSA 唯一的它是目前最流行的公钥加密算法。\n\n公钥 公开给所有人 用来锁 加密  或者验  验证签名\n私钥 用来开 解密Decrypt 或者签 数字签名\n\n\n\n证书体系\n办证 (Issue)：\n\n淘宝把自己的公钥交给 CA (权威机构)。\nCA 审核通过后，用 CA 的私钥 在淘宝的公钥上盖了个章（数字签名），生成了证书。\n你的浏览器访问淘宝，淘宝出示证书。\n浏览器怎么知道这个证书上的章是真的？\n浏览器内置了 CA 的公钥（操作系统自带）。\n浏览器用 CA 的公钥 去解密/验证那个数字签名。如果解开了，说明这个章确实是 CA 盖的，证书是真的。\n\n验证网站证书的真伪，是验证 CA 的签名，所以要用 CA 的公钥。\n时延相关\ntransmission delay 网卡把数据推到线路上的时间 是数据长度、带宽（datarate\npropagation delay 在物理介质里跑要花的时间\nT=物理距离/传播速度 跟数据包大小无关\nnslookup 查ip\ntracert  trace route\narp 查mac地址\nnetstat 查连接状态\n通信模式\n单播:一对一 unicasting\n广播 broadcasting\n组播/多播 multicasting 场景：比如看“IPTV 网络电视”或者“Zoom 分组会议”。只有加入了“体育频道组”的人能收到体育频道的视频流，不看的人收不到。既不是只发给一个人，也不是发给全网所有人，而是发给特定的一群人（子集）。\n支持向机器的一个子集subnet\n\nsocket\nprimitive原语\n阻塞调用者: accept\nsocket bind listen都是瞬时操作\n什么是基于udp的 RTP real time transport protocol\n"},"课程笔记/计算理论/01-正则语言与有限自动机":{"slug":"课程笔记/计算理论/01-正则语言与有限自动机","filePath":"课程笔记/计算理论/01 正则语言与有限自动机.md","title":"01 正则语言与有限自动机","links":[],"tags":[],"content":"等价链\nDFA=NFA=正则表达式=正则文法\n能被DFA接收的就是正则语言\n基本定义\n\n\n字母表(alphabet): 有限的符号集合. 例如 ∑={0,1}.\n\n\n串(string): 由符号组成的有限序列. 例如 01001. 串的连接: ◦\n\n\n空串: e, 使得we=ew=w,∀w.\n\n\n语言(language): 由串构成的集合.\n\n\nKleene 闭包 (Kleene star): L∗ = L0 ∪L1…\n\n∑∗ 即为由该字母表内符号组成的所有串的集合, 它显然是一个语言.\n\n\n\n串和语言实质上都是在一个字母表下谈论的, 在不引起歧义的情况下我们可以不指明字母表.如语言L={a^n·b^n |n≥1} 的符号表为 {a,b}\n\n\n注意空集 ∅, 空串 e, 空串构成的语言{e} 三者的区别.\n\n\n有限自动机\n确定有限自动机\ndeterministic finite automata, 简称 DFA。\n由五元组(K,∑,δ,s,F) 构成\n\n\nK 是由状态构成的有限集合（就是状态机的那个状态）\n\n\n∑是字母表/字符集.\n\n\ns∈K 是起始状态.\n\n\nF ⊆K 是接受状态的集合（感觉通过状态更准确，即终止且通过的状态）\n\n\nδ:K×∑→K 为状态转移函数（状态+读入字符→下一个状态）[这里读入空字符是不能进行状态转移的]\n\n\n注意 δ 是输入一个状态和一个字符, 输出一个新状态的函数. 它不仅保证了每一个状态在每一个读取的字符下都会有一个新状态 (可能与原状态相同), 同时可保证了这个新状态是唯一的. 所谓确定性即指下一个状态被当前状态和输入唯一确定.\n\n\n我们有时候会混用“状态机”,“有限自动机”, “自动机” 等词汇, 它们的意义都是相同的. 双圆的是终止状态,而start 指向的状态为起始状态\n\n\n格局\nDFA 的格局 (configuration) 为 (q,w) ∈ K ×∑∗\n\n元素对，前一个元素是状态，后一个元素是尚未被读取的字符串的全集\n格局就是现在在什么状态、还剩下什么输入没有读取\n我们定义格局间的二元关系M 为:\n我们称(q,w) 通过一步推得 (q′,w′). M 描述的是消耗一个字符进行一次状态转移的一步推导过程.\n可以描述多步推导的过程：在M 这个二元关系加上传递性就能达到这个目的,为了后面叙述方便我们再加上自反性,即零步推导也算推导.\n我们把加上自反性和传递闭包的二元关系称为∗M,∗的意思和字符中的Kleene 星号类似,代表零步或者多步.\n在格局和我们定义的二元关系的语言下, 我们可以很容易的形式化描述一个串被自动机接受与否. 串w∈∑∗ 被M 接受,当且仅当存在状态q∈F 使得(s,w) ∗ M (q,e). 而所有被M 所接受的语言,我们记为L(M).\n\n(s,e)∗ M (q,e).\n\n非确定有限自动机\n(nondeterministic finite automata, 简称NFA), 由五元组(K,Σ,Δ, s, F) 构成:\n\nK 是由状态构成的有限集合.\nΣ是字母表/字符集.\ns∈K 是起始状态.\nF⊆K 是接受状态的集合.\nΔ⊆K×(Σ∪{e}）×K 为状态转移关系.（从函数变成了关系/集合，这个集合里是一个三元组（当前状态，触发条件，目标状态 ））\n\n触发条件：字母表或空字符串\n\n\n这里的Delta 为状态间的关系, 这也就决定了一个状态在某一字符/输入下可以转移到多个状态, 也说明了不是每一个状态都可以在任一输入下进行转移的.\n在介绍完DFA 与NFA 后, 一个自然的问题是它们的计算能力是一样的吗? 所谓计算能力, 粗略来说就是比较能够接受的语言的多少. 形式上来说, 两个FA M1 和M2 是等价的, 当且仅当L(M1) = L(M2). 直觉上来说, NFA 的计算能力似乎要比DFA 稍稍强一点, 毕竟它看起来可以不确定能够多一些可能, 但事实却不如此.\n\n定理1.1\n\n证明：\n\n左到右：显然。因为任意一个DFA都是一个NFA。每一个函数都天然构成一个关系\n\nDFA 从（当前状态，读入符号）可以得到一个唯一输出（下一个状态）\nNFA 是一个三元组\n\n\n右到左\n让DFA的一个状态等于NFA的一组状态，就可以用DFA来模拟NFA了\n\n这个E是e闭包 ，q通过空字符串能切换到的所有状态p，q与p等价。\n\n\n\n新的状态=原来状态的总个数\n字母表不变\n原始状态的等价集合\n只要这个集合里，包含了至少一个 NFA 的原接受状态，它就是 DFA 的接受状态。\n对于当前状态组Q，对于里面的每一个状态q，看看读入a后得到的状态组里的所有p。每一个p都计算他的e闭包，得到一个集合，就是新的巨大的状态组\n\n正则语言\n\n能被正则表达式识别的串全体，称为正则语言\n\n空和字符\n并 连接 星\n\n正则基本性质\n\n\nS或R和R或S等价\n字符串拼接结合律\n字符串拼接分配律\n空集合的0个或多个 结果是空字符串  等式两边都是语言（字符串的集合） 星号是从这个集合里选0or多个字符串然后拼接起来形成语言\n右边：R或者S出现0次or任意次，可以产生任何由R和S组成的序列\n\n左边是任意任意次，意会一下\n\n\n\n自动机能够识别正则语言\n定理1.2 自动机能接受的语言在并、连接、星、补、交下封闭\n\n4. 把原来可以接收和不能接收反一下就可以\n5. 用补集和并集结合起来\n推论1.1\n\n定理1.3\n\n推论1.2\n自动机和正则语言是等价的. 具体来说, 一个语言是正则的当且仅当它能被某个自动机接受.\n算法\n把自然语言转换成DFA自动机\n\n先把自然语言转换成正则表达式\n根据这个定理的启发，可以把正则表达式转换成自动机。\n就是把公式的每个小零件（如 a、b、U、*）都换成对应的 NFA 小机器，然后用 e 转移（epsilon 转移，或“免费”转移）把它们“粘”起来。\n\n\n\n把NFA转换成DFA 就是状态组的那个定理\n注意某个状态的e闭包会包括它本身\n\n非正则语言\n有限状态机实质上并不能记住过去经历的状态,\n“鸽笼原理” (Pigeonhole Principle)： 如果你喂给它一个很长的字符串（比如长度 m=10，比状态数 n=5 要长），机器在读取这个字符串时，必定会经过同一个状态至少两次。\n\nx是字符串中进入环之前的部分\ny是绕环一圈对应的字符串，不能为空\nz是离开环之后到终点的部分\n然后i就是绕了几圈。\n我们保证在读取 n 个字符之内必定会找到第一个环，所以 x 和 y 加起来的总长度不可能超过 n。\n\n\nquestion"},"课程笔记/计算理论/02-上下文无关文法与下推自动机":{"slug":"课程笔记/计算理论/02-上下文无关文法与下推自动机","filePath":"课程笔记/计算理论/02 上下文无关文法与下推自动机.md","title":"02 上下文无关文法与下推自动机","links":[],"tags":[],"content":"CFG\n\n\n串里的一个非终结符根据规则进行替换,可以不替换成终结符\n\nCFL 减去 Regular，剩下的还是 CFL。\n\n\n上下文无关语法的构造\n\n语法树与等价类与最左推导\n\n\n歧义\n\n\n\n\nPDA\n\n（（ 当前状态，读入字符，从栈顶弹出字符 ），（ 转移到状态p，往栈顶压入字符串 ））最终的接受状态:\n\n到达接受状态\n不读入其他字符\n当前栈顶没有元素需要弹出\n\n使用例:把需要被记忆的字符压入栈即可 。\n\n读入w 读入c 然后读入w的反转，因此需要记住w的内容，才能在后面读入反转的时候确认\n读完c之后，切换到f状态，将栈内字符逐个弹出进行核对【在规则中设定了，当读入字符是x 栈顶字符是y的时候，才能进行状态的转移】\n非确定性下推自动机,一个输入三元组可能会导致两种变化方式.但是只要存在一条能走通的路（最终停在接受态且栈空），这个串就被接受。\n下面是一个容易混淆的点\n\nCFG和PDA的关系\n\n\n一开始就转移到终止状态并在栈顶放一个起始字符\n处于状态q时,不读取任何输入符号,如果栈顶符号是一个非终结符A,那么不读输入,而是选择任意选择一条A到x的规则,把A从栈顶弹出并且将x压入.\n处于状态q时,如果栈顶符号是一个终结符a,那么必须从输入中读入一个符号a,匹配成功,就消耗掉这个a(不压入栈中),并将栈顶的a弹出.\n直到(q,e,e)就结束了\n\n\n\n\n从PDA的起始状态s开始,把栈底最顽固的Z消灭掉,然后抵达最终状态f’,字符就被接受了\n那么下一步变成,吃掉一个字符a,把B换成了C,当前的状态跳到了r.问题变成了从r出发,消灭c,到达p\n吃掉一个字符a,把B换成了C1C2,为了消灭这个东西,我们需要从r出发走到p’,把c1消灭.然后从p’出发走到p,把c2消灭\n如果任务是从q出发消灭空字符e,最后回到q,那么什么都不需要做直接生成空串即可.\n\n\nPDA构造CFG\n\n\n解题规范\n证明CFG可以生成怎样的语言\n\n泵引理\n\n\n\n泵定理\n"},"课程笔记/计算理论/03-图灵机":{"slug":"课程笔记/计算理论/03-图灵机","filePath":"课程笔记/计算理论/03 图灵机.md","title":"03 图灵机","links":[],"tags":[],"content":"\n接收状态,停机.\n拒绝状态,停机\n永远跑下去,不停机,就是死循环\n语言是所有能被机器(程序)接受的语言集合\n存在一个图灵机,对于任何输入,要么接收,要么拒绝,绝对不会死循环.那么这个图灵机可以判定的语言就叫做递归语言.\n存在一个图灵机,对于属于语言的串,可以接受.但是对于不属于语言的串,他可能进入拒绝,也可能死循环.他只能半判定\\识别,\n一个语言由任意文法生成,当且仅当它是递归可枚举的(RE)\n任意文法生成递归可枚举语言,然后图灵机可以识别的是递归可枚举语言.递归语言是RE的一个更高级 更严格的子集.\n\n任意文法&gt;上下文有关文法&gt;上下文无关文法\n上下文有关文法:推导出的结果不能比原来的短.实际上任意文法包含上下文有关文法\n原始递归函数\n\n\n乘法加法除法截断减法 模运算 判零 逻辑函数 是原始递归函数\n停机问题\n\n通用图灵机 UTM\n三条纸带，分别模拟数据程序和状态。\n第一条纸袋 存放图灵机M的编码和输入字符串w\n第二条纸带空\n第三条存放起始状态s的编码\n运行 先把图灵机M的编码从第一条拷贝到第一条，然后把第一条只留下输入数据w\n这时候tape2充当指令集，用来查询，在这个状态下读到这个字符应该做什么。tape1就当做memory了，用来读取和修改数据。tape3充当状态寄存器，记录被模拟机器当前正处于哪个状态\n意义是 将程序和机器分离开来：只需要换一下tape2上的描述就可以了。这是存储程序计算机的雏形。"},"课程笔记/计算理论/04-不可判定性":{"slug":"课程笔记/计算理论/04-不可判定性","filePath":"课程笔记/计算理论/04 不可判定性.md","title":"04 不可判定性","links":[],"tags":[],"content":"可判定性与判定性问题\n判定:停机\n识别:会停机,也会死循环.\n有些问题是不可判定的.\n停机问题\n一切不可判定的根源\n给定一个程序 M 和一个输入 w，能否写出一个通用程序来判断 M 在 w 上是会停机还是会死循环？\n假设存在这样的判定程序，我们可以构造一个“悖论程序”：如果判定程序说它会停机，它就故意进入死循环；如果判定程序说它会死循环，它就立刻停机。这导致了逻辑崩溃，从而反证出判定程序不存在。\n规约\n证明一个新问题不可判定的方法\n如果 A 可判定 \\Rightarrow 停机问题就可判定 \\Rightarrow 与已知矛盾 \\Rightarrow 所以 A 不可判定。\n里斯定理\n任何关于递归可枚举语言的非平凡性质都是不可判定的\n非平凡:指不是所有图灵机都有,也不是所有图灵机都没有的性质.比如:语言是否为空,是否包含某个串,是否无限.\nDFA/NFA/正则表达式 的所有基本问题(是否接收 是否为空 是否相等)都是可判定的\nCFG/PDA 空性(是否生成空语言)可判定,但是否生成所有串是不可判定的\n图灵机TM 几乎所有关于语言性质的问题都是不可判定的.\n证明不可判定:先里斯定理,再规约法转换为停机问题\n"},"课程笔记/计算理论/计算理论":{"slug":"课程笔记/计算理论/计算理论","filePath":"课程笔记/计算理论/计算理论.md","title":"计算理论","links":[],"tags":[],"content":"判断题\n正规语言:所有有限集合都是正规语言,包括空集\\仅含空串  全集也是正规语言 但是全集是无限集合\n\nRegular \\subset DCFL \\subset CFL \\subset Recursive \\subset RE\n\n\n规则：\n\n里层的一定是外层的   （正规语言一定是 CFL）。\n外层的不一定是里层的（CFL 不一定是正规）。\n\n\n\n\n\n你的题目 (4)：Every regular is CFG? → True，因为 Regular 在 CFL 肚子里。\n你的题目 (6)：RE 必须是无限的？→ False，最里面的 Regular 可以是有限的，那最外面的 RE 当然也可以是有限的。\n\n\n\n\nRE 只能确认“有”（存在性）。\n\n\n确认“无”（全称量词）是 RE 做不到的。\n\n\n所以它不是 RE。\n\n\nAckermann 函数：它是可计算的，但增长太快，不是原始递归的（题目 7）。\n\n\na^n b^n c^n：经典的非CFL。\n\n\na^n b^n：经典的 CFL（但非正规）\n\n\n正规语言不仅要求有一个dfa能接受它包含的所有字符串 还必须拒绝所有不属于这个语言的字符串。因此，他的子集不一定正规，比如说要符合某种特定条件的，就无法被筛查。因此并相关的反例可以用全集。\n\n\n任何集合和空集连接结果都是空集。因为AB是从A和B里各挑选一个拼在一起。因此，连接相关的反例可以用空集。 连接结果是空集（正规。\n\n\n上下文无关文法：利用栈！ 比如x中的每个字符对应y中的1到3个字符。\n\n\n\n\n正则语言: 在并交补连接星号下都封闭\n\n图灵机是可数的因为就是代码嘛。但是语言是别墅的，所有可能的字符串集合的组合方式比自然数要大的多得多。\n+是至少有一个 *是可以有0个\n可计算函数，能跑出结果的。原始primitive递归函数，只允许用固定次数的for循环写的程序，比如加法乘法阶乘指数运算等。\n**Ackermann Function (阿克曼函数)**是可计算函数，但不是运势地柜函数，因为必须用深度嵌套递归才能计算\n如果A是RE，A的补也是RE，那么说明A可判定！。否则的话就只是可识别。\n符号： A \\le B 读作： “问题 A 归约到 问题 B” 通俗理解： “外包” 或者 “变身”。A有一种办法能变成B，因此 解决问题A的难度，不超过解决问题B的难度。归约性质：两边同时取反，归约关系不变。 即：\\bar{H_e} \\le \\bar{(\\bar{L})} \\implies \\bar{H_e} \\le L。\n\n\n正则语言 (RL) 判定与证明 (约16-20分)：判断给定语言是否正则，并给出理由（通常用泵引理 Pumping Lemma 证明非正则）。\nCFG 与 PDA 同步构造 (约18-20分)：为特定语言（如 anbmcxyR 类）设计上下文无关文法和下推自动机。\n原始递归函数 (PRF) 证明 (约10-12分)：证明给定函数是 PRF，通常涉及复合 (Composition) 和递归 (Recursion) 操作。\n图灵机 (TM) 构造与 UTM 概念 (约10-12分)：设计基础 TM 完成计算，或考察通用图灵机 (UTM) 的带子分工与意义。\n判定性与还原 (Reducibility) 证明 (约18分)：判断语言属于 R (递归)、RE (递归可枚举) 还是非 RE，并利用归约 (Reduction) 进行证明（通常要求不直接使用 Rice 定理）\n"}}