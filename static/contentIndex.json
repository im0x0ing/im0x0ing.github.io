{"index":{"slug":"index","filePath":"index.md","title":"🏠 首页","links":["about"],"tags":[],"content":"欢迎来到 ING wiki！\n本质自用, 持续建设中…\n📂 导航\n\n关于我\n\n📝 最近更新\n\n这里可以写一些最近的想法或者置顶的内容。\n"},"工具使用/Obsidian插件":{"slug":"工具使用/Obsidian插件","filePath":"工具使用/Obsidian插件.md","title":"Obsidian插件","links":[],"tags":[],"content":"templater\n可以把Templates文件夹下的笔记作为模板,左侧功能栏点击即可套用到其他笔记上.不会影响已写的内容.\nConsistent Attachments and Links\n右键某个文件夹,可以从整个仓库收集属于该文件夹下笔记的图片,并放到该文件夹下的attachments文件夹中.\n\n首先要在obsidian设置-文件与链接-附件默认存放路径,确定好附件存放方式是在文件夹下的attachments文件夹.\n使用时,比如先移动了一个笔记,然后右键笔记所属文件夹即可选择collect attachments.[注意不要对附件文件夹做任何删除操作,这个移动是附件本体进行移动,不是副本移动]\n\nGit\n好用,可以把整个obsidian仓库托管到git然后设置每两小时提交一次(如果有修改的话).我之前琢磨附件插件的时候把附件删没了全靠git找回来(当然也可以去回收站找)\nShell Commands\n可以编写终端指令.使用例:\n\n编写了一个指令,每次Obsidian打开的时候会自动进入我的博客本地仓库进行一次发布.\n"},"工具使用/博客搭建":{"slug":"工具使用/博客搭建","filePath":"工具使用/博客搭建.md","title":"博客搭建","links":[],"tags":[],"content":"基于Obsidian和Quartz4.流程:\n\n将quartz4仓库克隆到本地.然后将content文件夹重定向到本地obsidian仓库的public文件夹.这样两边的内容会进行一个同步.\n为本地quartz仓库配置私钥和公钥.私钥链接到github私有仓库.公钥连接到github公有仓库.这样只有静态产物会deploy到公有仓库,将公有仓库名字设置为username.github.io即可.\n在obsidian中的Public文件夹下书写笔记,然后在quartz4本地仓库进行提交.这样之后私有仓库[博客源码]会更新.公有仓库[静态产物]也会更新,最终体现在博客网页上.\n\n评论\ngiscus 基于github仓库discussion\ntips\n\nquartz.config.ts-&gt;plugins -&gt; transformers\n加上一行Plugin.HardLineBreaks(),,就会调用remark-breaks 这个库,将所有换行强制渲染成&lt;br&gt;,否则笔记里面的本来的换行选然后会变成空格.[只有两次回车/两个空格一次回车会被渲染成换行但是太麻烦了所以]\n"},"技术积累/Golang/库/fmt":{"slug":"技术积累/Golang/库/fmt","filePath":"技术积累/Golang/库/fmt.md","title":"fmt","links":[],"tags":[],"content":"print\n \n \nfmt.Scanln(&amp;n)//读取到的数据放入到这个地址中"},"技术积累/Golang/库/strings":{"slug":"技术积累/Golang/库/strings","filePath":"技术积累/Golang/库/strings.md","title":"strings","links":[],"tags":[],"content":"strings.Builder\n常用于在循环中对字符串进行增加的操作.builder就相当于一个缓冲区,在最后才生成最终的字符串.\nimport &quot;strings&quot;\n \nvar sb strings.Builder\nsb.Grow(100)//预分配内存,可以避免中途多次扩容,提高性能\n \nsb.WriteString(&quot;Hello&quot;) // 写入字符串\nsb.WriteByte(&#039; &#039;) // 写入单个字节 (比如空格)\n \nresult := sb.String()//最终生成结果字符串"},"技术积累/Golang/数据结构/slice切片动态数组类型":{"slug":"技术积累/Golang/数据结构/slice切片动态数组类型","filePath":"技术积累/Golang/数据结构/slice切片动态数组类型.md","title":"04 slice切片动态数组类型","links":[],"tags":[],"content":"tips\n// 原写法  s := []byte{} 得到的不是nil切片\n// 替代写法 var s []byte 得到的是nil切片,但是可以照常append go自己会处理\n也可以s := make([]byte, 0)\n//注意切片是左闭右开,\n固定长度数组array\n但是在go中不等同于其他语言数组的地位,可以说slice才是go语言的数组.\n\n根据索引初始化 注意默认值是0\n查看数组的数据类型：长度变成了类型的一部分,因此存在两个问题\n\n因此传参的时候也要区分不同长度的数组了\n而且仍然是一个值传递（把本来的数组拷贝给形参，所以还是会有之前那个内存和地址的问题，所以不能进行改动）\n\n\n所以说要传参的话最好还是写动态数组,也可以使用切片操作符 [:] 你可以把数组“切”一下,这里是创建一个引用 不是copy,相当于传了地址\n\nrange关键字\n根据遍历不同集合返回不同值。\n\n数组或切片\n\n返回两个值  当前元素所在索引和当前元素值本身如果不关心某个返回值的话可以把它设置成匿名\n\n\n\n动态数组:切片 slice\n数据结构\n连续的内存,本身只包含三个信息(可以在runtime包下查询)\ntype slice struct {\n    // 指向起点的地址\n    array unsafe.Pointer\n    // 切片长度\n    len   int\n    // 切片容量\n    cap   int\n}\n\n指针 第一个元素的内存地址\n长度 当前存放的元素个数  访问切片是否合法\n容量 总共能装多少个元素(提前分配的空间元素个数),cap永远大于等于len 考虑性能优化\n\n\n索引时只需要计算目标地址 = 起始地址 + ( 索引 x 每个元素的大小 ),因此时间复杂度是O(1)\n\n特征\n\n传递时表面上是进行slice header的值传递,但因为内部存放的是unsafe.Pointer地址,因此实际上相当于引用传递,可以直接进行传递并在函数中进行值修改.[go语言中没有真正的引用传递,基本都是这样的伪引用传递].\n\n因此len和cap在函数中被修改是不会反映到底层数据结构的\n\n\n括号里面是空的，表示动态。可以看到类型也是动态数组类型\n\nslice切片的四种声明方式/初始化\n\n声明但不进行初始化\n\n判断一个slice是否为空nil [没有空间,而全0不算空]\n空slice不能够进行赋值,但是可以进行append(相当于一个一个开辟空间)\n\n\n\nvar s []init\n \n//判断一个slice是否为0\nif  slice1 == nil{\n\tfmt.println(&quot;是一个空切片&quot;)\n\t}else{\n\tfmt.println(&quot;不是一个空切片&quot;)}\nelse和前后两个括号需要在同一行否则会报语法错\n\n基于make进行初始化\n\n只初始化len而不初始化cap.\n\n此时会将len和cap同时默认设置为len的值.因为如果len&gt;cap会初始化失败.\n切片的长度一旦被指定了，就代表对应位置已经被分配了元素，设置的会是对应元素类型下的零值.\n\n\n分别指定len和cap\n\n在index【len,cap)的区域无法被访问,因为逻辑上不存在元素,访问会被报错.\n\n\n\n\n\ns := make([]int,8)\ns := make([]int,8,16)\n\n%v 可以打印数组内详细数据\n\n\n初始化连带赋值\n\n会将len和cap同时设为3并且完成赋值\n\n\n\n  s := []int{2,3,4}\n初始化源码\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n    // 根据 cap 结合每个元素的大小，计算出消耗的总容量\n    mem, overflow := math.MulUintptr(et.size, uintptr(cap))\n    if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {\n        // 倘若容量超限，len 取负值或者 len 超过 cap，直接 panic\n        mem, overflow := math.MulUintptr(et.size, uintptr(len))\n        if overflow || mem &gt; maxAlloc || len &lt; 0 {\n            panicmakeslicelen()\n        }\n        panicmakeslicecap()\n    }\n    // 走 mallocgc 进行内存分配以及切片初始化,以及回收\n    return mallocgc(mem, et, true)\n}\n追加与截取\n切片的追加\n通过 append 操作，可以在 slice 的末尾，额外新增一个元素.\n\n这里的末尾指的是针对 slice 的长度 len 而言.实际上截取的话,从起点开始的容量会保留,详见辨析5\n这个过程中倘若发现 slice 的剩余cap已经不足了，则会对 slice 进行扩容.动态开辟相当于本来cap的容量\n\n\n在创建 slice 时，如果能够预估到其未来所需的容量空间,应该提前分配好对应容量，避免在运行过程中频繁触发扩容操作，这样会对性能产生不利的影响.\n\n\n实例1\n倘若希望使用 append 操作完成 slice 赋值，则应该在初始化 slice 时，给其设置不同的长度 len 和容量 cap 值，cap 和 len 之间的差值就是预留出来用于 append 操作的空间. 具体代码如下：\nfunc Test_slice(t *testing.T){\n    s := make([]int,0,5)\n    for i := 0; i &lt; 5; i++{\n       s = append(s, i)//追加的对象数组,以及追加的数据\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n实例2\n我们将 slice 的长度和容量都设置为 5,然后通过遍历 slice 的方式进行执行位置元素的赋值（不使用 append 操作）：\nfunc Test_slice(t *testing.T){\n    s := make([]int,5)\n    for i := 0; i &lt; 5; i++{\n       s[i] = i\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n扩容\n当len与cap相等时,下一次append操作就会进行一次扩容\n    // len:4, cap: 4\n    s := []int{2,3,4,5}\n    // len:5, cap: 8    len=原来的长度+1,cap=原来的cap*2\n    s = append(s,6)\n\n\n预期容量:\n\n如果只追加一个元素,预期容量就是原本的容量+1,类似的.\n\n老容量&lt;256 则扩容为原来的两倍\n老容量&gt;256 那么就进入一个循环,按照特殊方式扩容直到大于等于预期容量.如果在这个循环中数值太大了以至于越界,那么就直接取预期新容量为最终值\n\n\n如果预期元素是比如一个切片,那么预期容量就可能会超出原容量的两倍.\n\n\n根据数据类型推算出实际需要的内存大小,然后mallocgc中还要对内存分配单元mspan的等级制度,推算得到实际需要申请的内存空间大小(向上取整)\n\nmheap是go管理的所有内存之和\nmspan就是标准大小地块,有不同大小等级共程序申请使用.\n\n\n调用 mallocgc，对新切片进行内存初始化\n调用 memmove 方法，将老切片中的内容拷贝到新切片中\n返回扩容后的新切片【扩容后会变成新的地址】\n源码:\n\nfunc growslice(et *_type, old slice, cap int) slice {\n    //... \n    if cap &lt; old.cap {\n        panic(errorString(&quot;growslice: cap out of range&quot;))\n    }\n \n \n    if et.size == 0 {\n        // 倘若元素大小为 0，则无需分配空间直接返回\n        return slice{unsafe.Pointer(&amp;zerobase), old.len, cap}\n    }\n \n \n    // 计算扩容后数组的容量\n    newcap := old.cap\n    // 取原容量两倍的容量数值\n    doublecap := newcap + newcap\n    // 倘若新的容量大于原容量的两倍，直接取新容量作为数组扩容后的容量\n    if cap &gt; doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256\n        // 倘若原容量小于 256，则扩容后新容量为原容量的两倍\n        if old.cap &lt; threshold {\n            newcap = doublecap\n        } else {\n            // 在原容量的基础上，对原容量 * 5/4 并且加上 192\n            // 循环执行上述操作，直到扩容后的容量已经大于等于预期的新容量为止\n            for 0 &lt; newcap &amp;&amp; newcap &lt; cap {             \n                newcap += (newcap + 3*threshold) / 4\n            }\n            // 倘若数值越界了，则取预期的新容量 cap 封顶\n            if newcap &lt;= 0 {\n                newcap = cap\n            }\n        }\n    }\n \n \n    var overflow bool\n    var lenmem, newlenmem, capmem uintptr\n    // 基于容量，确定新数组容器所需要的内存空间大小 capmem\n    switch {\n    // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap.\n    // 同时会针对 span class 进行取整\n    case et.size == 1:\n        lenmem = uintptr(old.len)\n        newlenmem = uintptr(cap)\n        capmem = roundupsize(uintptr(newcap))\n        overflow = uintptr(newcap) &gt; maxAlloc\n        newcap = int(capmem)\n    // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小\n    // 并会针对 span class 进行取整\n    case et.size == goarch.PtrSize:\n        lenmem = uintptr(old.len) * goarch.PtrSize\n        newlenmem = uintptr(cap) * goarch.PtrSize\n        capmem = roundupsize(uintptr(newcap) * goarch.PtrSize)\n        overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize\n        newcap = int(capmem / goarch.PtrSize)\n    // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算   \n    case isPowerOfTwo(et.size):\n        var shift uintptr\n        if goarch.PtrSize == 8 {\n            // Mask shift for better code generation.\n            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63\n        } else {\n            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31\n        }\n        lenmem = uintptr(old.len) &lt;&lt; shift\n        newlenmem = uintptr(cap) &lt;&lt; shift\n        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)\n        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)\n        newcap = int(capmem &gt;&gt; shift)\n    // 兜底分支：根据元素大小乘以元素个数\n    // 再针对 span class 进行取整     \n    default:\n        lenmem = uintptr(old.len) * et.size\n        newlenmem = uintptr(cap) * et.size\n        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n        capmem = roundupsize(capmem)\n        newcap = int(capmem / et.size)\n    }\n \n \n \n \n    // 进行实际的切片初始化操作\n    var p unsafe.Pointer\n    // 非指针类型\n    if et.ptrdata == 0 {\n        p = mallocgc(capmem, nil, false)\n        // ...\n    } else {\n        // 指针类型\n        p = mallocgc(capmem, et, true)\n        // ...\n    }\n    // 将切片的内容拷贝到扩容后的位置 p \n    memmove(p, old.array, lenmem)\n    return slice{p, old.len, newcap}\n}\n切片的截取\n\n要注意这里是左闭右开,因此[0:2]取的是第0.1位,2并没有算进来\n\n\n[:]=[0:len(s)]\n\n\n[:3]=[0:3]\n\n\n[4:]=[4:len(s)]\n\n\n本质上是引用传递操作,因此无论截取多少次,底层都是同一块内存空间数据.不过截取会创建出新的slice header实例\n\n\n因为实际上指向的是同一个地址区间,因此修改其中一个元素会影响到另外一个数组的\n\n\n如果要分开截取的话就使用copy函数,相当于拷贝一个副本,这样修改的话不会影响到本来的slice\n\n\n\n元素删除\n从切片中删除元素(只对len做修改)的实现思路，本质上和切片内容截取的思路是一致的.\n\n删除 slice 中的首个元素，在操作上等同于从切片 index = 1 开始向后进行内容截取\n删除 slice 的尾部元素，则操作等价于截取切片内容，并将终点设置在 len(s) - 1 的位置\n删除 slice 中间的某个元素，操作思路则是采用内容截取加上元素追加的复合操作，可以先截取待删除元素的左侧部分内容，然后在此基础上追加上待删除元素后侧部分的内容\n最后，当我们需要删除 slice 中的所有元素时，也可以采用切片内容截取的操作方式：s[:0]. 这样操作后，slice header 中的指针 array 仍指向原处，但是逻辑意义上其长度 len 已经等于 0，而容量 cap 则仍保留为原值.\n\nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [1,2,3,4]\n    s = s[1:]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [0,1,2,3]\n    s = s[0:len(s)-1]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // 删除 index = 2 的元素\n    s = append(s[:2],s[3:]...)//\n    // s: [0,1,3,4], len: 4, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = s[:0]\n    // s: [], len: 0, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n…:\n\n在函数定义中,func myFunc(args ...int)，这里 ... 意味着 myFunc 是一个可变参数函数。它可以接受任意数量的 int 作为参数（0个、1个或多个）。\n在函数调用中 ：append(s1, s2...)，这里的 ... 意思是“将这个切片 (slice) 拆包/解开 (unpack/expand)”。\n\n因为append并不接受一个slice作为第二个参数,于是我们用…将slice拆分为单独元素\n\n\n\n切片拷贝\n包括简单拷贝和完整拷贝两种\n\n简单拷贝\n\n只要对切片的字面量进行赋值传递.这样相当于创建出了一个新的 slice header 实例，但是其中的指针 array、容量 cap 和长度 len 仍和老的 slice header 实例相同..\n对切片进行%p打印地址,打印出来的不是slice header的地址,而是内部array字段指向的数组地址\n切片的截取操作也属于是简单拷贝，s 和 s1 会使用同一片内存空间，只不过地址起点位置偏移了一个元素的长度. s1 和 s 的地址，刚好相差 8 个 byte.\n\n\n完整拷贝\n\n指的是会创建出一个和 slice 容量大小相等的独立的内存区域，并将原 slice 中的元素一一拷贝到新空间中.在实现上，slice 的完整复制可以调用系统方法 copy，通过日志打印的方式可以看到，s 和 s1 的地址是相互独立的.因此对应的数组地址也是全新的\n\n\n\n问题辨析\nfunc Test_slice(t *testing.T){\n    s := make([]int,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 20\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,0,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [10], len of s: 1, cap of s: 10\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,11)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 11\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0 0] len=2 cap=4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:9]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0] len:1 cap:4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1[0] = -1\n    t.Logf(&quot;s: %v&quot;,s)\n}\n//结果:s: [0 0 0 0 0 0 0 0 -1 0]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    v := s[10]\n    // 求问，此时数组访问是否会越界\n}\n//会越界,因为len=10 是0-9的索引上有值\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1 = append(s1,[]int{10,11,12}...)\n    v := s[10]\n    // ...\n    // 求问，此时数组访问是否会越界\n}\n//由于 s 预留的空间不足，s1 会发生扩容,扩容后会返回拷贝后的新切片,这里的拷贝是完整拷贝,意味着修改 s1 不再会影响到 s\n// s 继续维持原本的长度值 10 和容量值 12，因此访问 s[10] 会panic\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v&quot;,s)\n}\n \n \nfunc changeSlice(s1 []int){\n  s1[0] = -1\n}\n//结果:s=[00000000-10  ]s1=[-10  ]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s, len(s), cap(s))\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1, len(s1), cap(s1))\n}\n \n \nfunc changeSlice(s1 []int){\n  s1 = append(s1, 10)\n}\n//结果:s=[0000000000  ]不变 s1也不变\n//在局部方法 changeSlice 中，虽然对 s1 进行了 append 操作，但这这会在局部方法中这个独立的 slice header 中生效，不会影响到原方法 Test_slice 当中的 s 和 s1 的**长度和容量**.    \n \n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = append(s[:2],s[3:]...)\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n    v := s[4] \n    // 是否会数组访问越界\n}\n//[0,1,3,4] 会.\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,512)  \n    s = append(s,1)\n    t.Logf(&quot;len of s: %d, cap of s: %d&quot;,len(s),cap(s))\n}\n//结果:len=513 cap: 根据不到两倍且&gt;256的计算方式(n += (n+3*256)/4) 可以计算到832, 然后根据mspan向上补齐的法则,得到848\n其他\nslice 不是并发安全的数据结构,没有对并发读写的保护机制.\n参考资料\n你真的了解go语言中的切片吗？—小徐先生的编程世界"},"技术积累/Golang/语法特性/值传递与引用传递":{"slug":"技术积累/Golang/语法特性/值传递与引用传递","filePath":"技术积累/Golang/语法特性/值传递与引用传递.md","title":"值传递与引用传递","links":[],"tags":[],"content":"go的默认传参方式是copy,如果传递的不是地址的话,对参数的修改无法生效."},"技术积累/算法题/语法细节":{"slug":"技术积累/算法题/语法细节","filePath":"技术积累/算法题/语法细节.md","title":"未命名","links":[],"tags":[],"content":"\ngo中的交换可以这样写:\n\n s[left], s[right] = s[right], s[left]\n\n关于小括号和花括号\n\n() 小括号：显式类型转换 (Type Conversion)可以写t:=[]byte(s)直接把字符串显式转换成数组.string(cnt)再这样转换回去就行了\n{} 花括号：初始化/构造 (Composite Literal)\n\n\n"},"生活杂谈/test":{"slug":"生活杂谈/test","filePath":"生活杂谈/test.md","title":"test","links":[],"tags":[],"content":""},"课程笔记/操作系统/01-introduction":{"slug":"课程笔记/操作系统/01-introduction","filePath":"课程笔记/操作系统/01 introduction.md","title":"01 introduction","links":["tags/flashcard"],"tags":["flashcard"],"content":"操作系统概述\n定义与设计目标\n操作系统：\n\n职能：资源管理系统\n存在：本质上是软件程序\n\n最基础最中央的部分是内核kernel\n\n\n\n设计目标：\n\n可靠性和安全性\n\n异常处理机制：中断\n权限管理系统：特权\n\n\n易用性\n\n方便用户使用系统资源：系统调用\n\n\n高效性\n\n任务执行设计：批处理系统-》分时系统\n\n\n公平性\n\n进程管理的冲突与饥饿starvation\n\n\n可拓展性、易维护性\n\n设计与实现\n从目标/需求开始：user goals &amp; system goals\n机制和策略相分离 flashcard\n\n\n机制/规则被存在酒店的中心服务器上（database） 和策略分离开了,比如配置文件就相当于policy\n\n\n\n                  \n                  例题 \n                  \n                \n\n\n\n\n操作系统提供的三种能力\n复用 multiplexing\n\ncpu复用 多个程序共享 时间分配复用\n内存复用 多个进程  空间分配复用\n\n隔离  isolation\n\n程序之间不能访问对方的数据\n数据范围权限的隔离\n用户 kernal\n\n抽象 abstraction\n进程间通讯 interaction\n操作系统的整体设计\n计算机系统架构\n\n根据处理器的数量和组织形式，存在三种计算机系统架构\n\n单处理器\n\n有且仅有一个单核通用处理器general-purpose processor\n可以有若干专用处理器用来处理特定指令，并不运行线程\n\n\n多处理器系统\n\n有多个单核通用处理器的系统，处理器共享同一块主内存，通过总线或者交换网络连接\n增加了处理西数量能够增加吞吐量throughput，也就是单位时间内处理的任务数量，但是增加并不线性（处理器之间通信需要时间和额外开销）\n\n\n集群系统\n\n通过冗余实现高可用服务，通过并行实现高性能计算，由多个独立的计算机系统作为节点，通过高速通信网络相互连接形成\n分为对称和不对称两种，对称集群中各个节点互相监督，不对称集群中存在“替补”监督工作中的节点，或者接替有问题节点的工作。\n\n\n\n操作系统的任务执行设计\n1. （单道）批处理系统  flashcard\nbatch processing system\n\n批处理：若干任务被作为一整批交付给操作系统，操作系统会自动按照顺序串行serial执行任务\n单道：一段时间内内存中只有一道程序在运行（进程process ），结束后再切换到下一个任务\n问题：当存在I/O操作任务时，由于耗时，CPU长时间处于空闲状态\n\n\n\n                  \n                  I/O \n                  \n                \n\n即CPU和RAM（主内存）与“外部世界”之间进行数据交换的过程\n\n存储设备（磁盘IO）\n网络设备（网络IO）\n人机交互设备\n其他外部设备\n\n特点：速度慢。\n\n\n\n\n2. 多道批处理系统 flashcard\nmultiprogramming batch processing system\n\n一段时间内，四个进程 （job=process）都加载到内存中，并发运行（在A完成之前B可能也开始了）。当当前 job 发生 I/O 时，操作系统负责让 CPU 转而运行另一个 job。\n但微观来看，多道批处理仍然是顺序串行的。\n不关心运行的先后顺序（任意），只要同时加载进去就叫做multiprogramming。调度的部分是由jobschedule完成（批处理\n原因：内存大，cpu强，有能力同时处理4个进程，因此就可以提升硬件的使用效果\nneeded for硬件计算资源CPU utlization\n交互性差，在完成任务前用户无法操作\n\n\n\n                  \n                  并发与并行 \n                  \n                \n\n并发**(concurrency)**是指两个或多个事件在同一时间间隔内发生，而并行是指两个或多个事件在同一时刻发生。逻辑上，并行是并发的子集。\n\n3. 分时系统 flashcard\ntimesharing systems/multitasking\n\nmultiprogramming的逻辑拓展：保留其内存中有多个进程的并发特点\n处理器会在jobs上面轮流地赋予cpu资源，在进程间不断切换（很短的时间内），让用户察觉不到进程的切换/cpu的共享，达到近似于并行的效果。\n注重的是用户的交互性interactivity，允许多个用户同时使用同一台计算机，所有任务之间互相独立，互不干扰、互不阻塞，因此任务的最长周转时间减少，用户的操作也会被及时响应，实现了更方便进行人机对话。\n对硬件配置有较高要求（每个用户的terminal）和调度算法\n\n\n操作系统的结构设计\n宏/巨内核(monolithic-kernels) flashcard\n也叫单内核或大内核\n\n将所有主要功能紧密耦合，操作系统效率高\n维护十分困难；某个部分出现困难，整个系统都会受影响。\n\n\n\n\n分层设计(layer approach)\n\n将系统分为若干层，底层为硬件，顶层为用户接口，第 i 层只调用i−1 层提供的接口。每一层都实现良好的封装，于是开发过程中只需要逐步实现并调试验证每一层，再逐级向上开发即可；在维护或扩展过程中，只要修改每一层的内部实现，而不需要修改其它层的代码，这样就大大降低了开发和维护的难度。 \n由于每次执行一个功能都需要上下跨越多层，发生多次接口调用，分层设计下的系统效率往往都受到限制；不仅如此，要想真正意义上实现良好的分层设计，就需要对各层有良好的定义，这个设计难度是不小的。\n\n微内核(micro-kernels) flashcard\n\n将不是必要的东西都从内核拿出去，放到用户空间以用户态执行。只有通讯、内存管理、进程管理等基本功能直接运行在内核态。其他功能部件通过消息传递机制和内核互动。\n维护扩展变得容易，自身效率得到提升，可靠性也提高了。但是很多模块移到usermode不安全\n\n\n\n模块化设计(modules approach)\n模块-接口法。理想的设计可以让系统多线并行，只要商量好接口就能独立实现，维护和扩展容易。但是设计开发很困难。\n混合系统(hybrid systems)\n宏内核和微内核的思路结合起来，是目前主流的操作系统模式\n操作系统的运行原理\n中断interrupts\n中断（广义）是贯穿现代操作系统的一个重要技术，它使得“计划之外”的事情可以及时的被告知并处理（让产生意外的人自行上报这些意外） 现代操作系统都是中断驱动的\ninterrupt-request line flashcard\n\nCPU 有称为 interrupt-request line 的线路。CPU会在每一条指令结束后检测是否有中断发生，并会读取 interrupt number 并且以此作为 interrupt vector 中的 index 来跳转到对应的 interrupt-handler routine。\n\n\n中断向量表 interrupt vector table flashcard\n中断向量表是快速定位中断处理方法的手段。通过中断号来索引中断处理方法，实现了一种“随机访问”，大大加速了中断处理的速度。\n\n分类\n\n硬件引起的中断（外中断）\n软件引起的中断（内中断）trap\n\nerror 非主动的\nsystem call 程序主动的 调用操作系统的功能\n\n\n\n\n\n                  \n                  riscv的对应术语区别 \n                  \n                \n\n\n中断traps\n\n硬件中断 interrupts\n软件中断\n\nerror→exceptions\n系统调用→ecalls（环境调用）\n\n\n\n\n\n\n\n\n\n                  \n                  cause a page fault \n                  \n                \n\n缺页 访问memory地址的时候由于对应的地址内容非法而产生的中断\n\n\n\n过程\n\n\ndevice driver I/O与操作系统之间的驱动\n左边：CPU\n右边：I/O controller\nI/Ocontroller发起中断之后，CPU对其进行处理，调用interrupt handler，处理好之后return到被中断的下一条指令重新开始运行 的这么一个循环过程\n\n波动表示状态的改变\n\n\n\n                  \n                  中断状态的保存 \n                  \n                \n\n为了保证中断处理完成后仍能继续当前任务，操作系统需要保存当前任务的状态，以便完成中断处理后恢复当前任务的状态。\n\n\n中断冲突 flashcard\n中断处理也同样需要资源，这意味着中断也有可能产生冲突\n\n优先处理优先级高的中断：中断分级\n\n虽然低级的中断可以被高级的中断打断，但是保存和恢复现场状态的过程是不应当被打断的。\n\n\n原子性行为不可被中断，重要任务不应该被中断：中断屏蔽\n\n\n\n                  \n                  中断请求线 \n                  \n                \n\n\nmaskable interrupt-request line 可屏蔽的中断 它可以在执行不可中断的关键程序之前被 CPU 关闭，等到关键程序结束后再解除屏蔽处理其中的中断。\n 2. non-maskable interrupt-request line 不可屏蔽的中断 为一些不可恢复的内存错误等事件保留\n\n\n\n\n计时器 timer flashcard\n\n计时器需要一个固定频率的时钟以及一个计数器，在每个时钟周期令计数器减 1，当计数器归零时产生中断，告诉操作系统定的时已经到了\n功能虽然基础但是十分重要，例如分时系统中就需要计数器来控制时间片的长度，又比如操作系统需要定期检查内存中的进程，以防止进程一直占用系统资源\n\n\n特权模式privileged mode\n允许用户程序执行常规操作，危险操作由专业人士执行。\n工业上特权模式有许多复杂的实现形式，比如\n双模式(dual-mode） flashcard\n\n用户态  user mode\n内核态  kernal mode\nMode bit 为 0，表示 CPU 工作在内核态；mode bit 为 1 时，CPU 工作在用户态。modebit由特权指令进行管理。\n\n\n\n特权指令(privileged instruction)\n例如 I/O 控制，计时器管理，中断管理等。这些指令只能在内核态下执行，而用户态下执行这些指令时会认为这条指令不存在。\n\n\n                  \n                  是不是在kernalmode下运行的所有指令都是特权指令？ \n                  \n                \n\n不是，非特权指令也可以运行在kernalmode下，但是特权指令只能在kernalmode下运行\n\n\n双模式之间的交互\n用户委托进行危险操作的过程：比如writing data to a disk drive ，用户程序想要使用kernal提供的服务，需要调用系统调用（system call）切换到kernelmode。\n\n具体实现上即发生软中断（trap）的时候\n\n细节：将usermode本身执行的上下文保存下来以便于恢复等\n系统调用可能需要传递参数。参数可以放在寄存器里直接传递；也可以放在一块内存中，用寄存器传递地址；也可以用栈传递。\n\n\n\n                  \n                  能否让中断运行在usermode？ \n                  \n                \n\n不行，等同于kernel的权限和usermode是一样的，破坏了隔离性（多个user program都对设备进行io）\n\n\n系统调用\n\n系统向用户程序提供服务的一个接口，它们经常以 C/C++ 函数的形式存在，对于某些比较接近底层的任务，也可能是通过汇编编写的。\n但说到底，系统调用还是相对底层的设计，通常的开发并不基于如此底层的设计展开。更常见的是利用各种抽象层级更高的 Application Programming Interface, API 进行开发。\nAPI 是一个非常常见的概念，在我看来系统调用本身也是一种极为底层的 API。API 的核心思想是让调用者只需要知道如何与被调用者交流以实现目的，而不需要关心其具体实现。这同时也暗示着，只要 API 一致，同样的程序在不同的平台上也能直接编译后运行。\n显然，API 与编程语言往往是强相关的，特定编程语言在操作系统上运行也是需要一定的“环境”的，也就是我们所说的运行时环境(run-time environment, RTE)。RTE 通常包括了编译器(compilers)、解释器(interpreters)、库(libraries)和装载器(loaders)等，它们共同组成了一个完整的运行时环境。\n\n\n\n                  \n                  库函数与系统调用 \n                  \n                \n\n库函数运行在用户空间而系统调用运行在内核空间。大部分库函数可能使用系统调用来实现目的。\n\n\n\nsystemcall是函数 通过interface被调用 但是调用的过程比函数调用更复杂（根据systemcontrol的index下标去查询systemcall的表得到systemcall具体的内容）\n系统调用的分类\n\n链接器和装载器\n操作系统到底是如何执行一个程序的呢？以 C 为例，一个写完的代码需要经过编译、链接、装载三个步骤，才能成为一个在内存中的，可以被执行的程序。\n\n\n编译器首先将若干 .c 源文件编译为若干 .o 文件（这里合并了预处理、编译、汇编步骤），这些 .o 文件被称为可重定位目标文件(relocatable object file)，其存在形式为机器码\n\n\n随后链接器将若干 .o 文件连带所需要的一些库文件（如 .a 文件）链接为一个可执行目标文件(executable object file)。\n\n\n静态链接将库文件的代码直接合并进入最终的可执行文件\n\n\n动态链接仅仅将库文件的引用信息写入最终的可执行文件，而在程序运行时再去寻找这些库文件\n\n\n\n引导\n\n在计算机刚刚启动，操作系统还未开始运行之前，需要开机后的第一个程序——引导加载器(bootstrap loader)来一步一步地初始化操作系统。对大多数操作系统来说，bootstrap 都会被存储在 ROM 中，并且需要在一个已知的位置\nBootstrap loader 会载入更加复杂的，完整的 bootstrap，而包含 bootstrap 程序的分区就被称为引导分区(bootstrap partition)。\n\n同步/异步IO\n\n\n同步(synchronous)\n\n用户等待io操作的完成（控制权移交给操作系统直到io操作结束\n\n\n异步（Asynchronous)\n\nio操作启动以后用户发起io的请求后，控制权迅速返回调用程序，然后io操作再自己去进行（并记录好这个操作的有关信息比如是由哪个进程发起的 需要把得到的数据交给谁之类（device-status table\n\n\n\n\n\n三个management\nprocess management\n\n操作系统分配给进程一定的资源。进程在运行中需要始终拥有这些资源才能够运行完毕。\n\nprogram 静态概念\nprocess   运行中的动态实体（抽象概念\n\n一个程序可以有多个运行中的进程\n不同进程所占用的资源不同，因此可以说进程是一个资源分配的单位\n进程又可以有对应的子进程（树状继承关系\n\n\n\n进程当前指向的地址 pc寄存器\n一个程序可能有多个执行的顺序 叫做thread线程\n\n\n                  \n                  是否时在整个运行过程中，都要占有所有该进程需要的资源？ \n                  \n                \n\n进程运行的各个生命周期，需要的资源不同。在需要的时候再进行占用，不需要的时候进行释放，提高了灵活性和资源利用率。\n\n\n进程里面可以包含多个执行的序列：线程thread\n线程：执行的最小单位\n进程：分配资源的单位\n\n进程的创建\n\n进程的继承关系\n\n\n交互的能力（给另一个进程发消息 signal\n进程的状态\n删除进程\n多个进程之间共享内存（访问冲突\n\nmemory management\n\n让进程能（按照权限/规定）了解到自己目前所拥有的内存（静态分配or动态分配）的结构，的视图。\nstorage management\n在存储的介质上面（硬盘/SSD）\n\n提供一个抽象的访问接口：文件file\n文件的层结构：目录\n文件访问的权限\n文件是单个数据实体\n文件系统是一整套文件以及管理目录的整体\n磁盘上面分成若干块的partition 并赋予文件系统（一个盘符就代表一个单独的文件系统）\nmass-storage management\n海量存储管理，也就是磁盘管理\n相较于面向用户的storage管理 更多的是面向硬件的管理\nI/O subsystem\n\n\n\n                  \n                  system call能否实现成为library（函数调用 \n                  \n                \n\n存在安全性风险，比如软件调用特权指令等\n\n\n虚拟机\n本质其实是一种抽象\n给上层提供和底层硬件一样的interface\n\n\nhardware：host宿主机\nvirtual machine managerVMM/hypervisor：提供了具备操作系统特性的一个基本的管理软件，提供接口供虚拟机运行，结构相对来说简单\n\ntype1 裸金属的虚拟化baremtal hyperboza 比较好因为不需要完整的运行操作系统\ntype2 比如qemu 离不开地下原生os的运行\n\n\nguests：进程，可以运行多个进程（一个进程就是一个自成一体的完整操作系统 ）\n\n对guestos不做修改：全虚拟化\n对guestos做一点改动：半虚拟化，但是运行效率更高\nsysgen ：device driver之类的配置\n在操作系统power-on的过程中cpu执行的第一个软件（系统初始化自检硬件部分）：firmware固件\nbootloader是加载操作系统用的（locate kernel image on disk 并且加载进ram，switching the cpu mode for kernel execution）"},"课程笔记/操作系统/02.1-进程":{"slug":"课程笔记/操作系统/02.1-进程","filePath":"课程笔记/操作系统/02.1 进程.md","title":"02.1 进程","links":["tags/flashcard"],"tags":["flashcard"],"content":"进程基本概念 flashcard\n\n一段本质上是静态的、存储在硬盘上的指令数据，而当它附带运行程序所需要的必要信息进入内存，得到相关资源后，它成为一个动态的、与计算机资源互动的实体，这个实体就是进程(process)。简单来说就是运行中的一个实例。\nprocess=job。\n\n\n\n进程的形式 flashcard\n在内存中需要一块虚拟的地址空间来存储。包含两个部分\n虚拟地址空间中的用户部分\n\ntext section(code) 存储代码 加载到内存前以 executable file 的形式存储在 disk 中\nstack section 常说的栈 存储一些暂时性的数据，如函数传参、返回值、局部变量等\ndata section 存储代码中的全局变量、静态变量\nheap section 常说的堆，被动态分配的内存\n\n\n内存映像：0~max地址之间的区域叫做address space\n\n\n进程访问的物理空间是虚地址，因此这里的max也叫做maxVA(最大的虚地址)\n空洞hole：这个部分其实占比例很大，是无法合法访问的区域。\ntext和data部分所需要的空间在一开始就被确定，heap和stack可以动态扩展和收缩（但是加上hole的整个空间不变）\n\n\n虚拟地址空间中的内核部分\nPCB\n\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\n\n\nprocess control block（PCB） flashcard\n操作系统用一个PCB表示进程，每个进程有且仅有一个PCB，PCB 是进程存在的唯一标志。其中包含许多当前进程的相关信息\n\nprocess state 进程的状态\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\nCPU-scheduling information CPU调度参考的信息，包括优先级、调度队列的指针、调度参数等。\nmemory-management information 包括页表、段表等信息，具体与实现的内存系统有关。\nAccounting information 一些关于进程的动态数据的统计和记录，比如已经跑了多久、时间限制、进程号等等\nIO status information 被分配给进程的IO设备列表、打开的文件列表等\n\n\n是每个进程所独有的数据，和别的进程无关。\n是抽象概念的数据结构，不一定实现为block。不同的系统可能有不同的 PCB。Linux 中的进程用结构体 task_struct存储。\n如果只是中断去处理什么而不涉及进程切换，PCB也可以不用工作，而重要的信息直接保存到kernel stack里面。\n\n\n\n进程管理\n进程树 (process tree)\n\n\n用户进程在操作系统中，总体上遵循树状组织形式，每一个进程有一个唯一标识符进程号（通常为pid）\n进程之间存在一种父子关系，即 child 进程是由 parent 进程创建的，用 ppid 来标识它的 parent 进程\n\n进程的创建 flashcard\n\nchild 进程的资源可能直接来自操作系统的分配，也可能来自 parent 进程的继承，限制使用后者的好处是能够避免因为创建太多子进程而导致资源不够用。\n进程树的根是 systemd，历史上也曾叫过 init，它是操作系统启动后运行的第一个用户进程，至少在 Linux 中，它的 pid 被分配为 1，而它的 ppid 是 0，可以理解为这个进程的 parent 是 scheduler 而非一个进程\n\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;sys/types.h&gt;\n \nint main() {\n    printf(&quot;A process starts!\\n&quot;);\n \n    pid_t pid;\n    **pid = fork();**\n \n    if (pid &lt; 0) {\n        printf(&quot;Fork failed!\\n&quot;);\n    } else if (pid == 0) {\n        // sleep(1);\n        printf(&quot;pid is zero, so it&#039;s child process!\\n&quot;);\n    } else {\n        **// wait(NULL);**\n        // sleep(1);\n        printf(&quot;pid is nonzero thus it&#039;s parent process!\\n&quot;);\n    }\n}\n \n\nUNIX 系统中可以使用系统调用 fork() 来创建一个新进程。这个新进程是父进程的一份拷贝，它们只有 pid 和 ppid 不同，另外子进程当前内存使用记录为 0，除此以外全部相同。\npid = fork()之后，内存中有两个进程，一起从这行代码的下一行往下执行，通过检查返回值pid来判断属于parent还是child。在父进程中，fork（）返回的是创建的子进程的pid，子进程返回0，执行失败返回负数。\n\n这里的pid_t是一个局部变量\n\n\nwaite（NULL） 即父进程可以继续运行，或者等待子进程运行完以后再运行\n\n使得当前进程进入 waiting 状态，并在任一子进程终止，或被信号停止，或被信号恢复时进入 ready 状态，同时返回发生该事件的子进程的 pid\n如果第 18 行仍然被注释，那么 parent 进程和 child 进程将并发执行，即完成 fork() 后两个进程都从 11 行开始继续向下并发的执行，互不阻塞\n\n操作系统会让它们交替使用CPU。谁先完成自己的printf，完全取决于操作系统的“心情”（调度）。所以可能会先看到父进程的输出，也可能先看到子进程的输出。\n\n\n如果 18 行的注释被取消，那么 parent 进程将等待 child 进程结束后再继续。\n\n父进程执行wait(NULL)这行时，会被阻塞，需要等到子进程完全结束（执行完所有代码或调用了exit）之后才能继续往下执行自己的内容，子进程输出一定在父进程之前\n逻辑上创建的新进程有两种情况：\n\n\n\n\n\n\n复制 parent 进程的代码数据；\n载入新的程序并继续执行；\n而实际在 Linux 中，第一种通过 fork() 实现，第二种通过 fork() 后 execXX() 实现，execXX() 会覆盖那个进程的地址空间，以实现执行其他程序\n\n进程的终止 flashcard\n\n当进程调用 exit() 这个系统调用时，将被终止。\nC 语言 main 函数返回时也会隐式地调用 exit()。\n进程也会由于一些信号、异常等终止。\n这意味着这个进程将不再执行，其资源将被释放，同时返回状态值，而这个状态值将被 parent 进程的 wait() 接收。\n\n父进程通过调用 wait() 来做两件事：\n\n等待子进程结束。\n接收（回收） 子进程的这个“状态码”（检查作业本）。\n\n\n特别的，如果 parent 进程尚未调用 wait()，则这个 child 进程还不会完全消失，因为要返回的东西还没返回（child 并不知道 parent 会不会、什么时候来回收它）。这种逻辑上已经终止，但仍然占有一部分资源，等待 parent 进程调用 wait() 的进程，我们称之为僵尸进程(zombie)。\n当子进程没有结束，或者终止了但父进程没有调用 wait() 的情况下，父进程就结束了，子进程就会成为 孤儿进程 (orphan processes)（如果parent exiting ，成为孤儿进程，它的父进程变成init process（pid=1）init 进程会定期调用 wait()）\n\n\n\n进程间通信\n\n\n如果一个进程受到其它进程的影响，或会影响其它进程，那么我们称之为协作进程(cooperation process)，比如一个进程的输出作为另一个进程的输入使用，之类的。\n\n为了模块化设计，必不可少\n\n\n\n进程间通信(inter-process communication, IPC) flashcard\n\n是为了在进程的资源相互隔离的情况下，让不同的进程能相互访问资源从而协调工作。\n两种方式\n\n共享内存(shared memory)：（a）\n\n相比下面几种效率更高，需要用到 system call 的地方只有建立共享内存的时候\n两个进程各自有一块虚拟内存，映射到同一块物理内存。\n也需要信号量等同步手段保护\n\n\n消息传递(message passing)：（b）\n\n在分布式系统中更容易实现，对于少量数据通信很有用（因为不需要处理冲突问题 ）；\n\n建立link\n\n直接通信 特定某个id的进程\n间接通信 中转手段，比如信箱mailbox（well-known mailbox//ports）\n\n\n同步 blocking\n\nblocking send  让sender blocked 直到信息被接收到\nblocking receive receiver block直到信息可以被接收到\n\n\n异步 non-blocking\n\n\n\n\n\n\n\n\n\n信号量(semaphores)：本意用来线程间同步，但是可以通过 sem_open() 系统调用来建立和维护进程间的信号量；这样的信号量属于 OS 资源，它会在相关进程结束后由 OS 释放\n\n\n文件 / 管道(pipe)：\n\n管道本质上也是一种文件，创建管道时操作系统会返回两端的文件描述符\n但一个管道只支持单向传输，即只能 A 写 B 读，如果要实现双向需要两个管道【逻辑上是一个半双工的信道】\n\n\n\n\n【模型】producer-consumer problem\nproducer 信息输出方\nconsumer 信息接收方\n\n无界缓冲区 unbounded-buffer 缓冲区的大小相比于发送的信息相比不会满\n有界缓冲区 bounded-buffer\n\nproducer往buffer中放入items，consumer取出\n指定指针index-in给producer使用，index-out提供给consumer\n\n\n检查如果==out：认为没有freeitem是可以放的【下一个位置就是out指针】\n否则放入并且后移一位：0~buffersize-1，下一个又从0开始【理解为环形队列】\n\n\n\n\n如果有可取用的item 就往后移一位，并取出使用\n问题是：会浪费一个element 当out=1 in=0的时候 in没有办法insert进去了\n：\n\n\n\n\n"},"课程笔记/操作系统/02.2-调度":{"slug":"课程笔记/操作系统/02.2-调度","filePath":"课程笔记/操作系统/02.2 调度.md","title":"02.2 调度","links":["tags/flashcard"],"tags":["flashcard"],"content":"就绪队列(ready queue)和等待队列(wait queue) flashcard\n实际上换进程就是换PCB的指针位置放到哪个队列（kernel负责移动）\n\n\nready quene（里面的process都处在ready状态）（ CPU等待队列：）\n实际实现中，由于等待的io或者事件不同，可能维护多个等待队列。\n\nIO设备等待队列：device queue 等待完用好IO设备之后PCB被移走\n\n\n\n不需要等待其他设备也不需要使用处理器的进程？：空闲状态、将要结束的状态等，这样的进程就不会出现在上述队列中，会被放在job queue（系统中所有进程都在其中）\n\n\n进程状态state flashcard\n进程在execute时会改变状态。一个处理器上只有一个进程可以running。\n\nnew\n\n进程正在创建过程中，包括申请 PCB，分配初始资源等；\n\n\nrunning\n\n进程正在运行（正在使用CPU资源）\n有几个核就最多有几个进程处于running状态\n\n\nwaiting\n\n进程正在等待某个事件的发生，比如调用systemcall之后进程暂停的状态/IO操作中/其他event\n此时即使有空余的 CPU 资源，该进程也无法继续\n一般进程从running到waiting是主动的（系统调用之类 ），离开waiting进入ready是被动的\n\n\nready\n\n进程已经准备好了只差CPU资源，一旦有CPU资源可以分配给该进程，就会变为running态（等待 CPU 资源的派发(dispatch)，接受调度）\n如果有进程ready 说明一定有进程正在running\nCPU 调度实际上指的就是若干进程在ready和running之间的切换，当发生了 interrupt，如计时器到时间了，running就会切换到ready\n\n\nterminated\n\n进程因为某些原因终止，结束运行，需要释放资源；\n\n\ninterrupt触发后，本来要执行的指令被中断，os陷入到kernel中，在进行中断处理的时候，发现允许进程处理的时间片到了，那么就需要把这个进程换下来换成别的进程。原本的那个进程进入ready的状态。\nscheduler dispatch 调度程序，决定下一个将要运行的进程\nwaiting不能直接进入到runing必须经过ready\n\n\n调度\nscheduler类型 flashcard\n\n\nlong-term scheduler：（job scheduler）\n\n历史上的概念，主流操作系统里面已经没有了，现在实际上就是用户自己在担任这个角色。选择哪个processes需要从硬盘进入memory（the ready queue）\n如果允许太多io bound的进程进入cpu 那么就会阻塞在io queue里面，那么cpu就得不到有效的使用，因为等待io的进程太多，而准备运行的进程太少\n\n\nshort-term scheduler （CPU scheduler）\n\n多道 (multiprogramming) 环境下，进程的个数通常大于 CPU 的个数。CPU 调度就是 OS 关于哪个 ready 进程可以运行（使用 CPU）以及运行多久的决定。\n\n\nmedium term scheduler\n\n主内存严重不足时，需要将优先级较高的进程先加载到RAM（主内存）中。\n换到外存（硬盘）中（wipe out）之后状态仍然是waiting，当接收到所需的用户输入之后，会被考虑重新换到内存中。\n\n\n\n\n进程类型\n\nI/O-bound (I/O 密集型): 这种程序大部分时间都在“等待”。比如等待网络数据、等待读取硬盘文件。它只需要 CPU 算一小会儿，然后就去等待 I/O。\nCPU-bound (计算密集型): 这种程序是需要 CPU 一直不停地算很久，很少需要等待 I/O。比如视频渲染、科学计算。\n一个好的操作系统会混合搭配这两种程序，确保 CPU 和硬盘/网络都能保持忙碌，提高整体效率。\n\n\n\n                  \n                  Title \n                  \n                \n\n\n主内存 就是内存，CPU工作的区域，而 RAM 是主内存的物理实现。\n外存  SSD/HDD(硬盘)是外存的物理实现\nROM 是一个完全不同的东西。它是一个小容量、只读、断电不丢的芯片，它的唯一工作就是在你按下开机键时，引导电脑去“外存”里加载操作系统到“主内存(RAM)”中\n\n\n\n调度的时机 flashcard\n\nscheduler调度\n\n非抢占式调度(non-preemptive scheduling) running的进程由于某些原因需要主动离开running状态【绿色】\n抢占式调度(preemptive scheduling) ready的某个进程需要立刻得到CPU资源【蓝色】\n\n其他态转变为ready态来排队\n或者在排队的时候某个人想插队（优先级调度 ）\n\n\n非抢占式调度是由已经拥有资源的进程主动释放 CPU 资源引起的，而抢占式调度则是不占有资源的进程索取 CPU 资源成功引起的。\n\n\n调度的过程：上下文切换 flashcard\n由 CPU scheduler 选择哪一个ready态的将要被执行后，由 dispatcher 来完成具体的切换工作包括：\n\n在两个进程间进行上下文切换(context switch，包括恢复现场、保证进程执行一致性的过程)\n\n上下文：① CPU 寄存器中的值，② 进程状态，③ 内存的管理信息\n\n\n切换到用户态；\n跳转到用户程序中合适的位置以继续进程执行；\n\n\n进程切换：包括被中断和systemcall两种\n\n被中断 进入ready\nsystem call 进入waiting\n\n\n而从 dispatcher 停止上一个运行时的进程，完成上下文切换，并启动下一个进程的延时，称为 dispatch latency。\n\n\n\n调度算法\n调度算法的评价指标(scheduling criteria) flashcard\n\nMaximize CPU Utilization \n\nCPU 使用率，CPU 使用时间 / 总时间。即 CPU 非空闲的时间比例\n从 CPU 是否足够忙碌来看硬件性能是否充分发挥\n\n\nMaximize Throughput \n\n吞吐量，每个时间单元内完成的进程数\n从结果来看任务完成是否足够高效\n\n\nMinimize Turnaround Time\n\n周转时间，从进程创立到进程完成的时间，包括等待进入内存、在 ready queue 中等待、在 CPU 上执行、I/O 执行等时间\n通过观察最大周转时间，能反映调度的效率和“公平性”\n\n\nMinimize Waiting Time \n\n等待时间，在 ready queue 中（或在 Ready 状态下）等待所花的时间之和\n由于任务所需要的 CPU 时间、I/O 时间不受调度算法影响，所以抛开这些只看在 ready queue 中的等待时间，能反映调度算法的效率\n等待时间 = 周转时间 - 运行时间\n\n\nMinimize Response Time \n\n响应时间，交互系统从进程创立到第一次产生响应的时间\n能反应交互式系统中调度算法的“及时性”\n\n\n\n\n调度算法\n以下调度算法存在理想化建模，以及以multiprogram为基础\nFirst-Come, First-Serve (FCFS) | Nonpreemptive flashcard\n先申请 CPU 的进程首先获得 CPU，用First-In, First-Out（FIFO）队列实现\n\n\nShortest-Job-First (SJF) flashcard\nSJF 的核心想法是，让下一次运行时间最短的进程先来运行；根据数学知识，我们可以得知这样能得到最少的平均等待时间\n\n对于非抢占式的系统来说，当我们忽略 I/O 等会进入 waiting 的情况（因为题目通常这样设计），进程「下一次运行时间」就是整个进程所需的总运行时间。\n对于抢占式的系统而言，「下一次运行时间」实际上是进程的剩余运行时间，因为进程可能曾经被打断过。\n因此我们将 SJF 进一步细分成了两种。\n\nNon-preemptive: Shortest-next-CPU-burst\n选取 ready queue 中下次 CPU 执行时间最短的进程。这样会使得给定的一组进程具有 minimum average waiting time.\n\n\n在这个情景中，0s 时只有 P1 到达，因此 P1 先运行\n由于是非抢占式的，因此 P1 运行过程中其他进程的到达并不会导致重新调度，P1 得以完全运行\nP1 结束时，剩余进程都已到达，处于 ready 状态，因此调度器从 ready queue 中选取 brust time 最短的来运行，以此类推。[一个进程运行结束后进行再调度]\n\n​Preemptive: Shortest-remaining-time-first(SRTF)\n​每当 CPU 调度时（注意抢占式调度的调度时机），选择最短剩余运行时间的进程。\n\n\n在这个情境中，0s 时只有 P1 到达，因此 P1 先运行\n但不同的是，由于是抢占式的，因此 2s P2 到达时也会引发一次调度，此时 P1 的剩余时间是 8s，P2 是 6s，因此 P2 优先运行\n4s 时 P3 到达也引发一次调度，但此时 P1 的剩余时间是 8s，P2 是 4s，P3 是 7s，其中 P2 最短，因此仍然是 P2 继续运行[新进程到达时发生一次调度]\n5s 时 P4 到达也引发一次调度，此时 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，P4 是 2s，其中 P4 最短，因此 P4 优先运行\nP4 运行结束时，ready queue 中 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，因此 P2 先运行，以此类推。\n​SJF 的两个版本都可以获得最小的平均等待时间，但最大的问题在于我们并不知道「下一次运行时间 」。解决方案是预测，将下次执行时间预测为此前 CPU 执行长度的指数平均。指数平均需要操作系统统计该进程此前的运行情况\n\nRound-Robin (RR) | Preemptive flashcard\n定义一个 时间片 (time slice / time quantum) ，即一个固定的较小时间单元 (10-100ms)。\n\n除非一个 process 是 ready queue 中的唯一进程，它不会连续运行超过一个时间片的时间。\nReady queue 是一个 FIFO 的循环队列。每次调度时取出 ready queue 中的第一个进程，设置一个计时器使得进程在一个时间片后发生中断，然后 dispatch the process。\n\n相比 SJF 而言，平均等待时间更长，但响应时间更短。\n​RR scheduling 的性能很大程度上取决于时间片的大小。如果时间片较小，则 response/interactivity 会很好，但会有较大的 overhead，因为有较多的 context-switch；时间片较大则响应较差，但 overhead 会较小。\n如果时间片无限大，则 RR≈FCFS。\n在实践中，时间片大约 10~100ms，每次 contest-switch 约 10μs。即 context-switch 的时间花费是比较小的。\n\n\nPriority Scheduling flashcard\n每个进程都有一个优先级，每次调度时选取最高优先级的进程。（下例中规定优先级值小的优先级高）\n优先级可以是内部的或者外部的：\n\ninternal: 一些测量数据，例如 SJF 是 Priority 的一个特例，即优先级由预测 CPU 运行时间决定。\nexternal: 由用户指定进程的重要性。\n​要实现 Priority Scheduling，可以简单地将 ready queue 用 priority queue 实现；priority queue 也可以是抢占式或非抢占式的，如 SJF 一样。\n​Priority 的一个重要问题是 indefinite blocking / starvation ，即低优先级的进程可能永远没有机会被执行。一个解决方法是 Priority Aging ，即根据等待时间逐渐增加在系统中等待的进程的优先级。\n\n\nMultilevel Queue Scheduling flashcard\n在实际应用中，进程通常被分为不同的组，每个组有一个自己的 ready queue，且每个队列内部有自己独立的调度算法。\n\n前台队列使用 RR 调度以保证 response，后台队列可以使用 FCFS。\n队列之间也应当有调度。通常使用 preemptive priority scheduling，即当且仅当高优先级的队列（如前台队列）为空时，低优先级的队列（如后台队列）中的进程才能获准运行。\n使用队列间的 time-slicing，例如一个队列使用 80% 的时间片而另一个使用 20%。\n\n\n\nMultilevel Feedback Queue Scheduling flashcard\n​Multilevel Feedback Queue Scheduling 允许进程在队列之间迁移。这种算法可以有很多种实现，因为队列的数量、每个队列中的调度策略、队列之间的调度算法以及将进程升级到更高优先级/降级到更低优先级的队列的条件都是可变的。一个系统中的最优配置在另一个系统中不一定很好。这种算法也是最为复杂的。\n\n有三个队列 0, 1, 2，优先级逐次降低。\n当进程 ready 时被添加到 Q0 中，Q0 内部采用 RR Scheduling，的每个进程都有 8ms 的时间完成其运行，如果没有完成则被打断并进入 Q1；\n只有当 Q0 为空时 Q1 才可能被运行。Q1 内部也使用 RR Scheduling，每个进程有 16ms 时间完成其运行，如果没有完成则被打断并进入 Q2；\n只有当 Q1 也为空时 Q2 才可能被运行。Q2 内部采用 FCFS 算法。\n"},"课程笔记/操作系统/02.3-线程":{"slug":"课程笔记/操作系统/02.3-线程","filePath":"课程笔记/操作系统/02.3 线程.md","title":"02.3 线程","links":["tags/flashcard"],"tags":["flashcard"],"content":"多线程编程Multi-Threaded Programming flashcard\n》线程是一种轻量级的进程，它在进程的基础上进行划分，是进程内的一个可调度的执行单元，以减小进程 folk 和切换的开销为目的。\n》对于支持线程的操作系统，实际调度的是内核级线程而非进程。也就是说，线程是运行以及 CPU 调度的基本单元。（而进程是分配资源的基本单元。）\n同一进程的若干线程\n\n共享代码、数据等“相对静态”的资源\n各自维护寄存器、栈、PC 等“相对动态”的资源\n\n优点\n\n立线程相比进程是很经济的，因为 code, data &amp; heap 已经在内存中了。在同一进程的线程间进行 context switch 时也会更快，因为不需要 cache flush\n线程天生和同一进程内的其它线程共享资源，因此同进程内线程天生就有线程间通信的能力。不需要IPC（inter-process communication）进行不同进程间交流\n同时，由于将进程进行了再划分，一方面在硬件支持的情况下能更好地适配并行，另一方面也能（代价更小地）让任务的粒度变小，此时可以将整个进程的阻塞转移到单个线程的阻塞上，进一步减少响应时间。\n\n缺点\n\n虽然将若干任务都放到一个进程的多线程可以提高效率，但是一旦“篮子”坏了，那所有“鸡蛋”都无法幸免；\n其次，虽然天然的共享属性让线程能更方便地进行线程间通信，但也带来了内存保护的问题。\n由于 OS 对每个进程地址空间的大小限制，多线程可能会使得进程的内存限制更加紧缩（这在 64 位体系结构中不再是问题）\n\n\n线程实现方式 flashcard\n按照线程划分的实现位置，多线程模型分为\n\n用户级多线程(user threads)\n\n它在操作系统上只是一个进程，这个进程包含 线程库 (Thread Library) 的部分，​这部分代码负责完成线程的创建、切换等操作；\n\n\n内核级多线程(kernel threads)。\n\n内核级线程则是由操作系统支持这些操作。\n两者各有优缺点：\n\n\n用户级多线程 &gt; 内核级多线程\n\n用户级多线程不需要进入内核态实现多线程，也不需要占用线程 ID，因此理论上可以比内核级支持更多的线程数；\n由于其划分是针对进程的，而不同进程之间的线程实现没有直接关系，而且由于是在用户空间实现算法，所以能够更容易的对单个进程内的多个线程的调度算法进行自定义；\n\n\n用户级多线程 &lt; 内核级多线程\n\n由于对内核来说，用户级多线程仍然是一个普通的进程，所以当用户级的线程出现阻塞时，内核会认为整个进程都被阻塞；内核级线程由于是内核实现，所以单线程的阻塞并不会导致整个进程阻塞；\n在多核的情况下，用户级多线程没法利用多核进行线程并行；只有内核 (OS) 才能把工作分配到不同的 CPU 核心上\n\n\n\n\n多线程主要模型 flashcard\n需要注意的是，用户级多线程和内核级多线程并不冲突，因而排列组合后得到多线程主要有如下三种模型：\n\n(a) One-to-one model. (b) Many-to-many model. (c) Many-to-one model.\n\n每个用户线程都创建一个内核线程，开销大，但是不会有一个阻塞都被阻塞的问题\n可以智能地调度userthread要用哪个kernelthread，一个被阻塞了就换另一个kernelthread工作\n只给kernelthreads分配一个CPUcore，一个被阻塞就会都被阻塞[kernelthread的阻塞问题]\n\n\n\n线程池\n\n适用场景：大量同时并发任务处理000000"},"课程笔记/操作系统/04.1-主存":{"slug":"课程笔记/操作系统/04.1-主存","filePath":"课程笔记/操作系统/04.1 主存.md","title":"04.1 主存","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n内存是一个很大的字节数组，CPU 根据 PC (Program Counter) 的值从内存中提取指令。程序需要运行，至少部分程序及其访问的数据应在内存中（或者更明确地，内存中的一个进程里）\nCPU 可以直接访问的通用存储只有 main memory 和 registers。对 registers 的访问通常可以在一个 CPU 时钟周期中完成，而完成内存的访问可能需要多个时钟周期。在这些时钟周期里，由于没有用来完成指令的数据，这会引起 stall）。\n\n为了补救，在 CPU 芯片上增设更快的内存，称为 cache 。\n\n\n同时，需要保护内存空间，防止用户程序修改操作系统或其他用户程序的代码或者数据。\n\nAddress Binding flashcard\n\n.c-&gt;.o的过程\n\n编译器complier将源代码中的地址绑定到Relocatable Address\n\n源代码中的地址通常是用符号表示（symbolic）： 例如各种变量、函数名；汇编中的 label 等\nRelocatable Address：可重定位地址。相对于某一个段/模块等的偏移，例如 sp - 8, ds:[0]。即把源代码符号地址背后的具体内容重排到源程序的相对位置\n\n\n\n\n.p-&gt;.exe（and其他可执行文件形式）的过程\n\n链接器linker 收集所有.o文件，将每个代码文件的地址绑定成相对整个程序的地址\n\n\n加载器loader 将可执行文件绑定到内存地址中，得到最终的绝对地址Absolute Address\n\n当然，如果编译器在编译时就知道程序所处的内存地址，则会生成 absolute code-》program in memory\n\n\n\n\n\n连续内存分配\n\n在 Batch（批处理）系统中，每次只有一个程序被加载入物理内存，并被运行至结束。\n\n如果程序所需的存储空间比物理内存大，则将程序分开为可以运行至产生某个结果且大小可以放入空余内存的部分，逐个运行，将运行结果传递给下一个部分。\n\n\n现在我们需要把多个进程同时放在内存中，并且支持其彼此之间的快速切换。最简单的内存分配方法之一，就是将内存分成许多的 partition，每个 partition 包含一个进程。其要求有：\n\nProtection: 保证进程之间不会互相闯入对方的存储。\nFast execution: 不能由于 protection 降低访问内存的效率。\nFast context switch: 每当进行 context switch 时，可以比较快地找到并访问当前进程的内存。\n\n\n当进程进入系统，操作系统根据各个进程的内存需要以及当前的空闲内存空间来决定为哪些进程分配内存。当一个进程被分配到了空间，他将被载入到内存中，并与其他进程竞争 CPU 时间。当一个进程结束时，它释放它的空间。\n如果一个进程请求空间来运行，但没有足够的内存来满足其要求\n\n直接拒绝其请求并给出一个错误信息\n或将其加入 waiting queue 中，当有内存被释放时 CPU 来检查是否为其分配内存。\n\n\n\n内存分区策略partion flashcard\nFixed Partition 固定大小partition\n\n固定 partition 的大小（除了 OS 使用的内存），只需要记录每个partition是否被占用即可。\nInternal Fragmentation：一个partition中剩余的空间不能够被别的进程所使用。【 不可用内存分布在 partition 之内】\n\nVariable Partition\n\n不固定 partition 的大小，维护一个表，记录可用和已用的内存。\n最开始时是一大块可用内存块（可用内存块称为hole），经过一段时间运行后可能就会包含一系列不同大小的孔\nExternal Fragmentation： 一段时间运行后，内存空间被分为大量的hole，加起来可以满足要求但是并不连续，所以无法被利用。【 不可用内存分布在 partition 之外】\n\n\n\n动态存储分配问题 Dynamic Storage-Allocation Problem flashcard\n根据一组 hole 来分配大小为 n 的请求，的问题\n解决方法有：\n\nfirst-fit 分配首个足够大的 hole。这种方法会使得分配集中在低地址区，并在此处产生大量的碎片，在每次尝试分配的时候都会遍历到，增大查找的开销。\nbest-fit 分配最小的足够大的 hole。除非空闲列表按大小排序，否则这种方法需要对整个列表进行遍历。这种方法同样会留下许多碎片。\nworst-fit 分配最大的 hole。同样，除非列表有序，否则我们需要遍历整个列表。这种方法的好处是每次分配后通常不会使剩下的空闲块太小，这在中小进程较多的情况下性能较好，并且产生碎片的几率更小。\n\n\n\n内存保护机制Protection flashcard\n保证一个进程能且仅能访问自己空间中的地址。通过一套 base 和 limit 寄存器来确定一个程序的空间：\n\n\n每当 context switch 到一个新的进程时，CPU 会 load 这两个寄存器的值\n每当 user mode 想要进行一次内存访问时，CPU 都要检查其是否试图访问非法地址；如果是，则会引发一个 trap 并被当做致命错误处理（通常会 terminate 掉进程 ）：\n\n\n\n分段Segmentation\nBasic Method\n虽然我们程序中的主函数、数组、符号表、子函数等等内部需要有一定的顺序，但是这些模块之间的先后顺序是无关紧要的。\n\n\n一个程序是由一组 segment （段）构成的，每个 segment 都有其名称和长度。我们只要知道 segment 在物理内存中的基地址 (base) 和段内偏移地址 (offset) 就可以对应到物理地址中了。\n对于每一个 segment，我们给其一个编号。即，我们通过二元有序组 表示了一个地址。这种表示称为 logical address（逻辑地址）或 virtual address（虚拟地址）。\n通常，在编译用户程序时，编译器会自动构造段。\n\nSegmentation—Logical Address &amp; MMU\n要将逻辑地址映射到物理地址，首先我们需要找到段的基地址。\n\nsegment table\n\n其中每个条目以 segment-number 索引\n存储其 段基地址 segment-base 和 段界限 segment-limit（可能还包含权限位）。\n因此逻辑地址的映射方式如下图：如果offset&lt;limit，则加上base得到物理地址\n\n\n这一过程是由硬件设备 MMU (Memory-Management Unit, 内存管理单元) 完成的。CPU 使用的是逻辑地址，而内存寻址使用的是物理地址，MMU 完成的是翻译（映射）和保护工作：这里的 relocation register 即为 base register。\n\nProblems\n分段将一个程序分为数个部分，但是其内存分配的策略与简单的 partition 是一致的。因此，分段仍然会存在 external fragmentation 的问题：其表征是总空余内存是足够的，但是由于它不连续导致其无法使用。也就是说，这个问题的核心点在于 not contiguous。我们有两种思路来解决这一问题：将\n\n内存重排使得 holes 连成一块\n\nCompaction 就是将内存中的内容重排使得所有空闲空间连续。这一操作要求内存中的程序是 relocatable  的，即其地址是相对 base 的偏移；这一要求在前面两种内存分配方式中是满足的。但是这一操作需要将内存逐一复制，这将消耗很多时间。\n\n\n或者设计方案让程序不再需要连续的地址。\n\n实际上，分段已经是这个方向上做出的一种尝试了，因为它将程序分为了几块，相比于简单的 partition，分段有助于减小 external fragmentation。为了更好地解决这个问题，我们提出 paging。\n\n\n\n分页Paging\nPaging （分页）是一种允许进程的物理地址空间不连续的内存管理方案。它避免了 external fragmentation 和 Compaction。各种形式的 paging 被大多数操作系统采用；实现 paging 需要 OS 和硬件的协作\nBasic Method\n\n物理地址:\n\n将 physical memory 切分成等大小的块（2 的幂，通常为 4KB = 2^12B ），称为 frames（帧）\n当一个进程要执行时，其内容填到一些可用的 frame 中，其中的每一个地址可以用这个 frame 的 base/number(唯一)以及相对这个 base 的 offset 表示\n\n\n逻辑地址:\n\n将 logical memory 切分成同样大小的块，称为 pages（页）\n同时 CPU 生成逻辑地址，逻辑地址包含一个 page number 和一个 page offset；另有一个 page table，它以 page number 索引，其中的第 i 项存储的是 page number 为 i 的 page 所在物理内存的 frame 的 base。这样，每一个 page 将通过其 page number 映射到一个 frame 上；进而 page 中的每一个地址也通过 offset 与frame中的对应地址建立映射。\n\n\n也就是说，当 MMU 需要将一个 logical address 翻译为 physical address 时，它需要获取 page number p，在 page table 中找到第 p 个 page 对应的的 frame number（也就是 frame base） f ，在 f 后面连接上 offset d 就得到了对应的 physical address。如我们之前所说，logical address 和 physical address 的 offset 应是一致的。\n\n当一个进程需要执行时，其每一页都需要一帧。因此，如果进程需要 n 页，则内存中需要有 n 个帧。如果有，那么就可以分配给新进程：进程的每一页装入一个帧，frame number 放入进程的 page table 中。\n由于操作系统管理物理内存，它应该知道物理内存的分配细节，即共有多少帧、帧是否空闲等。这些信息保存在 frame table 中，每个条目对应一个帧，保存其是否被占用；如果被占用，是被哪个进程的哪个页占用。\n\nWhy “Not Contiguous”\nPage table 硬件实现\n1. Simplest method\n最简单的方法是用一组专用的寄存器来实现。\n\n这一实现方法的优点是使用时非常迅速，因为对寄存器的访问是十分高效的。\n但是，由于成本等原因，寄存器的数量有限，因此这种方法要求 page table 的大小很小；同时，由于专用寄存器只有一组，因此 context switch 时需要存储并重新加载这些寄存器。\n\n2. Page table in memory &amp; PTBR\n\n大多数现代计算机允许页表非常大，因此对于这些机器，采用快速寄存器实现页表就不可行了。我们将页表放在内存中，并用 Page-Table Base Register (PTBR) 指向页表。在 context switch 时只需要修改 PTBR。\n但是这种方法的效率存在问题。要访问 logical address 对应的 physical address，我们首先要根据 PTBR 和 page number 来找到页表在内存的位置，并在其中得到 page 对应的 frame number，这需要一次内存访问；然后我们根据 frame number 和 page offset 算出真实的 physical address，并访问对应的字节内容。即，访问一个字节需要两次内存访问，这会加倍原本的内存访问的时间，这是难以接受的。\n\n3. TLB flashcard\n\n这个问题的解决方法用到一个专用的高速查找硬件 cache (associative memory，支持 parallel search)，这里称它为 translation look-aside buffer (TLB)。总之就是缓存!\nTLB 的每个条目由 key &amp; value 组成，分别表示 page number 和 frame number，通常有 641024 个条目（PPT 上说 641024，课本上说 32~1024，区别不大）\n当我们需要找到一个 page number 对应的 frame number 时，TLB 会 同时与其中所有的 key 进行比较：如果找到对应条目，就不必访问内存；如果没有找到（称为 TLB miss），则访问内存并将新的 key &amp; value 存入 TLB 中，这会替换掉 TLB 原有的一个条目。\n替换的策略包括 least recently used (LRU), round-robin, random 等。有些 TLB 支持将某些条目[比如重要的内核代码] wired down，即他们不会从 TLB 中被替换。在 MIPS 架构中，TLB miss 作为 exception 由操作系统处理；在 X86 架构中，TLB miss 由硬件处理。\n\n\nTLB with ASID\n\n每个进程都有自己的页表,每个页是按照多级结构存储的\n如同我们提到过的，每个 process 都有其自己的 page table。因此切换进程时也需要切换 page table。亦即，我们需要保证 TLB 与当前进程的 page table 是一致的。\n\n\n为了保证这一要求，我们可以在每次切换时 flush TLB。\n或者，有些 TLB 还在每个条目中保存 Address-Space Identifier (ASID)，每个 ASID 唯一标识一个进程。当 TLB 进行匹配时，除了 page number 外也对 ASID 进行匹配。\n\nEffective memory-access time EAT\n\nMemory Protection内存保护\n分页环境下的内存保护由与每个 frame 关联的 protection bits 实现。这些 bits 通常保存在页表中。例如 valid-invalid bit：\n\nv (Valid/有效)： 表示对应的页是进程合法地址空间的一部分，因此地址转换可以正常进行。\ni (Invalid/无效)： 表示对应的页不是进程合法地址空间的一部分，如果 CPU 试图生成该页号对应的地址，计算机将触发一个 trap (陷入) 到操作系统，表示这是一个无效的页引用 (invalid page reference)。\n如图所示，在一个具有 14 位地址空间（0 到 16383）的系统中，我们有一个程序应该仅使用地址 0 到 10468。给定页面大小为 2 KB，我们有如图 9.13 所示的情况。页面 0、1、2、3、4 和 5 中的地址通过页表正常映射。但是，尝试生成页面 6 或 7 中的地址会发现位被设置为无效，陷入无效页面引用异常\n注意，因为程序只延伸到地址 10468，任何超过该地址的引用都是非法的。然而，对页面 5 的引用被归类为有效的，所以对地址 12287 以内的访问都是有效的。只有从 12288 到 16383 的地址是无效的。这个问题是 2-KB 页面大小的结果，反映了分页的内部碎片。\n某些系统提供硬件形式的页表长度寄存器（PTLR），以指示页表的大小。这个值会针对每个逻辑地址进行检查，以验证该地址在进程的有效范围内。未通过此测试将导致对操作系统的错误陷阱。\n\nShared Pages\n分页可以允许进程间共享代码，例如同一程序的多个进程可以使用同一份代码，只要这份代码是 reentrant code （or non-self-modifying code : never changes between execution），如下图所示：图中所述的是多个进程共享一份库代码的情况；共享还可以用于进程之间的交流。当然，每个进程也可以有其自己的代码和数据。\n分页Problems\n\n会导致内部碎片。内存分配是以 frame 为单位执行的，如果进程要求的内存不是 frame 大小的整数倍，那么最后一个 frame 就会用不完，产生内部碎片。最坏的情况下，一个需要 n pages + 1 byte 的进程需要分配 n+1 个 frame，那么就会产生 FrameSize - 1 那么大的 Internal Fragmentation。\n如果进程的大小与页大小无关，每个进程中内部碎片的均值为 ½ FrameSize。在实际情况中，平均值比这小很多。当然，我们不能为了减小内部碎片而将 frame 的大小无限减小，因为更小的 frame size 需要更多的页表项。\n\nStructure of Page Table\n多级页表\n页表是一个数组， page_table[i] 中存储的是 page number 为 i 的 page 所对应的 frame number。考虑我们的逻辑地址结构：\n\n这样的逻辑地址结构需要一个存储 2^p 个元素的 page table，即需要这么大的连续内存，这是非常大的消耗。我们考虑将 p 再分为 p1 和 p2 ：\n\n两级页表， outer_page_table[i] 中存储的是 p1 为 i 的 inner page table，即inner_page_table[i][] 的基地址；\n而 inner_page_table[i][j] 中存储的就是 p1 为 i，p2 为 j 的 page 对应的 frame number，即 page number 为 p1p2 （没有分割时的 p）对应的 frame number。\n称 p1 为 page directory number ，p2 为 page table number，d 为 page offset。 \n逻辑地址 代替 物理地址满足了程序的 contiguous 要求。考虑这中分两页的 page table 结构，我们可以发现我们只是将 p 分成了两部分；对于程序来说，p+d 构成的整体（即逻辑地址）仍然是 contiguous 的，而且程序并不会意识到我们将 p 分成了 p1 和 p2 两部分，就像曾经它没有意识到我们将 address 分为了 p 和 d 两部分一样。这些划分只是我们为了更好地分配内存所做的、Operating-System-Level 的事情而已。\n考虑这样做的好处：hierarchical paging 其实就是对页表的分页（page the page table）。因此，它避免了 page table 必须处在连续内存的问题，这一问题在 p 比较大时尤其严重。\n另外，这样做在一般情况下可以节省空间。我们之前提到，页表不一定会全部使用；并且由于逻辑地址是连续的，因此用到的页表项也是连续的，都排在页表的头部。因此如果我们采用了二级页表，那么许多排在后面的 inner page table 将完全为空；此时我们可以直接不给这些 inner page table 分配空间，即我们只分配最大的 p1 那么多个 inner page table。这样我们可以节省很多空间。即使在最差的情况下，所有页表都被使用了，我们的页表所用的总条目数也只有类似地，我们可以设计更多级的页表。例如，64 位的逻辑地址空间使用二级页表就是不够的，否则它的页表就会长成这样：这样，我们就建立了一个三级页表。\n实际上，我们不必使用全部的 64 位，即我们不需要一个 64 位那么巨大的 virtual address space。AMD-64 支持 48-bit 的虚拟地址，ARM64 支持 39-bit 和 48-bit 的虚拟地址空间：\n\nHashed Page Tables 哈希页表\n前面介绍的页表是使用一个 table 保存 page# 对应的 frame#，这种解决方案面临的问题是空间需求是且连续的；我们通过多级页表解决这个问题。而哈希页表给 page# 分配 frame# 并不是随意分配，而是通过哈希计算得到。这样的方式将空间需求降低到且每个 page 对应的表项在内存中并不需要连续，从而解决了这个问题。哈希页表的每一个条目除了 page number 和 frame number 以外，还有一个指向有同一哈希值的下一个页表项的指针。这个结构与一般的哈希表是一致的。这是 32-bit address spaces 页表的一个常用方案。\nInverted Page Tables 倒排页表\n在之前的分页方法时，每个进程都有一个页表。这种方法会导致这些表可能使用大量的物理内存。\nInverted page tables 索引 physical address 而不是 logical address，也就是说，整个系统只有一个页表，并且每个物理内存的 frame 只有一条相应的条目。寻址时，CPU 遍历页表，找到对应的 pid 和 page number，其在页表中所处的位置即为 frame number：==页表的第 i 项（帧 i）存储了哪个进程的哪个页占用了这个帧，即存储了 (pid, p) 对。==\n\n这种做法的缺点是\n\n寻址过程需要很长时间。我们也可以用 TLB 或者 hashed table 来加速。\n这种方法不能够共享内存，因为 page table 的每一个条目（与 frame number 一一对应）只能存储一个 page number。\n传统页表是每个进程有一个独立的页表，把用到的页和对应的frame联系起来。倒排页表整个系统只有一个，第i项表示帧i，存储了哪个进程的哪个页占用了这个帧。\n\nSwapping\n\n进程的指令和数据必须在内存中以执行，但是我们可以将进程或进程的一部分暂时从内存 swap 到 ==backing store （备份存储，通常是一个比较快的磁盘）==中，继续运行时从中重新拿回到内存。\nSwapping 使得所有进程总的物理地址空间总和超过系统中真实的物理地址空间称为可能，提高了系统的 degree of multiprogramming。\n当然，在内存比较充足的情况下，swapping 并不必使用。Swapping 可能会导致很长的 context switch 用时，因为下一个进程可能并不在内存中，而由于磁盘的 I/O 很慢，swapping 到内存会花费很长时间。\n在分页的机制中，我们可以只 swap out 一些 pages，而不必 swap out 一整个进程：\n"},"课程笔记/操作系统/04.2-virtual-memory":{"slug":"课程笔记/操作系统/04.2-virtual-memory","filePath":"课程笔记/操作系统/04.2 virtual memory.md","title":"04.2 virtual memory","links":["tags/flashcard"],"tags":["flashcard"],"content":"地址空间与异常\n地址空间 (address space) 指的是地址取值的全集。\n\n物理地址空间\n\n例如，对于一个 32 位寻址的体系结构，其 物理地址空间（物理地址的集合）就是 ，亦即 0x00000000 ~ 0xffffffff。\n- flat memory内存模型: 在引入分段 / 分页技术之前，各个进程和操作系统共同使用同一个物理地址空间。它会带来比较大的碎片，同时隔离性较差，内存的保护较弱。\n\n\n虚拟地址空间\n\n而在引入了分段 / 分页技术之后，每个进程都有了自己的一套 logical memory (a.k.a. virtual memory) ，其对应的的地址空间就叫做 逻辑地址空间 (logical address space) 或者 虚拟地址空间 (virtual address space)；而对应的段表 / 页表的作用就是提供从虚拟地址空间到物理地址空间的映射（映射过程中，由于 swapping 机制的存在，也有可能出现 swap 的过程）。\n\n\n我们知道，上述的映射过程由 OS 和 MMU 共同实现，因此进程的虚拟地址空间是被隔离的；只要 MMU 不出现问题以及页表不被篡改（这通常比较困难），其他进程就没有办法访问到这个进程的内存。\n也就是说，虚拟内存供软件使用，而 CPU 在访问对应的内存地址时会由 MMU 自动转换为对应的物理地址；如果对应的 page 不在物理内存中，就会触发一次 page fault，这是一个 exception。有 3 种可能的情况：\n\n当前的进程的页表中并没有这个虚拟地址对应的 page；\n权限不符，例如试图运行某个权限位是 RW- 的 page 中的代码，或者试图写入某个权限位是 R-X 或 R-- 的 page 中的某个内存单元；\n当前虚拟地址是合法的，但是对应的 page 被 swapped out 了。\n\n\n我们知道，exception 会交由操作系统处理；如果是前两种情况，操作系统应当报错并做相关处理（例如杀掉对应进程）；而如果是后一种情况，操作系统应当将进程阻塞，并将对应的 page 交换回来，调页完成后唤醒进程。\n在一条指令执行期间，可能触发多次 page fault（指令本身和访问的地址可能都不在物理内存中）。当 page fault 被解决后，指令被重新运行；因此一条指令在真正成功运行之前可能会被尝试运行多次。\n\nKernel Addresses &amp; Userspace Addresses flashcard\n\n每个进程的虚拟地址空间（下简称地址空间、AS）被分为了 Kernel Portion 和 User Portion\n\nkernel 模式下的代码可以访问这两块空间 [CPU 陷入内核代码，进入高权限，但它依然是在这个进程的上下文中工作]\nuser 模式下的代码只能访问 User Portion。\n\n\n每个进程的 AS 的 kernel portion 都映射到了同一块物理内存。原因是显然的：所有进程用到的都是同一套 kernel，因此没必要把 kernel 用的内存（存例如各个进程的页表、各种队列之类的东西）复制好几份。\n\n实现\n\n在 32 位虚拟地址空间（4GB）的设计里，kernel 默认使用高 1GB，各个进程的 user portion 使用低 3GB 的虚拟地址空间；通过在 build kernel 之前更改 CONFIG_PAGE_OFFSET 可以更改这一分配\n\n32位系统只使用一套页表\n\n\n对于 64 位虚拟地址空间的设计，由于根本用不了这么多，因此 kernel space 和 user space 被自然分隔开：其中 TTBR (Translation Table Base Register) 保存页表的基地址\n=TTBR0 管理的用户空间 + TTBR1 管理的内核空间。对应两套页表\nTTBR0 是每个进程的页表对应的 TTBR\nTTBR1 是 kernel portion 的页表对应的 TTBR。\n\n\n\n\n                  \n                  分配策略和置换策略的区别 \n                  \n                \n\n\n延迟分配 和 COW 是在内存充足时优化分配或复制的策略，目的是推迟或避免分配，从而节省内存。\n页面置换 是在内存不足时（物理帧耗尽）强制释放内存的策略，目的是在资源紧张时保证系统能继续运行。\n\n\n\n分配策略\nLazy Allocation / Demand Paging flashcard\n操作系统在分配 user space 的内存时，会使用 lazy allocation：\n\n当用户程序申请一块内存时，操作系统并不会真的立即在物理内存中分配对应的内存；直到这块内存被真正访问。\n原理: 很多用户程序申请的内存大小比真正需要使用的通常要大，例如 buffer 等。\n\n\n程序（例如通过 malloc 库函数）发现需要更多内存，于是调用 brk() 系统调用来请求扩大其堆（Heap）的边界。\n\n此时，虚拟堆大小为 8KB，物理内存占用（Rss - Resident Set Size）也是 8KB。\n\n\n内核响应 brk() 请求，仅仅扩大了进程的虚拟内存区域（VMA）。新的页面此时并未映射到任何物理内存。\n\n进程的虚拟堆大小（Size）增加到 16KB，但其物理内存占用（Rss）仍然是 8KB。内核只是在进程的虚拟地址空间中“画了一块饼”，但没有给它“真正的食物”（物理内存）。\n\n\n程序执行代码，试图第一次读取或写入刚刚申请到的新虚拟内存地址。\n\nCPU（通过 MMU）在页表中查找该虚拟地址，发现它没有任何对应的物理内存映射。\n处理器触发一个缺页中断（Page Fault）。这不是一个程序错误，而是一个给内核的信号。\n\n\n内核捕获这个中断，意识到这是一个合法的“按需分页”请求。\n- 它从可用的“free”列表中找到一个空闲的物理页帧（Page Frame）。\n- 内核将这个物理页帧映射到程序试图访问的虚拟地址。\n- 它为此创建或更新页表项（PTE - Page Table Entry）。\n- 状态： 物理内存占用（Rss）现在增加到 12KB（假设新分配的页是 4KB）。\n\n\nCopy-on-Write flashcard\n\n很多子进程在 fork() 之后立刻调用 exec()[创建一个复制的子进程,并且用一个全新的程序(可执行文件)的内容覆盖内核态中父进程的代码、数据、栈和堆.]因此将父进程的地址空间整个复制一份是比较浪费的明明马上就会被覆盖.\nCopy-on-Write机制允许父进程和子进程最初使用同一份物理页来进行工作，在任何一个进程需要写入某个共享 frame 时再进行复制。\n进一步地，Linux 等操作系统提供了 vfork()，进一步优化子进程在 fork() 之后立刻调用 exec() 的情形。vfork() 并不使用 copy-on-write；调用 vfork() 之后，父进程会被挂起，子进程使用父进程的地址空间。如果子进程此时修改地址空间中的任何页面，这些修改对父进程都是可见的。\n\n\n置换策略\nPage Replacement flashcard\n\n我们在Lazy Allocation或者Copy-on-Write讨论的情况下，或者在 kernel、I/O buffer 之类的情况下,需要从磁盘将页调入内存,会需要空闲的物理帧[需要有一个位置].\n\n但是没有空闲的物理帧时应该怎么办呢？我们可以交换出去一整个进程:\n\n将一个进程的所有页都写回磁盘（备份存储），释放它占用的所有帧。\n\n\n更常见地，我们找到一个当前不在使用的帧，并释放它。\n基本步骤是：\n\n\n\n\n找到这个 victim frame；\n将其内容写回备份存储swap space/disk；\n\n dirty bit (a.k.a. modify bit) 该位保存对应 frame 是否被修改过；如果没有被修改过,就不用写回\n\n\n调入 Page X： 将进程 P 缺失的 Page X 从硬盘（备份存储）调入到刚刚腾出的物理帧 F_A 中。\n修改页表（和 TLB 等）以表示它不在内存中了。\n\n将页表中的有效位设置为无效\n从TLB中删除对应条目\n如何确定哪个 frame 应当用来作为 victim frame 呢？我们的核心目标是，降低 page fault 的频率。\n\n\n\n\n\n\n                  \n                  如何从磁盘匹配和找回被换出的页面？ \n                  \n                \n\n被换出的页面总能被系统准确找回，这是因为页表和备份存储（Backing Store）有明确的记录机制。\n当下次 CPU 再次请求访问这个已被换出的页面时，步骤如下：\n\n触发缺页中断（Page Fault）： CPU 请求访问 Page X，MMU 查阅该进程的页表。页表显示 X 的 valid-invalid bit 设置为 无效（i），触发 Page Fault，控制权交给 OS 内核。\n定位 Page X： OS 检查页表中的其他信息（这些信息在页被换出时被记录）\n\n页表项： 页表项不再存储帧号，而是存储一个特殊标记，该标记指向 Page X 在**备份存储（磁盘）**上的确切位置（例如，交换空间中的块地址）。\n\n\n调页（Paging）：\n\nOS 执行页面置换流程（找到 Victim Frame）。\nOS 从备份存储中，根据第 2 步记录的地址，将 Page X 调入到这个 Victim Frame 中。\n\n\n更新页表： Page X 被调入后，OS 更新页表，将该页的 valid-invalid bit 设置为有效（v），并记录它现在所处的物理帧号。\n指令重执行： OS 将控制权交还给 CPU，让 CPU 重新执行被中断的那条指令。\n\n\n\n页面置换算法 (page replacement algorithms) flashcard\nOptimal\n这种算法选择 最长时间内不再被访问的页面 换出。容易证明，这种方案的 page-fault rate 是最低的。不过，由于实际实现中我们没有办法预测结果，因此它只作为理论最优解用来判定其他算法的优劣。\nFIFO (First In First Out)\n这种算法换出 最先进入内存的页面。实现比较简单，使用一个队列保存调入内存的顺序即可。\n这种算法的问题是，其逻辑和实际不符；实际情况下有很多页面会经常被访问。\n另外，这种算法可能会遇到物理帧增加的时候 page-fault 反而更多的异常情况。这被称为 Belady’s Anomaly：\n\n123412512345是一次请求访问的页面号\n\n上半部分:限制进程只能使用 3 个帧。\n\n关键页 A 可能会在它再次被访问之前就被淘汰了（FIFO 逻辑）。\n\n\n下半部分:限制进程可以使用 4 个帧。\n\n由于内存变大，关键页 A 驻留的时间变长了。但与此同时，它占用的位置可能会导致另一个很快就要被用到的更关键的页 B 被提前淘汰，从而导致总体缺页次数增加\n\n\n\n\n\n\nLRU (Least Recently Used)\n\n实现的一种策略是给每个页表项一个 counter，每次访问某个 page 时，将 counter 更新为当前的时间[只要被用了,就会往后调,从淘汰最早变成了淘汰间隔最长]\n\n每次需要置换时，搜索 counter 最小的页。也可以用 heap 来优化。\n\n\n另一种策略是用一个栈保存 page numbers，每次访问时找到它然后把它挪到栈顶。\n这两种实现开销都比较大。\n\nLRU-Approximation\n\n因此，我们在 LRU 和性能之间做一个折中；引入一个 reference bit，来近似地实现 LRU。当一个 page 被访问时这个 bit 被置为 1；操作系统定期将 reference bit 清零。因此，在需要交换时，只需要找一个 reference bit 为 0 的就可以说明它在这段时间内没有被访问过。\n或者加上优先级bit\n加上counting bit 记录被访问的次数\n\n\n进阶策略\nAllocation of Frames\n为什么要分配frame\n\n\n采取 全局置换 (global replacement)\n\n当进程 A 发生缺页中断需要一个新的帧时，操作系统可以从所有物理帧中（即系统中所有进程 P1, P2, P3… 占用的帧）中选取一个 Victim Frame[灵活:更好的系统吞吐量但是不隔离:自己的pagefault率会取决于其他进程的运行状况]\n那么我们就不一定有必要提前规定每个进程最多能够使用多少个 frame；\n\n\n\n采取 局部替换 (local replacement)[隔离但僵化]\n\n只在当前进程分配到的物理帧中进行替换\n那么我们就需要提前把物理 frame 的资源分配给各个进程[要划分好区间不然就跟全局置换一样了]。\n\n\n\n当我们需要决定一个进程能够使用的页面总数时，我们在上述最小和最大的区间内有非常多的选择，这就引入了分配算法。常见的分配算法包括平均分配，或者按进程对内存的实际需求按比例分配；也可以参考进程的优先级，高优先级相对分配到的更多，或者更能满足其实际需求。\n\n\n现在的很多计算机都有多个 CPU，而每个 CPU 都可以比其他 CPU 更快地访问内存的某些部分。如果这种差异比较明显，我们称这种系统为 非均匀内存访问 (NUMA, Non-Uniform Memory Access) 系统。在这种系统下，为了更好的性能表现，前述的分配和调页算法可能更加复杂。\n\n\n分配多少个 Frames\n给每个进程分配多少个 frame 呢？\n\n最大值不可能超过物理内存包含的 frame 总数\n最小值是由具体的计算机架构决定的。[作系统只需要确保在执行任意一条指令时，该进程拥有足够的帧来容纳该指令涉及的所有页。因此最小值是最复杂的那条指令的帧]\n\n指令在解决其涉及的全部 page fault 之后才能真正被运行[指令是原子操作,如果发生pagefault,cpu会暂停当前指令并进行中断处理]\n因此每个进程分配的 frame 的最小值不应小于单个指令可能使用到的 frame 总数[允许指令运行,是最低要求,还会有其他帧来存储整个进程的代码\\全局变量\\堆\\栈等等]。一般情况如下\n\n指令本身:1个page[指令会进行对齐]\n两个访问内存的操作数，其中每个操作数访问的内存[可能]跨越 2 个 page（即，这块数据在一个 page 的末尾和下一个 page 的开头）\n那么这个架构上运行的进程的 minimum frame number 是 5。\n\n\n\n\n\nThrashing  flashcard\n\n如果一个进程可用的帧数量比较少（少于其频繁访问的页面数目），那么它会频繁出现 page fault；同一个 page 可能会被频繁地换入换出，以满足运行的要求。这种高度的页面调度活动成为称为 抖动 (thrashing)；其调页时间甚至会大于执行时间。\n工作集模型 (working set model) 用来确定一个进程频繁访问的页面，保证这些页面不被换出；需要调页时从剩余的页面进行交换。如果频繁访问的页面数已经大于了当前进程可用的页面数，操作系统就应当把整个进程换出，以防止出现抖动现象。\n\n\nKernel Memory Allocation\n\nKernel 中的很多数据结构大小区分比较大，其中很多小于甚至远小于一个 page.因此，kernel 的设计应当尽可能节省内存，努力减少碎片。\n尽可能减小 kernel 内存开销的考虑是：\n\n一方面，kernel 有可能有一部分常驻在物理内存中，不受调页系统的控制\n另一方面，有的硬件设备可能和物理内存直接交互，因此可能会需要连续的物理内存。\n这两者对物理内存的要求都比较严格，因此我们应当尽可能减小这些开销。\n\n\n\nBuddy System flashcard\n\nBuddy system 从物理连续的段上分配内存；每次分配内存大小是 2 的幂次方，例如请求是 11KB，则分配 16KB。\n当分配时，从物理段上切分出对应的大小，例如下图体现了分配 21KB 时的情况， 会被分配。\n当它被释放时，会 合并 (coalesce) 相邻的块形成更大的块供之后使用。\n\n\nSlab Allocation flashcard\n核心的原理是，操作系统中很多 object 的大小是已知且固定的[PCB/socket buffers/PTE之类的]。内存被划分成若干个固定大小的块，每个块都被分配给一个具体的类型。当进程需要分配内存时，它会查询缓存，如果找到一个空闲的块，就直接使用该块；如果缓存中没有空闲的块，就会从系统内存中申请一个新的块：\n"},"课程笔记/计算机组成/02-Instructions":{"slug":"课程笔记/计算机组成/02-Instructions","filePath":"课程笔记/计算机组成/02 Instructions.md","title":"02 Instructions","links":["tags/flashcard","ABI-(Application-Binary-Interface)"],"tags":["flashcard"],"content":"summary\n\n\n寄存器 registers flashcard\n\nRISC-V architecture 提供 32 个数据寄存器，分别命名为 x0 ~ x31 ，每个寄存器的大小是 64 位。\n\nx0 的值恒为 0\nPreserved on call 意为是否保证调用前后这些寄存器的值不变。\n\n\n也提供一系列浮点数寄存器 f0 ~ f31。\n之所以寄存器的个数不多，是因为过多的寄存器会增加电子信号的传播距离，从而导致时钟周期的延长。\n将不常用的（或之后用到的）变量存入内存的过程被称为溢出寄存器 (Spilling Register)\n寄存器存储空间小，内存存储空间大 因此小规模的数据会放在寄存器内，而更大规模的数据则会存储在计算机的内存(memory) 中\n各种操作与运算都只能在寄存器内完成\n寄存器有着更快的运行速度和更高的吞吐量，使得访问寄存器内的数据更加迅速和方便，且访问寄存器的能耗更低；而访问内存需要 load 和 store 指令，那么就需要执行更多的指令\n\n\n字节地址 flashcard\n\n\n==在 RISC-V architecture 中，一个 word 为 32 位（4Bytes ），一个 doubleword 为 64 位（8Bytes ）。==\nRISC-V architecture 的地址是 64 位的，地址为字节地址，因此总共可以寻址2的64次方个字节，即2的61次方个 dword ，因为一个 dword 占3位（8Bytes用3个字节地址位表示）。\n\n如果想操作某一个 bit（比如把第 3 个 bit 从 0 改成 1 ），CPU 必须：\n\n读取 (Read)：先把这个 bit 所在的整个字节（整个房间）的数据（8个 bits）全部取到 CPU 寄存器中。\n修改 (Modify)：在 CPU 内部，使用位运算（比如 OR 运算）来单独修改那 1 个 bit，而其他 7 个 bit 保持不变。\n写回 (Write)：把修改后的整个字节（8个 bits）再存回到原来的内存地址\n\n\n\n\n\n\n寻址 flashcard\n\n在一些 architecture 中，word 的起始地址必须是 word 大小的整倍数，dword 也一样，这种要求称为 alignment restriction。\n\nRISC-V 允许不对齐的寻址，但是效率会低。\n一次只能读出4字节内存中的一行\n\n\nRISC-V 支持\n\n立即数寻址 ( lui )\n间接寻址 ( jalr )\n基址寻址 ( 8(sp) )：\nPC relative 寻址：分支地址为PC和分支偏移量（立即数的2倍）之和\n\n因为所有合法的指令必须存放在偶数内存地址【指令：16bit（压缩指令）/32bit 】因此最低位始终为0，因此为了优化，指令中会略去最后一个0\n把存储的 immediate 还原成真正的 Branch offset\n\n\n\n\n\n\n\n\n大小端 flashcard\n\nRISC-V 使用 little endian 小端编址。也就是说，当我们从 0x1000 这个地址读出一个 dword 时，我们读到的实际上是 0x1000~0x1007 这 8 个字节，并将 0x1000 存入寄存器低位，0x1007 存入高位。\n\n存储字节 0x88 就是 bit：10001000\n大小端只关心字节的顺序，不关心字节内部bit的顺序\n\n\n\n\n补码 2’s complement flashcard\n\n因此在将不足 64 位的数据载入寄存器时\n\n如果数据是无符号数，只需要使用 0 将寄存器的其他部分填充 (zero extension)\n\n指令中的lwu , lhu , lbu 使用zero extension。\n\n\n而如果是有符号数，则需要用最高位即符号位填充剩余部分，称为符号扩展 (sign extension)。\n\n指令中的 lw , lh , lb 使用sign extension\n\n\n\n\n\n对于补码先看符号位，负数的话就对数字部分做补码还原，还是取反加一。\n1’scomplement是反码，先看符号位，负数就对数字部分做反码还原，取反即可\n\n\n指令\n设计准则\n正则化 simplicity favors regularity 简化规范\n越小越快 smaller is faster 32个通用寄存器 32*64bit\n指令\n\nArithmetic\n\n加法\n\nadd：寄存器 1 + 寄存器 2\n|add reg1, reg2, reg3    // (in C) reg1 = reg2 + reg3|\naddi(Add Immediate)：寄存器 + 常量\n|addi reg1, reg2, const  // (in C) reg1 = reg2 + const|\n\n\n减法\n\nsub：寄存器 1 - 寄存器 2\n|sub reg1, reg2, reg3    // (in C) reg1 = reg2 - reg3|\n==注意：没有subi，但是可以通过addi一个负常数来实现==\n\n\n\nLogical Operations\n\n\nsll/slli，srl/srli 分别为逻辑左移/右移\n\n左移i位相当于乘以2的i次方，右移i位相当于整除2的i次方 \n逻辑右移时最左边补 0\n不带i的指令表示根据寄存器的值确定移动位数，带i的指令表示用立即数确定移动位数\n|slli x11, x19, 4    // reg x11 = reg x19 &lt;&lt; 4 bits|\n\n\nsra/srai 为算术右移，最左边补符号位\n\nBit Operations\n|and reg1, reg2, reg3    // (in C) reg1 = reg2 &amp; reg3`|\n\n|or reg1, reg2, reg3    // (in C) reg1 = reg2 | reg3`|\n\nAND、OR、XOR 也有立即数版本的指令，分别为：andi、ori和xori\n\n|xor reg1, reg2, reg3    `|\n\nRISC-V 中没有 NOT 指令，因为它可以通过异或表示出来：任何数与 111…111 异或的结果即为该数取反后的结果\n\nMaking Decisions\n计算机与计算器的一大不同之处在于计算机具备决策的能力：它能够执行分支（条件）语句、循环语句等。\n在 RISC-V 汇编语言中，关于决策的指令格式均为：inst rs1, rs2, L1\n\n其中rs1、rs2是寄存器\nL1是标签（跳转位置，也可以是立即数 imm，表示跳转到 PC+imm 的指令）\ninst是指令，比较的是补码值。/0\n\n其分类如下：\n\n条件分支(conditional branch)：先检测值，根据检测结果决定是否将控制权转交给新地址上的语句的一类指令\n无条件分支(unconditional branch)：条件恒为真的条件分支，因此该语句一定会执行\n\n有以下几种可用指令：\n\nbeq(Branch If Equal)：如果寄存器rs1和rs2的值相等，那么跳转至带标签L1的语句\nbne(Branch If Not Equal)：如果寄存器rs1和rs2的值不相等，那么跳转至带标签L1的语句\nblt(Branch If Less Than)：如果寄存器rs1的值小于rs2的值，那么跳转至带标签L1的语句\n\nbltu：无符号版本 unsigned 比如存的是地址，就只能用bltu当作无符号数来比较，否则会引入符号位。【如果高位地址用不上也不容易出错，如果地址比较大就一定要bltu】\n\n\nbge(Branch If Greater Than or Equal)：如果寄存器rs1的值大于等于rs2的值，那么跳转至带标签L1的语句\n\nbgeu：无符号版本 unsigned\n\n\n\nif\n\nif-else\n\ncase-switch\n对于case/switch语句，我们可以使用一张放有可选指令序列地址的表格（称为分支地址表，Branch Address Table），这样的话程序就可以根据条件判断的结果，通过表格的索引找到合适的指令序列。\n\n\n\nloops\n\n循环访问数组\nwhile\n\nset on less than\nslt x5, x19, x20\n\n如果 x19&lt;x20，那么将 x5 赋值为 1\n\nData Transfer Instructions\n由于对数据的各种操作只能在寄存器内完成，而无法在内存中实现，因此数据需要再寄存器和内存之间来回传递，来完成这一传递操作的指令被称为数据传输指令\nRISC-V 有以下数据传输指令：\n\nld（Load Doubleword）：加载指令，将数据从内存拷贝到寄存器当中\n|ld reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 一个保存内存基础地址的寄存器（可以理解为能访问到整个内存的头指针）\noffset: 偏移量，是一个常数\n内存数据的实际地址 = mem_base_addr + offset\n\n\nsd（Store Doubleword）：存储指令，将寄存器的数据拷贝到内存中\n|`sd reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 内存基础地址寄存器\noffset: 偏移量\n\n\nlbu(Load Byte Unsigned)：加载 1 字节的数据，并看作无符号数\nlb(Load Byte)：lbu的有符号数版本\n\n\n在 RISC 指令集中，只有 load 系列和 store 系列指令能够访问内存。\n\n\n立即数 Constant or Immediate Operands\n\n一般的做法是将常数保存在一个寄存器当中，通过一个地址指针指向这个寄存器，然后通过 add 指令实现加法操作\n|ld x9, AddrConstant4(x3) //x9 = constant 4 add x22, x22, x9|\n实际上我们可以引入一个新的概念：立即数（Immediate），这样就避免了加载指令（即通过操作 addi x22, x22, 4 即可实现）\n\n同步Synchronization in RISC-V\n假设两个处理器在同一片内存空间中工作，并且它们的工作顺序为：P1写入数据后，P2再读取数据。没有同步（Synchoronize）好，那么就会产生数据竞争（Data Race）的问题（结果取决于访问顺序，因此这个结果就是不确定的）。\n避免这一问题的方法是原子读取 / 写入 (Atomic Read/Write) 内存操作，这种操作确保读和写之间不会有任何访问这块内存空间的行为。\n有些处理器有专门实现原子操作的指令，比如原子交换 (Atomic Swap/Exchange)（实现寄存器和内存数据的交换）等。而 RISC-V 提供了一个指令对 (Instruction Pair) lr.d和sc.d：\n\nlr.d（Load-Reserved Doubleword）：\n\nlr.d rd, (rs1) 将存储在寄存器rs1的内存地址上的数据加载到寄存器rd上，同时保留这块内存地址，除sc.d的其他指令不应该访问这块地址\n\n\nsc.d（Store-Conditional Doubleword）：\n\nsc.d rd, rs1, (rs2) 将寄存器rs1上的数据放入存储在寄存器rs2的内存地址上，并且由寄存器rd指示该指令是否成功：若成功，则rd = 0，否则rd为一个非零值（表示有其他指令访问过这块内存空间）\n\n\n\n\n其他\n\n拓展指令集内容：\n\nM：与乘除法相关的指令\nA：原子运算，包括前面提到过的lr.d和sc.d指令，以及它们的 32 位版本lr.w和sc.w等\nF：单精度浮点运算相关指令\nD：双精度浮点运算相关指令\nC：压缩的指令，只有 16 位宽\n\n\n伪指令\n\n过程（Procedure）或函数（Function）\n调用过程Procedure Call Instructions flashcard\n\n\njal与jalr\n\njalr是基于【寄存器地址+12位立即数偏移量】\njal是基于pc相对地址【20位立即数】，jal rd，offset\n\n\n对于调用者：调用某个程序地址后，将返回地址（跳转的下一条地址PC+4）存入x1（ra）中\n对于被调用者，x0无法被写入，表示不保存任何返回地址，仅作跳转。\n\n调用过程中的寄存器Registers for procedure calling\nRISC-V寄存器 flashcard\nLocal Data on the Stack\n栈与栈帧 flashcard\nMemory Layout\nMemory Layout flashcard\nRICV-V指令格式 flashcard\n指令编码32bit, 记其为机器码（Machine Code）。我们可以把每条指令当作一块块二进制数字构成的组合，而这单块的数字被称为字段（Field）。我们为字段赋予了一些名称，每个字段有不同的功能：\n\nopcode：指令要做的运算，可用这个字段区分各种类型的指令格式(instruction format)\nfunct3：额外的opcode字段\nfunct7：额外的opcode字段\nrd：寄存器目标操作数，保存运算的结果\nrs1：第一个寄存器源操作数\nrs2：第二个寄存器源操作数\nimmediate：立即数，即常数\n根据不同的 opcode 我们可以将指令分为 6 种类型，它们的字段构成如下：\n\n\nR 型指令一般用于算术、逻辑运算\nI 型指令一般用于加载操作、涉及立即数的算术逻辑运算、jalr指令\n\n因为寄存器的大小为 64 位，也就是说对于移位操作 slli，srli和srai，它们最多只能移位 64 位，因此移位操作中immediate字段只有后 6 位能实际被用来存储移位的步数，前 6 位用来存储额外的opcode字段（funct6）\n关于 jalr 指令，如果跳转地址（立即数）过大，超过了 20 位，那么可以先用 lui 指令将高 20 位数字放入临时寄存器中，然后再用 jalr 指令跳转到地址剩余的低位数字(临时寄存器)上\n\n\nS 型指令一般用于存储操作\nU 型指令一般用于与高位立即数相关的操作\n\n在大多数情况下，立即数不会很大（），能够直接存在指令中；但如果超过 12 位，RISC-V 会用 lui (load upper immediate) 指令来处理这类较大的立即数。\n它可以加载立即数的高 20 位，将其放入寄存器中间的第 12 位到第 31 位，寄存器的低 12 位用 0 填充，高 32 位用第 31 位上的数字填充。\n例如，要将 32 位立即数赋给寄存器，可以先用lui指令将高 20 位赋给寄存器，之后用addi 指令将剩余的 12 位加到寄存器中。\n\n\nSB 型指令一般用于条件分支语句\n\n可表示的地址范围为 -4096-4094，且都是 2 的倍数（因为立即数第一位恒为 0）\n\n\nUJ 型指令一般用于无条件分支语句（jal）\n\nrd用于存放链接地址（即返回地址）\n\n\n\n\n\n另外，为什么 SB 和 UJ 不存立即数（也就是偏移）的最低位呢？（关注表格，可以发现只包括 i[12:1] 或者 i[20:1]，缺失 i[0]）因为，偏移的最后一位一定是 0，即地址一定是 2 字节对齐的，因此没有必要保存。\n\n\n数组和指针\n事实上，用指针访问数组元素比用索引访问数组元素更快一些。它们分别具有如下特点：\n\n数组索引\n\n需要根据数组基地址、当前索引和元素大小计算出数组元素的地址，而且每趟循环都需要更新和重新计算，有些麻烦\n虽然从理论上来说效率不高，但实际上编译器已经为我们做了一定的优化，比如用移位运算替代乘法运算，避免在循环内进行数组地址计算等\n\n\n指针\n\n它直接指向内存地址（可以看到，在循环开始前就已经算好了），无需多余的计算步骤\n\n\n\n例子\nRISC-V 汇编语言来翻译一个用 C 语言写的冒泡排序函数\nC 语言翻译成汇编语言步骤\n\n为程序的每个变量分配相应的寄存器\n为过程的主体部分书写代码\n在过程调用期间保留要用的寄存器\n\nswap函数\nvoid swap(long long int v[], size_t k) {\n    long long int temp;\n    temp = v[k];\n    v[k] = v[k+1];\n    v[k+1] = temp;\n}\nswap:\n    slli x6, x11, 3      // reg x6 = k * 8 -》变成byte字节地址\n    add  x6, x10, x6     // reg x6 = v + (k * 8)\n    ld   x5, 0(x6)       // reg x5 (temp) = v[k]\n    ld   x7, 8(x6)       // reg x7 = v[k + 1]\n    sd   x7, 0(x6)       // v[k] = reg x7\n    sd   x5, 8(x6)       // v[k+1] = reg x5 (tmp)\n    jalr x0, 0(x1)       // return to calling routine\nsort函数\nvoid sort(long long int v[], size_t int n) {\n    size_t i, j;\n    for (i = 0; i &lt; n; i++) {\n        for (j = i - 1; j &gt;= 0 &amp;&amp; v[j] &gt; v[j + 1]; j--) {\n            swap(v, j);\n        }\n    }\n}\n// Saving registers\nsort:\n    addi sp, sp, -40      // make room on stack for 5 registers\n    sd   x1, 32(sp)       // save return address on stack\n    sd   x22, 24(sp)      // save x22 on stack\n    sd   x21, 16(sp)      // save x21 on stack\n    sd   x20, 8(sp)       // save x20 on stack\n    sd   x19, 0(sp)       // save x19 on stack\n \n// Procedure body\n// Move parameters\n    mv   x21, x10         // copy parameter x10 into x21\n    mv   x22, x11         // copy parameter x11 into x22\n \n// Outer loop\n    li   x19, 0           // i = 0\nfor1tst: \n    bge  x19, x22, exit1  // go to exit1 if i &gt;= n\n \n// Inner loop\n    addi x20, x19, -1     // j = i - 1\nfor2tst:\n    blt  x20, x0, exit2   // go to exit2 if j &lt; 0\n    slli x5, x20, 3       // x5 = j * 8\n    add  x5, x21, x5      // x5 = v + (j * 8)\n    ld   x6, 0(x5)        // x6 = v[j]\n    ld   x7, 8(x5)        // x7 = v[j + 1]\n    ble  x6, x7, exit2    // go to exit2 if x6 &lt; x7\n \n// Pass parameters and call\n    mv   x10, x21         // first swap parameter is v\n    mv   x11, x20         // second swap parameter is j\n    jal  x1, swap         // call swap\n \n// Inner loop\n    addi x20, x20, -1     // j for2tst\n    j for2tst             // go to for2tst\n \n// Outer loop\nexit2: \n    addi x19, x19, 1      // i++\n    j for1tst             // go to for1tst\n \n// Restoring registers\nexit1:\n    ld   x19, 0(sp)       // restore x19 from stack\n    ld   x20, 8(sp)       // restore x20 from stack\n    ld   x21, 16(sp)      // restore x21 from stack\n    ld   x22, 24(sp)      // restore x22 from stack\n    ld   x1, 32(sp)       // restore return address from stack\n    addi sp, sp, 40       // restore stack pointer\n \n// Procedure return\n    jalr x0, 0(x1)        // return to calling routine\n指令集架构\n谬误\n\n更多强大的指令会带来更高的性能\n\n虽然更强大的指令意味着执行相同功能所需指令数更少，但同时也意味着这些指令会更加复杂，难以实现，这样反而影响所有指令的效率\n\n\n直接用汇编语言编写的程序性能更高\n\n在现代的处理器中，编译器可能比人脑更擅长将高级语言代码转换为性能更优的汇编语言代码\n而且，对于人类来说，因为汇编代码量较大，所以会带来更多犯错的机会，且编写效率实在不高\n\n\n指令集的向后兼容意味着无需改变现有的指令集\n\n以 x86 为例，虽然它做到了向后兼容，但它的指令数还是呈上升趋势\n\n\n用字节表示地址的机器内，连续的字地址的间距不是 1 而是 4（字节）\n\n一个地址只能放一个字节\n双字地址间距就是8字节\n\n\n使用指向在定义过程外的自动变量的指针\n\n典型例子：某个过程返回一个指向局部数组的指针，但这个过程在返回后就没了，包括这个局部数组，因此这个指针指向一个没有任何意义的地方，如果动用这个指针，很可能会让整个程序崩溃\n\n\n\n指令集架构 instruction set architecture flashcard\n目前世界上主流的 ISA 主要分为两大类：\n\nCISC (复杂指令集)：一条指令可以完成很复杂的操作。\n\nx86 电脑、笔记本、服务器\n\n\nRISC (精简指令集)：指令都很简单、统一，通过组合简单指令来完成复杂任务。\n\nRISC-V\nARM  手机 平板 嵌入式设备 苹果电脑\nMIPS\n当下计算机建立在两个关键原则（即存储程序概念，Stored-Program Concept）：\n\n\n指令用数字来表示\n程序就像数字一样存储在内存中，可用来被读取或写入\n\n\n\nMIPS\n\n32 位指令\n32 个通用寄存器，其中一个寄存器的值始终为 0\n只能通过加载和存储指令来访问内存数据\n没有能够批量加载 / 存储多个寄存器的指令\n寻址模式适用于各种大小的数据\n\nRISC-V 和 MIPS 的不同之处有：\n\n条件分支（除了相等和不等）：\n\nRISC-V 仅仅比较两个寄存器的大小，而 MIPS 还会用一个寄存器存储比较结果（1 或 0，对应真值）\nMIPS 只有“小于”分支指令，该指令有符号数（slt）和无符号数（sltu）版本\n\n\n\n指令格式的区别\n\nx86\n8086 指令集仅支持字节（8 位）和字（16 位，注意 RISC-V 的字是 32 位）类型的数据，而 80386 增加了 32 位地址和数据（双字，注意 RISC-V 的双字是 64 位）。\nx86 指令与 RISC-V 的不同之处在于：\n\nx86 指令的算术和逻辑指令中，有一个操作数同时充当源和目标；而 RISC-V（以及 MIPS）会将源寄存器和目标寄存器区分开来\nx86 指令的其中一个操作数可以是内存，下面的表格展示了 x86 中所有可能的操作数搭配\n\n寄存器\n80386 指令集有 14 个寄存器，如下图所示：\n\n寻址模式\n80386 的寻址模式如下图所示：\n\n指令格式\n下图为典型 x86 指令格式- 每条指令的开头（左侧）指明了指令要做的操作\n\n有些指令存在一个 Postbyte 字段，它用来指明寻址模式\nx86 的整数指令有以下几类：\n数据传送指令\n算术和逻辑指令\n控制流\n字符串指令\n分别对应的常见指令有：\n\n\nTranslating and starting a program\n一个 C 语言的程序（源代码）转化为存储在内存中的一个文件的过程\n\n\n编译器 (Compiler)：高级编程语言 → 汇编语言\n\n有的编译器兼具汇编器的功能\n\n\n汇编器 (Assembler)：\n\n伪指令 → 指令\n\n伪指令(Pseudo Instruction)：可以理解为汇编指令的扩展（或者缩写），形式上看似指令，而实际上并不存在这种指令，但汇编器会将其自动转化为实际存在的指令\n\n\n可接受各种进制的数\n用符号表(symbol table) 存储标签名称和内存地址的对应关系，便于将标签转化为实际的地址\n基本的功能：汇编语言 → 机器码，即汇编程序 → 目标文件(Object File)。在 UNIX 系统中，目标文件包含以下内容：\n\n目标文件头 (Object File Header)：描述目标文件中其他区域的大小和位置\n文本段 (Text Segment)：包含机器码\n静态数据段 (Static Data Segment)：包含程序生命周期中分配的数据（在 UNIX 中这个区域同时存放静态和动态数据）\n重定位信息 (Relocation Information)：根据程序被加载至内存的绝对地址来区分指令和数据\n符号表 (Symbol Table)\n调试信息 (Debugging Information)：简要描述模块的编译情况，使调试器能够将机器指令和 C 源文件关联起来，且能够读取其中的数据结构\n\n\n\n\n链接器 (Linker)\n\n对于多文件的编译，采取的做法是先编译、汇编单个的文件，然后将这些机器语言程序链接起来，这样可以尽可能减少重编译和重汇编的情况\n工作流程：\n\n将代码和数据模块以符号化的形式存在内存中\n弄清数据和指令标志对应的地址\n补充好内部和外部的引用\n\n\n经链接器加工后，最终生成一个可执行文件 (Executable File)，它与目标文件的区别在于后者存在不确定 (Unresolved) 的引用\n\n\n加载器 (Loader)：将可执行文件放入内存或磁盘中，工作流程为：\n\n读取可执行文件头，得到文本段和数据段的大小\n创建一个指向足够容纳文本和数据的空间的地址\n将可执行文件的指令和数据拷贝到内存中\n将主程序的参数（如果有的话）放入栈中\n对寄存器进行初始化操作，并将栈指针指向第一个空闲的位置上\n跳转到启动例程，将参数拷贝到参数寄存器中，并调用程序的主例程。让主例程返回时，启动例程中止整个程序，附带exit系统调用\n\n\n\nDynamic Linking\n前面介绍的链接方法属于静态链接，虽然它能快速调用库函数，但它具有以下缺陷：不能及时更新库函数，会一次性加载所有库函数（即使很多库函数没被用到）。因此我们更多地会用到动态链接库(Dynamically Linked Libraries, DLL) 来克服这些缺陷——这种库可以在程序运行时被链接到程序里。\n动态链接库有如下特征：\n\n需要可重定位的过程代码\n能够避免由静态链接获取所有库函数带来的占用存储空间过大的问题\n能够自动获取最新版本的库\n\nLazy Linkage\n在原始版本的 DLL 中，程序和库都需要保留额外的信息，用于定位非局部的过程；加载器会运行一个动态的链接器，使用这些额外的信息找到合适的库并更新所有的外部引用。这种 DLL 的缺点是它仍然会一次性加载所有库函数。一种改进方法是使用懒过程链接(Lazy Procedure Linkage) 版本的 DLL，它能保证只有当程序调用库函数时，对应的库才会被链接到程序里。下图展示了这种版本的 DLL：\n\n数据类型\ngo\n\nc\n\n无论是 32 位还是 64 位系统，long long 类型的大小都是 8 字节\nlong 在 32 位系统上是 4 字节，在 64 位系统上是 8 字节\n"},"课程笔记/计算机网络/物理层-the-physical-layer":{"slug":"课程笔记/计算机网络/物理层-the-physical-layer","filePath":"课程笔记/计算机网络/物理层 the physical layer.md","title":"物理层 the physical layer","links":["tags/flashcard"],"tags":["flashcard"],"content":"物理层的主要任务\n\n网络中硬件设备和传输介质的种类繁多，通信方式也各不相同。物理层应尽可能屏蔽这些差异，让数据链路层感觉不到这些差异。\n\n发送方的数据链路层将需要发送的帧交给物理层\n传输后接收方的物理层将这些帧传递给接收方的数据链路层。\n具体地说，物理层确定与传输媒体接口有关的一些特性：\n\n\n机械特性：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。\n电气特性：指明在接口电缆的各条线上出现的电压的范围。\n功能特性：规定物理接口上各条信号线的功能分配和确切定义（各条线上出现各种电压表示何种意义）。\n规程特性 / 过程特性：定义了各信号线的工作顺序和时序，使得比特流传输得以完成。\n\n2 基本概念\n\n数据是需要传送的信息，信号是数据在传输过程中的存在形式。\n\n2.1 link/channel/data rate/baud rate\n链路和信道 flashcard\n\n(物理) 链路 link；承载信号的 physical path\n一条物理链路可以通通过分时、分频等方式容纳多个 信道 channel (也称为逻辑链路)，每条信道对应着一个发送方和一个接收方。\n\n\n比特率 bit rate flashcard\n\n也可以叫data rate数据率 - 单位时间内传输的信息中 bit 的数目，即 (数据量 / 时间)。\n\n单位是 b/s Kb/s Mb/s Gb/s\n也可以写成 bps Kbps Mbps Gbps\n注意是 bit/s 不是 Byte/s\n就算实际发送的比特比数据多【譬如用1111表示1 】，但是data rate不变.也就是说冗余的比特我们不算在内\n\n\n\n\nsymbol rate flashcard\n\n码元 / 符号 symbol - 用一个数字脉冲表示的一个 k 进制数字。就是一次采样得到的结果，可能包含不同数量的bit。\n\n比如假设电平有4档分别编码00，01，10，11，那么一次采样就是2bit数据。那么分辨8个电压的话一次采样的结果就有3bit。\n\n\nsymbol rate / baud rate - 单位时间内传输的 symbol 数目，即单位时间内可能发生的信号变化次数。就是单位时间采样次数。symbol/second就是baud\n\n\n例如一个四进制码元（0123，四个）可以携带2bit（log24）信息，那么如果数据率是64kb/s，那么symbolrate是32kbaud（因为2bit/symbol）。当然也存在0.5bit/symbol的情况。\n\n\n2.2 带宽\n带宽相关原理/谐波拟合方波 flashcard\n\n\n用一个一倍基频的谐波（傅里叶分量）拟合方波\n用一个一倍基频和一个二倍基频的谐波拟合\n用一个一倍基频和一个二倍基频和一个四倍基频的谐波拟合\n……\n谐波越多，拟合方波越成功。但是物理媒体有限制：截止频率fc，超过这个频率的波会有不同的减弱。所以只能使用0-fc频率【带宽/频带宽度】\n\n周期：b（需要传输b bit信号）/r（data rate）\n频率：r/b 周期的倒数\n那么N*r/b⇐fc N为可以接受的谐波个数，N倍基频不能大于截止频率。可以得到N⇐b*fc/r。\n因为N越大，信号质量越好，所以r过大时信号质量就会不好。因此在信号质量有一定要求的情况下，带宽越大，数据率就越大。因此数据率的最大值也可以称为带宽\n\n\n\n\n带宽的辨析 flashcard\n\n(数字) 带宽 (digital) bandwidth：最大可能的 data rate，用来表示通信线路传输数据的能力，频带宽度越大，数据率越大，因此把数据率最大值也叫做带宽。单位与 data rate 一致。\n(模拟) 带宽 (analog) bandwidth：信道的频带宽度，单位是 Hz。带宽是传输介质的一种物理特性，滤波器可以通过过滤掉某些频率的信号来进一步限制信号的带宽。\n\n带宽指的是一段频率范围，它并不要求这段频率一定从 0 开始；事实上对于无线信道来说，发送低频率的信号也是不可能的，因为波长会很大，天线长度要跟波长一样长。\n\n我们称之前所说的频率为 0∼B Hz 的信号为基带信号 (baseband signal)\n而将其搬移到 S∼S+B Hz 的信号为通带信号 (passband signal)。\n\n\n\n\n\n\n2.3 采样定理\nNyquist’s theorem 奈奎斯特定理 flashcard\n\n条件：在理想 (无噪声) 低通 (带宽有限) 信道中\n\n【有噪声也可以适用】，因为提出的是理论上限，有噪声只会更低\n\n\n极限码元传输速率（采样频率）是 2W Baud，其中 W 是理想低通信道的 (模拟) 带宽，大于这个极限码元速率也采不出更多了就浪费了。\n\n若用 V 表示每个码元离散电平的数目 (即其可以取值的离散值的个数；即其进制数)，则极限数据速率为 2W log₂(V) (b/s)。\n8级电平，用log28个bit可以表示一个symbol，即3bit/symbol\n\n\n\n\nShannon’s theorem 香农定理 flashcard\n\n条件：在受高斯白噪声干扰的信道中\n用 W 表示信道的 (模拟) 带宽，S 表示信号平均功率，N 表示高斯噪声功率，则极限数据速率是 W log₂(1 + S/N) (b/s)。\n\n信噪比 Signal-to-Noise Ratio, SNR：公式中的 S/N 就是信噪比，没有单位；但为了方便表示更大的范围，也用 10lg(S/N) 表示信噪比，单位为分贝 dB（比如用50分贝来表示10的五次方的信噪比）。就是说如果看到分贝单位的信噪比需要进行换算之后还原成普通信噪比代入公式.\n\n\n\n\n\n\n                  \n                  求极限数据速率例题 flashcard\n                  \n                \n\n\n对于给出了 V (信号电平数) 的情况，无论是否说明无噪声都应使用 Nyquist’s theorem 确定 data rate 的一个上界。\n对于给出了 SNR (信噪比) 的情况，也应根据 Shannon’s theorem 确定另一个上界。\n\n示例一：电话系统\n电话系统的典型参数是信道带宽为 3000Hz，信噪比为 30dB，则该系统的最大数据传输速率为： 3k×log2​(1+10^(30/10)) b/s≈30kb/s\n示例二：结合两种定理\n二进制信号在信噪比为 127:1 的 4kHz 信道上传输，求最大数据传输速率。【2进制信号可以理解成2元信号】\n\n根据 Nyquist’s theorem，最大数据速率为2×4k×log2​(2) b/s=8kb/s\n根据 Shannon’s theorem，最大数据速率为4k×log2​(1+127) b/s=28kb/s\n结论： 二者均为上界，应取其中较小的一个，因此该信道的最大数据传输速率为 8kb/s。\n\n示例三 无意义信息\n\n一条无噪声的 8kHz 信道，每个信号包含 8 级，每秒采样 24k 次，那么可以获得的最大传输速率是？\n\n无噪声 - Nyquist, data rate = 2 * 8kHz * log₂(8) bit/symbol = 48kbps\n“题目中给出的每秒采样 24k 次是无意义的，因为超过了波特率的上限 2W = 16 kBaud，所以 72kbps 是错误答案”\n\n\n\n示例四 不乘2的情况\n\n一个信道每 1/8s 采样一次，传输信号共有 16 中变化状态，最大数据传输速率是？【最大采样是带宽的2倍，这里已经告诉我们采样频率了就不乘2了】\n\n8Baud * log₂(16) bit/symbol = 32bps\n\n\n\n\n\n\n3 信息交互方式 flashcard\n\n单工链路 simplex link - 1条信道，固定单向通信。【 广播】\n半双工链路 half-duplex link - 2条信道，双向可通信但不能同时。【 对讲机】\n全双工链路 full-duplex link - 2条信道，两边可以同时收发。【 打电话】\n\n注意2条 channel 不一定需要2条物理链路，一条通过一些复用方式或者双向传输也可以实现。\n\n\n\n\n4 传输介质 / 传输媒体 flashcard\nTransmission media，数据传输系统中发送设备和接收设备之间的物理通路。\n\n导向传输介质 Guided trans media\n\n双绞线 twisted pair：绞合以【减少相邻导线的电磁干扰】。\n\n在双绞线外加一层金属丝编织的屏蔽层，可以进一步【提高抗电磁干扰的能力 】，称为屏蔽双绞线 STP, Shielded Twisted Pair\n没有屏蔽层的称为非屏蔽双绞线 UTP, Unshielded Twisted Pair。\n\n\n同轴电缆 coaxial cable\n光纤 fiber optics\n\n\n非导向传输介质 / 无线传输 Wireless transmission\n\n无线电波 Radio：有较强的穿透能力，不需对准某个方向；无线手机通信、WLAN (wireless local area network) 等。\n微波、红外线、激光：有很强的方向性，直线传播。\n\n\n\n\n\n5 数字调制 / 数字数据到模拟信号\n数据与代表它们的信号之间的转换过程称为数字调制 digital modulation。\n5.1 基带传输 Baseband Transmission flashcard\n\n直接将数据转换为数字信号，数字信号是离散的，占用传输介质上的全部频率，用于有线介质 (光纤不是基带传输) 【编码】\n\n**Non-Return to Zero\n\n用正电压 / 有光表示 1，负电压 / 没有光表示 0。\n问题是如果 0 和 1 交替，接收端可以在每一次变化时校准；但是如果一直是 0 或者 1 的话过一段时间可能就数错了会失去同步。\n\n\nManchester (以太网 Ethernet 的编码方式)\n\n用一个高和一个低表示1，一个低一个高表示0 (实际上就是与一个时钟信号做了 XOR，如图)。解决了时钟信号的问题，即每个码元中间一定有电平跳变。\n问题是带宽开销增大了—倍。\n\n\nNRZI NRZ Invert (USB 2.0 的编码方式)：\n\n用信号翻转表示 1，信号不变表示 0。没有带宽开销的增加；\n解决了一长串都是 1 的问题；但是如果一长串都是 0 还是不行。\n\n\n4B/5B mapping：\n\n把4bit的data重新映射到一套新的5bit编码\n经过设计的新编码保证映射结果最多只会出现连续 3 个 0，就能解决NRZI NRZ Invert的问题。虽然增加了 25% 的开销，但是比 Manchester 好一些。\n\n\n扰频/倒频 scrambling：\n\n尝试解决一长串 0 和 1 的问题。发送数据之前，用一个伪随机序列 XOR 数据，接收器用同样的序列 XOR 后得到结果。\n但是其实不太靠谱如果信号和xor数据一模一样的话异或完全是0，而且容易被截获\n\n\n双极编码 bipolar encoding / AMI, Alternate Mark Inversion：\n\n这种编码方式关注信号的平衡性；短时间内正电压和负电压一样多的信号称为平衡信号 balanced signal。这样的信号均值为0，即没有直流分量；由于传输介质的物理性质，没有直流分量是一个优点。\n这种编码方式用 +1 或者 -1 表示 1，每次的 1 与前一次的 1 表示法相反，保证最多只差 1 个；用 0 表示 0。\n\n\n8B/10B 编码模式：\n\n同时考虑这些问题，通过映射保证没有超过 5 个连续的 0 或  1，同时保持 0 和 1 数目相对均等；其额外带宽消耗也只有 25%\n\n\n\n\n5.2 通带传输 Passband Transmission flashcard\n通过调节载波信号的幅值、相位或频率来运载数据，占据载波信号频率为中心的一段频带，用于无线和光纤信道。【 调制】\n\n\n幅移键控 ASK, Amplitude Shift Keying：\n\n通过两个不同的振幅分别表示 0 和 1；可以用更多的幅值等级表示更多的信息。\n\n\n频移键控 FSK, Frequency Shift Keying：\n\n类似地，通过不同频率表示不同的码元。\n\n\n相移键控 PSK, Phase Shift Keying：\n\n将载波波形偏移—定的相位。\n\n二进制相移键控 BPSK, Binary PSK：将波形偏移 0° 和 180°。\n正交相移键控 QPSK, Quadrature PSK：将波形偏移 45°, 135°, 225° 和 315°。\n\n\n\n\n\n叠加综合\n\n星座图 constellation diagram：为了让每个码元传输更多 bit 的信息，也可以将这些方式综合起来使用。下面的星座图用黑点表示一个合法的振幅和相位的组合，每一个symbol可能是这n个黑点中的一个\n\n其中每个黑点到原点的距离表示振幅，\n和 x 轴正方向所成角度表示相位偏移。\n\n\n正交调幅 QAM, Quadrature Amplitude Modulation：上图 (a) 即为前述 QPSK，而后面两个图是 QAM 【正交相移键控x调幅】的两个实例，它们的每个 symbol 分别携带 4 bit 和 6 bit 的信息。\nGray code：为星座图分配每个黑点代表的 bit 时，需要考虑少量的突发噪音不会导致很多 bit 出错。可以使用 Gray code 解决这一问题（相邻点的 bit 码仅相差一位）。\n\n6 多路复用\n频分复用 FDM, Frequency Division Multiplexing flashcard\n经过调制后，要传输的信号所占带宽是有限的；而线路可使用的带宽远大于这一宽度。\n我们可以对多路信号采用不同频率进行调制，使得调制后各路信号频率不同，不会互相干扰；即将信道带宽分割为多种不同频带的子信道，实现多路复用。\n\n每个频带之间保留足够宽的距离，保证相邻的频带不会相互重叠。这一部分保护间隙称为保护频带 guard band。 \n正交频分复用 OFDM, Orthogonal FDM：基本思想是：每个子载波相互正交；即每个子载波在其子载波的中心频率处能量为0。这样在每个子载波中心频率处取样，就不会被其他子载波干扰了。这样的方式不需要 guard band，且频带利用率很高。\n\n时分复用 TDM, Time Division Multiplexing flashcard\n每个用户周期性地轮流工作，每次在一个非常短的时间内获得整个带宽。类似于频分复用，时分复用也可能会需要增加保护时间 guard time，保证不重叠\n\n\nTDM 的调度方式是机械的，一种动态按需分配时间片的方式是统计时分复用 STDM, Statistical TDM。但是需要额外的信息来标识可能效率反而会变低\n\n码分复用 CDM, Code Division Multiplexing/码分多址CDMA, Code Division Multiple Access#flashcard flashcard\n\n\n若干由 1 或 -1 组成的序列S, Sˉ 表示其反码 (序列中的每个数取其相反数)。\n对于任意两个序列 S 和 T，其归一化内积 (normalized inner product) =内积（对应位置相乘的积相加）/m，其中 m 是序列的长度，此处为 8。\n\n容易理解，有 S⋅S=1，S⋅Sˉ=−1。若 S⋅T=0，我们称这两个序列是正交 (orthogonal) 的； 显然此时 Sˉ⋅T=S⋅Tˉ=Sˉ⋅Tˉ=0。根据这一定义，图中 (a) 的 4 个序列ABCD是两两正交的。\n\n\n现在我们尝试利用这些序列发送信号。每个发送端（ABCD）被分配了一个序列；\n\n每一个周期中，发送端可以选择发送 1 (通过发送这个序列)，或者发送 0 (通过发送这个序列的反码)，或者什么都不发送。当多个站同时发送时，它们发送的信号会叠加起来；\n但是由于序列的正交性，我们可以将每个站发送的信息单独解码出来。假设在某一个周期中，A 和 D 发送了 0，B 发送了 1，C 什么都没有发送，那么叠加出的信号就形如 S=Aˉ+B+Dˉ=(1,−1,3,−1,1,3,−1,−1)。我们将这个信号与 B 作归一化内积：\nS⋅B=8−1+1+3+1+1+3−1+1​=1\n\n\n即 B 发送的是 1。如果与 C 作归一化内积，则结果为 0，表示 C 什么都没有发送。如果与 A 或 D 做归一化内积，则结果为 -1，表示发送的是反码 (即 0)。这是因为，归一化内积满足分配律，S⋅D=(Aˉ+B+Dˉ)⋅D=Aˉ⋅D+B⋅D+Dˉ⋅D，而前两项由于正交性为 0，第三项为 -1，因此最终结果为 -1；其他的情况也是类似的。\n下面回顾我们做了什么。我们==在原本需要发送 1个 bit 的时间发送了 m 个 bit 组成的序列==，这样的序列可以有 m 个且两两正交 (考虑正交矩阵)，==从而满足 m 个发送方同时互不干扰地传输的需要==。同时由于我们在单位时间内传输的 bit 数是原来的 m 倍，因此==所需要的带宽也是原来的 m 倍==。如此我们将一个窄带信号扩展到了一个很宽的频带上，这样更能容忍干扰，同时允许多个用户共享同一个频带。\n\n\n\n7 公共电话交换网络 The Public Switched Telephone Network, PSTN flashcard\n\n\n7.1 本地回路 Local Loop flashcard\n\n调制解调器 modem: 调制器 modulator 和 解调器 demodulator 的缩写，数字信息和模拟信号流之间的转换。\n非对称用户线 ADSL Asymmetric Digital Subscriber Line: 使用 FDM。在过去，整个电话系统中的传输都是模拟的，实际的语音信号以电压的形式从源端传输到接收方。\n\n\n7.2 中继线 Trunk flashcard\n\n编码解码器 codec: coder-decoder，模拟信号转为数字信号，使用脉冲编码调制 PCM, Pulse Code Modulation。\n波分复用 WDM, Wavelength Division Multiplexing：感觉和频分复用差不多，毕竟频率和波长没啥区别。可能 FDM 用来说电，WDM 用来说光这个样子。\n\n\n7.3 交换 Switching flashcard\n\n\n电路交换 Circuit Switching:\n\n先建立连接，然后直接发，最后释放连接；过程中路径被独占。路径的结点收到就立刻发给下一个结点，不储存。\n\n\n报文交换 Message Switching\n\n不需要建立连接。报文携带目的地址和源地址，途中每个结点在收到整个 message 以后再找下一条路进行传输。\n这样可以动态选择合适空闲的线路，增加线路的可靠性和利用率。但是会引起转发时延，并需要缓存空间。\n\n\n分组交换 / 包交换 Packet Switching\n\n将报文合理分块，增加携带分组编号等信息。\n在报文交换的基础上，缩短了时延，减少了期望的出错重发数据量，同时由于 packet 的长度有所限制，存储管理也方便了很多；动态寻找线路时各个 packet 也可以选择不同路径 (因此，packet 的数据不一定按序到达)。问题是额外信息量进一步增加，且发送前和接收后的工作量也会增加。\n\n\n"}}