{"index":{"slug":"index","filePath":"index.md","title":"🏠 首页","links":["about"],"tags":[],"content":"欢迎来到 ING wiki！\n本质自用, 持续建设中…\n📂 导航\n\n关于我\n\n📝 最近更新\n\n这里可以写一些最近的想法或者置顶的内容。\n"},"工具使用/Obsidian插件":{"slug":"工具使用/Obsidian插件","filePath":"工具使用/Obsidian插件.md","title":"Obsidian插件","links":[],"tags":[],"content":"templater\n可以把Templates文件夹下的笔记作为模板,左侧功能栏点击即可套用到其他笔记上.不会影响已写的内容.\nConsistent Attachments and Links\n右键某个文件夹,可以从整个仓库收集属于该文件夹下笔记的图片,并放到该文件夹下的attachments文件夹中.\n\n首先要在obsidian设置-文件与链接-附件默认存放路径,确定好附件存放方式是在文件夹下的attachments文件夹.\n使用时,比如先移动了一个笔记,然后右键笔记所属文件夹即可选择collect attachments.[注意不要对附件文件夹做任何删除操作,这个移动是附件本体进行移动,不是副本移动]\n\nclear unused images\n就是删除未被引用的附件图片\nGit\n好用,可以把整个obsidian仓库托管到git然后设置每两小时提交一次(如果有修改的话).我之前琢磨附件插件的时候把附件删没了全靠git找回来(当然也可以去回收站找)\nShell Commands\n可以编写终端指令.使用例:\n\n编写了一个指令,每次Obsidian打开的时候会自动进入我的博客本地仓库进行一次发布.\n"},"工具使用/博客搭建":{"slug":"工具使用/博客搭建","filePath":"工具使用/博客搭建.md","title":"博客搭建","links":[],"tags":[],"content":"基于Obsidian和Quartz4.流程:\n\n将quartz4仓库克隆到本地.然后将content文件夹重定向到本地obsidian仓库的public文件夹.这样两边的内容会进行一个同步.\n为本地quartz仓库配置私钥和公钥.私钥链接到github私有仓库.公钥连接到github公有仓库.这样只有静态产物会deploy到公有仓库,将公有仓库名字设置为username.github.io即可.\n在obsidian中的Public文件夹下书写笔记,然后在quartz4本地仓库进行提交.这样之后私有仓库[博客源码]会更新.公有仓库[静态产物]也会更新,最终体现在博客网页上.\n\n评论\ngiscus 基于github仓库discussion\ntips\n\nquartz.config.ts-&gt;plugins -&gt; transformers\n加上一行Plugin.HardLineBreaks(),,就会调用remark-breaks 这个库,将所有换行强制渲染成&lt;br&gt;,否则笔记里面的本来的换行选然后会变成空格.[只有两次回车/两个空格一次回车会被渲染成换行但是太麻烦了所以]\n"},"技术积累/Golang/库/Golang标准库":{"slug":"技术积累/Golang/库/Golang标准库","filePath":"技术积累/Golang/库/Golang标准库.md","title":"Golang标准库","links":[],"tags":[],"content":""},"技术积累/Golang/库/fmt":{"slug":"技术积累/Golang/库/fmt","filePath":"技术积累/Golang/库/fmt.md","title":"fmt","links":[],"tags":[],"content":"fmt.Print(&quot;Hello&quot;)//不换行原样输出\nfmt.Println(&quot;a&quot;,&quot;b&quot;)//自动换行且参数之间自动加空格\nfmt.Printf(&quot;我是%s,%d岁&quot;, name, age )//格式化输出,不换行\n \nfmt.Scanln(&amp;n)//读取到的数据放入到这个地址中"},"技术积累/Golang/库/slices":{"slug":"技术积累/Golang/库/slices","filePath":"技术积累/Golang/库/slices.md","title":"slices","links":[],"tags":[],"content":"slices.Sort(x):针对有序类型,默认升序排序,使用默认比较.可以对整数\\浮点数和字符串进行排序\nnums := []int{3, 1, 2}\nslices.Sort(nums) // nums 变为 [1, 2, 3]\nslices.SortFunc(x, cmp):针对任何类型,适用于结构体\\二维数组\\自定义类型\n排序使用自定义排序,必须提供func(a,b,E)int\n// 比较函数：如果 p &lt; q 返回负数，如果 p &gt; q 返回正数，相等返回 0。\ncmp := func(p, q []int) int { return p[0] - q[0] }\nslices.SortFunc(intervals, cmp)\n只要func(p, q T) int返回值&gt;0 就认为p&gt;q,p应该排在q的后面.以此类推."},"技术积累/Golang/库/strings":{"slug":"技术积累/Golang/库/strings","filePath":"技术积累/Golang/库/strings.md","title":"strings","links":[],"tags":[],"content":"strings.Builder\n常用于在循环中对字符串进行增加的操作.builder就相当于一个缓冲区,在最后才生成最终的字符串.\nimport &quot;strings&quot;\n \nvar sb strings.Builder\nsb.Grow(100)//预分配内存,可以避免中途多次扩容,提高性能\n \nsb.WriteString(&quot;Hello&quot;) // 写入字符串\nsb.WriteByte(&#039; &#039;) // 写入单个字节 (比如空格)\n \nresult := sb.String()//最终生成结果字符串"},"技术积累/Golang/核心知识/01-slice切片动态数组类型":{"slug":"技术积累/Golang/核心知识/01-slice切片动态数组类型","filePath":"技术积累/Golang/核心知识/01 slice切片动态数组类型.md","title":"04 slice切片动态数组类型","links":[],"tags":[],"content":"tips\n\n\nvar s []byte 得到的是nil切片,但是可以照常append go自己会处理.适用于不知道长度的情况下\n\n\ns:=make([]int,0,k) 知道长度的情况下,这种做法更优.\n\n\n注意切片是左闭右开,\n\n\n固定长度数组array\n但是在go中不等同于其他语言数组的地位,可以说slice才是go语言的数组.\n\n根据索引初始化 注意默认值是0\n查看数组的数据类型：长度变成了类型的一部分,因此存在两个问题\n\n因此传参的时候也要区分不同长度的数组了\n而且仍然是一个值传递（把本来的数组拷贝给形参，所以还是会有之前那个内存和地址的问题，所以不能进行改动）\n\n\n所以说要传参的话最好还是写动态数组,也可以使用切片操作符 [:] 你可以把数组“切”一下,这里是创建一个引用 不是copy,相当于传了地址\n\nrange关键字\n根据遍历不同集合返回不同值。\n\n数组或切片\n\n返回两个值  当前元素所在索引和当前元素值本身如果不关心某个返回值的话可以把它设置成匿名\n\n\n\n动态数组:切片 slice\n数据结构\n连续的内存,本身只包含三个信息(可以在runtime包下查询)\ntype slice struct {\n    // 指向起点的地址\n    array unsafe.Pointer\n    // 切片长度\n    len   int\n    // 切片容量\n    cap   int\n}\n\n指针 第一个元素的内存地址\n长度 当前存放的元素个数  访问切片是否合法\n容量 总共能装多少个元素(提前分配的空间元素个数),cap永远大于等于len 考虑性能优化\n\n\n索引时只需要计算目标地址 = 起始地址 + ( 索引 x 每个元素的大小 ),因此时间复杂度是O(1)\n\n特征\n\n传递时表面上是进行slice header的值传递,但因为内部存放的是unsafe.Pointer地址,因此实际上相当于引用传递,可以直接进行传递并在函数中进行值修改.[go语言中没有真正的引用传递,基本都是这样的伪引用传递].\n\n因此len和cap在函数中被修改是不会反映到底层数据结构的\n\n\n括号里面是空的，表示动态。可以看到类型也是动态数组类型\n\nslice切片的四种声明方式/初始化\n\n声明但不进行初始化\n\n判断一个slice是否为空nil [没有空间,而全0不算空]\n空slice不能够进行赋值,但是可以进行append(相当于一个一个开辟空间)\n\n\n\nvar s []init\n \n//判断一个slice是否为0\nif  slice1 == nil{\n\tfmt.println(&quot;是一个空切片&quot;)\n\t}else{\n\tfmt.println(&quot;不是一个空切片&quot;)}\nelse和前后两个括号需要在同一行否则会报语法错\n\n基于make进行初始化\n\n只初始化len而不初始化cap.\n\n此时会将len和cap同时默认设置为len的值.因为如果len&gt;cap会初始化失败.\n切片的长度一旦被指定了，就代表对应位置已经被分配了元素，设置的会是对应元素类型下的零值.\n\n\n分别指定len和cap\n\n在index【len,cap)的区域无法被访问,因为逻辑上不存在元素,访问会被报错.\n\n\n\n\n\ns := make([]int,8)\ns := make([]int,8,16)\n\n%v 可以打印数组内详细数据\n\n\n初始化连带赋值\n\n会将len和cap同时设为3并且完成赋值\n\n\n\n  s := []int{2,3,4}\n初始化源码\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n    // 根据 cap 结合每个元素的大小，计算出消耗的总容量\n    mem, overflow := math.MulUintptr(et.size, uintptr(cap))\n    if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {\n        // 倘若容量超限，len 取负值或者 len 超过 cap，直接 panic\n        mem, overflow := math.MulUintptr(et.size, uintptr(len))\n        if overflow || mem &gt; maxAlloc || len &lt; 0 {\n            panicmakeslicelen()\n        }\n        panicmakeslicecap()\n    }\n    // 走 mallocgc 进行内存分配以及切片初始化,以及回收\n    return mallocgc(mem, et, true)\n}\n追加与截取\n切片的追加\n通过 append 操作，可以在 slice 的末尾，额外新增一个元素.\n\n这里的末尾指的是针对 slice 的长度 len 而言.实际上截取的话,从起点开始的容量会保留,详见辨析5\n这个过程中倘若发现 slice 的剩余cap已经不足了，则会对 slice 进行扩容.动态开辟相当于本来cap的容量\n\n\n在创建 slice 时，如果能够预估到其未来所需的容量空间,应该提前分配好对应容量，避免在运行过程中频繁触发扩容操作，这样会对性能产生不利的影响.\n\n\n实例1\n倘若希望使用 append 操作完成 slice 赋值，则应该在初始化 slice 时，给其设置不同的长度 len 和容量 cap 值，cap 和 len 之间的差值就是预留出来用于 append 操作的空间. 具体代码如下：\nfunc Test_slice(t *testing.T){\n    s := make([]int,0,5)\n    for i := 0; i &lt; 5; i++{\n       s = append(s, i)//追加的对象数组,以及追加的数据\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n实例2\n我们将 slice 的长度和容量都设置为 5,然后通过遍历 slice 的方式进行执行位置元素的赋值（不使用 append 操作）：\nfunc Test_slice(t *testing.T){\n    s := make([]int,5)\n    for i := 0; i &lt; 5; i++{\n       s[i] = i\n    }\n    // 结果为：\n    // s: [0,1,2,3,4]\n}\n扩容\n当len与cap相等时,下一次append操作就会进行一次扩容\n    // len:4, cap: 4\n    s := []int{2,3,4,5}\n    // len:5, cap: 8    len=原来的长度+1,cap=原来的cap*2\n    s = append(s,6)\n\n\n\n预期容量:\n\n如果只追加一个元素,预期容量就是原本的容量+1,\n如果预期元素是比如一个切片,那么预期容量就可能会超出原容量的两倍.\n\n\n\n如果预期容量小于原切片容量,panic\n\n\n倘若切片元素大小为 0（元素类型为 struct{}），则直接复用一个全局的 zerobase 实例，直接返回\n\n\n倘若预期的新容量超过老容量的两倍，则直接采用预期的新容量\n\n\n倘若老容量小于 256，则直接采用老容量的2倍作为新容量\n\n\n倘若老容量已经大于等于 256，则在老容量的基础上扩容 1/4 的比例并且累加上 192 的数值，持续这样处理，直到得到的新容量已经大于等于预期的新容量为止..如果在这个循环中数值太大了以至于越界,那么就直接取预期新容量为最终值\n\n这样做,可以使得随着容量增长,增长因子从2.0平滑过度到1.25\n1.18之前是直接*1.25,内存分配行为发生剧烈变化不够优雅\nnewcap += (newcap + 3*threshold) / 4。\n\n\n\n根据数据类型推算出实际需要的内存大小,然后mallocgc中还要对内存分配单元mspan的等级制度,推算得到实际需要申请的内存空间大小(向上取整)\n\nmheap是go管理的所有内存之和\nmspan就是标准大小地块,有不同大小等级共程序申请使用.\n\n\n\n调用 mallocgc，对新切片进行内存初始化\n\n\n调用 memmove 方法，将老切片中的内容拷贝到新切片中\n\n\n返回扩容后的新切片【扩容后会变成新的地址】\n源码:\n\n\nfunc growslice(et *_type, old slice, cap int) slice {\n    //... \n    if cap &lt; old.cap {\n        panic(errorString(&quot;growslice: cap out of range&quot;))\n    }\n \n \n    if et.size == 0 {\n        // 倘若元素大小为 0，则无需分配空间直接返回\n        return slice{unsafe.Pointer(&amp;zerobase), old.len, cap}\n    }\n \n \n    // 计算扩容后数组的容量\n    newcap := old.cap\n    // 取原容量两倍的容量数值\n    doublecap := newcap + newcap\n    // 倘若新的容量大于原容量的两倍，直接取新容量作为数组扩容后的容量\n    if cap &gt; doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256\n        // 倘若原容量小于 256，则扩容后新容量为原容量的两倍\n        if old.cap &lt; threshold {\n            newcap = doublecap\n        } else {\n            // 在原容量的基础上，对原容量 * 5/4 并且加上 192\n            // 循环执行上述操作，直到扩容后的容量已经大于等于预期的新容量为止\n            for 0 &lt; newcap &amp;&amp; newcap &lt; cap {             \n                newcap += (newcap + 3*threshold) / 4\n            }\n            // 倘若数值越界了，则取预期的新容量 cap 封顶\n            if newcap &lt;= 0 {\n                newcap = cap\n            }\n        }\n    }\n \n \n    var overflow bool\n    var lenmem, newlenmem, capmem uintptr\n    // 基于容量，确定新数组容器所需要的内存空间大小 capmem\n    switch {\n    // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap.\n    // 同时会针对 span class 进行取整\n    case et.size == 1:\n        lenmem = uintptr(old.len)\n        newlenmem = uintptr(cap)\n        capmem = roundupsize(uintptr(newcap))\n        overflow = uintptr(newcap) &gt; maxAlloc\n        newcap = int(capmem)\n    // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小\n    // 并会针对 span class 进行取整\n    case et.size == goarch.PtrSize:\n        lenmem = uintptr(old.len) * goarch.PtrSize\n        newlenmem = uintptr(cap) * goarch.PtrSize\n        capmem = roundupsize(uintptr(newcap) * goarch.PtrSize)\n        overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize\n        newcap = int(capmem / goarch.PtrSize)\n    // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算   \n    case isPowerOfTwo(et.size):\n        var shift uintptr\n        if goarch.PtrSize == 8 {\n            // Mask shift for better code generation.\n            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63\n        } else {\n            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31\n        }\n        lenmem = uintptr(old.len) &lt;&lt; shift\n        newlenmem = uintptr(cap) &lt;&lt; shift\n        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)\n        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)\n        newcap = int(capmem &gt;&gt; shift)\n    // 兜底分支：根据元素大小乘以元素个数\n    // 再针对 span class 进行取整     \n    default:\n        lenmem = uintptr(old.len) * et.size\n        newlenmem = uintptr(cap) * et.size\n        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n        capmem = roundupsize(capmem)\n        newcap = int(capmem / et.size)\n    }\n \n \n \n \n    // 进行实际的切片初始化操作\n    var p unsafe.Pointer\n    // 非指针类型\n    if et.ptrdata == 0 {\n        p = mallocgc(capmem, nil, false)\n        // ...\n    } else {\n        // 指针类型\n        p = mallocgc(capmem, et, true)\n        // ...\n    }\n    // 将切片的内容拷贝到扩容后的位置 p \n    memmove(p, old.array, lenmem)\n    return slice{p, old.len, newcap}\n}\n切片的截取\n\n要注意这里是左闭右开,因此[0:2]取的是第0.1位,2并没有算进来\n\n\n[:]=[0:len(s)]\n\n\n[:3]=[0:3]\n\n\n[4:]=[4:len(s)]\n\n\n本质上是引用传递操作,因此无论截取多少次,底层都是同一块内存空间数据.不过截取会创建出新的slice header实例\n\n\n因为实际上指向的是同一个地址区间,因此修改其中一个元素会影响到另外一个数组的\n\n\n如果要分开截取的话就使用copy函数,相当于拷贝一个副本,这样修改的话不会影响到本来的slice\n\n\n\n元素删除\n从切片中删除元素(只对len做修改)的实现思路，本质上和切片内容截取的思路是一致的.\n\n删除 slice 中的首个元素，在操作上等同于从切片 index = 1 开始向后进行内容截取\n删除 slice 的尾部元素，则操作等价于截取切片内容，并将终点设置在 len(s) - 1 的位置\n删除 slice 中间的某个元素，操作思路则是采用内容截取加上元素追加的复合操作，可以先截取待删除元素的左侧部分内容，然后在此基础上追加上待删除元素后侧部分的内容\n最后，当我们需要删除 slice 中的所有元素时，也可以采用切片内容截取的操作方式：s[:0]. 这样操作后，slice header 中的指针 array 仍指向原处，但是逻辑意义上其长度 len 已经等于 0，而容量 cap 则仍保留为原值.\n\nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [1,2,3,4]\n    s = s[1:]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // [0,1,2,3]\n    s = s[0:len(s)-1]\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // 删除 index = 2 的元素\n    s = append(s[:2],s[3:]...)//\n    // s: [0,1,3,4], len: 4, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = s[:0]\n    // s: [], len: 0, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\n…:\n\n在函数定义中,func myFunc(args ...int)，这里 ... 意味着 myFunc 是一个可变参数函数。它可以接受任意数量的 int 作为参数（0个、1个或多个）。\n在函数调用中 ：append(s1, s2...)，这里的 ... 意思是“将这个切片 (slice) 拆包/解开 (unpack/expand)”。\n\n因为append并不接受一个slice作为第二个参数,于是我们用…将slice拆分为单独元素\n\n\n\n切片拷贝\n包括简单拷贝和完整拷贝两种\n\n简单拷贝\n\n只要对切片的字面量进行赋值传递.这样相当于创建出了一个新的 slice header 实例，但是其中的指针 array、容量 cap 和长度 len 仍和老的 slice header 实例相同..\n对切片进行%p打印地址,打印出来的不是slice header的地址,而是内部array字段指向的数组地址\n切片的截取操作也属于是简单拷贝，s 和 s1 会使用同一片内存空间，只不过地址起点位置偏移了一个元素的长度. s1 和 s 的地址，刚好相差 8 个 byte.\n\n\n完整拷贝\n\n指的是会创建出一个和 slice 容量大小相等的独立的内存区域，并将原 slice 中的元素一一拷贝到新空间中.在实现上，slice 的完整复制可以调用系统方法 copy，通过日志打印的方式可以看到，s 和 s1 的地址是相互独立的.因此对应的数组地址也是全新的\n\n\n\n问题辨析\nfunc Test_slice(t *testing.T){\n    s := make([]int,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 20\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,0,10)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [10], len of s: 1, cap of s: 10\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,11)  \n    s = append(s,10)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s,len(s),cap(s))\n}\n//结果:s: [0 0 0 0 0 0 0 0 0 0 10], len of s: 11, cap of s: 11\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0 0] len=2 cap=4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:9]\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1,len(s1),cap(s1))\n}\n//结果:s1=[0] len:1 cap:4\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1[0] = -1\n    t.Logf(&quot;s: %v&quot;,s)\n}\n//结果:s: [0 0 0 0 0 0 0 0 -1 0]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    v := s[10]\n    // 求问，此时数组访问是否会越界\n}\n//会越界,因为len=10 是0-9的索引上有值\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    s1 = append(s1,[]int{10,11,12}...)\n    v := s[10]\n    // ...\n    // 求问，此时数组访问是否会越界\n}\n//由于 s 预留的空间不足，s1 会发生扩容,扩容后会返回拷贝后的新切片,这里的拷贝是完整拷贝,意味着修改 s1 不再会影响到 s\n// s 继续维持原本的长度值 10 和容量值 12，因此访问 s[10] 会panic\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v&quot;,s)\n}\n \n \nfunc changeSlice(s1 []int){\n  s1[0] = -1\n}\n//结果:s=[00000000-10  ]s1=[-10  ]\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,10,12)  \n    s1 := s[8:]\n    changeSlice(s1)\n    t.Logf(&quot;s: %v, len of s: %d, cap of s: %d&quot;,s, len(s), cap(s))\n    t.Logf(&quot;s1: %v, len of s1: %d, cap of s1: %d&quot;,s1, len(s1), cap(s1))\n}\n \n \nfunc changeSlice(s1 []int){\n  s1 = append(s1, 10)\n}\n//结果:s=[0000000000  ]不变 s1也不变\n//在局部方法 changeSlice 中，虽然对 s1 进行了 append 操作，但这这会在局部方法中这个独立的 slice header 中生效，不会影响到原方法 Test_slice 当中的 s 和 s1 的**长度和容量**.    \n \n \nfunc Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    s = append(s[:2],s[3:]...)\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n    v := s[4] \n    // 是否会数组访问越界\n}\n//[0,1,3,4] 会.\n \n \nfunc Test_slice(t *testing.T){\n    s := make([]int,512)  \n    s = append(s,1)\n    t.Logf(&quot;len of s: %d, cap of s: %d&quot;,len(s),cap(s))\n}\n//结果:len=513 cap: 根据不到两倍且&gt;256的计算方式(n += (n+3*256)/4) 可以计算到832, 然后根据mspan向上补齐的法则,得到848\n其他\nslice 不是并发安全的数据结构,没有对并发读写的保护机制.\n参考资料\n你真的了解go语言中的切片吗？—小徐先生的编程世界"},"技术积累/Golang/核心知识/02-map-实现原理":{"slug":"技术积累/Golang/核心知识/02-map-实现原理","filePath":"技术积累/Golang/核心知识/02 map 实现原理.md","title":"02 map 实现原理","links":["tags/待解决"],"tags":["待解决"],"content":"（1）存储基于 key-value 对映射的模式；\n（2）基于 key 维度实现存储数据的去重；\n（3）读、写、删操作控制，时间复杂度 O(1).\n定义\n声明\n\n\n\n\n如果满了的话再添加就会再加一个10(当前容量)\nmap里面感觉长度和容量变成一个东西了\n然后实际上存入的内容并非按存入顺序,而是采用基本的哈希方式来存的,可以认为是随机的.并且go会随机化起始点,所以哪怕两次遍历一个数组,得到的结果是不同的.因此如果要按照key的字母顺序来处理map数据,需要有一个有序索引slice然后用这个slice去map里面一个个查询\n\n\n\nmake是必须的,要有一个开辟空间的这么一个声明,才会有空间(虽然不设定容量的话空间为0)\n\n没有空间时赋值:越界报错\n有空间为0,赋值:会一个一个开辟的所以没事\n\n\n\n\n就是在声明的时候直接初始化,一般用这个\n\n\nkey的类型要求\n必须为可比较的类型，slice、map、func不可比较\n使用方式\n读\nv1 :=myMap[10]\n//倘若key存在,则获取到对应的val\n//倘若key不存在或者map未初始化,则会返回val类型的零值\n \nv2,ok := myMap[10]\n//添加一个bool类型的flag标识,读取成功则为true,读取失败为false[读取失败,key不存在/map未初始化]\n同一种语法能够实现不同返回值类型的适配，是由于代码在汇编时，会根据返回参数类型的区别，映射到不同的实现方法\n写\nmyMap[5] = 6\n//如果map未初始化,直接执行写操作会导致panic报错\n删\ndelete(myMap,5)\n//key存在:删除对应整个键值对\n//key不存在或map未初始化,方法会直接结束,不会产生显式提示\n遍历\nfor k,v := range myMap{\n  // ...\n}\n \nfor k := range myMap{\n  // ...\n}\n//获取key,不关注val的取值\n两次遍历一个数组,得到的结果是不同的.因此如果要按照key的字母顺序来处理map数据,需要有一个有序索引slice然后用这个slice去map里面一个个查询\n并发冲突\nmap 不是并发安全的数据结构，倘若存在并发读写行为，会抛出 fatal error.\n具体规则是：\n（1）并发读没有问题；\n（2）并发读写中的“写”是广义上的，包含写入、更新、删除等操作；\n（3）读的时候发现其他 goroutine 在并发写，抛出 fatal error；\n（4）写的时候发现其他 goroutine 在并发写，抛出 fatal error.\n需要关注，此处并发读写会引发 fatal error，是一种比 panic 更严重的错误，无法使用 recover 操作捕获. 待解决\n核心原理\nmap 又称为 hash map，在算法上基于 hash 实现 key 的映射和寻址；在数据结构上基于桶数组实现 key-value 对的存储.\n以一组 key-value 对写入 map 的流程为例进行简述：\n（1）通过哈希方法取得 key 的 hash 值；\n（2）hash 值对桶数组长度取模，确定其所属的桶；\n（3）在桶中插入 key-value 对.\n\nhash 的性质，保证了相同的 key 必然产生相同的 hash 值，因此能映射到相同的桶中，通过桶内遍历的方式锁定对应的 key-value 对.\n因此，只要在宏观流程上，控制每个桶中 key-value 对的数量，就能保证 map 的几项操作都限制为常数级别的时间复杂度.\n\nhash\nhash 译作散列，是一种将任意长度的输入压缩到某一固定长度的输出摘要的过程，由于这种转换属于压缩映射，输入空间远大于输出空间，因此不同输入可能会映射成相同的输出结果. 此外，hash在压缩过程中会存在部分信息的遗失，因此这种映射关系具有不可逆的特质.\n（1）hash 的可重入性：相同的 key，必然产生相同的 hash 值；\n（2）hash 的离散性：只要两个 key 不相同，不论其相似度的高低，产生的 hash 值会在整个输出域内均匀地离散化；\n（3）hash 的单向性：企图通过 hash 值反向映射回 key 是无迹可寻的.\n（4）hash 冲突：由于输入域（key）无穷大，输出域（hash 值）有限，因此必然存在不同 key 映射到相同 hash 值的情况，称之为 hash 冲突.\nbucket\nmap 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储：\n（1）每个桶固定可以存放 8 个 key-value 对；\n（2）倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.\nhash冲突\n\n首先，由于 hash 冲突的存在，不同 key 可能存在相同的 hash 值；\n再者，hash 值会对桶数组长度取模，因此不同 hash 值可能被打到同一个桶中.\n综上，不同的 key-value 可能被映射到 map 的同一个桶当中.\n\n此时最经典的解决手段分为两种：拉链法和开放寻址法.\n\n拉链法，将命中同一个桶的元素通过链表的形式进行链接，因此很便于动态扩展\n开放寻址法, 在插入新条目时，会基于一定的探测策略持续寻找，直到找到一个可用于存放数据的空位为止.\n\n\nmap的解决\n在 map 解决 hash /分桶 冲突问题时，实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述：\n（1）桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；\n（2）每个桶固定可以存放 8 个 key-value 对；\n（3）当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；\n（4）倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第（3）步；\n（5）倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.\n就是先用开放寻址,后用拉链法,对每个桶通过开放寻址保证填满\n扩容优化性能\nmap 的桶数组长度固定不变，那么随着 key-value 对数量的增长，当一个桶下挂载的 key-value 达到一定的量级，此时操作的时间复杂度会趋于线性，无法满足诉求.\n\n因此在实现上，map 桶数组的长度会随着 key-value 对数量的变化而实时调整，以保证每个桶内的 key-value 对数量始终控制在常量级别，满足各项操作为 O(1) 时间复杂度的要求.\nmap 扩容机制的核心点包括：\n（1）扩容分为增量扩容和等量扩容；\n（2）当桶内 key-value 总数/桶数组长度 &gt; 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；\n（3）当桶内溢出桶(从第二个开始到结束)数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶数组的长度保持为原值；[考虑到kv对不多,但是溢出桶很多的情况(可能本来很多后来慢慢删掉了,会有很多空洞)]\n（4）采用渐进扩容的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动.就是说分摊到后续的每一笔写操作中去这样,比较温和.\n\nkey属于哪个桶是有映射关系的,哈希不变,但是对桶数组取模有影响,就是加上一倍老数组个数.\n\n对4取模,得到的结果是0 那么桶0里面的kv对 key取哈希后得到最低两位都是00(对4取模等价于对3按位与)桶1 最低位01.\n那扩容后对8取模,等价于对7按位与.那么最第三位都要是0 按位与出来=0的才能放在8桶数组的0号位.最低位是100的会放在4号位,和本来的0号位差4\n所以说0号桶里的数,在扩容后,要么在0要么在4,差的就是一倍的老数组个数.就是大致被拆成两份,因此每个桶中的数据规模也大致变成原来的一半.\n\n数据结构\n源码位置在runtime/map.go\nhmap =map\n\ncount 总kv对数量\nB unit8 标注出桶数组的长度是2的B次方(1&lt;&lt;B)\nbuckets unsafe.pointer 指向桶数组起点位置\nextra 预先申请好的溢出桶节点\n对每个kv 还会存一个top值对应key的哈希值高八位来标识一些额外含义\n\n\ntype hmap struct {\n    count     int \n    flags     uint8//map状态标识,标识map是否被goroutine并发读写\n    B         uint8  \n    noverflow uint16 //溢出桶的数量\n    hash0     uint32 //hash随机因子,生成key的hash值得时候会用到\n    buckets    unsafe.Pointer //桶数组\n    oldbuckets unsafe.Pointer //扩容过程中老得同数组\n    nevacuate  uintptr//扩容进度标识,因为扩容是渐进的       \n    extra *mapextra \n}\nmapextra 溢出桶\n\ntype mapextra struct {\n    overflow    *[]*bmap//供桶数组buckets使用的溢出桶\n    oldoverflow *[]*bmap//扩容流程中,老桶数组使用的溢出桶\n \n \n    nextOverflow *bmap//下一个可用的溢出桶\n}\n在 map 初始化时，倘若容量过大，会提前申请好一批溢出桶，以供后续使用，这部分溢出桶存放在 hmap.mapextra 当中：\nbmap =map中的桶\n\n可以存储8组kv对,以及一个指向下一个桶的指针\n每组kv对包括 key的高八位哈希值tophash,key,val 三个部分.每组kv对可以直接通过内存地址偏移的方式去找.所以下面三个值都不是太有用\nconst bucketCnt = 8\ntype bmap struct {\n    tophash [bucketCnt]uint8\n    //keys [bucketCnt]T\n    //values [bucketCnt]T\n    //overflow uint8\n}\n构造方法/初始化"},"技术积累/Golang/核心知识/03-GMP-原理":{"slug":"技术积累/Golang/核心知识/03-GMP-原理","filePath":"技术积累/Golang/核心知识/03 GMP 原理.md","title":"03 GMP 原理","links":[],"tags":[],"content":"概念梳理\n线程\n通常语义中的线程，指的是内核级线程，核心点如下：\n（1）是操作系统最小调度单元；\n（2）创建、销毁、调度交由内核完成，cpu 需完成用户态与内核态间的切换；\n（3）可充分利用多核，实现并行.\n协程\n协程，又称为用户级线程，核心点如下：\n（1）与线程存在映射关系，为 M：1；\n（2）创建、销毁、调度在用户态完成.实际上是Go代码指针的修改,切换不同协程结构体而已,对CPU来说一直是在跑同一个线程\n（3）从属同一个内核级线程，无法并行；一个协程阻塞会导致从属同一线程的所有协程无法执行.\nGoroutine\nGoroutine，经 Golang 优化后的特殊“协程”，核心点如下：\n（1）与线程存在映射关系，为 M：N；\n（2）创建、销毁、调度在用户态完成，对内核透明，足够轻便；\n（3）可利用多个线程，实现并行；\n（4）通过调度器的斡旋，实现和线程间的动态绑定和灵活调度；\n（5）栈空间大小可动态扩缩，因地制宜.\nGMP模型\ngmp = goroutine + machine + processor （+ 一套有机组合的机制），下面先单独拆出每个组件进行介绍，最后再总览全局，对 gmp 进行总述\ng\n（1）g 即goroutine，是 golang 中对协程的抽象；\n（2）g 有自己的运行栈、状态、以及执行的任务函数（用户通过 go func 指定）；\n（3）g 需要绑定到 p 才能执行，在 g 的视角中，p 就是它的 cpu.\np\n（1）p 即 processor，是 golang 中的调度器；\n（2）p 是 gmp 的中枢，借由 p 承上启下，实现 g 和 m 之间的动态有机结合；\n（3）对 g 而言，p 是其 cpu，g 只有被 p 调度，才得以执行；\n（4）对 m 而言，p 是其执行代理，为其提供必要信息的同时（可执行的 g、内存分配情况等），并隐藏了繁杂的调度细节；\n（5）p 的数量决定了 g 最大并行数量，可由用户通过 GOMAXPROCS 进行设定（超过 CPU 核数时无意义）.\nm\n（1）m 即 machine，是 golang 中对线程的抽象；\n（2）m 不直接执行 g，而是先和 p 绑定，由其实现代理；\n（3）借由 p 的存在，m 无需和 g 绑死，也无需记录 g 的状态信息，因此 g 在全生命周期中可以实现跨 m 执行.\ngmp\n\nGMP 宏观模型如上图所示，下面对其要点和细节进行逐一介绍：\n（1）M 是线程的抽象；G 是 goroutine；P 是承上启下的调度器；\n（2）M调度G前，需要和P绑定；一个m绑定一个g\n（3）全局有多个M和多个P，但同时并行的G的最大数量等于P的数量；\n（4）G的存放队列有三类\n\nP的本地队列\n全局队列\nwait队列（图中未展示，为io阻塞就绪态goroutine队列）；\n（5）M调度G时，优先取P本地队列，其次取全局队列，最后取wait队列；这样的好处是，取本地队列时，可以接近于无锁化，减少全局锁竞争；\n（6）为防止不同P的闲忙差异过大，设立work-stealing机制，本地队列为空的P可以尝试从其他P本地队列偷取一半的G补充到自身队列.\n\n全局队列:不能满,必须要能够扩容,但是扩容会锁死所有p,所以用链表可以直接挂到末尾.并且如果有移动的话不需要内存拷贝,只需要指针操作.\n本地队列:固定长度数组256,因为p访问本地队列非常频繁,一口气加载连续内存的空间局部性比较友好,也没有gc开销\n核心数据结构\ng\n\ntype g struct {\n    // ...\n    m         *m    //负责执行当前g的m\n    // ...\n    sched     gobuf//gobuffer 存档\n    // ...\n}\n \n \ntype gobuf struct {\n    sp   uintptr //保存 CPU 的 rsp 寄存器的值，指向函数调用栈栈顶\n    pc   uintptr //保存 CPU 的 rip 寄存器的值，指向程序下一条执行指令的地址\n    ret  uintptr //保存系统调用的返回值\n    bp   uintptr // 保存 CPU 的 rbp 寄存器的值，存储函数栈帧的起始位置.\n}\n \n \nconst(\n  _Gidle = itoa // 0 为协程开始创建时的状态，此时尚未初始化完成\n  _Grunnable // 1 协程在待执行队列中，等待被执行\n  _Grunning // 2 协程在待执行队列中，等待被执行\n  _Gsyscall // 3 协程正在执行系统调用\n  _Gwaiting // 4 协程处于挂起态，需要等待被唤醒. gc、channel 通信或者锁操作时经常会进入这种状态\n  _Gdead // 6 协程刚初始化完成或者已经被销毁，会处于此状态\n  _Gcopystack // 8 协程正在栈扩容流程中\n  _Gpreempted // 9 协程被抢占后的状态\n)\nm\ntype m struct {\n    g0      *g     // goroutine with scheduling stack一类特殊的调度协程,不用于执行用户函数,负责执行g之间的切换调度,与m的关系为1:1,也不需要排队,就是m的一部分\n    // ...\n    tls           [tlsSlots]uintptr // thread-local storage (for x86 extern register)线程本地存储,存储内容只对当前线程可见,线程本地存储的是m.tls 的地址，m.tls[0] 存储的是当前运行的 g，因此线程可以通过 g 找到当前的 m、p、g0 等信息.\n    //其实代码执行的时候,cpu也不知道自己在哪个m里面,所以要用m.tls[0].m去找,这么做主要是因为需要更快速的访问g所以牺牲了访问m的所需时间\n    // ...\n}\np\ntype p struct {\n    // ...\n    runqhead uint32  //队列头\n    runqtail uint32   //队列尾\n    runq     [256]guintptr   //本地g队列,最大长度256\n    \n    runnext guintptr  //下一个可以执行的g  比如一些插队的,比如两个协程之间有一些亲缘关系,那么大概率会共享数据,这样就优先运行亲缘近的,可以更好的利用cpu缓存不用洗掉本来的数据\n    // ...\n}\nschedt\n全局g队列的封装\ntype schedt struct {\n    // ...\n    lock mutex   //全局g队列的锁\n    // ...\n    runq     gQueue   //全局g队列\n    runqsize int32 //全局g队列的容量\n    // ...\n}\n调度流程\n两种g的转换\ng可以分为两类\n\n普通g\n调度普通g的g0 执行固定的调度流程,与m的关系是1: 1\n\nm 通过 p 调度执行的 goroutine 永远在普通 g 和 g0 之间进行切换\n\n当 g0 找到可执行的 g 时，会调用 gogo 方法，调度 g 执行用户定义的任务\n当 g 需要主动让渡或被动调度时，会触发 mcall 方法，将执行权重新交还给 g0.\n\nfunc gogo(buf *gobuf)//根据缓存内容恢复普通g\n// ...\nfunc mcall(fn func(*g)) //fn是一个处理函数,在彻底切换到g0之后会被执行,一般是一些调度器逻辑,把放弃了cpu的这个g放到队列尾之类的\n调度类型\n主动调度\n\n一种用户主动执行让渡的方式，主要方式是，用户在执行代码中调用了runtime.Gosched 方法，此时当前 g 会当让出执行权，主动回到全局队列, 等待下次被调度执行.\n保证了当前 P 的本地任务能得到执行，也让其他 P 有机会分担这个 G\n\nfunc Gosched() {\n    checkTimeouts()\n    mcall(gosched_m)//让g0把g放到全局队列\n    }\n被动调度\n常见的被动调度触发方式\n\n因 channel 操作或互斥锁操作陷入阻塞等操作，g会调用 gopark 方法.这里的阻塞是用户态阻塞,不需要占用m,g进行mcall,让g0把自己放进等待队列.\n\nfunc gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {\n    // ...\n    mcall(park_m)\n}\n\ngoready 方法通常与 gopark 方法成对出现，当满足唤醒条件后就会被调用.能够将 g 从阻塞态中恢复，重新进入等待执行的状态.优先进入本地队列,如果本地队列满了,就会进入全局队列\n\nfunc goready(gp *g, traceskip int) {\n    systemstack(func() {\n        ready(gp, traceskip, true)\n    })\n}\n\n\n                  \n                  用户态阻塞与线程态阻塞 \n                  \n                \n\n用户态阻塞:只需要进行逻辑等待,只要信号来了立马就能恢复，并不占用m\n\nchannel,等待有人往里面塞数据\nmutex,等待锁被释放的信号\nsleep,等待闹钟响了的信号\n\n线程阻塞(m阻塞),总之会让内核卡住干不了别的事情\n\n磁盘io\n系统调用\n\n\n\n正常调度\ng 中的执行任务已完成，g0 会将当前 g 置为死亡状态，发起新一轮调度.\n抢占调度\n\n\n倘若 g 执行系统调用[m阻塞]超过指定的时长，且全局的 p 资源比较紧缺，此时将 p 和 g 解绑，把p抢占出来用于其他 g 的调度.\n\n\n等 g 完成系统调用后，会重新进入全局队列中等待被调度.[这时候m已经没有p了,所以也就意味着没有本地队列,g就回到全局队列,而m会试着去寻找空闲的p]\n\n\n值得一提的是，前 3 种调度方式都由 m 下的 g0 完成，唯独抢占调度不同.\n\n\n因为发起系统调用时需要打破用户态的边界进入内核态，此时 m 也会因系统调用而陷入僵直，无法主动完成抢占调度的行为.\n\n\n因此，在 Golang 进程会有一个全局监控协程 monitor g 的存在，这个 g 会越过 p 直接与一个 m [专用的,独立的m]进行绑定，不断轮询对所有 p 的执行状况进行监控. 倘若发现满足抢占调度的条件，则会从第三方的角度出手干预，主动发起该动作.\n\n在 Go 的内存里，有一个全局数组叫 allp，里面记录了所有 P（独轮车） 的实时状态。\n\n\n\n宏观调度流程\n（1）以 g0 → g → g0 的一轮循环为例进行串联；\n（2）g0 执行 schedule() 函数，寻找到用于执行的 g；\n（3）g0 执行 execute() 方法，更新当前 g、p 的状态信息，并调用 gogo() 方法，将执行权交给 g；\n（4）g 因主动让渡( gosche_m() )、被动调度( park_m() )、正常结束( goexit0() )等原因，调用 m_call 函数，执行权重新回到 g0 手中；\n（5）g0 执行 schedule() 函数，开启新一轮循环.\nfunc schedule() {\n    // ...\n    gp, inheritTime, tryWakeP := findRunnable() // blocks until work is available//寻找到下一个执行的goroutine\n \n \n    // ...\n    execute(gp, inheritTime)//执行该goroutine:更新状态信息,并且调用gogo方法加载gobuf\n}\nfindRunnable\n如何找到下一个要执行的g.\n是 M（在 g0 栈上）运行调度程序，操作 P 的本地队列或全局队列来获取 G\nfunc findRunnable() (gp *g, inheritTime, tryWakeP bool) {\n    _g_ := getg()\n \n \ntop:\n    _p_ := _g_.m.p.ptr()\n    // ...\n    // 1. p每执行61次调度,会从全局队列中获取一个 goroutine 进行执行\n    if _p_.schedtick%61 == 0 &amp;&amp; sched.runqsize &gt; 0 {\n        lock(&amp;sched.lock)\n        gp = globrunqget(_p_, 1)\n        unlock(&amp;sched.lock)\n        if gp != nil {\n            return gp, false, false\n        }\n    }\n    \n    // ...\n    //2. 尝试从p本地队列中获取一个可执行的goroutine:runqget方法\n    if gp, inheritTime := runqget(_p_); gp != nil {\n        return gp, inheritTime, false\n    }\n    \n    // ...\n    //3. 倘若本地队列没有可执行的g,会从全局队列中获取\n    if sched.runqsize != 0 {\n        lock(&amp;sched.lock)//加锁\n        gp := globrunqget(_p_, 0)\n        unlock(&amp;sched.lock)\n        if gp != nil {\n            return gp, false, false\n        }\n    }\n    \n\t//4. 倘若本地队列和全局队列都没有g,则会获取准备就绪的网络协程\n    if netpollinited() &amp;&amp; atomic.Load(&amp;netpollWaiters) &gt; 0 &amp;&amp; atomic.Load64(&amp;sched.lastpoll) != 0 {\n        if list := netpoll(0); !list.empty() { // non-blocking\n            gp := list.pop()\n            injectglist(&amp;list)\n            casgstatus(gp, _Gwaiting, _Grunnable)//刚获取网络协程时，g 的状态是处于 waiting 的，因此需要先更新为 runnable 状态.\n            return gp, false, false\n        }\n    }\n \n    // ...\n    //5. work-stealing:从其他 p 中偷取 g\n    procs := uint32(gomaxprocs)\n    if _g_.m.spinning || 2*atomic.Load(&amp;sched.nmspinning) &lt; procs-atomic.Load(&amp;sched.npidle) {\n        if !_g_.m.spinning {\n            _g_.m.spinning = true\n            atomic.Xadd(&amp;sched.nmspinning, 1)\n        }\n \n        gp, inheritTime, tnow, w, newWork := stealWork(now)\n        now = tnow\n        if gp != nil {\n            // Successfully stole.\n            return gp, inheritTime, false\n        }\n        if newWork {\n            // There may be new timer or GC work; restart to\n            // discover.\n            goto top\n        }\n        if w != 0 &amp;&amp; (pollUntil == 0 || w &lt; pollUntil) {\n            // Earlier timer to wait for.\n            pollUntil = w\n        }\n    }\n具体函数\n1. 防饿死\n\np每执行61次调度,会从全局队列中获取一个 goroutine 进行执行\n\n通过globrunqget,传入max=1(最多只拿一个)\n\n\n\nfunc globrunqget(_p_ *p, max int32) *g {\n//全局队列为空\n    if sched.runqsize == 0 {\n        return nil\n    }\n//要获取的goroutine数为,全局g总数/p总数+1 比如11个g2个p,每个p分到6个\n    n := sched.runqsize/gomaxprocs + 1\n    if n &gt; sched.runqsize {\n        n = sched.runqsize\n    }//不超过全局g数\n    //如果是防饿死机制,max=1,这是调用者指定的\n    if max &gt; 0 &amp;&amp; n &gt; max {\n        n = max\n    }\n    //不超过本地队列容量的一半(别塞太满)\n    if n &gt; int32(len(_p_.runq))/2 {\n        n = int32(len(_p_.runq)) / 2\n    }\n\t//开始搬运\n    sched.runqsize -= n\n    gp := sched.runq.pop()//弹出一个是马上要执行的g\n    n--\n    //剩下的g, 循环塞进p的本地队列\n    for ; n &gt; 0; n-- {\n        gp1 := sched.runq.pop()\n        runqput(_p_, gp1, false)\n    }\n    return gp//返回要跑的那个g\n}\n将一个 g 由全局队列转移到 p 本地队列的执行逻辑:\nfunc runqput(_p_ *p, gp *g, next bool) {\n    // ...\n \nretry:\n    h := atomic.LoadAcq(&amp;_p_.runqhead) // 原子加载头节点索引\n    t := _p_.runqtail//加载尾节点索引\n    //环形队列还没满的时候 //go语言中环形队列的t和h不会归零会一直向上增长,计算当前环形队列中元素个数只需要相减就好了\n    if t-h &lt; uint32(len(_p_.runq)) {\n        _p_.runq[t%uint32(len(_p_.runq))].set(gp)//计算放入的位置:环形队列需要对长度取模,并放入数据\n        atomic.StoreRel(&amp;_p_.runqtail, t+1) //更新尾指针并解锁,StoreRel叫做释放写\n        return\n    }\n    //队列满了就执行runqputslow把一半g放到全局队列\n    if runqputslow(_p_, gp, h, t) {\n        return\n    }\n    // 如果slow过程失败了,比如被别人偷了导致 head 变了,就retry重试\n    goto retry\n原子操作:\n对于p的本地队列来说,生产者只有一个就是p自己,只有p能往自己的本地队列里面加东西.而消费者包括p自己从本地队列拿g去执行,也包括其他p通过work stealing机制来偷取p.\n\n因为偷取都是从队头偷取,放东西从队尾放.因此队头指针需要用原子操作,为了获取到确定是最新的head.\n因为是先写入数据,后移动尾指针.移动尾指针之前,这块数据对其他人来说并不可见,因此也不用担心竞争,所以不用原子写入操作.而移动尾指针需要是原子操作StoreRel,这个函数可以确保必须要先写入数据,再更新尾指针,防止cpu进行指令重排.\nLoadAcq:确保获取到最新的\nStoreRel:确保前面的修改已完成并写入内存\nCasRel:会检查当前值是否还是刚才读到的值\n\n\n\n                  \n                  Title \n                  \n                \n\n本地队列采用了单生产者-多消费者的无锁环形队列设计.\n为了性能,利用了原子操作的内存屏障语义来替代互斥锁\n\n移动tail指针,使用store-release语义.\n读取head指针,使用load-acquire语义.\n\n\n\n\n\n                  \n                  互斥锁与原子操作 \n                  \n                \n\n全局队列采用互斥锁,因为逻辑太复杂,原子操作搞不定.而且平摊成本,虽然锁比较慢,但是要操作全局队列的情况也比较少.\n本地队列一般用原子操作,主要是锁太慢了,而访问本地队列很频繁\n\n\n倘若发现本地队列 runq 已经满了，则会返回来将本地队列中一半的 g 放回全局队列中，帮助当前 p 缓解执行压力.\nfunc runqputslow(_p_ *p, gp *g, h, t uint32) bool {\n    var batch [len(_p_.runq)/2 + 1]*g //大小是队列容量的一半+新来的那个\n    // First, grab a batch from local queue.要转移的数量是队列容量的一半\n    n := t - h\n    n = n / 2\n    \n    // ...\n    //从队头开始复制到全局队列\n    for i := uint32(0); i &lt; n; i++ {\n        batch[i] = _p_.runq[(h+i)%uint32(len(_p_.runq))].ptr()\n    }\n    if !atomic.CasRel(&amp;_p_.runqhead, h, h+n) { // cas-release, commits consume\n        return false\n    }//更新队头指针\n    \n    batch[n] = gp//把新来的这个放到最后\n \n \n    // Link the goroutines.本地队列是数组结构,全局队列是链表结构,因此需要转换成链表\n    for i := uint32(0); i &lt; n; i++ {\n        batch[i].schedlink.set(batch[i+1])\n    }\n    //组装成一个临时的队列对象q\n    var q gQueue\n    q.head.set(batch[0])\n    q.tail.set(batch[n])\n \n \n    // Now put the batch on global queue.\n    //操作全局队列,必须加锁\n    lock(&amp;sched.lock)\n    globrunqputbatch(&amp;q, int32(n+1))\n    unlock(&amp;sched.lock)\n    return true\n为什么从队头开始搬:\n\n等了很久了,如果是阻塞的话可能还要接着等,不如放到全局让其他的p接走.\n队尾的g很可能跟当前的g有亲缘关系\n\n2. 从本地队列获取\n尝试从 p 本地队列中获取一个可执行的 goroutine\n if gp, inheritTime := runqget(_p_); gp != nil {\n        return gp, inheritTime, false\n    }\n3.\n \n4.\n \n5.\n \n多种阻塞\n\n\n由于原子、互斥量或通道操作调用导致 Goroutine 阻塞，调度器将把当前阻塞的 Goroutine 切换出去，重新调度 LRQ 上的其他 Goroutine；\n\n\n由于网络请求和 IO 操作导致 Goroutine 阻塞。Go 程序提供了网络轮询器（NetPoller）来处理网络请求和 IO 操作的问题，其后台通过 kqueue（MacOS），epoll（Linux）或 iocp（Windows）来实现 IO 多路复用。通过使用 NetPoller 进行网络系统调用，调度器可以防止 Goroutine 在进行这些系统调用时阻塞 M。这可以让 M 执行 P 的 LRQ 中其他的 Goroutines，而不需要创建新的 M。执行网络系统调用不需要额外的 M，网络轮询器使用系统线程，它时刻处理一个有效的事件循环，有助于减少操作系统上的调度负载。用户层眼中看到的 Goroutine 中的“block socket”，实现了 goroutine-per-connection 简单的网络编程模式。实际上是通过 Go runtime 中的 netpoller 通过 Non-block socket + I/O 多路复用机制“模拟”出来的。\n\n\n当调用一些系统方法的时候（如文件 I/O），如果系统方法调用的时候发生阻塞，这种情况下，网络轮询器（NetPoller）无法使用，而进行系统调用的 G1 将阻塞当前 M1。调度器引入 其它M 来服务 M1 的P。\n\n\n如果在 Goroutine 去执行一个 sleep 操作，导致 M 被阻塞了。Go 程序后台有一个监控线程 sysmon，它监控那些长时间运行的 G 任务然后设置可以强占的标识符，别的 Goroutine 就可以抢先进来执行。\n\n"},"技术积累/Golang/核心知识/04-内存模型与分配机制":{"slug":"技术积累/Golang/核心知识/04-内存模型与分配机制","filePath":"技术积累/Golang/核心知识/04 内存模型与分配机制.md","title":"04 内存模型与分配机制","links":[],"tags":[],"content":"内存模型\n回顾操作系统\n\n操作系统中经典的多级存储模型设计.\n\n多级模型:根据读取速度\\空间大小\\价格的不同\n\n寄存器\n高速缓存\n内存\n磁盘\n\n\n动态切换\n\n\n虚拟内存与物理内存:\n\n在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）\n优化用户体验（进程感知到获得的内存空间是“连续”的）\n“放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）\n\n\n分页管理:\n\n操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作“页”，于物理内存而言叫作“帧”，原因及要点如下：\n\n提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）\n提高内外存交换效率（更细的粒度带来了更高的灵活度）\n与虚拟内存机制呼应，便于建立虚拟地址→物理地址的映射关系（聚合映射关系的数据结构，称为页表）\nlinux 页/帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）\n\n\n\n\n\ngo内存模型\n核心要点:\n\n空间换时间,一次缓存,多次复用.\n因为申请内存的操作很重,那么一次多申请一些.\nGolang中的堆mheap:\n\n\n对操作系统而言,这是用户进程中缓存的内存\n对于go进程内部,堆是所有对象的内存起源\n\n\n多级缓存,实现无/细锁化\n堆是Go运行时最大的临界共享资源,这意味着每次存取都要加锁.\nGolang在堆之上依次细化力度:\n\n\nmheap:全局内存起源,访问要加全局锁\nmcentral:每种对象大小规格(全局共划分为68种)对应的缓存,锁的粒度也仅限于同一种规格以内\nmcache:每个P持有一份的内存缓存,访问时无锁.\n\n\n多级规格,提高利用率\n"},"技术积累/Golang/核心知识/05-GC垃圾回收原理":{"slug":"技术积累/Golang/核心知识/05-GC垃圾回收原理","filePath":"技术积累/Golang/核心知识/05 GC垃圾回收原理.md","title":"05 GC垃圾回收原理","links":[],"tags":[],"content":""},"技术积累/Golang/核心知识/06-Channel-实现原理":{"slug":"技术积累/Golang/核心知识/06-Channel-实现原理","filePath":"技术积累/Golang/核心知识/06 Channel 实现原理.md","title":"06 Channel 实现原理","links":[],"tags":[],"content":""},"技术积累/Golang/核心知识/数据结构的实现":{"slug":"技术积累/Golang/核心知识/数据结构的实现","filePath":"技术积累/Golang/核心知识/数据结构的实现.md","title":"数据结构的实现","links":[],"tags":[],"content":"map: 带有溢出桶机制的哈希表\n字符串: 只读的字节切片\n切片: 动态数组描述符\n接口: 带着类型信息的胖指针\n通道channel: 带锁的环形队列"},"技术积累/Golang/语法特性/值传递与引用传递":{"slug":"技术积累/Golang/语法特性/值传递与引用传递","filePath":"技术积累/Golang/语法特性/值传递与引用传递.md","title":"值传递与引用传递","links":[],"tags":[],"content":"go的默认传参方式是copy,如果传递的不是地址的话,对参数的修改无法生效."},"技术积累/Golang/语法特性/多态-接口interface":{"slug":"技术积累/Golang/语法特性/多态-接口interface","filePath":"技术积累/Golang/语法特性/多态-接口interface.md","title":"接口","links":[],"tags":[],"content":"多态\n需要有接口概念interface\n只要符合接口定义的函数,就被认为是这个接口的一分子.然后可以作为接口成员,调用相应包函数..\n注意: 符合接口定义的函数: 传入的参数类型的定义也必须严格一致.\n// src/container/heap/heap.go\n \ntype Interface interface {\n    sort.Interface\n    Push(x any)    // 👈 官方规定：这里必须接收interface{}\n    Pop() any      // 👈 官方规定：这里必须返回interface{}\n}\n \n \n// 那么如果照着这样写编译器就会报错\nfunc (h *IHeap) Push(x [2]int) { // 直接接收 [2]int\n    *h = append(*h, x)\n}\n \ninterface类型:\n\n类似于slice,结构内部有指针*type 和 *data\n一个变量能不能赋给一个接口，唯一标准是：这个变量的“类型”是否实现了该接口要求的【所有方法】。要看方法到底是定义在了值上,还是定义在了指针上.\n\n类继承接口的话不需要写进结构体定义,只需要自己实现接口中的方法,就相当于继承了.那么接口的指针就可以指向这个子类.如果没有实现完全,也是无法继承的.\n让接口对到谁,就调用谁的方法\n\n\n相当于把有同样方法的类进行归类然后用一个接口可以统一进行管理\n理解\n比如: 调用方说想要一个能插USB口的东西,那么只要这个东西实现了USB规定的方法(触电\\数据传输等),就必须要能插进USB接口.\n与C++不同的是,Go中采用隐式结构.只需要方法名相同即可.\n有一个接口叫 Payer（支付方式），要求有一个 Pay() 方法。\n\n你写了一个 Alipay 结构体，里面写了个 Pay() 方法。\n你又写了一个 WeChat 结构体，里面也写了个 Pay() 方法。\n那么编译器就会认为这两个结构体都属于Payer接口.\n\n主要的目的是进行解耦,比如下面这个例子\n//不使用接口\nfunc 结账(用户选择 string) {\n    if 用户选择 == &quot;支付宝&quot; {\n        调用支付宝API()\n    } else if 用户选择 == &quot;微信&quot; {\n        调用微信API()\n    } else if 用户选择 == &quot;银行卡&quot; {\n        调用银行卡API()\n    }\n    // 明年如果出了个“抖音支付”，你还得回来改这行代码，烦死。\n}\n \n//使用接口\n//只要是实现了 Payer 的东西，都能传进来\nfunc 结账(p Payer) {\n    p.Pay() \n}\n使用\n//定义\ntype Payer interface {\n\tPay(amount int) // 只要能从兜里掏钱，就是 Payer\n}\n \n//类型1\ntype Alipay struct {\n\tAccountName string\n}\nfunc (a Alipay) Pay(amount int) {\n\tfmt.Printf(&quot;【支付宝】%s 扫码支付了 %d 元\\n&quot;, a.AccountName, amount)\n}\n \n//类型2\ntype Cash struct {\n\tBalance int // 余额\n}\n// 实现 Pay 方法\n// 注意：这里使用的是【指针接收者】 (c *Cash)\n// 意思：现金支付会减少我的余额，必须修改内部数据！\nfunc (c *Cash) Pay(amount int) {\n\tif c.Balance &gt;= amount {\n\t\tc.Balance -= amount // 修改了结构体内部的值\n\t\tfmt.Printf(&quot;【现金】从钱包扣款 %d 元，剩余 %d 元\\n&quot;, amount, c.Balance)\n\t} else {\n\t\tfmt.Println(&quot;【现金】余额不足！&quot;)\n\t}\n}\n \n//多态函数\nfunc Checkout(p Payer, price int) {\n\tfmt.Println(&quot;&gt;&gt;&gt; 开始结账...&quot;)\n\tp.Pay(price) // 多态调用\n\tfmt.Println(&quot;&gt;&gt;&gt; 结账完成\\n&quot;)\n}\n \n \n//main函数\nfunc main() {\n\t// 场景 1：使用支付宝 (值接收者)\n\tmyAlipay := Alipay{AccountName: &quot;Deng&#039;s Phone&quot;}\n\tCheckout(myAlipay, 100) \n\t// 传入值 myAlipay 没问题，因为它的方法是值接收者\n \n\t// 场景 2：使用现金 (指针接收者)\n\tmyWallet := Cash{Balance: 500}\n\tCheckout(myWallet, 200) //❌\n\tCheckout(&amp;myWallet, 200) \n\t// ✅ 必须传入地址 (&amp;myWallet)\n\t// 因为 Cash 的 Pay 方法是挂在指针上的,所以会认为指针才是实际的payer\n}\n使用2\nIHeap定义的Pop函数,会被作为heap.Pop的一部分被调用.\nheap.Pop会先把某个元素换到最后面,然后我用自己的Pop方法去把最后一个元素切掉.\n空接口\n\n作为通用万能类型:空接口interface{}\n可以用interface{}类型引用任意的数据类型   [go中数据类型基本都实现了这个空接口]\n\n断言\n如果断言成功了,这个类型就从一个空接口变成了一个具体的类型,可以认为是做了一个类型转换了\n// 语法： value, ok := 接口变量.(目标类型)\nrealValue, ok := x.([2]int)\n \nif ok {\n    // 成功！\n    // realValue 现在是 [2]int 类型，可以放心用\n    fmt.Println(&quot;成功拿到数组：&quot;, realValue)\n} else {\n    // 失败！\n    // x 里装的根本不是 [2]int，可能是别的，或者 x 是 nil\n    // 此时程序不会崩，realValue 会是零值\n    fmt.Println(&quot;类型不对，不是数组&quot;)\n}\n \n \n// 语法： value := 接口变量.(目标类型) \nrealValue := x.([2]int) // 只有这一行，没有 ok\n \n \n \n\n关于指针\n如果方法定义在值上,就算把指针拿去调用接口,也是成立的.\n因为编译器允许你用 *Cat 类型的指针去调用 Cat 类型（值）的方法，所以 Go 认为 *Cat（指针）和 Cat（值）都实现了这个接口\n但是如果方法定义在指针上,用值去调用接口是不行的."},"技术积累/Golang/语法特性/未命名":{"slug":"技术积累/Golang/语法特性/未命名","filePath":"技术积累/Golang/语法特性/未命名.md","title":"未命名","links":[],"tags":[],"content":""},"技术积累/Golang/语法特性/语法细节":{"slug":"技术积累/Golang/语法特性/语法细节","filePath":"技术积累/Golang/语法特性/语法细节.md","title":"语法细节","links":[],"tags":[],"content":"变量声明与运算逻辑\n\n左大括号不能单独一行。\n不允许有未使用的变量和import，必须用——别名来忽略\n在if或者代码块内使用:=可能会意外覆盖同名变量，导致外部变量没有被修改\n:=只能在函数内部使用,且不能用于设置结构体字段\n不要用nil初始化未指定类型的变量\n自增自减只有后置,没有前置\n\n其他\n\n接口的底层是(Type,Value),只有(nil,nil)才是nil.\n\n"},"技术积累/兴趣驱动的待学清单":{"slug":"技术积累/兴趣驱动的待学清单","filePath":"技术积累/兴趣驱动的待学清单.md","title":"兴趣驱动的待学清单","links":[],"tags":[],"content":"\nPython爬虫\nJS逆向\n"},"技术积累/杂项/JSON":{"slug":"技术积累/杂项/JSON","filePath":"技术积累/杂项/JSON.md","title":"JSON","links":[],"tags":[],"content":"为了一个项目不同语言间的交流,设计的标准格式.\nJSON(JavaScript Object Notation)本质上就是一段 纯文本（String），长得非常有规律。不管是 C++、Go、Java 还是 Python，都能读写。\n{\n    &quot;stackIn&quot;: &quot;对象1&quot;,\n    &quot;stackOut&quot;: &quot;对象2&quot;\n}"},"技术积累/算法思想/KMP算法":{"slug":"技术积累/算法思想/KMP算法","filePath":"技术积累/算法思想/KMP算法.md","title":"KMP算法","links":[],"tags":[],"content":"取了三位学者名字的首字母。所以叫做KMP\n主要思想\n当出现字符串不匹配时,可以知道一部分之前已经匹配的内容,可以利用这些信息,避免从头匹配.\n原理\nnext数组\n本质上即为前缀表prefixtable\n\n用来回退.记录了模式串与主串不匹配的时候,模式串应该从哪里开始重新匹配.\n\n\n但是实现上也可以采用前缀表统一减一\n\n生成\n\n记录下标i之前（包括i）的字符串中，有多大长度的相同前后缀\n\n\n\n                  \n                  最长公共前后缀 \n                  \n                \n\n前缀:不包含最后一个字符的,所有以第一个字符开头的连续字串.\n后缀:不包含第一个字符的,所有以最后一个字符结尾的连续子串.\n\n\n\n前后缀相等（KMP的逻辑）： A B C … A B C （平移重复，同向）\n\n对于下标0: 单独一个’a’ 最长公共前后缀是0(因为计算公共前后缀是不包括第一个/最后一个的)\n对于下标1: ‘aa’ 最长公共前后缀是1\n对于下标2: ‘aab’最长公共前后缀是0\n\n使用\n使用前缀表的情况下: 找到不匹配的位置,那么去看它的前一个字符对应前缀表的数值是多少. 前往前面字符串的最大公共后缀的前一个位置重新匹配\n用next数组的情况下: 前往前面字符串的最大公共后缀的开头重新匹配\n\n实现\n\n单独生成next数组，时间复杂度是O(m)\n根据前缀表不断调整匹配的位置O(n)\n所以整个KMP算法的时间复杂度是O(n+m)\n\n构造next数组\n是针对模式串[即目标字符串]做的准备\n\n初始化\n\nj指向前缀末尾位置,i指向后缀末尾位置\n初始化next[0]-[可以让j=-1,然后next[0]=j,之后检索都用next[j+1]]\n\n\n处理前后缀不相同的情况\n\n下标i从1开始遍历,如果 s[i] 和 s[j+1] 不匹配，我们想找一个更短的前缀，这个前缀刚好也是当前 i 之前的后缀。\n因为next数组里面记录着以下标结尾的字串的相同前后缀长度.\n当我们从一个较长的匹配（L）回退到一个较短的匹配（X）时，X 的下一个字符可能依然无法满足当前的匹配需求。 因此这里要用for,直到下一个字符能匹配为止\naabaa 这时候j+1=2指向b,i指向新来的字符,如果是a那么匹配失败[aab!=aaa]\nj=next[j]=next[1]=1,从这个位置开始重新匹配,这样就可以aabaaa 把第二个a和最后一个a匹配起来.\n\n\n\n\n\n                  \n                  思考过程 \n                  \n                \n\nQ: 为什么j=next[j]就能达到这样的效果?next[j]里面放的是0j这个字符串的最大公共前后缀,为什么能对0i的这个字符串起到一个回退的作用?我觉得应该是看next[i-1] 发现前面这个字符串里面最大前后缀是1,然后新来了一个没匹配上,本来最大前后缀应该是2的,所以2-1=1 ,让前缀从这个1的地方开始重新匹配.\n\n\n\nS：主字符串（0 ~ i-1）。\nL：S 的最长公共前后缀（即 next[i-1] 对应的串）。\nX：S 的次长公共前后缀（我们需要找的目标）。\n需要证明的是：X 一定是 L 的最长公共前后缀。\n实际上是把L切成了两部分,前缀放到S的最前面,后缀留在原地,然后x作为s的次长公共前后缀,就确实是L的最长公共前后缀\n\n\n处理前后缀相同的情况\n\n如果 s[i] 与 s[j + 1] 相同，那么就同时向后移动i 和j 说明找到了相同的前后缀，同时还要将j（前缀的长度）赋给next[i]记录下来\n\n\n\n做匹配\n\n下标j指向模式串起始位置,i指向文本串起始位置.j初始值依然为-1[用-1表示起始/空状态]\ni在文本串中不断进行遍历,并且s[i]和s[j+1]作比较.\n\n如果不同,j就从next数组里寻找下一个匹配的位置(如果j在开头,就不动)\n如果相同,那么ij同时向后移动\n\n\n如果j指向了模式串的末尾,那么就说明模式串t完全匹配文本串s里的某子串了\n\n\n实际上i是一直往下走的,只有j一直在调整位置变换到(假设当前是文本串中的模式串,那么为了继续往下遍历, 应该处在哪个下标处)\n\n代码\n暴力解\n \nfunc strStr(haystack string, needle string) int {\n    l1:=len(haystack)\n    l2:=len(needle)\n    if l2==0{\n        return 0\n    }\n    if l1==0||l1&lt;l2{\n        return -1\n    }\n    for i:0=;i&lt;=l1-l2;i++{\n        if haystack[i:i+l2]==needle{\n            return i\n        }\n    }\n    return -1\n}\nkmp\nfunc strStr(haystack string, needle string) int {\n    if len(needle) == 0{\n        return 0\n    }\n    next:=make([]int,len(needle))\n    getNext(next, needle)\n    j:=-1\n    for i := 0; i &lt; len(haystack); i++ {\n\t\tfor j &gt;= 0 &amp;&amp; haystack[i] != needle[j+1] {\n\t\t\tj = next[j]     // 寻找下一个匹配点\n\t\t}\n\t\tif haystack[i] == needle[j+1] {\n\t\t\tj++\n\t\t}\n\t\tif j == len(needle)-1 {      // j指向了模式串的末尾\n\t\t\treturn i - len(needle) + 1\n\t\t}\n\t}\n    return -1\n}\n \n \nfunc getNext(next []int, s string){\n    j:=-1\n    next[0]=j\n    for i:=1;i&lt;len(next);i++{\n        for j&gt;=0&amp;&amp;s[i]!=s[j+1]{\n            j=next[j]\n        }\n        if s[i]==s[j+1]{\n            j++\n        }\n        next[i]=j\n    }\n}"},"技术积累/算法思想/hot100题解/121.-买卖股票的最佳时机":{"slug":"技术积累/算法思想/hot100题解/121.-买卖股票的最佳时机","filePath":"技术积累/算法思想/hot100题解/121. 买卖股票的最佳时机.md","title":"121. 买卖股票的最佳时机","links":[],"tags":[],"content":"给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。\n你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。\n返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。\n小记\n维护两个关键变量:\n\n记录从第一天到当前这一天为止,出现的最低价格(假设买入点)\n\n顺手记住的,所以只需要遍历一遍即可.\n\n\nans:记录到目前为止能获得的历史最大利润\n\n代码\nfunc maxProfit(prices []int) (ans int) {\n    minPrice := prices[0]\n    for _, p := range prices {\n        ans = max(ans, p-minPrice)\n        minPrice = min(minPrice, p)\n    }\n    return\n}"},"技术积累/算法思想/hot100题解/128.-最长连续序列":{"slug":"技术积累/算法思想/hot100题解/128.-最长连续序列","filePath":"技术积累/算法思想/hot100题解/128. 最长连续序列.md","title":"128. 最长连续序列","links":[],"tags":[],"content":"给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。\n请你设计并实现时间复杂度为 O(n) 的算法解决此问题。\n排序版O(N \\log N)\nfunc longestConsecutive(nums []int) int {\n    //直觉上:按顺序匹配出来放到新数组里面,但是可想而知时间复杂度应该很爆炸的\n    //先排序.然后快慢指针遍历?慢指针指向第一个连续,快指针一直遍历.如果遇到不连续的就把慢指针换过去从头开始计算.\n    slices.Sort(nums)\n    slow:=0\n    res:=0\n    cnt:=0\n    for fast,c:=range nums{\n        if fast&gt;0&amp;&amp;c!=nums[fast-1]&amp;&amp;c!=nums[fast-1]+1{\n            slow=fast\n        }\n        cnt=nums[fast]-nums[slow]+1\n        res=max(res,cnt)\n    }\n    return res\n}\nO(n)版\n小记\n\n用哈希表,可以自动去重\n从尾往前计算,如果对于x, x-1在哈希表中,那么说明x并不是连续序列的起点.\n小优化: 如果目前已有的连续序列已经大于剩下的不重复数字的个数了,那么说明没必要再往下找了\n\n代码\nfunc longestConsecutive(nums []int) (ans int) {\n    has := map[int]bool{}\n    for _, num := range nums {\n        has[num] = true // 把 nums 转成哈希集合\n    }\n \n    for x := range has { // 遍历哈希集合\n        if has[x-1] { // 如果 x 不是序列的起点，直接跳过\n            continue\n        }\n        // x 是序列的起点\n        y := x + 1\n        for has[y] { // 不断查找下一个数是否在哈希集合中\n            y++\n        }\n        // 循环结束后，y-1 是最后一个在哈希集合中的数\n        ans = max(ans, y-x) // 从 x 到 y-1 一共 y-x 个数\n    }\n    return\n}\n "},"技术积累/算法思想/hot100题解/21.-合并两个有序链表":{"slug":"技术积累/算法思想/hot100题解/21.-合并两个有序链表","filePath":"技术积累/算法思想/hot100题解/21. 合并两个有序链表.md","title":"21. 合并两个有序链表","links":[],"tags":[],"content":"将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n小记\n\n最好画图看一下指针怎么变吧\n头节点真好用\n注意最后返回值,总之要思路清晰了再写不要乱写了\n\n代码\nfunc mergeTwoLists(list1, list2 *ListNode) *ListNode {\n    dummy := ListNode{} // 用哨兵节点简化代码逻辑\n    cur := &amp;dummy // cur 指向新链表的末尾\n    for list1 != nil &amp;&amp; list2 != nil {\n        if list1.Val &lt; list2.Val {\n            cur.Next = list1 // 把 list1 加到新链表中\n            list1 = list1.Next\n        } else { // 注：相等的情况加哪个节点都是可以的\n            cur.Next = list2 // 把 list2 加到新链表中\n            list2 = list2.Next\n        }\n        cur = cur.Next\n    }\n    // 拼接剩余链表\n    if list1 != nil {\n        cur.Next = list1\n    } else {\n        cur.Next = list2\n    }\n    return dummy.Next\n}"},"技术积累/算法思想/hot100题解/215.-数组中的第K个最大元素":{"slug":"技术积累/算法思想/hot100题解/215.-数组中的第K个最大元素","filePath":"技术积累/算法思想/hot100题解/215. 数组中的第K个最大元素.md","title":"215. 数组中的第K个最大元素","links":["技术积累/算法思想/排序算法"],"tags":[],"content":"给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。\n请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。\n你必须设计并实现时间复杂度为 O(n) 的算法解决此问题。\n小记\nTransclude of 排序算法#快速选择思路\n代码\nTransclude of 排序算法#代码"},"技术积累/算法思想/hot100题解/5.-最长回文子串":{"slug":"技术积累/算法思想/hot100题解/5.-最长回文子串","filePath":"技术积累/算法思想/hot100题解/5. 最长回文子串.md","title":"5. 最长回文子串","links":[],"tags":[],"content":"给你一个字符串 s，找到 s 中最长的 回文 子串。\n小记\n\n关键是枚举回文子串的中心。\n\n然后从该中心触发,分奇数和偶数两种情况讨论即可\n在左右相等时,持续扩散,直到数组边界\n\n\n\n代码\nfunc longestPalindrome(s string) string {\n    n:=len(s)\n    ans:=0\n    resl:=-1\n    resr:=n\n    for i,_:=range s{\n        l,r:=i,i\n        for l&gt;=0&amp;&amp;r&lt;n&amp;&amp;s[l]==s[r]{\n            ans=max(ans,r-l+1)\n            if ans==r-l+1{\n                resl=l\n                resr=r\n            }\n            l--\n            r++\n        }\n \n        l,r=i,i+1\n        for l&gt;=0&amp;&amp;r&lt;n&amp;&amp;s[l]==s[r]{\n            ans=max(ans,r-l+1)\n            if ans==r-l+1{\n                resl=l\n                resr=r\n            }\n            l--\n            r++\n        }\n    }\n    return s[resl:resr+1]\n \n}\n拓展:manacher算法\n\n在空隙插入符号,统一奇数偶数的情况\n记录目前发现的右边最远的回文串的中心点,以及他的右边界.\n这个中心点视作镜子,那么左右两边的回文串可以只算一次\n"},"技术积累/算法思想/hot100题解/53.-最大子数组和":{"slug":"技术积累/算法思想/hot100题解/53.-最大子数组和","filePath":"技术积累/算法思想/hot100题解/53. 最大子数组和.md","title":"53. 最大子数组和","links":[],"tags":[],"content":"给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组是数组中的一个连续部分(非空元素序列)\n前缀和\n小记\n\n题目要求子数组不能为空，应当先计算前缀和-最小前缀和，再更新最小前缀和。相当于不能在同一天买入股票又卖出股票。\n而且实际上前缀和并不需要维护整个前缀和数组\n\n代码\nfunc maxSubArray(nums []int) int {\n    ans := math.MinInt\n    minPreSum := 0\n    preSum := 0\n    for _, x := range nums {\n        preSum += x // 当前的前缀和\n        ans = max(ans, preSum-minPreSum)   // 减去前缀和的最小值\n        minPreSum = min(minPreSum, preSum) // 维护前缀和的最小值\n    }\n    return ans\n}\n \n动态规划\n小记\nf[i] 代表：如果必须以第 i 个人作为终点，这一队人能凑出的最大数值是多少？\nf[i] = \\max(f[i-1], 0) + nums[i]\n代码\nfunc maxSubArray(nums []int) int {\n    ans := math.MinInt // 注意答案可以是负数，不能初始化成 0\n    f := 0\n    for _, x := range nums {\n        f = max(f, 0) + x\n        ans = max(ans, f)\n    }\n    return ans\n}\n "},"技术积累/算法思想/hot100题解/56.-合并区间":{"slug":"技术积累/算法思想/hot100题解/56.-合并区间","filePath":"技术积累/算法思想/hot100题解/56. 合并区间.md","title":"56. 合并区间","links":[],"tags":[],"content":"以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 \\一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间。\n小记\n\n先对每个区间的左端点进行排序,这样可以保证,如果下一个区间不能和当前区间合并,说明当前区间确实合并完毕了,可以以下一个数组为开头元素往下合并.\n合并逻辑:当sj落在第一个区间内,那么两个区间就可以合并,→[si,max(ei,ej)]\n实际上合并的过程是在答案数组中完成的,如果合并就更新,无法合并就把新的开头元素加进去,等待后续更新.\n\n代码\nfunc merge(intervals [][]int) (ans [][]int) {\n    slices.SortFunc(intervals, func(p, q []int) int { return p[0] - q[0] }) // 按照左端点从小到大排序\n    for _, p := range intervals {\n        m := len(ans)\n        if m &gt; 0 &amp;&amp; p[0] &lt;= ans[m-1][1] { // 可以合并\n            ans[m-1][1] = max(ans[m-1][1], p[1]) // 更新右端点最大值\n        } else { // 不相交，无法合并\n            ans = append(ans, p) // 新的合并区间\n        }\n    }\n    return\n}"},"技术积累/算法思想/hot100题解/72.-编辑距离":{"slug":"技术积累/算法思想/hot100题解/72.-编辑距离","filePath":"技术积累/算法思想/hot100题解/72. 编辑距离.md","title":"72. 编辑距离","links":[],"tags":[],"content":"给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数_\n你可以对一个单词进行如下三种操作：\n\n插入一个字符\n删除一个字符\n替换一个字符\n\n小记\n代码\n "},"技术积累/算法思想/hot100题解/动态规划/70.-爬楼梯":{"slug":"技术积累/算法思想/hot100题解/动态规划/70.-爬楼梯","filePath":"技术积累/算法思想/hot100题解/动态规划/70. 爬楼梯.md","title":"70. 爬楼梯","links":["技术积累/算法思想/动态规划-贪心算法"],"tags":[],"content":"假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\nTransclude of 动态规划-贪心算法#动态规划思路\n代码\n//易读版\nfunc climbStairs(n int) int {\n    if n == 1 {\n        return 1 // 特殊处理\n    }\n    f:=make([]int,n+1)\n    f[1],f[2]=1,2\n    for i:=3;i&lt;=n;i++{\n        f[i]=f[i-1]+f[i-2]\n    }\n    return f[n]\n}\n \n//不易读版\nfunc climbStairs(n int) int {\n    // 定义 dp 数组（这里叫 f）\n    f := make([]int, n+1)\n    // 初始化边界\n    f[0], f[1] = 1, 1//其实这个f[0]=1是很不好解释的,但是出于结果驱动还是=1吧\n    for i := 2; i &lt;= n; i++ {\n        f[i] = f[i-1] + f[i-2]\n    }\n    return f[n]\n}\n \n \n//空间优化版\nfunc climbStairs(n int) int {\n    p, q := 1, 1 // p是前两步，q是前一步\n    for i := 2; i &lt;= n; i++ {\n        p, q = q, p+q // 滚动更新\n    }\n    return q\n}"},"技术积累/算法思想/hot100题解/双指针/11.-盛最多水的容器":{"slug":"技术积累/算法思想/hot100题解/双指针/11.-盛最多水的容器","filePath":"技术积累/算法思想/hot100题解/双指针/11. 盛最多水的容器.md","title":"11. 盛最多水的容器","links":["技术积累/算法思想/hot100题解/双指针/42.-接雨水"],"tags":["盲过"],"content":"给定一个长度为 n 的整数数组 height 。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i]) 。\n找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。\n返回容器可以储存的最大水量。\n**说明：**你不能倾斜容器。\n\n其实思路跟42. 接雨水一模一样,没啥好说了\nfunc maxArea(height []int) (ans int) {\n    left, right := 0, len(height)-1\n    for left &lt; right {\n        area := (right - left) * min(height[left], height[right])\n        ans = max(ans, area)\n        if height[left] &lt; height[right] {\n            // height[left] 与右边的任意垂线都无法组成一个比 ans 更大的面积\n            left++\n        } else {\n            // height[right] 与左边的任意垂线都无法组成一个比 ans 更大的面积\n            right--\n        }\n    }\n    return\n}\n "},"技术积累/算法思想/hot100题解/双指针/42.-接雨水":{"slug":"技术积累/算法思想/hot100题解/双指针/42.-接雨水","filePath":"技术积累/算法思想/hot100题解/双指针/42. 接雨水.md","title":"42. 接雨水","links":[],"tags":[],"content":"接雨水\n给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n就是左右两边柱子最大值的最小值,减去当前位置柱子的高度,即为当前位置能接的雨水数量.\n\n遍历三遍数组\n需要三个额外的数组\n\n优化:\n只遍历一遍,不用额外数组\n\n初始化LR两个指针指向数组头和数组尾.\n当maxL⇐maxR.因为maxL是从左到右递增,maxR从右到左递增.所以说明L指向的位置,左右两边最小值就是maxL.因为area[i]是在maxL和maxR中取最小值嘛.然后减去柱子的高度可以直接得到雨水数量,再L++\n如果大于就反过来.\nfunc trap(height []int) (ans int) {\n    preMax, sufMax := 0, 0\n    left, right := 0, len(height)-1\n    for left &lt; right {//如果left=right 因为max是把当前的柱长计算在内,最后left\\right会相遇到场上最高点的.\n        preMax = max(preMax, height[left])\n        sufMax = max(sufMax, height[right])\n        if preMax &lt; sufMax {\n            ans += preMax - height[left]\n            left++\n        } else {\n            ans += sufMax - height[right]\n            right--\n        }\n    }\n    return\n}\n "},"技术积累/算法思想/hot100题解/图论/200.-岛屿数量":{"slug":"技术积累/算法思想/hot100题解/图论/200.-岛屿数量","filePath":"技术积累/算法思想/hot100题解/图论/200. 岛屿数量.md","title":"200. 岛屿数量","links":[],"tags":[],"content":"给你一个由 &#039;1&#039;（陆地）和 &#039;0&#039;（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n小记\n\n深度优先搜索.\n\n一旦我们发现 (i,j) 是 1，就从 (i,j) 开始，DFS 这个岛.主要是不能重复访问之前访问过的格子。\n找到一个岛(1)就开始左右上下四个方向走,直到全岛插满旗子(2)\n\n未发现的陆地格子:变2\n出界/水/已发现的陆地,就停止递归.\n\n\n\n如果都没有1了算法就结束了,返回岛屿个数\n为什么用图论思想?\ngrid中每个格子是一个节点,上下左右相邻说明存在边.所以题目就变换为寻找连通分量的总个数.\n\n\n\n代码\n注意二维数组的行列索引\nfunc numIslands(grid [][]byte) int {\n    m,n:=len(grid)-1,len(grid[0])-1\n    ans:=0\n    var dfs func(int ,int )\n    dfs =func(i,j int){\n        if i&lt;0||i&gt;m||j&lt;0||j&gt;n||grid[i][j]==&#039;0&#039;||grid[i][j]==&#039;2&#039;{\n            return \n        }\n        grid[i][j]=&#039;2&#039;\n        dfs(i,j-1)\n        dfs(i,j+1)\n        dfs(i-1,j)\n        dfs(i+1,j)\n    }\n \n    for i,row:=range grid{\n        for j,c:=range row{\n            if c==&#039;1&#039;{\n                dfs(i,j)\n                ans++\n            }\n        }\n    }\n    return ans\n}\n \n "},"技术积累/算法思想/hot100题解/图论/ACM模式输出":{"slug":"技术积累/算法思想/hot100题解/图论/ACM模式输出","filePath":"技术积累/算法思想/hot100题解/图论/ACM模式输出.md","title":"ACM模式输出","links":[],"tags":[],"content":""},"技术积累/算法思想/hot100题解/图论/图":{"slug":"技术积累/算法思想/hot100题解/图论/图","filePath":"技术积累/算法思想/hot100题解/图论/图.md","title":"图","links":[],"tags":[],"content":"图的基本概念\n二维坐标中，两点可以连成线，多个点连成的线就构成了图。\n当然图也可以就一个节点，甚至没有节点（空图\n图的种类\n整体上一般分为 有向图 和 无向图。\n有向图: 边是有方向的\n无向图: 边没有方向\n加权有向图: 就是边是有权值的\n加权无向图同理\n度\n无向图:\n\n有几条边连接该节点，该节点就有几度。\n有向图:\n每个节点有出度和入度。\n\n出度：从该节点出发的边的个数。\n入度：指向该节点边的个数。\n\n\n\n连通性\n\n连通图: 在无向图中,任何两个节点都是可以到达的,我们称之为连通图\n非连通图: 有节点不能到达其他节点\n强连通图: 在有向图中，任何两个节点是可以相互到达的\n连通分量: 无向图中的极大连通子图\n强连通分量: 有向图中极大强连通子图\n\n图的构造-如何用代码表示一个图\n朴素存储\n\n有8条边，我们就定义 8 * 2的数组，即有n条边就申请n * 2，这么大的数组.然后将每两个节点的关系记录到表中.\n可以用数组\\map\\类实现,但是如果想知道不相邻的两个节点是否相连,就必须要把存储空间都枚举一遍.\n\n邻接表\n数组+链表,是从边的数量来表示图,有多少边就申请对应大小的链表.\n\n\n利于稀疏图的存储,因为只需要存储边,空间利用率高\n遍历节点连接情况相对容易\n然是如果检查任意两个节点间是否存在边,效率就比较低,需要O(v)时间:V表示某节点连接其他节点的数量\n\n邻接矩阵\n使用二维数组来表示图结构,有多少节点就申请多大的二维数组\n例如： grid[2][5] = 6，表示 节点 2 连接 节点5 为有向图，节点2 指向 节点5，边的权值为6\n想表示无向图，即：grid[2][5] = 6，grid[5][2] = 6，表示节点2 与 节点5 相互连通，权值为6。\n\n\n适合稠密图(边数接近顶点数平方).在边少节点多的情况下会导致申请过大的二维数组,造成空间浪费.\n在寻找节点连接情况的时候,需要遍历整个矩阵(n平方).\n检查任意两个顶点之间是否存在边的操作非常快\n\n图的遍历方式\n深度优先搜索dfs\n递归深度达到最大:\n\n递归深度:“当前还没结束的函数调用数量”\n递归深度最深的情况，就是一条路走到黑，完全不回头，也不分叉\n\n广度优先搜索bfs"},"技术积累/算法思想/hot100题解/滑动窗口与前缀和/3.-无重复字符的最长子串":{"slug":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/3.-无重复字符的最长子串","filePath":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/3. 无重复字符的最长子串.md","title":"3. 无重复字符的最长子串","links":["技术积累/算法思想/字符串处理"],"tags":["盲过"],"content":"给定一个字符串 s ，请你找出其中不含有重复字符的 最长 子串 的长度\n小记\n\n滑动窗口思想\n重复字符:记录频率\nTransclude of 字符串处理#range与下标\n\n代码\nfunc lengthOfLongestSubstring(s string) int {\n    //不含有重复字符:一个数组来记录字符出现的频率,.如果新进来的这个数=2了,就缩小左边直到这个数前面那个重复的数出去,2-1=1.确保整个数组内没有重复元素的时候可以记录最大值ans.\n    cnt:=[128]int{}\n    left:=0\n    ans:=0\n    for i,c:=range s{\n        cnt[c]++\n        for cnt[c]&gt;1{\n            cnt[s[left]]--\n            left++\n        }\n        ans = max(ans, i-left+1)\n    } \n    return ans\n}"},"技术积累/算法思想/hot100题解/滑动窗口与前缀和/560.-和为K的子数组":{"slug":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/560.-和为K的子数组","filePath":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/560. 和为K的子数组.md","title":"560. 和为K的子数组","links":["技术积累/算法思想/n数之和"],"tags":[],"content":"给你一个整数数组 nums 和一个整数 k ，请你统计并返回该数组中和为 k 的子数组的个数。\n子数组是数组中元素的连续非空序列。\n小记\n\n使用n数之和的思想.\n\n当遍历到当前位置 j 时，前缀和是 s[j]。如果前面有个位置 i 的前缀和是 s[j] - k，那就说明中间这一段的和正好是 k。[target]\n\n\n查找前面有没有一个数=target,使用哈希表是最快的.\n\n代码\nfunc subarraySum(nums []int, k int) int {\n    // Key: 前缀和的值, Value: 这个前缀和出现的次数\n    // 预分配内存，避免map扩容，长度设为len(nums)+1\n    mp := make(map[int]int, len(nums)+1)\n    \n    //需要这个0存在。哈希表中存储的是index前缀和出现的次数\n    mp[0] = 1\n    \n    count := 0 // 记录最终答案\n    pre := 0   // 记录当前的前缀和\n    //如果当前前缀和直接等于 `k` (比如 `s[j]=2, k=2`)，我们需要找 `2-2=0`。如果不存 `0`，就会漏掉从头开始的子数组。\n    for _, x := range nums {\n        pre += x // 1. 更新当前前缀和\n        \n        // 2. 查表：看看前面有没有 前缀和 = (pre - k)\n        // 如果有，说明这两段前缀和的差值正好是 k.注意这里的写法\n        if c, ok := mp[pre-k]; ok {\n            count += c//因为重复也会被计入\n        }\n        // 3. 存表：把当前的前缀和记录下来，供后面查询\n        mp[pre]++\n    }\n    \n    return count\n}"},"技术积累/算法思想/hot100题解/滑动窗口与前缀和/滑动窗口与前缀和":{"slug":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/滑动窗口与前缀和","filePath":"技术积累/算法思想/hot100题解/滑动窗口与前缀和/滑动窗口与前缀和.md","title":"滑动窗口与前缀和","links":[],"tags":[],"content":"变长滑动窗口\n\n注意使用数组元素都是正数的性质\n\n右指针往右移 \\rightarrow 窗口内和一定变大。\n左指针往右移 \\rightarrow 窗口内和一定变小。\n\n\n如果题目中出现负数,则无法使用滑动窗口\n空间复杂度O(1)\n\n前缀和\n通常配合哈希表,通过数学差值计算解决问题,不依赖单调性(正负数均可)\n需要额外空间存储前缀信息:静态预处理\n定长滑动窗口\n正负数均可.\n空间复杂度O(1)"},"技术积累/算法思想/n数之和":{"slug":"技术积累/算法思想/n数之和","filePath":"技术积累/算法思想/n数之和.md","title":"n数之和","links":[],"tags":[],"content":"一个数组中不重复\n\n0 &lt;= a, b, c, d &lt; n\na、b、c 和 d 互不相同\nnums[a] + nums[b] + nums[c] + nums[d] == target\n\n\n\n保证数组有序.不有序就排一下序.\n需要保证a&lt;b&lt;c&lt;d,同时外层一个for循环把a固定住.\n内层for循环固定b,剩下c和d在[b+1,len(数组)]的范围内进行双指针即可.[二者相加结果为target-nums[a]-nums[b]]\n\n\n\n\n                  \n                  语法细节 \n                  \n                \n\n\n注意找到一组解之后不能停止,要一直循环到c&lt;d的临界\n注意去重.如果不允许重复的元组,那么就要用for a &gt; 0 &amp;&amp; nums[a] == nums[a-1] { continue }这种写法去重.\n\n注意这里一定要是for,就是去重到无重为止.//或者用ifcontinue,跳出当次循环,重新走一遍for的条件判断.\n\n\n小优化:如果在固定ab的时候,如果最小的abc和最大的d加起来就&gt;target的话,d就可以直接—.类似这样的技巧如果内存要求严格的话可以用\n\n\n"},"技术积累/算法思想/二分查找":{"slug":"技术积累/算法思想/二分查找","filePath":"技术积累/算法思想/二分查找.md","title":"二分查找","links":[],"tags":[],"content":"\n数组下标都是从0开始的。\n数组内存空间的地址是连续的\n数组的元素是不能删的，只能覆盖。\n\n二分查找\n搜索的区间是左闭右闭还是左闭右开还是全开\n这个是一个原则,在后面的区间处理中要贯彻.区间是一个不变量\n\n在区间为空后再进行返回,可以找第一个等于target的数的下标,泛用性更强.\n返回值=目标的下标,找不到就返回数组长度\n暴力做法遍历,时间是on的时间复杂度\n二分查找利用了数组有序的性质\n\n// 【下面列了三种写法，选一种自己喜欢的就行】\n \n// lowerBound 返回最小的满足 nums[i] &gt;= target 的 i\n// 如果数组为空，或者所有数都 &lt; target，则返回 nums.length\n// 要求 nums 是非递减的，即 nums[i] &lt;= nums[i + 1]\n \n// 闭区间写法\nfunc lowerBound(nums []int, target int) int {\n    left, right := 0, len(nums)-1 // 闭区间 [left, right]\n    for left &lt;= right {           // 区间不为空\n \n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid + 1 // 范围缩小到 [mid+1, right]\n        } else {\n            right = mid - 1 // 范围缩小到 [left, mid-1]//这里right一定要-1 反正最后是返回left的值,不会存在正好错过target的情况\n        }\n    }//最后一步应该是L=R的时候,发现num[mid]&gt;=target,那么right-1\n    //没找到就是L=R的时候num[mid]&lt;target,那么left+1\n    return left // 或者 right+1///循环结束时,一定是left=right+1,违背while循环条件,那么返回left,就会是target的下标.\n}\n//如果所有元素都比8小,那么left回一直向右移动,最后就会返回整个数组的长度(R的右边也就是下标+1=数组长度)\n \n// 左闭右开区间写法\nfunc lowerBound2(nums []int, target int) int {\n    left, right := 0, len(nums) // 左闭右开区间 [left, right)\n    for left &lt; right {          // 区间不为空\n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid + 1 // 范围缩小到 [mid+1, right)\n        } else {\n            right = mid // 范围缩小到 [left, mid)\n        }\n    }\n    return left // 或者 right\n}\n \n// 开区间写法[推荐!]\nfunc lowerBound3(nums []int, target int) int {\n    left, right := -1, len(nums) // 开区间 (left, right)\n    for left+1 &lt; right {         // 区间不为空\n        // 循环不变量：\n        // nums[left] &lt; target\n        // nums[right] &gt;= target\n        mid := left + (right-left)/2\n        if nums[mid] &lt; target {\n            left = mid // 范围缩小到 (mid, right)\n        } else {\n            right = mid // 范围缩小到 (left, mid)\n        }\n    }\n    return right // 或者 left+1\n}\n- **Left**：初始化为“一定满足条件的值”或者“最小边界 - 1”。\n- **Right**：初始化为“一定不满足条件的值”或者“最大边界 + 1”。\n \nfunc search(nums []int, target int) int {\n    i := lowerBound(nums, target) // 选择其中一种写法即可\n    if i == len(nums) || nums[i] != target {\n        return -1\n    }//排错逻辑:都比目标小,或者只有比目标大的数\n    return i\n}\n \n作者：灵茶山艾府\n链接：leetcode.cn/problems/binary-search/solutions/2023397/er-fen-cha-zhao-zong-shi-xie-bu-dui-yi-g-eplk/\n来源：力扣（LeetCode）\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\ntips\n为什么要写成 left + (right-left)/2 而不是 (left+right)/2？\n\n防止相加太大会溢出.跟计算顺序有关,最好先算相减的部分除2,得到一个比较小的结果,所以计算过程中永远不会产生超过right的值,是绝对安全的.[既然right都没有溢出,那么这个mid的值也不会溢出了]\ngo中用&gt;&gt;1来代替除2,因为位运算比除法运算更快,虽然go自己会进行优化,但是这样写显得比较专业吧\n\n\n\n                  \n                  有符号数的范围 \n                  \n                \n\n\n负数怎么理解?理解为,符号位代表-2的六十三次方,而数字位是加上对应正数.所以10000就是2的六十三次方,加的正数部分为0\n\n\n时间复杂度\n每次循环，查找范围都缩小一半。\n第 1 次循环：你比较了中间值，如果不匹配，你扔掉了一半。剩下 N/2 个元素。\n第 k 次循环：剩下 N / 2^k 个元素。\n什么时候结束？\n当剩下的元素只有 1 个（或者 0 个）时，循环结束。\n也就是说：\n\\frac{N}{2^k} = 1\nN = 2^k\n如果每次都对N除2 那么除干净的时候应该除了log2N次\n忽略底数（因为常数差异不影响增长量级)和一次计算中的时间部分，记作 O(\\log n)\n语法\nleft和right不能在循环里面重新定义,否则while的条件一直不变.\n而middle最好在循环里面定义,因为\n"},"技术积累/算法思想/二叉树/二叉树":{"slug":"技术积累/算法思想/二叉树/二叉树","filePath":"技术积累/算法思想/二叉树/二叉树.md","title":"二叉树","links":["技术积累/算法思想/栈与队列/递归"],"tags":[],"content":"二叉树的种类\n满二叉树\n只有度为0的结点和度为2的结点,而且度为0的结点在同一层上\n完全二叉树\n在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层（h从1开始），则该层包含 1~ 2^(h-1) 个节点。\n\n堆就是一棵完全二叉树\n二叉搜索树\n有序树.\n\n若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n它的左、右子树也分别为二叉搜索树\n\n\n平衡二叉搜索树\n又称作AVL树.\n它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\n\n二叉树的存储方式\n可以链式存储(指针),也可以顺序存储(数组)\n如果父节点的数组下标是 i，那么它的左孩子就是 i * 2 + 1，右孩子就是 i * 2 + 2\n遍历方式\n深度优先遍历\n先往深处走,遇到叶子节点再往回走\n这里的前中后指的是中间节点的遍历顺序\n前序遍历: 递归/迭代法    中左右\n中序遍历: 递归/迭代法    左中右\n后序遍历: 递归/迭代法    左右中\n用递归比较方便.同时,栈其实是递归的一种实现结构,因此前中后序遍历是可以用栈实现的.\n广度优先遍历\n层次遍历: 迭代法\n一般用队列来实现,因为队列是先进先出的,这样才能一层一层地遍历二叉树\n具体实现\ntype TreeNode struct {\n    Val int\n    Left *TreeNode\n    Right *TreeNode\n}\n递归遍历\nTransclude of 递归#递归算法三要素\n\n参数应该是子树的根节点.首先这个递归函数是得作用在一整棵树上的.然后再递归去对各个子树做操作.而结果数组不需要经过传递.\n最终到子树的叶子节点,node==nil的时候就返回,也不需要加入res数组\n\n\nfunc preorderTraversal(root *TreeNode) (res []int) {\n    var traversal func(node *TreeNode)//声明递归函数变量\n    traversal = func(node *TreeNode) {//给变量赋值\n\t//base case\n\tif node == nil {\n            return\n\t}\n\t\n\tres = append(res,node.Val)//把中(也就是自己)放进篮子\n\ttraversal(node.Left)//左递归\n\ttraversal(node.Right)//右递归\n    }\n    traversal(root)//使用递归函数\n    return res\n}\n \n迭代遍历\nTransclude of 递归#递归的实现\n因此直接用栈也可以实现深度优先遍历.\n前序遍历\n前序遍历是中左右.因此每次先将根节点放入栈中,然后将右节点加入栈,再加入左节点.这样出栈的时候是中左右的顺序\n中序遍历\n统一迭代法\n层序遍历"},"技术积累/算法思想/二叉树/对称二叉树":{"slug":"技术积累/算法思想/二叉树/对称二叉树","filePath":"技术积累/算法思想/二叉树/对称二叉树.md","title":"对称二叉树","links":[],"tags":[],"content":""},"技术积累/算法思想/二叉树/翻转二叉树":{"slug":"技术积累/算法思想/二叉树/翻转二叉树","filePath":"技术积累/算法思想/二叉树/翻转二叉树.md","title":"翻转二叉树","links":[],"tags":[],"content":""},"技术积累/算法思想/动态规划-贪心算法":{"slug":"技术积累/算法思想/动态规划-贪心算法","filePath":"技术积累/算法思想/动态规划-贪心算法.md","title":"动态规划-贪心算法","links":["技术积累/算法思想/hot100题解/动态规划/70.-爬楼梯"],"tags":[],"content":"贪心算法\n\n贪心算法在每一步选择中，都采取在当前状态下最好、最优的选择（局部最优解）从而希望最终的结果也是全局最优的。\n只有当问题具备“贪心选择性质”时（即局部最优确实能推导出全局最优）才能得到正确答案。否则，它只能得到一个“差不多”的解，而不是最优解。\n\n动态规划\n\n动态规划将一个复杂的问题分解成若干个重叠的子问题。通过解决子问题，并将结果记录下来（Memoization/填表）避免重复计算，最后推导出原问题的解。\n核心在于“记表”，算过的东西绝对不算第二次。\n\n动态规划思路\n以70. 爬楼梯为例:\n第一层楼梯跨两步可以到第三层,第二层跨一步可以到第三层,因此,第三层楼梯的状态可以由前两层推导出来.也就是动态规划了.\n\n确定dp数组以及下标的含义:  爬到i层楼梯,有dp[i]种方法\n确定递推公式:  dp[i] = dp[i - 1] + dp[i - 2]\ndp数组如何初始化:  dp[1] = 1，dp[2] = 2.因为这题里n为正整数,因此不要考虑n=0的情况,反正也不符合生活实际\n确定遍历顺序:  从递推公式可以看出递推顺序一定是从前往后的\n举例推导dp数组: 就是检查一下\n"},"技术积累/算法思想/字符串处理":{"slug":"技术积累/算法思想/字符串处理","filePath":"技术积累/算法思想/字符串处理.md","title":"字符串处理","links":[],"tags":[],"content":"rune与byte与string\n\n&#039;a&#039; (单引号)：字符（Go 里叫 rune，本质是整数 `int32\n\nint32，有 32 位，最大能表示几十亿,会根据字符串里的元素自动匹配要表示什么.比如”an按”会解析出3个rune:a\\n\\按\n\n\n&quot;a&quot; (双引号：字符串`string\nbyte\n\n只有 8 位，最大只能表示到 255。英文字符（ASCII）比如 &#039;a&#039; 是 97，能装下。但汉字 &#039;按&#039; 的编号是 25353，一般是3个byte。\n\n\n\n\n\n                  \n                  Title \n                  \n                \n\n‘a’虽然被认为是rune,但是实际上属于无类型常量 (Untyped Constant).参与运算时自动适配对方类型。\n\n\nrange与下标\n字符串本质是只读的byte切片.如果要修改,一定要转换成真正的byte切片.[]byte(s),然后string(cnt)变回字符串\n\n如果是纯英文,数字,英文符号,字符串里的每一个byte都完全对应ASCII码\n如果是中文,emoji等非ASCII码字符,一个汉字在 UTF-8 编码中通常占用 3 个 byte.这时候要改用rune\n\n\nrange循环得到的是rune.\n\n因此如果字符串中有中文,遍历下标其实是跳跃的.\nfor i := 0; i &lt; len(s); i++循环得到的是byte,因为就是按照原字符串的byte切片下标来的.\n\n\n下标.s[0]默认拿出来的是字节.\n\n如果想要拿出来中文字符,需要runes := []rune(s)转换成rune切片,然后用下标拿取.\n\n\n\n哈希表\n//rune作为key\nm := map[rune]int{}\nm[&#039;a&#039;]=1\nm[&#039;某个表情符号&#039;]=2\n \n//byte作为key\nm :=map[byte]int){}\nm[&#039;x&#039;] = 100//这里如果要写中文和表情符号就不行了,因为不符合byte\n数组填充类\n其实很多数组填充类的问题，其做法都是先预先给数组扩容带填充后的大小，然后在从后向前进行操作。"},"技术积累/算法思想/排序算法":{"slug":"技术积累/算法思想/排序算法","filePath":"技术积累/算法思想/排序算法.md","title":"排序算法","links":["技术积累/算法思想/排序算法","tags/待解决"],"tags":["待解决"],"content":"快速选择quick select\n核心目的: 解决 Top K 问题，并且要做到 O(N) 的时间复杂度\n快速选择思路\nTransclude of 排序算法#快速排序思路\n而针对Top K问题,可以做如下优化.\n如果pivot&lt;K,那么不用进行左边递归,只需要进行右边递归即可.只处理一边，另一边直接忽略\n\n类似于二分，只要确定排序之后下标在n-k处的数据即可。\n主要是实现上的细节。循环的时候需要保证i⇐j 如果i&gt;j了会退出循环,i⇐j的时候进行交换,能够保证左边小右边大.\ni&gt;j的时候说明j到了小的这边,i到了大的那边,因此pivot跟nums[left]换一下位置就可以了.\n\n代码\n// 在子数组 [left, right] 中随机选择一个基准元素 pivot\n// 根据 pivot 重新排列子数组 [left, right]\n// 重新排列后，&lt;= pivot 的元素都在 pivot 的左侧，&gt;= pivot 的元素都在 pivot 的右侧\n// 返回 pivot 在重新排列后的 nums 中的下标\n// 特别地，如果子数组的所有元素都等于 pivot，我们会返回子数组的中心下标，避免退化\nfunc partition(nums []int, left int, right int) int {\n    // 1. 在子数组中随机选择一个下标，并换到最左边\n    i := left + rand.Intn(right-left+1)\n    pivot := nums[i]\n    // 把 pivot 与子数组第一个元素交换，避免 pivot 干扰后续划分，从而简化实现逻辑\n    nums[i], nums[left] = nums[left], nums[i]\n \n    // 2. 相向双指针遍历子数组 [left + 1, right]\n    // 循环不变量：在循环过程中，子数组的数据分布始终如下图\n    // [ pivot | &lt;=pivot | 尚未遍历 | &gt;=pivot ]\n    //   ^                 ^     ^         ^\n    //   left              i     j         right\n \n    i, j := left+1, right\n    for {\n        for i &lt;= j &amp;&amp; nums[i] &lt; pivot {\n            i++\n        }//i还没遇到j且i指向的元素小于pivot（不需要交换）的话就一直向右\n        // 此时 nums[i] &gt;= pivot：停下\n \n        for i &lt;= j &amp;&amp; nums[j] &gt; pivot {\n            j--\n        }\n        // 此时 nums[j] &lt;= pivot：停下\n \n        if i &gt;= j {\n            break\n        }\n \n        // 维持循环不变量\n        nums[i], nums[j] = nums[j], nums[i]\n        i++\n        j--\n    }\n \n    // 循环结束后\n    // [ pivot | &lt;=pivot | &gt;=pivot ]\n    //   ^             ^   ^     ^\n    //   left          j   i     right\n \n    // 3. 把 pivot 与 nums[j] 交换，完成划分（partition）\n    // 为什么与 j 交换？\n    // 如果与 i 交换，可能会出现 i = right + 1 的情况，已经下标越界了，无法交换\n    // 另一个原因是如果 nums[i] &gt; pivot，交换会导致一个大于 pivot 的数出现在子数组最左边，不是有效划分\n    // 与 j 交换，即使 j = left，交换也不会出错\n    nums[left], nums[j] = nums[j], nums[left]\n \n    // 交换后\n    // [ &lt;=pivot | pivot | &gt;=pivot ]\n    //               ^\n    //               j\n \n    // 返回 pivot 的下标\n    return j\n}\n \nfunc findKthLargest(nums []int, k int) int {\n    n := len(nums)\n    targetIndex := n - k  // 第 k 大元素在升序数组中的下标是 n - k\n    left, right := 0, n-1 // 闭区间\n    for {\n        i := partition(nums, left, right)\n        if i == targetIndex {\n            // 找到第 k 大元素\n            return nums[i]\n        }\n        if i &gt; targetIndex {\n            // 第 k 大元素在 [left, i - 1] 中\n            right = i - 1\n        } else {\n            // 第 k 大元素在 [i + 1, right] 中\n            left = i + 1\n        }\n    }\n}\n \n \n手写堆排序\n待解决\n手写快排\n待解决\n快速排序思路\n\n选定一个pivot,左边都是比它小的,右边都是比它大的,那么这个pivot的位置就固定正确了.\n然后到这个pivot的左边递归,右边也递归,重复上述操作.复杂度是 O(N \\log N)\n\n代码\nfunc QuickSort(nums, left, right) {\n    if left &gt;= right { return }\n    \n    // 1. 排好一个基准，拿到他的位置 pivotIndex\n    pivotIndex := partition(nums, left, right)\n    \n    // 2. 递归处理左边 (勤奋)\n    QuickSort(nums, left, pivotIndex - 1)\n    \n    // 3. 递归处理右边 (勤奋)\n    QuickSort(nums, pivotIndex + 1, right)\n}"},"技术积累/算法思想/栈与队列/对称匹配":{"slug":"技术积累/算法思想/栈与队列/对称匹配","filePath":"技术积累/算法思想/栈与队列/对称匹配.md","title":"对称匹配","links":[],"tags":[],"content":"由于栈结构的特殊性,非常适合做对称匹配类的题目\n不匹配的三种情况\n\n已经遍历完了字符串，但是栈不为空，说明有相应的左括号没有右括号来匹配，所以return false\n遍历字符串匹配的过程中，发现栈里没有要匹配的字符。所以return false\n遍历字符串匹配的过程中，栈已经为空了，没有匹配的字符了，说明右括号没有找到对应的左括号return false\n\n技巧:\n计算字符串长度如果是奇数那么一定不true\n在遇到左括号的时候把右括号入栈，那么下次遇到右括号就只需要比较当前元素和栈顶是否相等就可以了\nfunc isValid(s string) bool {\n    if len(s)%2 != 0 { // s 长度必须是偶数\n        return false\n    }\n    st := []rune{}\n    for _, c := range s {\n        switch c {\n        case &#039;(&#039;:\n            st = append(st, &#039;)&#039;) // 入栈对应的右括号\n        case &#039;[&#039;:\n            st = append(st, &#039;]&#039;)\n        case &#039;{&#039;:\n            st = append(st, &#039;}&#039;)\n        default: // c 是右括号\n            if len(st) == 0 || st[len(st)-1] != c {\n                return false // 没有左括号，或者左括号类型不对\n            }\n            st = st[:len(st)-1] // 出栈\n        }\n    }\n    return len(st) == 0 // 所有左括号必须匹配完毕\n}\n "},"技术积累/算法思想/栈与队列/栈与队列":{"slug":"技术积累/算法思想/栈与队列/栈与队列","filePath":"技术积累/算法思想/栈与队列/栈与队列.md","title":"栈与队列","links":[],"tags":[],"content":"\n\ngo 中没有名为Stack的容器, 一般直接用切片作为栈\n\n\nstack是如何实现的？\n\n实现：[]int (或其他类型的切片)。\nPush (入栈)：使用 append 函数。\nPop (出栈)：使用切片的截取操作\nTop (取栈顶)：直接索引 len(s)-1。\n\n\n\n// 这是一个 Go 语言实现栈的标准写法\nstack := make([]int, 0)\n \n// Push\nstack = append(stack, 1)\nstack = append(stack, 2)\n \n// Top (获取栈顶元素)\ntop := stack[len(stack)-1]\n \n// Pop (移除栈顶元素)\nstack = stack[:len(stack)-1]\n\n可以遍历stack空间么？\n栈的核心定义是后进先出,虽然说对于切片实现的栈可以用range去遍历,但是不建议,会破坏栈的封装性和逻辑定义.\n\n用两个栈实现先入先出队列\n\n输入栈 输入的时候放进来就好\n输出栈 输出的的时候,如果输出栈为空,就把进栈数据全部导入进来,再从出栈导入数据.\n如果输入栈和输出栈都为空,则说明模拟的队列为空\n\ntype MyQueue struct {\n    stackIn  *MyStack\n    stackOut *MyStack\n}\n \nfunc Constructor() MyQueue {\n    return MyQueue{\n      stackIn: &amp;MyStack{},\n      stackOut: &amp;MyStack{},\n    }\n}\n \n func (this *MyQueue) fillStackOut() {\n    if this.stackOut.Empty() {\n        for !this.stackIn.Empty(){\n            val:=this.stackIn.Pop()\n            this.stackOut.Push(val)\n        }\n    }\n }\n \nfunc (this *MyQueue) Push(x int)  {\n    this.stackIn.Push(x)\n}\n \n \nfunc (this *MyQueue) Pop() int {\n    this.fillStackOut()\n    return this.stackOut.Pop()\n}\n \n \nfunc (this *MyQueue) Peek() int {\n    this.fillStackOut()\n    return this.stackOut.Peek()\n}\n \n \nfunc (this *MyQueue) Empty() bool {\n    if this.stackIn.Empty()&amp;&amp;this.stackOut.Empty(){\n        return true\n    }\n    return false\n}\n \n \n/**\n * Your MyQueue object will be instantiated and called as such:\n * obj := Constructor();\n * obj.Push(x);\n * param_2 := obj.Pop();\n * param_3 := obj.Peek();\n * param_4 := obj.Empty();\n */\n type MyStack []int\n \n func (s *MyStack) Push(v int){\n    *s=append(*s,v)\n }\n \n func (s *MyStack) Pop() int {\n    val:=(*s)[len(*s)-1]\n    *s=(*s)[:len(*s)-1]\n    return val\n }\n \n \n func (s *MyStack) Peek()int{\n    return (*s)[len(*s)-1]\n }\n \n func (s *MyStack) Size() int {\n\treturn len(*s)\n}\n \n func (s *MyStack) Empty()bool{\n    return s.Size()==0\n }\n \n用一个队列实现栈\n先说两个队列实现栈的思路\n一个负责主要的进出栈,另外一个负责备份\nqueue.push(1);        \nqueue.push(2);        \nqueue.pop();   // 对栈来说这时候应该弹出2.如果只用一个队列来模拟的话,会弹出1.因此我们先把1放到另外一个队列,把2弹出之后再把1移回来.  \nqueue.push(3);        \nqueue.push(4);       \nqueue.pop();  // 注意弹出的操作    \nqueue.pop();    \nqueue.pop();    \nqueue.empty();    \ntype MyStack struct {\n    queue1 *MyQueue\n    queue2 *MyQueue\n}\n \n \nfunc Constructor() MyStack {\n    return MyStack{\n    queue1: &amp;MyQueue{},\n    queue2: &amp;MyQueue{},   \n    }\n}\n \n \nfunc (this *MyStack) Push(x int)  {\n    this.queue1.Push(x)\n}\n \nfunc (this *MyStack) fillQueue2(){\n    n:=this.queue1.Size()//这里必须单独捞出来,因为如果放在循环里面,每次进行条件比较的时候,都会重新计算一次size,但是pop会导致size变小,所以循环实际上只进行了一半\n    for i:=0;i&lt;n-1;i++{\n        val:=this.queue1.Pop()\n        this.queue2.Push(val)\n    }\n}\nfunc (this *MyStack) fillQueue1(){\n    n:=this.queue2.Size()\n    for i:=0;i&lt;n;i++{\n        val:=this.queue2.Pop()\n        this.queue1.Push(val)\n    }\n}\n \nfunc (this *MyStack) Pop() int {\n    this.fillQueue2()\n    val:=this.queue1.Pop()\n    this.fillQueue1()\n    return val\n}\n//实际上这里最后可以用交换指针的方法,不用再费劲倒回去.具体做法如下\nthis.queue1, this.queue2 = this.queue2, this.queue1\n \nfunc (this *MyStack) Top() int {\n    return this.queue1.Tail()\n}\n \n \nfunc (this *MyStack) Empty() bool {\n    return this.queue1.Empty()&amp;&amp;this.queue2.Empty()\n}\n \n \n/**\n * Your MyStack object will be instantiated and called as such:\n * obj := Constructor();\n * obj.Push(x);\n * param_2 := obj.Pop();\n * param_3 := obj.Top();\n * param_4 := obj.Empty();\n */\n \ntype MyQueue []int\n \nfunc (s *MyQueue) Push(v int){\n    (*s)=append(*s,v)\n}\n \nfunc (s *MyQueue) Pop() int{\n    val:=(*s)[0]\n    (*s)=(*s)[1:]\n    return val\n}\n \nfunc (s *MyQueue) Peek() int{\n    return (*s)[0]\n}\n \nfunc (s *MyQueue) Tail() int{\n    return (*s)[len(*s)-1]\n}\n \nfunc (s *MyQueue) Size() int{\n    return len(*s)\n}\nfunc (s *MyQueue) Empty() bool{\n    return s.Size()==0\n}\n其实还有另外一种写法,是push比较麻烦,pop比较简单的\ntype MyStack struct {\n    //创建两个队列\n    queue1 []int\n    queue2 []int\n}\n \n \nfunc Constructor() MyStack {\n    return MyStack{\t//初始化\n        queue1:make([]int,0),\n        queue2:make([]int,0),\n    }\n}\n \n \nfunc (this *MyStack) Push(x int)  {\n     //先将数据存在空的queue2中\n    this.queue2 = append(this.queue2,x)\t\n   //将queue1中所有元素移到queue2中，再将两个队列进行交换\n    this.Move() \n}\n \n//核心目的是,确保最新的元素永远排在第一个队列的最前面.也就是数组下标0处.用这个函数,queue1一直是栈的状态(先进先出.)\nfunc (this *MyStack) Move(){    \n    if len(this.queue1) == 0{\n        //交换，queue1置为queue2,queue2置为空\n        this.queue1,this.queue2 = this.queue2,this.queue1\n    }else{\n        //queue1元素从头开始一个一个追加到queue2中\n            this.queue2 = append(this.queue2,this.queue1[0])  \n            this.queue1 = this.queue1[1:]\t//去除第一个元素\n            this.Move()     //重复\n    }\n}\n \nfunc (this *MyStack) Pop() int {\n    val := this.queue1[0]\n    this.queue1 = this.queue1[1:]\t//去除第一个元素\n    return val\n \n}\n \n \nfunc (this *MyStack) Top() int {\n    return this.queue1[0]\t//直接返回\n}\n \n \nfunc (this *MyStack) Empty() bool {\nreturn len(this.queue1) == 0\n}\n优化:只用一个队列.\n对于队列而言.如果想要删掉最后进来的那个元素,只需要把前面的人全部拿出来重新排到队尾,然后把队列最前面的元素[也就是栈顶]弹出即可.妙哉妙哉..\ntype MyStack struct {\n    queue []int//创建一个队列\n}\n \n \n/** Initialize your data structure here. */\nfunc Constructor() MyStack {\n    return MyStack{   //初始化\n        queue:make([]int,0),\n    }\n}\n \n \n/** Push element x onto stack. */\nfunc (this *MyStack) Push(x int)  {\n    //添加元素\n    this.queue=append(this.queue,x)\n}\n \n \n/** Removes the element on top of the stack and returns that element. */\nfunc (this *MyStack) Pop() int {\n    n:=len(this.queue)-1//判断长度\n    for n!=0{ //除了最后一个，其余的都重新添加到队列里\n        val:=this.queue[0]\n        this.queue=this.queue[1:]\n        this.queue=append(this.queue,val)\n        n--\n    }\n    //弹出元素\n    val:=this.queue[0]\n    this.queue=this.queue[1:]\n    return val\n    \n}\n \n \n/** Get the top element. */\nfunc (this *MyStack) Top() int {\n    //利用Pop函数，弹出来的元素重新添加\n    val:=this.Pop()\n    this.queue=append(this.queue,val)//只是拿出来看一眼,马上塞回去\n    return val\n}\n \n \n/** Returns whether the stack is empty. */\nfunc (this *MyStack) Empty() bool {\n    return len(this.queue)==0\n}\n "},"技术积累/算法思想/栈与队列/递归":{"slug":"技术积累/算法思想/栈与队列/递归","filePath":"技术积累/算法思想/栈与队列/递归.md","title":"递归","links":[],"tags":[],"content":"递归的实现\n\n递归的实现就是：\n\n每一次递归调用都会把函数的局部变量、参数值和返回地址等压入调用栈中.\n然后递归返回的时候，从栈顶弹出上一次递归的各项参数\n\n\n因此实际上,栈与递归在某种程度上是可以转换的\n\n递归算法三要素\n\n确定递归函数的参数和返回值\n确定终止条件.[如果递归没有终止会导致栈溢出]\n确定单层递归的原理\n"},"技术积累/算法思想/移动匹配":{"slug":"技术积累/算法思想/移动匹配","filePath":"技术积累/算法思想/移动匹配.md","title":"移动匹配","links":[],"tags":[],"content":""},"技术积累/算法思想/语法细节":{"slug":"技术积累/算法思想/语法细节","filePath":"技术积累/算法思想/语法细节.md","title":"语法细节","links":[],"tags":[],"content":"\ngo中的交换可以这样写:\n\n s[left], s[right] = s[right], s[left]\n\n\n关于小括号和花括号\n\n() 小括号：显式类型转换 (Type Conversion)可以写t:=[]byte(s)直接把字符串显式转换成数组.string(cnt)再这样转换回去就行了\n{} 花括号：初始化/构造 (Composite Literal)\n\n\n\nimport后面用的是小括号\n\n\n循环中断\n\ncontinue 跳出当次循环\nbreak 结束当前循环\n如果想要结束所有循环,可以使用go语言的配合标签的break(Label)\n\n\n\npackage main\n \nimport &quot;fmt&quot;\n \nfunc main() {\n// 给外层循环起个名字叫 MyLoop (名字随便起)\nMyLoop: \n    for i := 0; i &lt; 3; i++ {\n        for j := 0; j &lt; 5; j++ {\n            if j == 2 {\n                // 指名道姓：我要跳出名叫 MyLoop 的那个循环\n                break MyLoop \n            }\n            fmt.Printf(&quot;i:%d, j:%d\\n&quot;, i, j)\n        }\n    }\n    // break MyLoop 后直接来到这里，外层循环也被终止了\n    fmt.Println(&quot;彻底结束&quot;)\n}\n\n逗号\n\ntype MyQueue struct {\n    stackIn  *MyStack\n    stackOut *MyStack\n}\n \nfunc Constructor() MyQueue {\n    return MyQueue{\n      stackIn: &amp;MyStack{},\n      stackOut: &amp;MyStack{},\n    }\n}\n冒号含义:贴标签.\n逗号含义:列表分隔,为了git版本控制友好.这样下一次要加一个字段的时候只有一行修改,而不是上一行加上逗号+新字段行.\n实际上,这就是一个JSON写法,key-value对.\n\n\n函数调用操作符.\n调用一个函数一定要加上(),表示执行这个函数.即使不需要传参数也要加\n如果不加括号,表示提到这个函数本身,是把函数当作一个变量或者对象\n\n\n结构体\n\n\n//情况1\ntype MyQueue []int\nfunc (q *MyQueue) Push(...)//如果要修改长度,一定要传切片的指针进去.\n(*q)[0]//既然穿了指针,那么修改切片中某个元素的时候就必须解引用\n \n \n//情况2\ntype MyQueue struct {\n    queue []int\n}\n//那么默认传myqueue的指针.但是如果要改queue中的元素,不需要解引用,m.queue[0]就可以.\n//如果要增删字段也比较方便.\n//缺点是需要多写一个m."},"生活杂谈/test":{"slug":"生活杂谈/test","filePath":"生活杂谈/test.md","title":"test","links":[],"tags":[],"content":""},"生活杂谈/面经/GC":{"slug":"生活杂谈/面经/GC","filePath":"生活杂谈/面经/GC.md","title":"GC","links":[],"tags":[],"content":"Garbage Collection\n工作原则是：只要这块内存还有人在用（有指针指向它）我就不能扔；没人指向它了，我就回收。\nSlice 导致内存泄露的经典场景： 想象一下，你从服务器下载了一个 100MB 的超大文件（比如一本小说），读到了内存里，变成了一个巨大的数组。\n// 1. 这是一个巨大的切片，底层数组占用 100MB\nbigData := getHugeFile() \n \n// 2. 你只需要前 10 个字节（比如只要标题）\ntinySlice := bigData[:10]\n \n// 3. 此时，你把 bigData 弄丢或者函数返回了，只留下了 tinySlice\nreturn tinySlice\n\n表面看： tinySlice 只有 10 个字节。\n实际上： tinySlice 的结构体里有一个指针,指向底层的那个数组\n结果： 只要 tinySlice 还活着，保洁阿姨（GC）就会认为：“哦，那个 100MB 的数组还有人（tinySlice）指着它呢，不能扔。”\n后果： 为了这 10 个字节的小数据，你强行占用了 100MB 的内存不释放。这就是内存泄露。\n\n解决办法:"},"生活杂谈/面经/summary":{"slug":"生活杂谈/面经/summary","filePath":"生活杂谈/面经/summary.md","title":"summary","links":[],"tags":[],"content":"一、 Go 语言基础（重灾区，必问）\n面试官非常喜欢问底层实现，特别是 Slice 和 GMP，几乎每场必面。\n\n\nSlice (切片) —— 出现频率：⭐⭐⭐⭐⭐\n\n\n底层原理： 数组指针 + 长度 (len) + 容量 (cap)。\n\n\n扩容机制： 什么时候翻倍？什么时候 1.25 倍？。\n\n\n引用 vs 复制： 传递 Slice 是值传递还是引用传递？（答案是值传递，但因为持有底层数组指针，所以修改元素会影响原数组，但 append 可能会导致扩容换数组）。\n\n\n\n\nGMP 模型 —— 出现频率：⭐⭐⭐⭐⭐\n\nG、M、P 分别是什么？调度流程是怎样的？。\n\n\n\nMap (字典) —— 出现频率：⭐⭐⭐⭐\n\n\n底层结构？是有序还是无序的？（无序）。\n\n\n并发读写会 Panic 吗？（会，怎么解决？用 sync.Map 或加锁）。\n\n\n\n\nChannel (通道) —— 出现频率：⭐⭐⭐⭐\n\n\n有缓冲 vs 无缓冲的区别。\n\n\n向关闭的 channel 读/写会发生什么？（写会 panic，读会返回零值）。\n\n\n\n\nContext &amp; Defer\n\n\ndefer 的执行顺序（栈，后进先出）。\n\n\ncontext 如何做超时控制？。\n\n\n\n\n\n二、 MySQL 数据库（结合你的 MiniSQL 项目看）\n这部分你结合你的项目复习，效果会翻倍。\n\n\n索引 (Index) —— 出现频率：⭐⭐⭐⭐⭐\n\n\nB+ 树： 为什么要用 B+ 树？和 B 树区别？。\n\n\n失效场景： where 条件、like 模糊查询、最左前缀原则。\n\n\n分类： 聚簇索引 vs 非聚簇索引。\n\n\n\n\n事务 (Transaction) —— 出现频率：⭐⭐⭐⭐\n\n\nACID 特性： 原子性、一致性、隔离性、持久性。\n\n\n隔离级别： 读未提交、读已提交、可重复读（默认）、串行化。如何解决幻读？（MVCC + Next-Key Lock）。\n\n\n\n\n慢查询优化\n\n\nlimit 分页太深怎么优化？。\n\n\nexplain 命令怎么看？\n\n\n\n\n\n三、 Redis &amp; 分布式（进阶加分项）\n字节跳动非常喜欢问 Redis，尤其是分布式锁。\n\n\n基础数据结构\n\nString, List, Hash, Set, ZSet (有序集合，底层是跳表)。\n\n\n\n分布式锁 (重点)\n\n怎么实现？SETNX 有什么问题？怎么续期（WatchDog 机制）？。\n\n\n\n消息队列 (Kafka)\n\n如何保证消息顺序？（Partition）消息积压怎么办？。\n\n\n\n\n四、 计算机网络 &amp; 操作系统\n\n\nTCP/IP\n\n\n三次握手： 为什么不是两次？最后一次 ACK 丢了怎么办？。\n\n\n输入一个 URL 到网页显示的流程（经典老题）。\n\n\n\n\nLinux 命令\n\n查询端口占用、查看磁盘/内存满没满 (top, df, netstat/lsof)。\n\n\n\n\n五、 手撕算法 (Code)\n从面经看，考的都是 Hot 100 里的经典题，没有怪题。\n\n\n链表类： 反转链表、反转链表 II。\n\n\nLRU 缓存： 设计 LRU（字节高频题）。\n\n\n字符串： 无重复字符的最长子串、回文串判断。\n\n\n排序： 快排（问最坏情况）。\n\n\n其他： 三数之和。\n\n"},"课程笔记/mySQL/其他/索引":{"slug":"课程笔记/mySQL/其他/索引","filePath":"课程笔记/mySQL/其他/索引.md","title":"索引","links":[],"tags":[],"content":""},"课程笔记/内存中的栈":{"slug":"课程笔记/内存中的栈","filePath":"课程笔记/内存中的栈.md","title":"内存中的栈","links":[],"tags":[],"content":""},"课程笔记/操作系统/01-introduction":{"slug":"课程笔记/操作系统/01-introduction","filePath":"课程笔记/操作系统/01 introduction.md","title":"01 introduction","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n操作系统概述\n定义与设计目标\n操作系统：\n\n职能：资源管理系统\n存在：本质上是软件程序\n\n最基础最中央的部分是内核kernel\n\n\n\n设计目标：\n\n可靠性和安全性\n\n异常处理机制：中断\n权限管理系统：特权\n\n\n易用性\n\n方便用户使用系统资源：系统调用\n\n\n高效性\n\n任务执行设计：批处理系统-》分时系统\n\n\n公平性\n\n进程管理的冲突与饥饿starvation\n\n\n可拓展性、易维护性\n\n设计与实现\n从目标/需求开始：user goals &amp; system goals\n机制和策略相分离 flashcard\n\n\n机制/规则被存在酒店的中心服务器上（database） 和策略分离开了,比如配置文件就相当于policy\n\n\n\n                  \n                  例题 \n                  \n                \n\n\n\n\n操作系统提供的三种能力\n复用 multiplexing\n\ncpu复用 多个程序共享 时间分配复用\n内存复用 多个进程  空间分配复用\n\n隔离  isolation\n\n程序之间不能访问对方的数据\n数据范围权限的隔离\n用户 kernal\n\n抽象 abstraction\n进程间通讯 interaction\n操作系统的整体设计\n计算机系统架构\n\n根据处理器的数量和组织形式，存在三种计算机系统架构\n\n单处理器\n\n有且仅有一个单核通用处理器general-purpose processor\n可以有若干专用处理器用来处理特定指令，并不运行线程\n\n\n多处理器系统\n\n有多个单核通用处理器的系统，处理器共享同一块主内存，通过总线或者交换网络连接\n增加了处理西数量能够增加吞吐量throughput，也就是单位时间内处理的任务数量，但是增加并不线性（处理器之间通信需要时间和额外开销）\n\n\n集群系统\n\n通过冗余实现高可用服务，通过并行实现高性能计算，由多个独立的计算机系统作为节点，通过高速通信网络相互连接形成\n分为对称和不对称两种，对称集群中各个节点互相监督，不对称集群中存在“替补”监督工作中的节点，或者接替有问题节点的工作。\n\n\n\n操作系统的任务执行设计\n1. （单道）批处理系统  flashcard\nbatch processing system\n\n批处理：若干任务被作为一整批交付给操作系统，操作系统会自动按照顺序串行serial执行任务\n单道：一段时间内内存中只有一道程序在运行（进程process ），结束后再切换到下一个任务\n问题：当存在I/O操作任务时，由于耗时，CPU长时间处于空闲状态\n\n\n\n                  \n                  I/O \n                  \n                \n\n即CPU和RAM（主内存）与“外部世界”之间进行数据交换的过程\n\n存储设备（磁盘IO）\n网络设备（网络IO）\n人机交互设备\n其他外部设备\n\n特点：速度慢。\n\n\n\n2. 多道批处理系统 flashcard\nmultiprogramming batch processing system\n\n一段时间内，四个进程 （job=process）都加载到内存中，并发运行（在A完成之前B可能也开始了）。当当前 job 发生 I/O 时，操作系统负责让 CPU 转而运行另一个 job。\n但微观来看，多道批处理仍然是顺序串行的。\n不关心运行的先后顺序（任意），只要同时加载进去就叫做multiprogramming。调度的部分是由jobschedule完成（批处理\n原因：内存大，cpu强，有能力同时处理4个进程，因此就可以提升硬件的使用效果\nneeded for硬件计算资源CPU utlization\n交互性差，在完成任务前用户无法操作\n\n\n\n                  \n                  并发与并行 \n                  \n                \n\n并发**(concurrency)**是指两个或多个事件在同一时间间隔内发生，而并行是指两个或多个事件在同一时刻发生。逻辑上，并行是并发的子集。\n\n3. 分时系统 flashcard\ntimesharing systems/multitasking\n\nmultiprogramming的逻辑拓展：保留其内存中有多个进程的并发特点\n处理器会在jobs上面轮流地赋予cpu资源，在进程间不断切换（很短的时间内），让用户察觉不到进程的切换/cpu的共享，达到近似于并行的效果。\n注重的是用户的交互性interactivity，允许多个用户同时使用同一台计算机，所有任务之间互相独立，互不干扰、互不阻塞，因此任务的最长周转时间减少，用户的操作也会被及时响应，实现了更方便进行人机对话。\n对硬件配置有较高要求（每个用户的terminal）和调度算法\n\n\n操作系统的结构设计\n宏/巨内核(monolithic-kernels) flashcard\n也叫单内核或大内核\n\n将所有主要功能紧密耦合，操作系统效率高\n维护十分困难；某个部分出现困难，整个系统都会受影响。\n\n\n\n分层设计(layer approach)\n\n将系统分为若干层，底层为硬件，顶层为用户接口，第 i 层只调用i−1 层提供的接口。每一层都实现良好的封装，于是开发过程中只需要逐步实现并调试验证每一层，再逐级向上开发即可；在维护或扩展过程中，只要修改每一层的内部实现，而不需要修改其它层的代码，这样就大大降低了开发和维护的难度。 \n由于每次执行一个功能都需要上下跨越多层，发生多次接口调用，分层设计下的系统效率往往都受到限制；不仅如此，要想真正意义上实现良好的分层设计，就需要对各层有良好的定义，这个设计难度是不小的。\n\n微内核(micro-kernels) flashcard\n\n将不是必要的东西都从内核拿出去，放到用户空间以用户态执行。只有通讯、内存管理、进程管理等基本功能直接运行在内核态。其他功能部件通过消息传递机制和内核互动。\n维护扩展变得容易，自身效率得到提升，可靠性也提高了。但是很多模块移到usermode不安全\n\n\n\n模块化设计(modules approach)\n模块-接口法。理想的设计可以让系统多线并行，只要商量好接口就能独立实现，维护和扩展容易。但是设计开发很困难。\n混合系统(hybrid systems)\n宏内核和微内核的思路结合起来，是目前主流的操作系统模式\n操作系统的运行原理\n中断interrupts\n中断（广义）是贯穿现代操作系统的一个重要技术，它使得“计划之外”的事情可以及时的被告知并处理（让产生意外的人自行上报这些意外） 现代操作系统都是中断驱动的\ninterrupt-request line flashcard\n\nCPU 有称为 interrupt-request line 的线路。CPU会在每一条指令结束后检测是否有中断发生，并会读取 interrupt number 并且以此作为 interrupt vector 中的 index 来跳转到对应的 interrupt-handler routine。\n\n\n中断向量表 interrupt vector table flashcard\n中断向量表是快速定位中断处理方法的手段。通过中断号来索引中断处理方法，实现了一种“随机访问”，大大加速了中断处理的速度。\n\n分类\n\n硬件引起的中断（外中断）\n软件引起的中断（内中断）trap\n\nerror 非主动的\nsystem call 程序主动的 调用操作系统的功能\n\n\n\n\n\n                  \n                  riscv的对应术语区别 \n                  \n                \n\n\n中断traps\n\n硬件中断 interrupts\n软件中断\n\nerror→exceptions\n系统调用→ecalls（环境调用）\n\n\n\n\n\n\n\n\n\n                  \n                  cause a page fault \n                  \n                \n\n缺页 访问memory地址的时候由于对应的地址内容非法而产生的中断\n\n\n\n过程\n\n\ndevice driver I/O与操作系统之间的驱动\n左边：CPU\n右边：I/O controller\nI/Ocontroller发起中断之后，CPU对其进行处理，调用interrupt handler，处理好之后return到被中断的下一条指令重新开始运行 的这么一个循环过程\n\n波动表示状态的改变\n\n\n\n                  \n                  中断状态的保存 \n                  \n                \n\n为了保证中断处理完成后仍能继续当前任务，操作系统需要保存当前任务的状态，以便完成中断处理后恢复当前任务的状态。\n\n\n中断冲突 flashcard\n中断处理也同样需要资源，这意味着中断也有可能产生冲突\n\n优先处理优先级高的中断：中断分级\n\n虽然低级的中断可以被高级的中断打断，但是保存和恢复现场状态的过程是不应当被打断的。\n\n\n原子性行为不可被中断，重要任务不应该被中断：中断屏蔽\n\n\n\n                  \n                  中断请求线 \n                  \n                \n\n\nmaskable interrupt-request line 可屏蔽的中断 它可以在执行不可中断的关键程序之前被 CPU 关闭，等到关键程序结束后再解除屏蔽处理其中的中断。\n 2. non-maskable interrupt-request line 不可屏蔽的中断 为一些不可恢复的内存错误等事件保留\n\n\n\n\n计时器 timer flashcard\n\n计时器需要一个固定频率的时钟以及一个计数器，在每个时钟周期令计数器减 1，当计数器归零时产生中断，告诉操作系统定的时已经到了\n功能虽然基础但是十分重要，例如分时系统中就需要计数器来控制时间片的长度，又比如操作系统需要定期检查内存中的进程，以防止进程一直占用系统资源\n\n\n特权模式privileged mode\n允许用户程序执行常规操作，危险操作由专业人士执行。\n工业上特权模式有许多复杂的实现形式，比如\n双模式(dual-mode） flashcard\n\n用户态  user mode\n内核态  kernal mode\nMode bit 为 0，表示 CPU 工作在内核态；mode bit 为 1 时，CPU 工作在用户态。modebit由特权指令进行管理。\n\n\n特权指令(privileged instruction)\n例如 I/O 控制，计时器管理，中断管理等。这些指令只能在内核态下执行，而用户态下执行这些指令时会认为这条指令不存在。\n\n\n                  \n                  是不是在kernalmode下运行的所有指令都是特权指令？ \n                  \n                \n\n不是，非特权指令也可以运行在kernalmode下，但是特权指令只能在kernalmode下运行\n\n\n双模式之间的交互\n用户委托进行危险操作的过程：比如writing data to a disk drive ，用户程序想要使用kernal提供的服务，需要调用系统调用（system call）切换到kernelmode。\n\n具体实现上即发生软中断（trap）的时候\n\n细节：将usermode本身执行的上下文保存下来以便于恢复等\n系统调用可能需要传递参数。参数可以放在寄存器里直接传递；也可以放在一块内存中，用寄存器传递地址；也可以用栈传递。\n\n\n\n                  \n                  能否让中断运行在usermode？ \n                  \n                \n\n不行，等同于kernel的权限和usermode是一样的，破坏了隔离性（多个user program都对设备进行io）\n\n\n系统调用\n\n系统向用户程序提供服务的一个接口，它们经常以 C/C++ 函数的形式存在，对于某些比较接近底层的任务，也可能是通过汇编编写的。\n但说到底，系统调用还是相对底层的设计，通常的开发并不基于如此底层的设计展开。更常见的是利用各种抽象层级更高的 Application Programming Interface, API 进行开发。\nAPI 是一个非常常见的概念，在我看来系统调用本身也是一种极为底层的 API。API 的核心思想是让调用者只需要知道如何与被调用者交流以实现目的，而不需要关心其具体实现。这同时也暗示着，只要 API 一致，同样的程序在不同的平台上也能直接编译后运行。\n显然，API 与编程语言往往是强相关的，特定编程语言在操作系统上运行也是需要一定的“环境”的，也就是我们所说的运行时环境(run-time environment, RTE)。RTE 通常包括了编译器(compilers)、解释器(interpreters)、库(libraries)和装载器(loaders)等，它们共同组成了一个完整的运行时环境。\n\n\n\n                  \n                  库函数与系统调用 \n                  \n                \n\n库函数运行在用户空间而系统调用运行在内核空间。大部分库函数可能使用系统调用来实现目的。\n\n\n\nsystemcall是函数 通过interface被调用 但是调用的过程比函数调用更复杂（根据systemcontrol的index下标去查询systemcall的表得到systemcall具体的内容）\n系统调用的分类\n\n链接器和装载器\n操作系统到底是如何执行一个程序的呢？以 C 为例，一个写完的代码需要经过编译、链接、装载三个步骤，才能成为一个在内存中的，可以被执行的程序。\n\n\n编译器首先将若干 .c 源文件编译为若干 .o 文件（这里合并了预处理、编译、汇编步骤），这些 .o 文件被称为可重定位目标文件(relocatable object file)，其存在形式为机器码\n\n\n随后链接器将若干 .o 文件连带所需要的一些库文件（如 .a 文件）链接为一个可执行目标文件(executable object file)。\n\n\n静态链接将库文件的代码直接合并进入最终的可执行文件\n\n\n动态链接仅仅将库文件的引用信息写入最终的可执行文件，而在程序运行时再去寻找这些库文件\n\n\n\n引导\n\n在计算机刚刚启动，操作系统还未开始运行之前，需要开机后的第一个程序——引导加载器(bootstrap loader)来一步一步地初始化操作系统。对大多数操作系统来说，bootstrap 都会被存储在 ROM 中，并且需要在一个已知的位置\nBootstrap loader 会载入更加复杂的，完整的 bootstrap，而包含 bootstrap 程序的分区就被称为引导分区(bootstrap partition)。\n\n同步/异步IO\n\n\n同步(synchronous)\n\n用户等待io操作的完成（控制权移交给操作系统直到io操作结束\n\n\n异步（Asynchronous)\n\nio操作启动以后用户发起io的请求后，控制权迅速返回调用程序，然后io操作再自己去进行（并记录好这个操作的有关信息比如是由哪个进程发起的 需要把得到的数据交给谁之类（device-status table\n\n\n\n\n\n三个management\nprocess management\n\n操作系统分配给进程一定的资源。进程在运行中需要始终拥有这些资源才能够运行完毕。\n\nprogram 静态概念\nprocess   运行中的动态实体（抽象概念\n\n一个程序可以有多个运行中的进程\n不同进程所占用的资源不同，因此可以说进程是一个资源分配的单位\n进程又可以有对应的子进程（树状继承关系\n\n\n\n进程当前指向的地址 pc寄存器\n一个程序可能有多个执行的顺序 叫做thread线程\n\n\n                  \n                  是否时在整个运行过程中，都要占有所有该进程需要的资源？ \n                  \n                \n\n进程运行的各个生命周期，需要的资源不同。在需要的时候再进行占用，不需要的时候进行释放，提高了灵活性和资源利用率。\n\n\n进程里面可以包含多个执行的序列：线程thread\n线程：执行的最小单位\n进程：分配资源的单位\n\n进程的创建\n\n进程的继承关系\n\n\n交互的能力（给另一个进程发消息 signal\n进程的状态\n删除进程\n多个进程之间共享内存（访问冲突\n\nmemory management\n\n让进程能（按照权限/规定）了解到自己目前所拥有的内存（静态分配or动态分配）的结构，的视图。\nstorage management\n在存储的介质上面（硬盘/SSD）\n\n提供一个抽象的访问接口：文件file\n文件的层结构：目录\n文件访问的权限\n文件是单个数据实体\n文件系统是一整套文件以及管理目录的整体\n磁盘上面分成若干块的partition 并赋予文件系统（一个盘符就代表一个单独的文件系统）\nmass-storage management\n海量存储管理，也就是磁盘管理\n相较于面向用户的storage管理 更多的是面向硬件的管理\nI/O subsystem\n\n\n\n                  \n                  system call能否实现成为library（函数调用 \n                  \n                \n\n存在安全性风险，比如软件调用特权指令等\n\n\n虚拟机\n本质其实是一种抽象\n给上层提供和底层硬件一样的interface\n\n\nhardware：host宿主机\nvirtual machine managerVMM/hypervisor：提供了具备操作系统特性的一个基本的管理软件，提供接口供虚拟机运行，结构相对来说简单\n\ntype1 裸金属的虚拟化baremtal hyperboza 比较好因为不需要完整的运行操作系统\ntype2 比如qemu 离不开地下原生os的运行\n\n\nguests：进程，可以运行多个进程（一个进程就是一个自成一体的完整操作系统 ）\n\n对guestos不做修改：全虚拟化\n对guestos做一点改动：半虚拟化，但是运行效率更高\nsysgen ：device driver之类的配置\n在操作系统power-on的过程中cpu执行的第一个软件（系统初始化自检硬件部分）：firmware固件\nbootloader是加载操作系统用的（locate kernel image on disk 并且加载进ram，switching the cpu mode for kernel execution）"},"课程笔记/操作系统/02.1-进程":{"slug":"课程笔记/操作系统/02.1-进程","filePath":"课程笔记/操作系统/02.1 进程.md","title":"02.1 进程","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n进程基本概念 flashcard\n\n一段本质上是静态的、存储在硬盘上的指令数据，而当它附带运行程序所需要的必要信息进入内存，得到相关资源后，它成为一个动态的、与计算机资源互动的实体，这个实体就是进程(process)。简单来说就是运行中的一个实例。\nprocess=job。\n\n\n进程的形式 flashcard\n在内存中需要一块虚拟的地址空间来存储。包含两个部分\n虚拟地址空间中的用户部分\n\ntext section(code) 存储代码 加载到内存前以 executable file 的形式存储在 disk 中\nstack section 常说的栈 存储一些暂时性的数据，如函数传参、返回值、局部变量等\ndata section 存储代码中的全局变量、静态变量\nheap section 常说的堆，被动态分配的内存\n\n\n内存映像：0~max地址之间的区域叫做address space\n\n\n进程访问的物理空间是虚地址，因此这里的max也叫做maxVA(最大的虚地址)\n空洞hole：这个部分其实占比例很大，是无法合法访问的区域。\ntext和data部分所需要的空间在一开始就被确定，heap和stack可以动态扩展和收缩（但是加上hole的整个空间不变）\n\n\n虚拟地址空间中的内核部分\nPCB\n\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\n\n\nprocess control block（PCB） flashcard\n操作系统用一个PCB表示进程，每个进程有且仅有一个PCB，PCB 是进程存在的唯一标志。其中包含许多当前进程的相关信息\n\nprocess state 进程的状态\nprogram counter 标识该进程跑到了哪里（存储中断前的工作状态，指向下一个要运行的指令\nCPU registers 保存进程相关的寄存器信息\nCPU-scheduling information CPU调度参考的信息，包括优先级、调度队列的指针、调度参数等。\nmemory-management information 包括页表、段表等信息，具体与实现的内存系统有关。\nAccounting information 一些关于进程的动态数据的统计和记录，比如已经跑了多久、时间限制、进程号等等\nIO status information 被分配给进程的IO设备列表、打开的文件列表等\n\n\n是每个进程所独有的数据，和别的进程无关。\n是抽象概念的数据结构，不一定实现为block。不同的系统可能有不同的 PCB。Linux 中的进程用结构体 task_struct存储。\n如果只是中断去处理什么而不涉及进程切换，PCB也可以不用工作，而重要的信息直接保存到kernel stack里面。\n\n\n\n进程管理\n进程树 (process tree)\n\n\n用户进程在操作系统中，总体上遵循树状组织形式，每一个进程有一个唯一标识符进程号（通常为pid）\n进程之间存在一种父子关系，即 child 进程是由 parent 进程创建的，用 ppid 来标识它的 parent 进程\n\n进程的创建 flashcard\n\nchild 进程的资源可能直接来自操作系统的分配，也可能来自 parent 进程的继承，限制使用后者的好处是能够避免因为创建太多子进程而导致资源不够用。\n进程树的根是 systemd，历史上也曾叫过 init，它是操作系统启动后运行的第一个用户进程，至少在 Linux 中，它的 pid 被分配为 1，而它的 ppid 是 0，可以理解为这个进程的 parent 是 scheduler 而非一个进程\n\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;sys/types.h&gt;\n \nint main() {\n    printf(&quot;A process starts!\\n&quot;);\n \n    pid_t pid;\n    **pid = fork();**\n \n    if (pid &lt; 0) {\n        printf(&quot;Fork failed!\\n&quot;);\n    } else if (pid == 0) {\n        // sleep(1);\n        printf(&quot;pid is zero, so it&#039;s child process!\\n&quot;);\n    } else {\n        **// wait(NULL);**\n        // sleep(1);\n        printf(&quot;pid is nonzero thus it&#039;s parent process!\\n&quot;);\n    }\n}\n \n\nUNIX 系统中可以使用系统调用 fork() 来创建一个新进程。这个新进程是父进程的一份拷贝，它们只有 pid 和 ppid 不同，另外子进程当前内存使用记录为 0，除此以外全部相同。\npid = fork()之后，内存中有两个进程，一起从这行代码的下一行往下执行，通过检查返回值pid来判断属于parent还是child。在父进程中，fork（）返回的是创建的子进程的pid，子进程返回0，执行失败返回负数。\n\n这里的pid_t是一个局部变量\n\n\nwaite（NULL） 即父进程可以继续运行，或者等待子进程运行完以后再运行\n\n使得当前进程进入 waiting 状态，并在任一子进程终止，或被信号停止，或被信号恢复时进入 ready 状态，同时返回发生该事件的子进程的 pid\n如果第 18 行仍然被注释，那么 parent 进程和 child 进程将并发执行，即完成 fork() 后两个进程都从 11 行开始继续向下并发的执行，互不阻塞\n\n操作系统会让它们交替使用CPU。谁先完成自己的printf，完全取决于操作系统的“心情”（调度）。所以可能会先看到父进程的输出，也可能先看到子进程的输出。\n\n\n如果 18 行的注释被取消，那么 parent 进程将等待 child 进程结束后再继续。\n\n父进程执行wait(NULL)这行时，会被阻塞，需要等到子进程完全结束（执行完所有代码或调用了exit）之后才能继续往下执行自己的内容，子进程输出一定在父进程之前\n逻辑上创建的新进程有两种情况：\n\n\n\n\n\n\n复制 parent 进程的代码数据；\n载入新的程序并继续执行；\n而实际在 Linux 中，第一种通过 fork() 实现，第二种通过 fork() 后 execXX() 实现，execXX() 会覆盖那个进程的地址空间，以实现执行其他程序\n\n进程的终止 flashcard\n\n当进程调用 exit() 这个系统调用时，将被终止。\nC 语言 main 函数返回时也会隐式地调用 exit()。\n进程也会由于一些信号、异常等终止。\n这意味着这个进程将不再执行，其资源将被释放，同时返回状态值，而这个状态值将被 parent 进程的 wait() 接收。\n\n父进程通过调用 wait() 来做两件事：\n\n等待子进程结束。\n接收（回收） 子进程的这个“状态码”（检查作业本）。\n\n\n特别的，如果 parent 进程尚未调用 wait()，则这个 child 进程还不会完全消失，因为要返回的东西还没返回（child 并不知道 parent 会不会、什么时候来回收它）。这种逻辑上已经终止，但仍然占有一部分资源，等待 parent 进程调用 wait() 的进程，我们称之为僵尸进程(zombie)。\n当子进程没有结束，或者终止了但父进程没有调用 wait() 的情况下，父进程就结束了，子进程就会成为 孤儿进程 (orphan processes)（如果parent exiting ，成为孤儿进程，它的父进程变成init process（pid=1）init 进程会定期调用 wait()）\n\n\n\n进程间通信\n\n\n如果一个进程受到其它进程的影响，或会影响其它进程，那么我们称之为协作进程(cooperation process)，比如一个进程的输出作为另一个进程的输入使用，之类的。\n\n为了模块化设计，必不可少\n\n\n\n进程间通信(inter-process communication, IPC) flashcard\n\n是为了在进程的资源相互隔离的情况下，让不同的进程能相互访问资源从而协调工作。\n两种方式\n\n共享内存(shared memory)：（a）\n\n相比下面几种效率更高，需要用到 system call 的地方只有建立共享内存的时候\n两个进程各自有一块虚拟内存，映射到同一块物理内存。\n也需要信号量等同步手段保护\n\n\n消息传递(message passing)：（b）\n\n在分布式系统中更容易实现，对于少量数据通信很有用（因为不需要处理冲突问题 ）；\n\n建立link\n\n直接通信 特定某个id的进程\n间接通信 中转手段，比如信箱mailbox（well-known mailbox//ports）\n\n\n同步 blocking\n\nblocking send  让sender blocked 直到信息被接收到\nblocking receive receiver block直到信息可以被接收到\n\n\n异步 non-blocking\n\n\n\n\n\n\n\n\n\n信号量(semaphores)：本意用来线程间同步，但是可以通过 sem_open() 系统调用来建立和维护进程间的信号量；这样的信号量属于 OS 资源，它会在相关进程结束后由 OS 释放\n\n\n文件 / 管道(pipe)：\n\n管道本质上也是一种文件，创建管道时操作系统会返回两端的文件描述符\n但一个管道只支持单向传输，即只能 A 写 B 读，如果要实现双向需要两个管道【逻辑上是一个半双工的信道】\n\n\n\n\n【模型】producer-consumer problem\nproducer 信息输出方\nconsumer 信息接收方\n\n无界缓冲区 unbounded-buffer 缓冲区的大小相比于发送的信息相比不会满\n有界缓冲区 bounded-buffer\n\nproducer往buffer中放入items，consumer取出\n指定指针index-in给producer使用，index-out提供给consumer\n\n\n检查如果==out：认为没有freeitem是可以放的【下一个位置就是out指针】\n否则放入并且后移一位：0~buffersize-1，下一个又从0开始【理解为环形队列】\n\n\n\n\n如果有可取用的item 就往后移一位，并取出使用\n问题是：会浪费一个element 当out=1 in=0的时候 in没有办法insert进去了\n：\n\n\n\n\n"},"课程笔记/操作系统/02.2-调度":{"slug":"课程笔记/操作系统/02.2-调度","filePath":"课程笔记/操作系统/02.2 调度.md","title":"02.2 调度","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n就绪队列(ready queue)和等待队列(wait queue) flashcard\n实际上换进程就是换PCB的指针位置放到哪个队列（kernel负责移动）\n\n\nready quene（里面的process都处在ready状态）（ CPU等待队列：）\n实际实现中，由于等待的io或者事件不同，可能维护多个等待队列。\n\nIO设备等待队列：device queue 等待完用好IO设备之后PCB被移走\n\n\n\n不需要等待其他设备也不需要使用处理器的进程？：空闲状态、将要结束的状态等，这样的进程就不会出现在上述队列中，会被放在job queue（系统中所有进程都在其中）\n\n\n进程状态state flashcard\n进程在execute时会改变状态。一个处理器上只有一个进程可以running。\n\nnew\n\n进程正在创建过程中，包括申请 PCB，分配初始资源等；\n\n\nrunning\n\n进程正在运行（正在使用CPU资源）\n有几个核就最多有几个进程处于running状态\n\n\nwaiting\n\n进程正在等待某个事件的发生，比如调用systemcall之后进程暂停的状态/IO操作中/其他event\n此时即使有空余的 CPU 资源，该进程也无法继续\n一般进程从running到waiting是主动的（系统调用之类 ），离开waiting进入ready是被动的\n\n\nready\n\n进程已经准备好了只差CPU资源，一旦有CPU资源可以分配给该进程，就会变为running态（等待 CPU 资源的派发(dispatch)，接受调度）\n如果有进程ready 说明一定有进程正在running\nCPU 调度实际上指的就是若干进程在ready和running之间的切换，当发生了 interrupt，如计时器到时间了，running就会切换到ready\n\n\nterminated\n\n进程因为某些原因终止，结束运行，需要释放资源；\n\n\ninterrupt触发后，本来要执行的指令被中断，os陷入到kernel中，在进行中断处理的时候，发现允许进程处理的时间片到了，那么就需要把这个进程换下来换成别的进程。原本的那个进程进入ready的状态。\nscheduler dispatch 调度程序，决定下一个将要运行的进程\nwaiting不能直接进入到runing必须经过ready\n\n\n调度\nscheduler类型 flashcard\n\n\nlong-term scheduler：（job scheduler）\n\n历史上的概念，主流操作系统里面已经没有了，现在实际上就是用户自己在担任这个角色。选择哪个processes需要从硬盘进入memory（the ready queue）\n如果允许太多io bound的进程进入cpu 那么就会阻塞在io queue里面，那么cpu就得不到有效的使用，因为等待io的进程太多，而准备运行的进程太少\n\n\nshort-term scheduler （CPU scheduler）\n\n多道 (multiprogramming) 环境下，进程的个数通常大于 CPU 的个数。CPU 调度就是 OS 关于哪个 ready 进程可以运行（使用 CPU）以及运行多久的决定。\n\n\nmedium term scheduler\n\n主内存严重不足时，需要将优先级较高的进程先加载到RAM（主内存）中。\n换到外存（硬盘）中（wipe out）之后状态仍然是waiting，当接收到所需的用户输入之后，会被考虑重新换到内存中。\n\n\n\n\n进程类型\n\nI/O-bound (I/O 密集型): 这种程序大部分时间都在“等待”。比如等待网络数据、等待读取硬盘文件。它只需要 CPU 算一小会儿，然后就去等待 I/O。\nCPU-bound (计算密集型): 这种程序是需要 CPU 一直不停地算很久，很少需要等待 I/O。比如视频渲染、科学计算。\n一个好的操作系统会混合搭配这两种程序，确保 CPU 和硬盘/网络都能保持忙碌，提高整体效率。\n\n\n\n                  \n                  Title \n                  \n                \n\n\n主内存 就是内存，CPU工作的区域，而 RAM 是主内存的物理实现。\n外存  SSD/HDD(硬盘)是外存的物理实现\nROM 是一个完全不同的东西。它是一个小容量、只读、断电不丢的芯片，它的唯一工作就是在你按下开机键时，引导电脑去“外存”里加载操作系统到“主内存(RAM)”中\n\n\n\n调度的时机 flashcard\n\nscheduler调度\n\n非抢占式调度(non-preemptive scheduling) running的进程由于某些原因需要主动离开running状态【绿色】\n抢占式调度(preemptive scheduling) ready的某个进程需要立刻得到CPU资源【蓝色】\n\n其他态转变为ready态来排队\n或者在排队的时候某个人想插队（优先级调度 ）\n\n\n非抢占式调度是由已经拥有资源的进程主动释放 CPU 资源引起的，而抢占式调度则是不占有资源的进程索取 CPU 资源成功引起的。\n\n\n调度的过程：上下文切换 flashcard\n由 CPU scheduler 选择哪一个ready态的将要被执行后，由 dispatcher 来完成具体的切换工作包括：\n\n在两个进程间进行上下文切换(context switch，包括恢复现场、保证进程执行一致性的过程)\n\n上下文：① CPU 寄存器中的值，② 进程状态，③ 内存的管理信息\n\n\n切换到用户态；\n跳转到用户程序中合适的位置以继续进程执行；\n\n\n进程切换：包括被中断和systemcall两种\n\n被中断 进入ready\nsystem call 进入waiting\n\n\n而从 dispatcher 停止上一个运行时的进程，完成上下文切换，并启动下一个进程的延时，称为 dispatch latency。\n\n\n\n调度算法\n调度算法的评价指标(scheduling criteria) flashcard\n\nMaximize CPU Utilization \n\nCPU 使用率，CPU 使用时间 / 总时间。即 CPU 非空闲的时间比例\n从 CPU 是否足够忙碌来看硬件性能是否充分发挥\n\n\nMaximize Throughput \n\n吞吐量，每个时间单元内完成的进程数\n从结果来看任务完成是否足够高效\n\n\nMinimize Turnaround Time\n\n周转时间，从进程创立到进程完成的时间，包括等待进入内存、在 ready queue 中等待、在 CPU 上执行、I/O 执行等时间\n通过观察最大周转时间，能反映调度的效率和“公平性”\n\n\nMinimize Waiting Time \n\n等待时间，在 ready queue 中（或在 Ready 状态下）等待所花的时间之和\n由于任务所需要的 CPU 时间、I/O 时间不受调度算法影响，所以抛开这些只看在 ready queue 中的等待时间，能反映调度算法的效率\n等待时间 = 周转时间 - 运行时间\n\n\nMinimize Response Time \n\n响应时间，交互系统从进程创立到第一次产生响应的时间\n能反应交互式系统中调度算法的“及时性”\n\n\n\n\n调度算法\n以下调度算法存在理想化建模，以及以multiprogram为基础\nFirst-Come, First-Serve (FCFS) | Nonpreemptive flashcard\n先申请 CPU 的进程首先获得 CPU，用First-In, First-Out（FIFO）队列实现\n\n\nShortest-Job-First (SJF) flashcard\nSJF 的核心想法是，让下一次运行时间最短的进程先来运行；根据数学知识，我们可以得知这样能得到最少的平均等待时间\n\n对于非抢占式的系统来说，当我们忽略 I/O 等会进入 waiting 的情况（因为题目通常这样设计），进程「下一次运行时间」就是整个进程所需的总运行时间。\n对于抢占式的系统而言，「下一次运行时间」实际上是进程的剩余运行时间，因为进程可能曾经被打断过。\n因此我们将 SJF 进一步细分成了两种。\n\nNon-preemptive: Shortest-next-CPU-burst\n选取 ready queue 中下次 CPU 执行时间最短的进程。这样会使得给定的一组进程具有 minimum average waiting time.\n\n\n在这个情景中，0s 时只有 P1 到达，因此 P1 先运行\n由于是非抢占式的，因此 P1 运行过程中其他进程的到达并不会导致重新调度，P1 得以完全运行\nP1 结束时，剩余进程都已到达，处于 ready 状态，因此调度器从 ready queue 中选取 brust time 最短的来运行，以此类推。[一个进程运行结束后进行再调度]\n\n​Preemptive: Shortest-remaining-time-first(SRTF)\n​每当 CPU 调度时（注意抢占式调度的调度时机），选择最短剩余运行时间的进程。\n\n\n在这个情境中，0s 时只有 P1 到达，因此 P1 先运行\n但不同的是，由于是抢占式的，因此 2s P2 到达时也会引发一次调度，此时 P1 的剩余时间是 8s，P2 是 6s，因此 P2 优先运行\n4s 时 P3 到达也引发一次调度，但此时 P1 的剩余时间是 8s，P2 是 4s，P3 是 7s，其中 P2 最短，因此仍然是 P2 继续运行[新进程到达时发生一次调度]\n5s 时 P4 到达也引发一次调度，此时 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，P4 是 2s，其中 P4 最短，因此 P4 优先运行\nP4 运行结束时，ready queue 中 P1 的剩余时间是 8s，P2 是 3s，P3 是 7s，因此 P2 先运行，以此类推。\n​SJF 的两个版本都可以获得最小的平均等待时间，但最大的问题在于我们并不知道「下一次运行时间 」。解决方案是预测，将下次执行时间预测为此前 CPU 执行长度的指数平均。指数平均需要操作系统统计该进程此前的运行情况\n\n\nRound-Robin (RR) | Preemptive flashcard\n定义一个 时间片 (time slice / time quantum) ，即一个固定的较小时间单元 (10-100ms)。\n\n除非一个 process 是 ready queue 中的唯一进程，它不会连续运行超过一个时间片的时间。\nReady queue 是一个 FIFO 的循环队列。每次调度时取出 ready queue 中的第一个进程，设置一个计时器使得进程在一个时间片后发生中断，然后 dispatch the process。\n\n相比 SJF 而言，平均等待时间更长，但响应时间更短。\n​RR scheduling 的性能很大程度上取决于时间片的大小。如果时间片较小，则 response/interactivity 会很好，但会有较大的 overhead，因为有较多的 context-switch；时间片较大则响应较差，但 overhead 会较小。\n如果时间片无限大，则 RR≈FCFS。\n在实践中，时间片大约 10~100ms，每次 contest-switch 约 10μs。即 context-switch 的时间花费是比较小的。\n\n\nPriority Scheduling flashcard\n每个进程都有一个优先级，每次调度时选取最高优先级的进程。（下例中规定优先级值小的优先级高）\n优先级可以是内部的或者外部的：\n\ninternal: 一些测量数据，例如 SJF 是 Priority 的一个特例，即优先级由预测 CPU 运行时间决定。\nexternal: 由用户指定进程的重要性。\n​要实现 Priority Scheduling，可以简单地将 ready queue 用 priority queue 实现；priority queue 也可以是抢占式或非抢占式的，如 SJF 一样。\n​Priority 的一个重要问题是 indefinite blocking / starvation ，即低优先级的进程可能永远没有机会被执行。一个解决方法是 Priority Aging ，即根据等待时间逐渐增加在系统中等待的进程的优先级。\n\n\nMultilevel Queue Scheduling flashcard\n在实际应用中，进程通常被分为不同的组，每个组有一个自己的 ready queue，且每个队列内部有自己独立的调度算法。\n\n前台队列使用 RR 调度以保证 response，后台队列可以使用 FCFS。\n队列之间也应当有调度。通常使用 preemptive priority scheduling，即当且仅当高优先级的队列（如前台队列）为空时，低优先级的队列（如后台队列）中的进程才能获准运行。\n使用队列间的 time-slicing，例如一个队列使用 80% 的时间片而另一个使用 20%。\n\n\n\nMultilevel Feedback Queue Scheduling flashcard\n​Multilevel Feedback Queue Scheduling 允许进程在队列之间迁移。这种算法可以有很多种实现，因为队列的数量、每个队列中的调度策略、队列之间的调度算法以及将进程升级到更高优先级/降级到更低优先级的队列的条件都是可变的。一个系统中的最优配置在另一个系统中不一定很好。这种算法也是最为复杂的。\n\n有三个队列 0, 1, 2，优先级逐次降低。\n当进程 ready 时被添加到 Q0 中，Q0 内部采用 RR Scheduling，的每个进程都有 8ms 的时间完成其运行，如果没有完成则被打断并进入 Q1；\n只有当 Q0 为空时 Q1 才可能被运行。Q1 内部也使用 RR Scheduling，每个进程有 16ms 时间完成其运行，如果没有完成则被打断并进入 Q2；\n只有当 Q1 也为空时 Q2 才可能被运行。Q2 内部采用 FCFS 算法。\n"},"课程笔记/操作系统/02.3-线程":{"slug":"课程笔记/操作系统/02.3-线程","filePath":"课程笔记/操作系统/02.3 线程.md","title":"02.3 线程","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n多线程编程Multi-Threaded Programming flashcard\n》线程是一种轻量级的进程，它在进程的基础上进行划分，是进程内的一个可调度的执行单元，以减小进程 folk 和切换的开销为目的。\n》对于支持线程的操作系统，实际调度的是内核级线程而非进程。也就是说，线程是运行以及 CPU 调度的基本单元。（而进程是分配资源的基本单元。）\n同一进程的若干线程\n\n共享代码、数据等“相对静态”的资源\n各自维护寄存器、栈、PC 等“相对动态”的资源\n\n优点\n\n立线程相比进程是很经济的，因为 code, data &amp; heap 已经在内存中了。在同一进程的线程间进行 context switch 时也会更快，因为不需要 cache flush\n线程天生和同一进程内的其它线程共享资源，因此同进程内线程天生就有线程间通信的能力。不需要IPC（inter-process communication）进行不同进程间交流\n同时，由于将进程进行了再划分，一方面在硬件支持的情况下能更好地适配并行，另一方面也能（代价更小地）让任务的粒度变小，此时可以将整个进程的阻塞转移到单个线程的阻塞上，进一步减少响应时间。\n\n缺点\n\n虽然将若干任务都放到一个进程的多线程可以提高效率，但是一旦“篮子”坏了，那所有“鸡蛋”都无法幸免；\n其次，虽然天然的共享属性让线程能更方便地进行线程间通信，但也带来了内存保护的问题。\n由于 OS 对每个进程地址空间的大小限制，多线程可能会使得进程的内存限制更加紧缩（这在 64 位体系结构中不再是问题）\n\n\n线程实现方式 flashcard\n按照线程划分的实现位置，多线程模型分为\n\n用户级多线程(user threads)\n\n它在操作系统上只是一个进程，这个进程包含 线程库 (Thread Library) 的部分，​这部分代码负责完成线程的创建、切换等操作；\n\n\n内核级多线程(kernel threads)。\n\n内核级线程则是由操作系统支持这些操作。\n两者各有优缺点：\n\n\n用户级多线程 &gt; 内核级多线程\n\n用户级多线程不需要进入内核态实现多线程，也不需要占用线程 ID，因此理论上可以比内核级支持更多的线程数；\n由于其划分是针对进程的，而不同进程之间的线程实现没有直接关系，而且由于是在用户空间实现算法，所以能够更容易的对单个进程内的多个线程的调度算法进行自定义；\n\n\n用户级多线程 &lt; 内核级多线程\n\n由于对内核来说，用户级多线程仍然是一个普通的进程，所以当用户级的线程出现阻塞时，内核会认为整个进程都被阻塞；内核级线程由于是内核实现，所以单线程的阻塞并不会导致整个进程阻塞；\n在多核的情况下，用户级多线程没法利用多核进行线程并行；只有内核 (OS) 才能把工作分配到不同的 CPU 核心上\n\n\n\n\n多线程主要模型 flashcard\n需要注意的是，用户级多线程和内核级多线程并不冲突，因而排列组合后得到多线程主要有如下三种模型：\n\n(a) One-to-one model. (b) Many-to-many model. (c) Many-to-one model.\n\n每个用户线程都创建一个内核线程，开销大，但是不会有一个阻塞都被阻塞的问题\n可以智能地调度userthread要用哪个kernelthread，一个被阻塞了就换另一个kernelthread工作\n只给kernelthreads分配一个CPUcore，一个被阻塞就会都被阻塞[kernelthread的阻塞问题]\n\n\n\n线程池\n\n适用场景：大量同时并发任务处理"},"课程笔记/操作系统/03.1-进程同步及其工具":{"slug":"课程笔记/操作系统/03.1-进程同步及其工具","filePath":"课程笔记/操作系统/03.1 进程同步及其工具.md","title":"03.1 进程同步及其工具","links":["tags/flashcard"],"tags":["flashcard"],"content":"\n并发: 同时运行但不一定完全对齐重叠,\n并行: 更加严格\n\n\n「​同步」的核心意义是，规定进程所做的工作之间的顺序或者先序关系，从而防止一些非法情况的发生。\n\n为什么需要同步\n\n Cooperating Process 是可以影响系统中其他运行进程或被其他进程影响的进程。\nCooperating processes 会共同使用一些数据\n\n可能是直接使用同一段地址空间（代码+数据）\n或者是通过共享的内存或信息传递来共用一些数据。\n\n\n因为数据的一致性需要 cooperating processes 有序的运行[与操作的时序有关]。对数据的同时访问 (concurrent access) 可能会导致 data inconsistency\n\nrace condition:\n\n多个进程同时操控同一个数据，因而结果取决于每一种操控的出现顺序的情形\n防止 race condition，我们需要保证同一时间只有一个进程可以操控某个变量。\n\nBounded-buffer Problem中的race condition问题\n给定两个进程：producer 和 consumer，它们共用大小为  的 buffer。Producer 生产数据放入 buffer，consumer 从 buffer 取出数据从而使用之。\n该问题需要保证：producer 不应当在 buffer 满时放入数据，consumer 也不应当在 buffer 空时取出数据。\n我们可能想要像这样实现这两个进程：\n/* Producer Process */\nwhile (true) {\n    /* produce an item in next_produced */\n    while (count == BUFFER_SIZE)\n        ; /* do nothing */\n    //直到消费者取走一个数据,导致count&lt;buffer_size\n    buffer[in] = next_produced;\n    in = (in + 1) % BUFFER_SIZE;\n    count++;\n}\n \n/* Consumer Process */\nwhile (true) {\n    while (count == 0)\n        ; /* do nothing */\n    next_consumed = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    count--;\n    /* consume the item in next_consumed */\n}\ncount++ (生产者做的) ：\n\nregister1 = count: 把内存里的数搬到 CPU 寄存器里\nregister1 = register1 + 1: 寄存器加 1\ncount = register1: 把算好的新值写回内存\ncount-- (消费者做的) 同理，也是搬运、减 1、写回。\n但是一系列操作是可以被打断的,所以可能会有下述运行顺序导致count值发生错误\n\nkernel中请求子进程pid中的race condition问题\n\n同时都去获取一个子进程pid,但是next_available_pid还未来得及更新的情况\nThe Critical-Section Problem flashcard\n\n考虑一个有 n 个进程的系统，每个进程中都有这样一段代码，它可能会修改一些与其他至少一个进程公用的数据，这段代码称为 critical section\n\n这个系统需要满足的重要性质是：当一个进程正在运行它的 critical section 时，其他进程都不能进入它的 critical section。\n\n\n需要设计一种能让各个进程 同步 (synchronize) 它们的活动，从而安全地共享数据的协议。\n\n\n\n​\nCritical-section problem 的解决方法必须满足如下三个要求 flashcard\n\nMutual exclusion:没有两个进程可以同时运行 critical section。\nProgress:系统整体上是在运行的,\nBounded waiting :提出请求后不会无限等待,最终一定能够进入 critical section\n\n\nkernel中的CS problem\n\n\n​对于单核系统，我们可以通过在 critical section 中禁止中断[即在 entry section 中 disable，在 exit section 中 enable]的方式来实现上述功能（虽然可能是危险的）\n\n\n但是对于多核系统，中断禁止的消息要传到所有核[不然别的进程会进入自己的cs]，消息传递会延迟进入临界区，会降低效率；同时也会影响时钟中断。\n\n\n我们需要保证 kernel 的设计实现了 critical section。Kernel 的实现分为两种类型\n\n分别是 抢占式内核 preemptive kernel 和 非抢占式内核 nonpreemptive kernel，其区别是是否允许处于 kernel mode 的进程被抢占。\n\n\n\n对单核来说\n\n非抢占式内核不会导致 kernel mode 的 race condition，因为在任一时间点只有一个进程能在内核态里跑.\n​抢占式内核要解决 critical-section problem 的话相对而言更难设计，但是同时也能有更快的响应。\n\n\n\n关于处理器/核/内核态/用户态的辨析.\n\n\nCPU(通常指物理封装的芯片)上可能有单核/多核.一个核只能同时运行一个任务.\n\n核之间共享总线接口和3级缓存\n但是12级缓存和计算单元是属于核自己的\n\n\n内存是单独的,cpu也是单独的,cpu只是加载内核代码去跑而已.实际上,内核态和用户态本质上没有区别,只是特权模式\\特权寄存器\\访问代码权限的区别.\n\n\nPeterson’s Solution\nPeterson’s solution 基于一定的假设解决了两个 task 的 synchornization：\nint turn;           // Who is allowed to enter\nboolean flag[2];    // Ready to enter its CS\n \nvoid foo() {\n    while (true) {\n        flag[i] = true;     // Mark self ready\n        turn = 1 - i;       // Assert that if the other process wishes to 如果我是1那么1-i就是0,如果我是0那么1-i就是1,这是一个谦让策略.\n                            // enter its CS, it can do so.\n        while (flag[1 - i] &amp;&amp; turn == 1 - i);   // Wait\n        /* critical section */\n        flag[i] = false;    // Set ready to false\n        /* remainder section */\n    }//谁最后执行 `turn = 1 - i`，谁就会因为“太客气”而被卡在门口等待\n}\n其中， i 是 0 或 1，表示第 i 个进程； turn 是当前有权进入 critical section 的进程（0 或 1）； flag[i] 是第 i 个进程是否准备好进入 critical section，初始值均为 FALSE。\n性质证明\n通过简易的分类讨论证明 Peterson’s Solution 满足三个性质：Mutual exclusion, process and bounded waiting。\n\np0已经在cs里面的时候p1无法进入\n\n如果p0成功进入cs,那么while (flag[1] &amp;&amp; turn == 1)为假.\np1的情况:可能是flag[1] = false,他自己不想进.或者flag[1] = true 但 turn = 1,但是这和上一条矛盾了.因此不存在.\nflag[1] = true 且 turn = 0符合.\n\n\n如果没有人在cs内,且有人想进去,就可以进,不会导致死锁\n\n因为 turn 或者是 0，或者是 1，不可能既是 0 又是 1。总有一个人能突破循环\n\n\n杜绝了饥饿\n\n当p1出来的时候会执行flag[1] = false,可以当p0进去.不会导致p0一直无法进入cs\n\n\n\nReordering\n1. 指令重排\n但实际上，Peterson’s solution 在现代计算机体系结构上不一定适用，因为现代的处理器和编译器有可能会为了优化性能而对一些读写操作进行重排。\n在优化中，处理器或编译器会考虑其重排的合理性，即保证了在单线程程序中结果值是稳定且正确的。但是这不能保证其在多线程共用数据时的正确性，重排可能会导致不稳定或者不期望的输出。例如如果编译器将对 flag[i] 和 turn 赋值的顺序交换：\n\n2. 内存访问重排Memory Access Reordering\n因为存在读写缓存,所以就算指令的执行顺序不变, 内存层面上的顺序还是有可能发生变化\nMemory Barrier\n​重排可能使得在多核运行时出现与期望不同的结果。为了解决这个问题，我们引入 Memory Barrier：它用来保证其之前的内存访问先于其后的完成。即，我们保证在此前对内存的改变对其他处理器上的进程是可见的\n遇到这行命令就停下来直到内存读写完毕.\nMemory Model\n​另外，在现代的体系结构上，一个线程写了对应的变量后有可能不会立刻写回内存，这也有可能导致问题：\n计算机架构如何确定它将向应用程序提供什么样的内存保证，这被称为其内存模型。通常，内存模型分为以下两类之一：\n\nStrongly ordered, 一个处理器[在操作系统原理和并发编程的语境下,处理器=核!=CPU]上修改了内存,其他所有处理器会马上看到修改后的值,即大家看到的顺序一致.\n\n友好,但是频繁通讯.比如x86\n\n\nWeakly ordered, 与strongly相反,其他处理器不一定能马上看到 ,甚至可能看到乱序.\n\n灵活,性能高;但是危险,需要显式使用memorybarrier.比如arm核riscv\n\n\n\n硬件指令\n​许多现代系统提供硬件指令，用于检测和修改 word 的内容，或者用于 atomically（uniterruptably，不可被打断地）交换两个 word。这里，我们不讨论特定机器的特定指令，而是通过指令 test_and_set() 和 compare_and_swap() 抽象了解这些指令背后的主要概念。\ntest_and_set\n指令 test_and_set() 的功能可以按如下方式来定义：这一指令的重要特征是，它的执行是 atomic 的。\nbool test_and_set(bool *target) {\n    bool rv = *target;\n    *target = true;\n    return rv;\n}\n我们可以在支持这个指令的机器上实现 mutual exclusive：定义一个 bool 变量 lock ，初始化为 false。进程的结构为：\nwhile (true) {\n    /* Entry Section */\n    while (test_and_set(&amp;lock))     \n        ; /* do nothing */\n \n    /* Critical Section */\n \n    /* Exit Section */\n    lock = false;\n \n    /* Remainder Section */\n}\n\n如果 lock 在 Entry Section 时为 true，那么 test_and_set(&amp;lock) 将返回 true，因此会始终在 while 循环中循环。[锁住了,所以不能进入cs]\n到某个时刻 lock 为 false，那么 test_and_set(&amp;lock) 将返回 false 同时将 lock 置为 true，进程进入 Critical Section，同时保证其他进程无法进入 Critical Section。\n当持锁的进程完成 Critical Section 的运行，它在 Exit Section 中释放 lock ，从而允许其他进程进入 Critical Section。\n而如果某个时刻 lock 为 false，而有两个或多个进程几乎同时调用了 test_and_set(&amp;lock) 。但由于它是 atomic 的，因此只有一个进程可以返回 false。\n​但是，如上所示的控制不能满足 bounded waiting 条件：\n\n​我们可以作如下更改以满足 bounded waiting：\n\nwhile (true) {\n    /* Entry Section */\n    waiting[i] = true;\n    while (waiting[i] &amp;&amp; test_and_set(&amp;lock))   \n        ; /* do nothing */\n    waiting[i] = false;\n \n    /* Critical Section */\n \n    /* Exit Section */\n    j = (i + 1) % n;\n    while ((j != i) &amp;&amp; !waiting[j]))\n        j = (j + 1) % n;\n    if (j == i)\n        lock = false;\n    else\n        waiting[j] = false;\n \n    /* Remainder Section */\n}\n我们引入了 bool 数组 waiting[] \n\n在 Entry Section 中，我们首先置 waiting[i] 为 true；当 waiting[i] 或者 lock 中任意一个被释放时，进程可以进入 Critical Section。\n初始时， lock 为 false，第一个请求进入 CS 的进程可以获许运行。\n在 Exit Section 中，进程从下一个进程开始，遍历一遍所有进程，发现正在等待的进程时释放它的 waiting[j] ，使其获许进入 CS，当前进程继续 Remainder Section 的运行；\n如果没有任何进程在等待，那么它释放 lock ，使得之后第一个请求进入 CS 的进程可以直接获许。\n这样的方式可以保证每一个进程至多等待 n-1 个进程在其前面进入 CS，满足了 bounded waiting 条件。\n\ncompare_and_swap\n指令 compare_and_swap() 可以如下定义：同样，compare_and_swap() 的执行是 atomic 的。\nint compare_and_swap(int *value, int expected, int new_value) {\n    int temp = *value;\n    if (*value == expected)\n        *value = new_value;\n    return temp;\n}\n类似地，我们声明一个全局变量 lock ，初始值设为 0。进程的结构为：\nwhile (true) {\n    /* Entry Section */\n    while (compare_and_swap(&amp;lock, 0, 1) != 0)  \n        ; /* do nothing */\n \n    /* Critical Section */\n \n    /* Exit Section */\n    lock = 0;\n \n    /* Remainder Section */\n}\n可见，compare_and_swap() 和 test_and_set() 没有本质区别。上例 compare_and_swap() 的使用方法同样无法保证 bounded waiting，我们可以使用与 test_and_set() 同样的方式来解决。\nAtomic Vaviables\n​可以使用 compare_and_swap() 指令来实现一些工具。其中一个工具就是 Atomic Variable。\n​一个变量在更新的过程中可能会导致一个 race condition，而 Atomic Variable 可以为数据提供 atomic updates。例如，我们使用不可打断的 increment(&amp;count); 指令来代替可被打断的 count++ 指令就可以解决本节开头的 Bounded-buffer Problem：\nvoid increment(atomic_int *v) {\n    int temp;\n    do {\n        temp = *v;\n    } while (temp != compare_and_swap(v, temp, temp+1));\n}//如果还是temp,那么+1,如果不是的话就修改失败:cas返回v的值,发现确实不相等,继续循环.\n\n\n并不是为了让v一直保持某个值,而是为了v变化时原本的值不丢掉.如果两个操作读到同一个v的旧值,那么它们各自相加的话不会得到叠加的结果而是会有人被覆盖掉.如果用AtomicVariable,如果原本的数值被改了,就取最新的值,确保了数据没有被损坏.\nCAS操作本身是原子的\n\n\n但是需要注意的是，Atomic Variable 并不能解决所有 race condition，因为它解决的问题仅是变量更新过程中的 race condition。因为check和act之间存在时间差,所以这个时间内还是可能被打断.\nMutex\n​我们尝试设计软件工具来解决 CS problem。我们讨论 Mutex (MUTual EXclusion) Lock 的实现，它通常被认为是最简单的 synchronization tool。\n​我们考虑让进程在 Entry Section 申请 acquire() 一个锁，然后在 Exit Section release() 一个锁。对于这个锁，我们用一个布尔变量来表示它是否 available：\nwhile (true) {\n    acquire();\n    /* critical section */\n    release();\n    /* remainder section */\n}\n \n/* ------- */\nvoid acquire() {\n    while (!available)\n        ; /* busy waiting */\n    avaliable = false;\n}\n \nvoid release() {\n    avaliable = true;\n}\n我们需要保证 acquire() 和 release() 是 atomic 的。我们可以使用 test_and_set() 和 compare_and_swap() 来实现：\nvoid acquire() {\n    while (compare_and_swap(&amp;available, 1, 0) != 1)\n        ; /* busy waiting */\n}\n \nvoid release() {\n    available = true;\n}\n但是这种实现的缺点是，它需要 busy waiting，即当有一个进程在临界区中时，其他进程在请求进入临界区时在 acquire() 中持续等待，\n例如当两个进程同时使用一个 CPU 时：\nSemaphores\nPriority Inversion"},"课程笔记/操作系统/04.1-主存":{"slug":"课程笔记/操作系统/04.1-主存","filePath":"课程笔记/操作系统/04.1 主存.md","title":"04.1 主存","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n\n内存是一个很大的字节数组，CPU 根据 PC (Program Counter) 的值从内存中提取指令。程序需要运行，至少部分程序及其访问的数据应在内存中（或者更明确地，内存中的一个进程里）\nCPU 可以直接访问的通用存储只有 main memory 和 registers。对 registers 的访问通常可以在一个 CPU 时钟周期中完成，而完成内存的访问可能需要多个时钟周期。在这些时钟周期里，由于没有用来完成指令的数据，这会引起 stall）。\n\n为了补救，在 CPU 芯片上增设更快的内存，称为 cache 。\n\n\n同时，需要保护内存空间，防止用户程序修改操作系统或其他用户程序的代码或者数据。\n\nAddress Binding flashcard\n\n.c-&gt;.o的过程\n\n编译器complier将源代码中的地址绑定到Relocatable Address\n\n源代码中的地址通常是用符号表示（symbolic）： 例如各种变量、函数名；汇编中的 label 等\nRelocatable Address：可重定位地址。相对于某一个段/模块等的偏移，例如 sp - 8, ds:[0]。即把源代码符号地址背后的具体内容重排到源程序的相对位置\n\n\n\n\n.p-&gt;.exe（and其他可执行文件形式）的过程\n\n链接器linker 收集所有.o文件，将每个代码文件的地址绑定成相对整个程序的地址\n\n\n加载器loader 将可执行文件绑定到内存地址中，得到最终的绝对地址Absolute Address\n\n当然，如果编译器在编译时就知道程序所处的内存地址，则会生成 absolute code-》program in memory\n\n\n\n\n\n连续内存分配\n\n在 Batch（批处理）系统中，每次只有一个程序被加载入物理内存，并被运行至结束。\n\n如果程序所需的存储空间比物理内存大，则将程序分开为可以运行至产生某个结果且大小可以放入空余内存的部分，逐个运行，将运行结果传递给下一个部分。\n\n\n现在我们需要把多个进程同时放在内存中，并且支持其彼此之间的快速切换。最简单的内存分配方法之一，就是将内存分成许多的 partition，每个 partition 包含一个进程。其要求有：\n\nProtection: 保证进程之间不会互相闯入对方的存储。\nFast execution: 不能由于 protection 降低访问内存的效率。\nFast context switch: 每当进行 context switch 时，可以比较快地找到并访问当前进程的内存。\n\n\n当进程进入系统，操作系统根据各个进程的内存需要以及当前的空闲内存空间来决定为哪些进程分配内存。当一个进程被分配到了空间，他将被载入到内存中，并与其他进程竞争 CPU 时间。当一个进程结束时，它释放它的空间。\n如果一个进程请求空间来运行，但没有足够的内存来满足其要求\n\n直接拒绝其请求并给出一个错误信息\n或将其加入 waiting queue 中，当有内存被释放时 CPU 来检查是否为其分配内存。\n\n\n\n内存分区策略partion flashcard\nFixed Partition 固定大小partition\n\n固定 partition 的大小（除了 OS 使用的内存），只需要记录每个partition是否被占用即可。\nInternal Fragmentation：一个partition中剩余的空间不能够被别的进程所使用。【 不可用内存分布在 partition 之内】\n\nVariable Partition\n\n不固定 partition 的大小，维护一个表，记录可用和已用的内存。\n最开始时是一大块可用内存块（可用内存块称为hole），经过一段时间运行后可能就会包含一系列不同大小的孔\nExternal Fragmentation： 一段时间运行后，内存空间被分为大量的hole，加起来可以满足要求但是并不连续，所以无法被利用。【 不可用内存分布在 partition 之外】\n\n\n动态存储分配问题 Dynamic Storage-Allocation Problem flashcard\n根据一组 hole 来分配大小为 n 的请求，的问题\n解决方法有：\n\nfirst-fit 分配首个足够大的 hole。这种方法会使得分配集中在低地址区，并在此处产生大量的碎片，在每次尝试分配的时候都会遍历到，增大查找的开销。\nbest-fit 分配最小的足够大的 hole。除非空闲列表按大小排序，否则这种方法需要对整个列表进行遍历。这种方法同样会留下许多碎片。\nworst-fit 分配最大的 hole。同样，除非列表有序，否则我们需要遍历整个列表。这种方法的好处是每次分配后通常不会使剩下的空闲块太小，这在中小进程较多的情况下性能较好，并且产生碎片的几率更小。\n\n\n内存保护机制Protection flashcard\n保证一个进程能且仅能访问自己空间中的地址。通过一套 base 和 limit 寄存器来确定一个程序的空间：\n\n\n每当 context switch 到一个新的进程时，CPU 会 load 这两个寄存器的值\n每当 user mode 想要进行一次内存访问时，CPU 都要检查其是否试图访问非法地址；如果是，则会引发一个 trap 并被当做致命错误处理（通常会 terminate 掉进程 ）：\n\n\n分段Segmentation\nBasic Method\n虽然我们程序中的主函数、数组、符号表、子函数等等内部需要有一定的顺序，但是这些模块之间的先后顺序是无关紧要的。\n\n\n一个程序是由一组 segment （段）构成的，每个 segment 都有其名称和长度。我们只要知道 segment 在物理内存中的基地址 (base) 和段内偏移地址 (offset) 就可以对应到物理地址中了。\n对于每一个 segment，我们给其一个编号。即，我们通过二元有序组 表示了一个地址。这种表示称为 logical address（逻辑地址）或 virtual address（虚拟地址）。\n通常，在编译用户程序时，编译器会自动构造段。\n\nSegmentation—Logical Address &amp; MMU\n要将逻辑地址映射到物理地址，首先我们需要找到段的基地址。\n\nsegment table\n\n其中每个条目以 segment-number 索引\n存储其 段基地址 segment-base 和 段界限 segment-limit（可能还包含权限位）。\n因此逻辑地址的映射方式如下图：如果offset&lt;limit，则加上base得到物理地址\n\n\n这一过程是由硬件设备 MMU (Memory-Management Unit, 内存管理单元) 完成的。CPU 使用的是逻辑地址，而内存寻址使用的是物理地址，MMU 完成的是翻译（映射）和保护工作：这里的 relocation register 即为 base register。\n\nProblems\n分段将一个程序分为数个部分，但是其内存分配的策略与简单的 partition 是一致的。因此，分段仍然会存在 external fragmentation 的问题：其表征是总空余内存是足够的，但是由于它不连续导致其无法使用。也就是说，这个问题的核心点在于 not contiguous。我们有两种思路来解决这一问题：将\n\n内存重排使得 holes 连成一块\n\nCompaction 就是将内存中的内容重排使得所有空闲空间连续。这一操作要求内存中的程序是 relocatable  的，即其地址是相对 base 的偏移；这一要求在前面两种内存分配方式中是满足的。但是这一操作需要将内存逐一复制，这将消耗很多时间。\n\n\n或者设计方案让程序不再需要连续的地址。\n\n实际上，分段已经是这个方向上做出的一种尝试了，因为它将程序分为了几块，相比于简单的 partition，分段有助于减小 external fragmentation。为了更好地解决这个问题，我们提出 paging。\n\n\n\n分页Paging\nPaging （分页）是一种允许进程的物理地址空间不连续的内存管理方案。它避免了 external fragmentation 和 Compaction。各种形式的 paging 被大多数操作系统采用；实现 paging 需要 OS 和硬件的协作\nBasic Method\n\n物理地址:\n\n将 physical memory 切分成等大小的块（2 的幂，通常为 4KB = 2^12B ），称为 frames（帧）\n当一个进程要执行时，其内容填到一些可用的 frame 中，其中的每一个地址可以用这个 frame 的 base/number(唯一)以及相对这个 base 的 offset 表示\n\n\n逻辑地址:\n\n将 logical memory 切分成同样大小的块，称为 pages（页）\n同时 CPU 生成逻辑地址，逻辑地址包含一个 page number 和一个 page offset；另有一个 page table，它以 page number 索引，其中的第 i 项存储的是 page number 为 i 的 page 所在物理内存的 frame 的 base。这样，每一个 page 将通过其 page number 映射到一个 frame 上；进而 page 中的每一个地址也通过 offset 与frame中的对应地址建立映射。\n\n\n也就是说，当 MMU 需要将一个 logical address 翻译为 physical address 时，它需要获取 page number p，在 page table 中找到第 p 个 page 对应的的 frame number（也就是 frame base） f ，在 f 后面连接上 offset d 就得到了对应的 physical address。如我们之前所说，logical address 和 physical address 的 offset 应是一致的。\n\n当一个进程需要执行时，其每一页都需要一帧。因此，如果进程需要 n 页，则内存中需要有 n 个帧。如果有，那么就可以分配给新进程：进程的每一页装入一个帧，frame number 放入进程的 page table 中。\n由于操作系统管理物理内存，它应该知道物理内存的分配细节，即共有多少帧、帧是否空闲等。这些信息保存在 frame table 中，每个条目对应一个帧，保存其是否被占用；如果被占用，是被哪个进程的哪个页占用。\n\nWhy “Not Contiguous”\nPage table 硬件实现\n1. Simplest method\n最简单的方法是用一组专用的寄存器来实现。\n\n这一实现方法的优点是使用时非常迅速，因为对寄存器的访问是十分高效的。\n但是，由于成本等原因，寄存器的数量有限，因此这种方法要求 page table 的大小很小；同时，由于专用寄存器只有一组，因此 context switch 时需要存储并重新加载这些寄存器。\n\n2. Page table in memory &amp; PTBR\n\n大多数现代计算机允许页表非常大，因此对于这些机器，采用快速寄存器实现页表就不可行了。我们将页表放在内存中，并用 Page-Table Base Register (PTBR) 指向页表。在 context switch 时只需要修改 PTBR。\n但是这种方法的效率存在问题。要访问 logical address 对应的 physical address，我们首先要根据 PTBR 和 page number 来找到页表在内存的位置，并在其中得到 page 对应的 frame number，这需要一次内存访问；然后我们根据 frame number 和 page offset 算出真实的 physical address，并访问对应的字节内容。即，访问一个字节需要两次内存访问，这会加倍原本的内存访问的时间，这是难以接受的。\n\n3. TLB flashcard\n\n这个问题的解决方法用到一个专用的高速查找硬件 cache (associative memory，支持 parallel search)，这里称它为 translation look-aside buffer (TLB)。总之就是缓存!\nTLB 的每个条目由 key &amp; value 组成，分别表示 page number 和 frame number，通常有 641024 个条目（PPT 上说 641024，课本上说 32~1024，区别不大）\n当我们需要找到一个 page number 对应的 frame number 时，TLB 会 同时与其中所有的 key 进行比较：如果找到对应条目，就不必访问内存；如果没有找到（称为 TLB miss），则访问内存并将新的 key &amp; value 存入 TLB 中，这会替换掉 TLB 原有的一个条目。\n替换的策略包括 least recently used (LRU), round-robin, random 等。有些 TLB 支持将某些条目[比如重要的内核代码] wired down，即他们不会从 TLB 中被替换。在 MIPS 架构中，TLB miss 作为 exception 由操作系统处理；在 X86 架构中，TLB miss 由硬件处理。\n\n\nTLB with ASID\n\n每个进程都有自己的页表,每个页是按照多级结构存储的\n如同我们提到过的，每个 process 都有其自己的 page table。因此切换进程时也需要切换 page table。亦即，我们需要保证 TLB 与当前进程的 page table 是一致的。\n\n\n为了保证这一要求，我们可以在每次切换时 flush TLB。\n或者，有些 TLB 还在每个条目中保存 Address-Space Identifier (ASID)，每个 ASID 唯一标识一个进程。当 TLB 进行匹配时，除了 page number 外也对 ASID 进行匹配。\n\nEffective memory-access time EAT\n\nMemory Protection内存保护\n分页环境下的内存保护由与每个 frame 关联的 protection bits 实现。这些 bits 通常保存在页表中。例如 valid-invalid bit：\n\nv (Valid/有效)： 表示对应的页是进程合法地址空间的一部分，因此地址转换可以正常进行。\ni (Invalid/无效)： 表示对应的页不是进程合法地址空间的一部分，如果 CPU 试图生成该页号对应的地址，计算机将触发一个 trap (陷入) 到操作系统，表示这是一个无效的页引用 (invalid page reference)。\n如图所示，在一个具有 14 位地址空间（0 到 16383）的系统中，我们有一个程序应该仅使用地址 0 到 10468。给定页面大小为 2 KB，我们有如图 9.13 所示的情况。页面 0、1、2、3、4 和 5 中的地址通过页表正常映射。但是，尝试生成页面 6 或 7 中的地址会发现位被设置为无效，陷入无效页面引用异常\n注意，因为程序只延伸到地址 10468，任何超过该地址的引用都是非法的。然而，对页面 5 的引用被归类为有效的，所以对地址 12287 以内的访问都是有效的。只有从 12288 到 16383 的地址是无效的。这个问题是 2-KB 页面大小的结果，反映了分页的内部碎片。\n某些系统提供硬件形式的页表长度寄存器（PTLR），以指示页表的大小。这个值会针对每个逻辑地址进行检查，以验证该地址在进程的有效范围内。未通过此测试将导致对操作系统的错误陷阱。\n\nShared Pages\n分页可以允许进程间共享代码，例如同一程序的多个进程可以使用同一份代码，只要这份代码是 reentrant code （or non-self-modifying code : never changes between execution），如下图所示：图中所述的是多个进程共享一份库代码的情况；共享还可以用于进程之间的交流。当然，每个进程也可以有其自己的代码和数据。\n分页Problems\n\n会导致内部碎片。内存分配是以 frame 为单位执行的，如果进程要求的内存不是 frame 大小的整数倍，那么最后一个 frame 就会用不完，产生内部碎片。最坏的情况下，一个需要 n pages + 1 byte 的进程需要分配 n+1 个 frame，那么就会产生 FrameSize - 1 那么大的 Internal Fragmentation。\n如果进程的大小与页大小无关，每个进程中内部碎片的均值为 ½ FrameSize。在实际情况中，平均值比这小很多。当然，我们不能为了减小内部碎片而将 frame 的大小无限减小，因为更小的 frame size 需要更多的页表项。\n\nStructure of Page Table\n多级页表\n页表是一个数组， page_table[i] 中存储的是 page number 为 i 的 page 所对应的 frame number。考虑我们的逻辑地址结构：\n\n这样的逻辑地址结构需要一个存储 2^p 个元素的 page table，即需要这么大的连续内存，这是非常大的消耗。我们考虑将 p 再分为 p1 和 p2 ：\n\n两级页表， outer_page_table[i] 中存储的是 p1 为 i 的 inner page table，即inner_page_table[i][] 的基地址；\n而 inner_page_table[i][j] 中存储的就是 p1 为 i，p2 为 j 的 page 对应的 frame number，即 page number 为 p1p2 （没有分割时的 p）对应的 frame number。\n称 p1 为 page directory number ，p2 为 page table number，d 为 page offset。 \n逻辑地址 代替 物理地址满足了程序的 contiguous 要求。考虑这中分两页的 page table 结构，我们可以发现我们只是将 p 分成了两部分；对于程序来说，p+d 构成的整体（即逻辑地址）仍然是 contiguous 的，而且程序并不会意识到我们将 p 分成了 p1 和 p2 两部分，就像曾经它没有意识到我们将 address 分为了 p 和 d 两部分一样。这些划分只是我们为了更好地分配内存所做的、Operating-System-Level 的事情而已。\n考虑这样做的好处：hierarchical paging 其实就是对页表的分页（page the page table）。因此，它避免了 page table 必须处在连续内存的问题，这一问题在 p 比较大时尤其严重。\n另外，这样做在一般情况下可以节省空间。我们之前提到，页表不一定会全部使用；并且由于逻辑地址是连续的，因此用到的页表项也是连续的，都排在页表的头部。因此如果我们采用了二级页表，那么许多排在后面的 inner page table 将完全为空；此时我们可以直接不给这些 inner page table 分配空间，即我们只分配最大的 p1 那么多个 inner page table。这样我们可以节省很多空间。即使在最差的情况下，所有页表都被使用了，我们的页表所用的总条目数也只有类似地，我们可以设计更多级的页表。例如，64 位的逻辑地址空间使用二级页表就是不够的，否则它的页表就会长成这样：这样，我们就建立了一个三级页表。\n实际上，我们不必使用全部的 64 位，即我们不需要一个 64 位那么巨大的 virtual address space。AMD-64 支持 48-bit 的虚拟地址，ARM64 支持 39-bit 和 48-bit 的虚拟地址空间：\n\nHashed Page Tables 哈希页表\n前面介绍的页表是使用一个 table 保存 page# 对应的 frame#，这种解决方案面临的问题是空间需求是且连续的；我们通过多级页表解决这个问题。而哈希页表给 page# 分配 frame# 并不是随意分配，而是通过哈希计算得到。这样的方式将空间需求降低到且每个 page 对应的表项在内存中并不需要连续，从而解决了这个问题。哈希页表的每一个条目除了 page number 和 frame number 以外，还有一个指向有同一哈希值的下一个页表项的指针。这个结构与一般的哈希表是一致的。这是 32-bit address spaces 页表的一个常用方案。\nInverted Page Tables 倒排页表\n在之前的分页方法时，每个进程都有一个页表。这种方法会导致这些表可能使用大量的物理内存。\nInverted page tables 索引 physical address 而不是 logical address，也就是说，整个系统只有一个页表，并且每个物理内存的 frame 只有一条相应的条目。寻址时，CPU 遍历页表，找到对应的 pid 和 page number，其在页表中所处的位置即为 frame number：==页表的第 i 项（帧 i）存储了哪个进程的哪个页占用了这个帧，即存储了 (pid, p) 对。==\n\n这种做法的缺点是\n\n寻址过程需要很长时间。我们也可以用 TLB 或者 hashed table 来加速。\n这种方法不能够共享内存，因为 page table 的每一个条目（与 frame number 一一对应）只能存储一个 page number。\n传统页表是每个进程有一个独立的页表，把用到的页和对应的frame联系起来。倒排页表整个系统只有一个，第i项表示帧i，存储了哪个进程的哪个页占用了这个帧。\n\nSwapping\n\n进程的指令和数据必须在内存中以执行，但是我们可以将进程或进程的一部分暂时从内存 swap 到 ==backing store （备份存储，通常是一个比较快的磁盘）==中，继续运行时从中重新拿回到内存。\nSwapping 使得所有进程总的物理地址空间总和超过系统中真实的物理地址空间称为可能，提高了系统的 degree of multiprogramming。\n当然，在内存比较充足的情况下，swapping 并不必使用。Swapping 可能会导致很长的 context switch 用时，因为下一个进程可能并不在内存中，而由于磁盘的 I/O 很慢，swapping 到内存会花费很长时间。\n在分页的机制中，我们可以只 swap out 一些 pages，而不必 swap out 一整个进程：\n"},"课程笔记/操作系统/04.2-virtual-memory":{"slug":"课程笔记/操作系统/04.2-virtual-memory","filePath":"课程笔记/操作系统/04.2 virtual memory.md","title":"04.2 virtual memory","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::OS\n地址空间与异常\n地址空间 (address space) 指的是地址取值的全集。\n\n物理地址空间\n\n例如，对于一个 32 位寻址的体系结构，其 物理地址空间（物理地址的集合）就是 ，亦即 0x00000000 ~ 0xffffffff。\n- flat memory内存模型: 在引入分段 / 分页技术之前，各个进程和操作系统共同使用同一个物理地址空间。它会带来比较大的碎片，同时隔离性较差，内存的保护较弱。\n\n\n虚拟地址空间\n\n而在引入了分段 / 分页技术之后，每个进程都有了自己的一套 logical memory (a.k.a. virtual memory) ，其对应的的地址空间就叫做 逻辑地址空间 (logical address space) 或者 虚拟地址空间 (virtual address space)；而对应的段表 / 页表的作用就是提供从虚拟地址空间到物理地址空间的映射（映射过程中，由于 swapping 机制的存在，也有可能出现 swap 的过程）。\n\n\n我们知道，上述的映射过程由 OS 和 MMU 共同实现，因此进程的虚拟地址空间是被隔离的；只要 MMU 不出现问题以及页表不被篡改（这通常比较困难），其他进程就没有办法访问到这个进程的内存。\n也就是说，虚拟内存供软件使用，而 CPU 在访问对应的内存地址时会由 MMU 自动转换为对应的物理地址；如果对应的 page 不在物理内存中，就会触发一次 page fault，这是一个 exception。有 3 种可能的情况：\n\n当前的进程的页表中并没有这个虚拟地址对应的 page；\n权限不符，例如试图运行某个权限位是 RW- 的 page 中的代码，或者试图写入某个权限位是 R-X 或 R-- 的 page 中的某个内存单元；\n当前虚拟地址是合法的，但是对应的 page 被 swapped out 了。\n\n\n我们知道，exception 会交由操作系统处理；如果是前两种情况，操作系统应当报错并做相关处理（例如杀掉对应进程）；而如果是后一种情况，操作系统应当将进程阻塞，并将对应的 page 交换回来，调页完成后唤醒进程。\n在一条指令执行期间，可能触发多次 page fault（指令本身和访问的地址可能都不在物理内存中）。当 page fault 被解决后，指令被重新运行；因此一条指令在真正成功运行之前可能会被尝试运行多次。\n\nKernel Addresses &amp; Userspace Addresses flashcard\n\n每个进程的虚拟地址空间（下简称地址空间、AS）被分为了 Kernel Portion 和 User Portion\n\nkernel 模式下的代码可以访问这两块空间 [CPU 陷入内核代码，进入高权限，但它依然是在这个进程的上下文中工作]\nuser 模式下的代码只能访问 User Portion。\n\n\n每个进程的 AS 的 kernel portion 都映射到了同一块物理内存。原因是显然的：所有进程用到的都是同一套 kernel，因此没必要把 kernel 用的内存（存例如各个进程的页表、各种队列之类的东西）复制好几份。\n\n实现\n\n在 32 位虚拟地址空间（4GB）的设计里，kernel 默认使用高 1GB，各个进程的 user portion 使用低 3GB 的虚拟地址空间；通过在 build kernel 之前更改 CONFIG_PAGE_OFFSET 可以更改这一分配\n\n32位系统只使用一套页表\n\n\n对于 64 位虚拟地址空间的设计，由于根本用不了这么多，因此 kernel space 和 user space 被自然分隔开：其中 TTBR (Translation Table Base Register) 保存页表的基地址\n=TTBR0 管理的用户空间 + TTBR1 管理的内核空间。对应两套页表\nTTBR0 是每个进程的页表对应的 TTBR\nTTBR1 是 kernel portion 的页表对应的 TTBR。\n\n\n\n\n                  \n                  分配策略和置换策略的区别 \n                  \n                \n\n\n延迟分配 和 COW 是在内存充足时优化分配或复制的策略，目的是推迟或避免分配，从而节省内存。\n页面置换 是在内存不足时（物理帧耗尽）强制释放内存的策略，目的是在资源紧张时保证系统能继续运行。\n\n\n\n分配策略\nLazy Allocation / Demand Paging flashcard\n操作系统在分配 user space 的内存时，会使用 lazy allocation：\n\n当用户程序申请一块内存时，操作系统并不会真的立即在物理内存中分配对应的内存；直到这块内存被真正访问。\n原理: 很多用户程序申请的内存大小比真正需要使用的通常要大，例如 buffer 等。\n\n\n程序（例如通过 malloc 库函数）发现需要更多内存，于是调用 brk() 系统调用来请求扩大其堆（Heap）的边界。\n\n此时，虚拟堆大小为 8KB，物理内存占用（Rss - Resident Set Size）也是 8KB。\n\n\n内核响应 brk() 请求，仅仅扩大了进程的虚拟内存区域（VMA）。新的页面此时并未映射到任何物理内存。\n\n进程的虚拟堆大小（Size）增加到 16KB，但其物理内存占用（Rss）仍然是 8KB。内核只是在进程的虚拟地址空间中“画了一块饼”，但没有给它“真正的食物”（物理内存）。\n\n\n程序执行代码，试图第一次读取或写入刚刚申请到的新虚拟内存地址。\n\nCPU（通过 MMU）在页表中查找该虚拟地址，发现它没有任何对应的物理内存映射。\n处理器触发一个缺页中断（Page Fault）。这不是一个程序错误，而是一个给内核的信号。\n\n\n内核捕获这个中断，意识到这是一个合法的“按需分页”请求。\n- 它从可用的“free”列表中找到一个空闲的物理页帧（Page Frame）。\n- 内核将这个物理页帧映射到程序试图访问的虚拟地址。\n- 它为此创建或更新页表项（PTE - Page Table Entry）。\n- 状态： 物理内存占用（Rss）现在增加到 12KB（假设新分配的页是 4KB）。\n\n\nCopy-on-Write flashcard\n\n很多子进程在 fork() 之后立刻调用 exec()[创建一个复制的子进程,并且用一个全新的程序(可执行文件)的内容覆盖内核态中父进程的代码、数据、栈和堆.]因此将父进程的地址空间整个复制一份是比较浪费的明明马上就会被覆盖.\nCopy-on-Write机制允许父进程和子进程最初使用同一份物理页来进行工作，在任何一个进程需要写入某个共享 frame 时再进行复制。\n进一步地，Linux 等操作系统提供了 vfork()，进一步优化子进程在 fork() 之后立刻调用 exec() 的情形。vfork() 并不使用 copy-on-write；调用 vfork() 之后，父进程会被挂起，子进程使用父进程的地址空间。如果子进程此时修改地址空间中的任何页面，这些修改对父进程都是可见的。\n\n\n置换策略\nPage Replacement flashcard\n\n我们在Lazy Allocation或者Copy-on-Write讨论的情况下，或者在 kernel、I/O buffer 之类的情况下,需要从磁盘将页调入内存,会需要空闲的物理帧[需要有一个位置].\n\n但是没有空闲的物理帧时应该怎么办呢？我们可以交换出去一整个进程:\n\n将一个进程的所有页都写回磁盘（备份存储），释放它占用的所有帧。\n\n\n更常见地，我们找到一个当前不在使用的帧，并释放它。\n基本步骤是：\n\n\n\n\n找到这个 victim frame；\n将其内容写回备份存储swap space/disk；\n\n dirty bit (a.k.a. modify bit) 该位保存对应 frame 是否被修改过；如果没有被修改过,就不用写回\n\n\n调入 Page X： 将进程 P 缺失的 Page X 从硬盘（备份存储）调入到刚刚腾出的物理帧 F_A 中。\n修改页表（和 TLB 等）以表示它不在内存中了。\n\n将页表中的有效位设置为无效\n从TLB中删除对应条目\n如何确定哪个 frame 应当用来作为 victim frame 呢？我们的核心目标是，降低 page fault 的频率。\n\n\n\n\n\n\n                  \n                  如何从磁盘匹配和找回被换出的页面？ \n                  \n                \n\n被换出的页面总能被系统准确找回，这是因为页表和备份存储（Backing Store）有明确的记录机制。\n当下次 CPU 再次请求访问这个已被换出的页面时，步骤如下：\n\n触发缺页中断（Page Fault）： CPU 请求访问 Page X，MMU 查阅该进程的页表。页表显示 X 的 valid-invalid bit 设置为 无效（i），触发 Page Fault，控制权交给 OS 内核。\n定位 Page X： OS 检查页表中的其他信息（这些信息在页被换出时被记录）\n\n页表项： 页表项不再存储帧号，而是存储一个特殊标记，该标记指向 Page X 在**备份存储（磁盘）**上的确切位置（例如，交换空间中的块地址）。\n\n\n调页（Paging）：\n\nOS 执行页面置换流程（找到 Victim Frame）。\nOS 从备份存储中，根据第 2 步记录的地址，将 Page X 调入到这个 Victim Frame 中。\n\n\n更新页表： Page X 被调入后，OS 更新页表，将该页的 valid-invalid bit 设置为有效（v），并记录它现在所处的物理帧号。\n指令重执行： OS 将控制权交还给 CPU，让 CPU 重新执行被中断的那条指令。\n\n\n\n页面置换算法 (page replacement algorithms) flashcard\nOptimal\n这种算法选择 最长时间内不再被访问的页面 换出。容易证明，这种方案的 page-fault rate 是最低的。不过，由于实际实现中我们没有办法预测结果，因此它只作为理论最优解用来判定其他算法的优劣。\nFIFO (First In First Out)\n这种算法换出 最先进入内存的页面。实现比较简单，使用一个队列保存调入内存的顺序即可。\n这种算法的问题是，其逻辑和实际不符；实际情况下有很多页面会经常被访问。\n另外，这种算法可能会遇到物理帧增加的时候 page-fault 反而更多的异常情况。这被称为 Belady’s Anomaly：\n\n123412512345是一次请求访问的页面号\n\n上半部分:限制进程只能使用 3 个帧。\n\n关键页 A 可能会在它再次被访问之前就被淘汰了（FIFO 逻辑）。\n\n\n下半部分:限制进程可以使用 4 个帧。\n\n由于内存变大，关键页 A 驻留的时间变长了。但与此同时，它占用的位置可能会导致另一个很快就要被用到的更关键的页 B 被提前淘汰，从而导致总体缺页次数增加\n\n\n\n\n\n\nLRU (Least Recently Used)\n\n实现的一种策略是给每个页表项一个 counter，每次访问某个 page 时，将 counter 更新为当前的时间[只要被用了,就会往后调,从淘汰最早变成了淘汰间隔最长]\n\n每次需要置换时，搜索 counter 最小的页。也可以用 heap 来优化。\n\n\n另一种策略是用一个栈保存 page numbers，每次访问时找到它然后把它挪到栈顶。\n这两种实现开销都比较大。\n\nLRU-Approximation\n\n因此，我们在 LRU 和性能之间做一个折中；引入一个 reference bit，来近似地实现 LRU。当一个 page 被访问时这个 bit 被置为 1；操作系统定期将 reference bit 清零。因此，在需要交换时，只需要找一个 reference bit 为 0 的就可以说明它在这段时间内没有被访问过。\n或者加上优先级bit\n加上counting bit 记录被访问的次数\n\n\n进阶策略\nAllocation of Frames\n为什么要分配frame\n\n\n采取 全局置换 (global replacement)\n\n当进程 A 发生缺页中断需要一个新的帧时，操作系统可以从所有物理帧中（即系统中所有进程 P1, P2, P3… 占用的帧）中选取一个 Victim Frame[灵活:更好的系统吞吐量但是不隔离:自己的pagefault率会取决于其他进程的运行状况]\n那么我们就不一定有必要提前规定每个进程最多能够使用多少个 frame；\n\n\n\n采取 局部替换 (local replacement)[隔离但僵化]\n\n只在当前进程分配到的物理帧中进行替换\n那么我们就需要提前把物理 frame 的资源分配给各个进程[要划分好区间不然就跟全局置换一样了]。\n\n\n\n当我们需要决定一个进程能够使用的页面总数时，我们在上述最小和最大的区间内有非常多的选择，这就引入了分配算法。常见的分配算法包括平均分配，或者按进程对内存的实际需求按比例分配；也可以参考进程的优先级，高优先级相对分配到的更多，或者更能满足其实际需求。\n\n\n现在的很多计算机都有多个 CPU，而每个 CPU 都可以比其他 CPU 更快地访问内存的某些部分。如果这种差异比较明显，我们称这种系统为 非均匀内存访问 (NUMA, Non-Uniform Memory Access) 系统。在这种系统下，为了更好的性能表现，前述的分配和调页算法可能更加复杂。\n\n\n分配多少个 Frames\n给每个进程分配多少个 frame 呢？\n\n最大值不可能超过物理内存包含的 frame 总数\n最小值是由具体的计算机架构决定的。[作系统只需要确保在执行任意一条指令时，该进程拥有足够的帧来容纳该指令涉及的所有页。因此最小值是最复杂的那条指令的帧]\n\n指令在解决其涉及的全部 page fault 之后才能真正被运行[指令是原子操作,如果发生pagefault,cpu会暂停当前指令并进行中断处理]\n因此每个进程分配的 frame 的最小值不应小于单个指令可能使用到的 frame 总数[允许指令运行,是最低要求,还会有其他帧来存储整个进程的代码\\全局变量\\堆\\栈等等]。一般情况如下\n\n指令本身:1个page[指令会进行对齐]\n两个访问内存的操作数，其中每个操作数访问的内存[可能]跨越 2 个 page（即，这块数据在一个 page 的末尾和下一个 page 的开头）\n那么这个架构上运行的进程的 minimum frame number 是 5。\n\n\n\n\n\nThrashing  flashcard\n\n如果一个进程可用的帧数量比较少（少于其频繁访问的页面数目），那么它会频繁出现 page fault；同一个 page 可能会被频繁地换入换出，以满足运行的要求。这种高度的页面调度活动成为称为 抖动 (thrashing)；其调页时间甚至会大于执行时间。\n工作集模型 (working set model) 用来确定一个进程频繁访问的页面，保证这些页面不被换出；需要调页时从剩余的页面进行交换。如果频繁访问的页面数已经大于了当前进程可用的页面数，操作系统就应当把整个进程换出，以防止出现抖动现象。\n\n\nKernel Memory Allocation\n\nKernel 中的很多数据结构大小区分比较大，其中很多小于甚至远小于一个 page.因此，kernel 的设计应当尽可能节省内存，努力减少碎片。\n尽可能减小 kernel 内存开销的考虑是：\n\n一方面，kernel 有可能有一部分常驻在物理内存中，不受调页系统的控制\n另一方面，有的硬件设备可能和物理内存直接交互，因此可能会需要连续的物理内存。\n这两者对物理内存的要求都比较严格，因此我们应当尽可能减小这些开销。\n\n\n\nBuddy System flashcard\n\nBuddy system 从物理连续的段上分配内存；每次分配内存大小是 2 的幂次方，例如请求是 11KB，则分配 16KB。\n当分配时，从物理段上切分出对应的大小，例如下图体现了分配 21KB 时的情况， 会被分配。\n当它被释放时，会 合并 (coalesce) 相邻的块形成更大的块供之后使用。\n\n\nSlab Allocation flashcard\n核心的原理是，操作系统中很多 object 的大小是已知且固定的[PCB/socket buffers/PTE之类的]。内存被划分成若干个固定大小的块，每个块都被分配给一个具体的类型。当进程需要分配内存时，它会查询缓存，如果找到一个空闲的块，就直接使用该块；如果缓存中没有空闲的块，就会从系统内存中申请一个新的块：\n"},"课程笔记/操作系统/其他/lab4-report":{"slug":"课程笔记/操作系统/其他/lab4-report","filePath":"课程笔记/操作系统/其他/lab4 report.md","title":"lab4 report","links":[],"tags":[],"content":"小组成员: 邓静怡,肖惠文\n准备工作\n\n\n从仓库拉取最新的代码\n\n\n修改 vmlinux.lds，将用户态程序 uapp 加载至 .data 段\n\n\n\n修改makefile编译且链接新的文件夹\n\n\n创建用户态进程\n更新结构体\n\n本次实验只需要创建4个用户态进程\n将特权寄存器设置到thread_struct中\n\n为多个用户态进程设置自己的页表\n\n内核线程可以共享一个页表,多个用户态进程则需要保证相对隔离\n\n修改task_init\n对于每个用户进程的初始化:\n\n增加用户态标志位\n\n初始化 sepc、sstatus、sscratch\n\n创建页表并复制内核页表到创建的页表中\n\n\n复制递归函数入口\n\n复制递归函数实现\n\n如果是一级/二级页表,就对页表的每一项(共512项)\n1. 从源页表PTE中提取下一级页表的物理地址\n2. 为新页表分配下级页表的空间,递归复制下级页表\n3. 为新页表PTE设置好对下级页表指向\n如果是三级页表.复制源页表的每一项即可.\n\n\n\n\n\n分配一块新的内存地址,拷贝 uapp 进去.然后将页面映射到页表中\n\n先计算所需的页数（uapp 的大小除以 PGSIZE 后向上取整）\n调用 alloc_pages() 函数\n再将 uapp memcpy 过去\n\n映射到页表中.\n\n\n\n设置栈-两个\n\n用户态栈：我们可以申请一个空的页面来作为用户态栈，并映射到进程的页表中\n\n内核态栈: 在 lab3 中已经设置好了，就是 thread.sp\n\n\n\nalloc_pages:\n\n分配物理页号并转换为虚拟地址返回.\nuapp:\n用户程序,编译生成uapp.bin纯二进制文件,链接时放入内核数据段.然后为每个进程拷贝一份uapp[到新分配的物理内存中][并且重新映射到用户进程自己的虚拟地址],防止冲突.\n每个用户态进程有自己的虚拟地址0x0 → 0x4000000000 (USER_END)\n\n切换逻辑\n由另一位同学负责\n异常分发与调试\n由另一位同学负责\nELF 解析与系统调用实现\n系统调用实现\n\n在发生系统调用异常时,调用系统调用处理函数\n\n进入系统调用处理函数,根据系统调用号分发到各个分处理函数,传入不同的参数\n\n然后设置regs中的返回值并手动将sepc+4\n\nwrite() 逻辑\n\ngetpid()逻辑\n\n\n\n\nELF\n\n\nsection:细粒度\n\n\nsegment:粗粒度.一个segment里面可能包含多个section.我们按segment为单位加载到内存\n\n\nELF header: 包含入口地址\\program headers在文件中的偏移量\\有多少个program headers(需要加载的段)\n\n\nprogram header: 每个program header描述一个segment\n\n段类型:是否需要加载\n在文件中的位置:从文件第几个字节开始\n虚拟地址:加载到内存的哪个地址\n文件里这段有多大size\n内存里需要多大空间\n权限\n\n\n\n未初始化数据在文件中不需要存储,只需要记录有多大\n但是在内存中就需要确切地分配好空间.file大小和mem大小的的差别就在这里(bss段.)加载之后直接清零即可\n\n更换payload\n\n修改task_init初始化步骤\n\n\n将原本读取二进制文件相关代码修改为使用 ELF 解析和加载程序\n分配完用户态栈后,设置sscratch寄存器\n\n\nELF加载函数\n\n内核区读取 ELF 信息[本实验中所有进程共用一个uapp因此是读取一样的代码和数据]\n\n为这个程序的每个 segment 分配独立的物理内存\n\n计算需要映射的内存大小并计算需要映射的页数\n\n按照页对齐分配物理内存\n\n将段内容从ELF文件拷贝到分配的内存[拷贝filesize]\n\n将bbs段空间清零[memsize-filesize]\n\n设置权限\n\n\n\n建立虚拟地址映射\n\n设置程序入口地址sepc[ELF]\n\n\n\n\n编译并运行\n\n思考题\n\n\n我们在实验中使用的用户态线程和内核态线程的对应关系是怎样的？（一对一，一对多，多对一还是多对多，言之有理即可）\n实验里调度的基本单位就是 task_struct.它同时保存了内核线程的寄存器上下文和对应用户态的关键寄存器.调度器每次切换的其实是这个结构本身,这个结构又只对应一个用户态进程.而没有在多个用户线程之间再映射同一个内核线程,因此可以认为是一对一的关系.\n\n\n系统调用返回为什么不能直接修改寄存器？\n陷入内核时 _traps 会把所有寄存器复制到 pt_regs,真正返回用户态时会从 pt_regs 恢复.如果内核里直接改真实寄存器,下一次 sret 恢复又会被 pt_regs 覆盖,所以必须写回 regs→a0 等保存区，保证状态一致.\n\n\n针对系统调用，为什么要手动将 sepc + 4？\nsepc 保留触发异常的指令地址.ecall 是一条 4 字节的指令,如果不手动加 4,sret 回去后还会再次执行同一条 ecall,进入死循环,所以要显式加 4 跳过它.\n\n\n为什么 Phdr 中，p_filesz 和 p_memsz 是不一样大的，它们分别表示什么？\np_filesz 是 segment 在 ELF 文件里真实占用的字节，比如 .text、.data；p_memsz 是进程运行时需要的内存大小，它还包含 .bss 这种在文件里不占空间,但运行时要被清零的部分，所以常常更大.加载时要先拷贝 p_filesz 区间,再把 p_filesz 到 p_memsz 清零.\n\n\n为什么多个进程的栈虚拟地址可以相同？用户态程序有没有方法知道栈所在的物理地址？\n每个进程有私有页表,把同一个用户栈虚拟地址映射到不同的物理页.因为用户态无法访问页表,也不能读取物理地址,所以它看不到真实物理位置,只能按虚拟地址使用,来做到地址空间隔离.\n\n\n心得体会\n\nELF: 一种可执行文件格式,里面除了代码和数据以外还包括目录[说明文件结构\\入口点\\段信息],以及附录[符号表,调试信息等]\n纯二进制文件: 只包含代码和数据,没有目录和附录\nstrip: 去掉ELF中非必须信息的过程.一般是用 objcopy 将 ELF 转换为纯二进制（.bin）\n先运行纯二进制文件,再切换成ELF文件.是为了通过简单操作验证基本流程是否正常,再切换到ELF支持更复杂的功能\n\n用户态进行系统调用的过程\n\n用户态调用ecall\ncpu会自动做的事情\n\n保存异常发生的PC到sepc\n记录异常原因到scause\n记录来自Umode到s’s’tasstatus\n切换到Smode\nstvec写入PC: 跳转到_traps\n\n\ntraps会切换栈:\n\n从用户栈切换到内核栈\n在内核栈上分配空间[pt_regs]并保存寄存器\n\n\n调用handler,调用的时候会覆盖原本的寄存器\n\nsie: 中断类型开关.决定哪些终端类型可以作用\nsstatus.sie: s态全局开关,决定在s态(内核态执行时),是否允许中断.\n当cpu在用户态运行时,特权级的中断总是启用的,不管sstatus是如何设置的."},"课程笔记/操作系统/流程总览/01-系统启动与进程创建":{"slug":"课程笔记/操作系统/流程总览/01-系统启动与进程创建","filePath":"课程笔记/操作系统/流程总览/01 系统启动与进程创建.md","title":"01 系统启动与进程创建","links":["课程笔记/操作系统/01-introduction","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"系统启动流程\n上电与引导\n计算机上电后的启动过程：\n\nCPU执行ROM中的引导加载器（bootstrap loader）\n\n这是开机后执行的第一个软件\n位置固定且已知\n\n\n引导加载器完成的任务\n\n硬件自检（POST）\n定位磁盘上的操作系统内核镜像\n将内核加载到主内存（RAM）\n切换CPU为内核态，开始执行内核代码\n\n\n\n内核初始化\n内核加载到内存后的初始化步骤：\n初始化中断系统\n\n设置中断向量表（interrupt vector table）\n\n建立中断号到中断处理程序的映射\n\n\n配置中断请求线（interrupt-request line）\n初始化计时器（timer）\n\n用于时间片管理\n\n\n\n初始化内存管理\n\n建立物理内存的帧表（frame table）\n\n记录每个物理帧的使用情况\n\n\n初始化内核的页表结构\n设置内存保护机制\n\n初始化进程管理\n\n创建初始的内核数据结构\n准备就绪队列（ready queue）\n准备等待队列（wait queue）\n\n创建第一个用户进程\n内核初始化完成后，创建第一个用户进程：\n\nLinux中通常是init或systemd\n进程ID（PID）为1\n\n创建步骤：\n\n分配进程控制块（PCB）\n建立虚拟地址空间\n建立页表映射\n通过加载器（loader）加载可执行文件\n切换到用户态并开始执行\n\n程序的地址绑定\n程序从源代码到内存的完整过程。\n编译、链接、加载\n\n\n编译阶段（.c → .o）\n\n编译器将源代码中的符号地址转换为可重定位地址\n符号地址：变量名、函数名等\n可重定位地址：相对于某个段的偏移\n\n\n\n链接阶段（.o → .exe）\n\n链接器将多个目标文件合并\n生成可执行文件\n地址变为相对于整个程序的地址\n\n\n\n加载阶段（.exe → 内存）\n\n加载器将可执行文件加载到内存\n完成地址绑定（Address Binding）\n得到绝对物理地址\n\n\n\n虚拟地址空间的建立\n每个进程拥有独立的虚拟地址空间：\n用户部分（User Portion）\n\ntext section：代码段\ndata section：全局变量、静态变量\nheap section：动态分配的内存（堆）\nstack section：函数调用、局部变量（栈）\n\n内核部分（Kernel Portion）\n\n存储PCB等内核数据结构\n所有进程的内核部分映射到同一块物理内存（参见Kernel Addresses &amp; Userspace Addresses）\n\n进程创建机制\nfork系统调用\nfork()是系统调用，用于创建子进程。\nfork的执行流程\n\n\n触发系统调用\n\n用户程序调用fork()\n触发软中断（trap）\nCPU切换到内核态\n\n\n\n内核创建子进程\n\n分配新的PCB\n子进程获得新的PID\n子进程的PPID指向父进程\n复制父进程的虚拟地址空间\n\n\n\n返回用户态\n\n父进程：fork()返回子进程的PID（非零值）\n子进程：fork()返回0\n两个进程从fork()后继续执行\n\n\n\nCopy-on-Write机制\nCopy-on-Write（COW）优化fork的性能：\n基本原理\n\nfork后，父子进程最初共享同一份物理页\n页表项标记为只读\n当任一进程尝试写入共享页时，触发写保护异常\n操作系统此时才真正复制该页\n\n优势\n\n节省内存空间\n提高fork效率\n特别适用于fork后立即exec的场景\n\nexec系统调用\nexec()用新程序覆盖当前进程的地址空间。\nexec的执行流程\n\n加载新的可执行文件\n\n从磁盘读取新程序\n解析可执行文件格式\n\n\n覆盖当前虚拟地址空间\n\n释放原有的页表映射\n建立新的页表映射\n\n\n重置执行环境\n\n重置程序计数器（PC）\n从新程序的入口点开始执行\n进程PID不变\n\n\n\nfork与exec的组合使用\n典型用法：\n\n父进程调用fork()创建子进程\n子进程调用exec()执行新程序\n父进程可选择调用wait()等待子进程结束\n\n示例场景：\n\nshell执行命令\n服务器处理请求\n\n进程的终止\n进程终止的方式（参见进程的终止）：\n正常终止\n\n调用exit()系统调用\nmain函数返回（隐式调用exit）\n\n异常终止\n\n信号终止\n异常导致的终止\n\n相关概念\n\n僵尸进程（zombie）：已终止但未被父进程回收\n孤儿进程（orphan）：父进程先于子进程终止\n\n相关概念\n\n01 introduction - 操作系统概述、中断、特权模式、引导\n02.1 进程 - 进程概念、PCB、进程创建与终止\n02.2 调度 - 进程状态、就绪队列、等待队列\n04.1 主存 - 内存保护、分页、页表、帧表\n04.2 virtual memory - 虚拟地址空间、COW机制\n"},"课程笔记/操作系统/流程总览/02-内存管理":{"slug":"课程笔记/操作系统/流程总览/02-内存管理","filePath":"课程笔记/操作系统/流程总览/02 内存管理.md","title":"02 内存管理","links":["课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"\n虚拟内存概述\n基本概念\n虚拟内存的作用\n\n每个进程拥有独立的虚拟地址空间\nCPU使用虚拟地址，由MMU（内存管理单元）自动转换为物理地址\n实现进程间的隔离与保护\n\n虚拟地址空间的结构\n\n用户空间（User Portion）：0 ~ 3GB（32位系统）\n\n\n\n\n内核空间（Kernel Portion）：3GB ~ 4GB（32位系统）\n\n\n\n\n所有进程的内核空间映射到同一块物理内存（参见Kernel Addresses &amp; Userspace Addresses）\n\n虚拟内存的优势\n\n隔离性：每个进程拥有独立的虚拟地址空间，互不干扰\n灵活性：进程可以使用比物理内存更大的虚拟地址空间\n效率：通过按需分页和页面置换，提高内存利用率\n共享性：多个进程可以共享同一块物理内存\n\n分页机制\n基本原理\n现代操作系统使用分页（Paging）机制管理内存。\n物理内存分帧\n\n将物理内存切分为等大小的帧（frame）\n通常大小为4KB\n\n虚拟内存分页\n\n将虚拟地址空间切分为等大小的页（page）\n大小与帧相同\n\n页表映射\n\n通过页表建立页到帧的映射关系\n页表存储在内存中\nPTBR（Page-Table Base Register）指向页表基地址\n\n地址转换过程\nCPU生成的虚拟地址转换为物理地址：\n\nCPU生成虚拟地址（page number + offset）\nMMU根据页表将page number转换为frame number\n物理地址 = frame number + offset\n\n地址结构\n\n虚拟地址 = 页号（p） + 页内偏移（d）\n物理地址 = 帧号（f） + 页内偏移（d）\n页内偏移在转换前后保持不变\n\n页表的硬件实现\n页表存储方式\n寄存器方式\n\n优点：访问速度快\n缺点：页表大小受限，上下文切换开销大\n适用于小型页表\n\n内存方式\n\nPTBR指向页表基地址\n优点：支持大型页表\n缺点：每次地址转换需要两次内存访问\n\nTLB加速机制\nTLB（Translation Look-aside Buffer）是页表的高速缓存：\n工作原理\n\nCPU访问虚拟地址时，首先查询TLB\nTLB命中：直接获得物理地址（一次内存访问）\nTLB未命中：访问内存中的页表（两次内存访问），并将结果存入TLB\n\nTLB特点\n\n支持并行搜索（associative memory）\n通常包含64~1024个条目\n每个条目包含：page number → frame number\n\nTLB与进程切换\n\n每个进程有自己的页表，切换时需要处理TLB\n方法1：flush TLB（清空所有TLB条目）\n方法2：使用ASID（Address-Space Identifier）\n\nTLB条目同时存储ASID\n匹配时同时检查page number和ASID\n避免频繁清空TLB\n\n\n\n多级页表\n为解决页表占用过多连续内存的问题，采用多级页表结构。\n基本思想\n\n对页表进行分页\n外层页表指向内层页表\n内层页表存储实际的frame number\n\n二级页表示例\n\n虚拟地址 = 外层页号（p1） + 内层页号（p2） + 页内偏移（d）\n通过p1索引外层页表，得到内层页表基地址\n通过p2索引内层页表，得到frame number\n\n优势\n\n页表不需要占用连续内存\n未使用的内层页表可以不分配\n节省内存空间\n\n按需分页\nLazy Allocation机制\n操作系统采用延迟分配（Lazy Allocation）策略：\n基本流程\n\n进程申请内存时，操作系统只扩大虚拟地址空间\n不立即分配物理内存\n当进程首次访问该虚拟地址时，触发缺页中断（page fault）\n操作系统在中断处理程序中分配物理内存\n\n优势\n\n节省物理内存\n提高系统响应速度\n很多申请的内存实际不会被使用\n\n缺页中断处理流程\n当进程访问的虚拟地址对应的页面不在物理内存中：\n\n\n触发page fault\n\nMMU在页表中查找\n发现valid bit为invalid\nCPU触发page fault异常，切换到内核态\n\n\n\n检查页面合法性\n\n检查虚拟地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n非法访问则终止进程\n\n\n\n分配物理帧\n\n如果有空闲帧，直接使用\n如果没有空闲帧，执行页面置换算法\n\n\n\n调入页面\n\n页面在磁盘上（被swap out）：从backing store读取\n页面是首次访问：分配新的零页\n\n\n\n更新页表\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n\n\n重新执行指令\n\n返回到用户态\n重新执行触发page fault的指令\n\n\n\n页面置换\n基本概念\n当物理内存不足时，需要将某些页面换出到磁盘。\n置换流程\n\n选择victim frame\n\n使用页面置换算法\n\n\n写回磁盘\n\n如果页面被修改过（dirty bit=1），将其写回磁盘\n未修改过的页面可以直接丢弃\n\n\n调入新页面\n\n将需要的页面从磁盘调入到victim frame\n\n\n更新页表\n\n将victim页面的页表项设置为无效\n记录页面在磁盘的位置\n\n\n\n页面置换算法\n详见页面置换算法 (page replacement algorithms)\n常见算法\n\nFIFO（First In First Out）：最简单，可能有Belady异常\nOptimal：理论最优，实际无法实现\nLRU（Least Recently Used）：近似最优，开销较大\nLRU-Approximation：使用reference bit近似实现\n\nreference bit机制\n\n每个页面关联一个reference bit\n页面被访问时置为1\n操作系统定期清零\n置换时选择reference bit为0的页面\n\n进程间内存共享\n多个进程可以共享同一块物理内存：\n共享代码\n参见Shared Pages\n应用场景\n\n多个进程执行同一程序时\n可以共享text段（代码段）\n\n实现方式\n\n不同进程的页表中，不同的虚拟页映射到同一物理帧\n\n要求\n\n代码必须是可重入的（reentrant code）\n\n共享内存IPC\n参见进程间通信\n应用场景\n\n进程间通信（IPC）\n高效的数据共享\n\n实现方式\n\n通过系统调用建立共享内存区域\n多个进程的虚拟地址空间映射到同一物理内存\n\n注意事项\n\n需要同步机制（如信号量）保护共享数据\n避免race condition\n\n内存保护\n页表保护位\n参见内存保护机制Protection和Memory Protection内存保护\nvalid-invalid bit\n\nvalid：页面在进程的合法地址空间内\ninvalid：页面不属于该进程，访问会触发trap\n\n权限位\n\n读权限（R）\n写权限（W）\n执行权限（X）\n\n保护机制\n\nMMU在地址转换时检查权限\n非法访问触发异常\n操作系统处理异常（通常终止进程）\n\nbase和limit寄存器\n参见内存保护机制Protection\n传统保护方式\n\nbase寄存器：进程地址空间的起始地址\nlimit寄存器：进程地址空间的大小\n每次访问检查：base ≤ 地址 &lt; base + limit\n\n相关概念\n\n04.1 主存 - 内存分配、分页、页表、TLB、帧表\n04.2 virtual memory - 虚拟内存、按需分页、页面置换\n02.1 进程 - 进程地址空间、进程间通信\n"},"课程笔记/操作系统/流程总览/03-进程调度":{"slug":"课程笔记/操作系统/流程总览/03-进程调度","filePath":"课程笔记/操作系统/流程总览/03 进程调度.md","title":"03 进程调度","links":["课程笔记/操作系统/02.2-调度","课程笔记/操作系统/01-introduction","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.3-线程"],"tags":[],"content":"进程状态\n五种基本状态\n进程在运行过程中会经历以下进程状态：\nNew（新建）\n\n进程正在创建过程中\n包括申请PCB、分配初始资源等\n\nReady（就绪）\n\n进程已准备好，等待CPU资源\n一旦获得CPU就可以立即执行\n\nRunning（运行）\n\n进程正在使用CPU执行\n单核系统中同时只有一个进程处于Running状态\n多核系统中Running进程数不超过核心数\n\nWaiting（等待）\n\n进程等待某个事件（如I/O完成、信号等）\n即使有空余的CPU资源，该进程也无法继续\n从Running到Waiting通常是主动的\n\nTerminated（终止）\n\n进程已结束\n需要释放资源\n\n状态转换\nReady → Running\n\n被调度器选中\n获得CPU资源\n称为派发（dispatch）\n\nRunning → Ready\n\n时间片用完（timer中断）\n被更高优先级进程抢占\n从Running到Ready是被动的\n\nRunning → Waiting\n\n主动等待（系统调用、I/O请求）\n需要等待某个事件发生\n\nWaiting → Ready\n\n等待的事件发生（如I/O完成）\n被中断唤醒\nWaiting不能直接进入Running，必须经过Ready\n\n队列管理\n就绪队列和等待队列\n参见就绪队列(ready queue)和等待队列(wait queue)\n就绪队列（Ready Queue）\n\n存放处于Ready状态的进程\n实际上是PCB的队列\n调度器从就绪队列选择进程执行\n\n等待队列（Wait Queue）\n\n存放处于Waiting状态的进程\n根据等待的事件类型可能有多个等待队列\n\nI/O设备等待队列\n信号量等待队列\n其他事件等待队列\n\n\n\n队列操作\n\n实际上是移动PCB指针在不同队列之间\n由内核负责管理\n\n调度时机\n非抢占式调度\n参见调度的时机\n触发条件\n\n进程主动释放CPU\n进入Waiting状态（系统调用、I/O请求）\n进程终止\n\n特点\n\n进程自愿放弃CPU\n调度开销小\n响应时间可能较长\n\n抢占式调度\n参见调度的时机\n触发条件\n\n时间片用完（timer中断）\n更高优先级的进程变为Ready状态\n当前进程被中断打断\n\n特点\n\n强制性调度\n调度开销较大\n响应时间更短\n现代操作系统普遍采用\n\n上下文切换\n基本概念\n上下文切换（context switch）是进程切换的核心机制。\n上下文包含的内容\n\nCPU寄存器的值（通用寄存器、PC、SP等）\n进程状态信息\n内存管理信息（页表指针等）\n\n完整切换流程\n当调度器决定切换到另一个进程时：\n1. 保存当前进程的上下文\n\n保存CPU寄存器到当前进程的PCB\n\n程序计数器（PC）\n通用寄存器\n栈指针（SP）\n\n\n保存进程状态\n保存内存管理信息\n\n2. 更新进程状态\n\n将当前进程从Running状态改为Ready或Waiting\n将当前进程的PCB移入相应的队列\n\n时间片用完 → Ready Queue\n等待事件 → Wait Queue\n\n\n\n3. 选择下一个进程\n\n调度器从Ready Queue中选择\n根据调度算法决定（参见调度算法）\n\nFCFS（First-Come, First-Served）\nSJF（Shortest-Job-First）\nRR（Round-Robin）\nPriority Scheduling\n多级队列调度\n\n\n\n4. 恢复下一个进程的上下文\n\n加载新进程的PCB中的寄存器值\n恢复CPU状态\n\n内存管理操作\n\n更新PTBR指向新进程的页表\n不同进程的虚拟地址空间被隔离\n\nTLB管理（参见TLB）\n\n方法1：flush TLB（清空所有TLB条目）\n\n简单但开销大\n下次访问需要重新加载TLB\n\n\n方法2：使用ASID（Address-Space Identifier）\n\nTLB条目同时存储ASID和page number\n切换时不需要清空TLB\n减少TLB miss\n\n\n\n内存保护（参见内存保护机制Protection）\n\n通过页表的保护位确保进程只能访问自己的虚拟地址空间\nvalid-invalid bit\n读写执行权限位\n\n5. 切换到新进程\n\n更新进程状态为Running\n设置CPU的mode bit为用户态\n跳转到新进程的PC指向的指令继续执行\n\n上下文切换的开销\n时间开销\n\n保存和恢复寄存器\n切换页表\n可能需要flush TLB\n更新内核数据结构\n典型的context switch时间约为10μs\n\n性能影响\n\n频繁切换会降低系统效率\n需要在响应时间和效率之间平衡\n\n中断驱动的调度\n中断机制\n现代操作系统是中断驱动的。\n中断的作用\n\n提供调度的时机\n响应外部事件\n处理异常情况\n\nTimer中断\n参见计时器 timer\n工作流程\n\n计时器定期产生中断（如每10ms）\nCPU保存当前上下文，跳转到中断处理程序\n中断处理程序检查当前进程的时间片是否用完\n如果用完，触发调度，将当前进程切换为Ready状态\n选择下一个进程执行\n\n时间片机制\n\n时间片（time quantum）：进程每次运行的最长时间\n通常为10~100ms\nRR调度算法的核心参数\n\nI/O中断\n工作流程\n\nI/O操作完成时，设备控制器发起中断\n中断处理程序唤醒等待该I/O的进程\n将进程从Waiting状态切换为Ready状态\n将进程PCB移入Ready Queue\n可能触发调度\n\n系统调用\n参见系统调用\n工作流程\n\n用户程序调用系统调用\n触发软中断（trap）\n切换到内核态执行系统调用\n如果系统调用需要等待（如read），进程进入Waiting状态\n触发调度\n\n调度算法简述\n详见调度算法\n基本算法\nFCFS（First-Come, First-Served）\n\n先来先服务\n非抢占式\n简单但可能导致长作业阻塞短作业\n\nSJF（Shortest-Job-First）\n\n最短作业优先\n可以是抢占式或非抢占式\n理论上最优，但难以预测运行时间\n\nRR（Round-Robin）\n\n时间片轮转\n抢占式\n响应时间好，但平均等待时间可能较长\n\nPriority Scheduling\n\n优先级调度\n可能导致饥饿（starvation）\n可通过aging机制解决\n\n多级队列调度\n参见Multilevel Queue Scheduling和Multilevel Feedback Queue Scheduling\n基本思想\n\n将进程分为不同类别\n每个类别有自己的队列和调度算法\n队列之间也有调度策略\n\n多级反馈队列\n\n允许进程在队列之间迁移\n根据进程行为动态调整优先级\n\n线程与调度\n线程概念\n参见02.3 线程\n线程的特点\n\n轻量级进程\n共享进程的代码、数据、堆\n各自维护寄存器、栈、PC\n\n线程与进程的关系\n\n进程是资源分配的基本单位\n线程是CPU调度的基本单位\n线程间切换开销小于进程间切换\n\n线程调度\n用户级线程\n\n线程库在用户空间实现\n对内核透明\n一个线程阻塞会导致整个进程阻塞\n\n内核级线程\n\n内核直接支持线程\n可以利用多核并行\n一个线程阻塞不影响进程内其他线程\n\n相关概念\n\n02.2 调度 - 进程状态、调度算法、上下文切换\n02.3 线程 - 线程概念、用户级线程、内核级线程\n01 introduction - 中断机制、计时器、系统调用\n02.1 进程 - PCB、进程创建与终止\n04.1 主存 - 页表、TLB、内存保护\n"},"课程笔记/操作系统/流程总览/04-完整流程示例":{"slug":"课程笔记/操作系统/流程总览/04-完整流程示例","filePath":"课程笔记/操作系统/流程总览/04 完整流程示例.md","title":"04 完整流程示例","links":["课程笔记/操作系统/流程总览/01-系统启动与进程创建","03-进程调度与切换","课程笔记/操作系统/流程总览/02-内存管理","课程笔记/操作系统/01-introduction","课程笔记/操作系统/03.1-进程同步及其工具","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"系统启动到第一个进程运行\n参考：系统启动流程\n完整流程\n1. 上电与引导\n\nCPU执行ROM中的引导加载器\n硬件自检（POST）\n定位并加载操作系统内核到RAM\n切换到内核态\n\n2. 内核初始化\n\n初始化中断系统：中断向量表、中断请求线、计时器\n初始化内存管理：帧表、内核页表、内存保护\n初始化进程管理：创建就绪队列和等待队列\n\n3. 创建第一个用户进程\n\n分配PCB\n建立虚拟地址空间\n建立页表映射\n加载可执行文件\n切换到用户态并开始执行\n\nfork创建新进程\n参考：fork系统调用\n场景：shell执行ls命令\n1. shell进程调用fork()\n\n触发系统调用，CPU切换到内核态\n内核分配新的PCB给子进程\n使用COW机制共享父进程地址空间\n返回：父进程得到子进程PID，子进程得到0\n\n2. 子进程调用exec(“ls”)\n\n触发系统调用\n内核加载ls程序的可执行文件\n建立新的页表映射，覆盖原有地址空间\n从ls程序入口点开始执行\n\n3. 父进程调用wait()\n\nshell进入Waiting状态\nshell的PCB移入等待队列\nCPU调度其他进程运行\n\n4. 子进程执行完毕\n\nls进程调用exit()\n触发系统调用\n释放资源，唤醒父进程\nshell从Waiting变为Ready\n\n时间片用完的进程切换\n参考：上下文切换\n场景：进程A的时间片用完\n1. Timer中断触发\n\n硬件计时器产生中断\nCPU保存当前指令的上下文\n跳转到中断处理程序（内核态）\n\n2. 中断处理\n\n内核的中断处理程序执行\n检查发现进程A的时间片已用完\n将进程A的状态改为Ready\n将进程A的PCB移入Ready Queue\n\n3. 调度决策\n\n调度器从Ready Queue中选择进程B\n根据调度算法（如RR、Priority等）决定\n\n4. 上下文切换\n\n保存进程A的寄存器到PCB\n加载进程B的寄存器从PCB\n切换页表：更新PTBR\n处理TLB：flush或使用ASID\n\n5. 恢复执行\n\n切换到用户态\n跳转到进程B的PC指向的指令\n进程B开始执行\n\n缺页中断处理\n参考：按需分页\n场景：进程访问未映射的虚拟地址\n1. 触发page fault\n\n进程访问某个虚拟地址\nMMU查页表，发现valid bit为invalid\nCPU触发page fault异常\n切换到内核态\n\n2. 检查合法性\n\n内核检查地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n如果非法，终止进程；如果合法，继续\n\n3. 分配物理帧\n\n检查是否有空闲帧\n如果有，直接使用\n如果没有，执行页面置换算法\n\n4. 调入页面\n\n如果是首次访问：分配新的零页\n如果被swap out：从磁盘读取页面内容\n\n5. 更新页表和TLB\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n6. 重新执行指令\n\n返回用户态\n重新执行触发page fault的指令\n这次可以正常访问\n\n页面置换流程\n参考：页面置换\n场景：物理内存不足时的处理\n1. 选择victim frame\n\n使用页面置换算法（LRU、FIFO等）\n找到要被换出的页面\n\n2. 检查dirty bit\n\n如果dirty bit为1（页面被修改过）\n\n需要将页面写回磁盘\nI/O操作\n\n\n如果dirty bit为0\n\n可以直接丢弃\n\n\n\n3. 更新victim页面的页表\n\n将valid bit设置为invalid\n记录页面在磁盘的位置\n从TLB中删除对应条目\n\n4. 调入新页面\n\n将需要的页面从磁盘调入到victim frame\n更新新页面的页表项\n设置valid bit为有效\n\n5. 继续执行\n\n返回用户态\n重新执行触发page fault的指令\n\nI/O操作流程\n参考：中断interrupts、中断驱动的调度\n场景：进程读取文件\n1. 进程发起I/O请求\n\n调用read()系统调用\n触发软中断（trap）\n切换到内核态\n\n2. 内核处理I/O请求\n\n检查文件权限\n发起I/O操作（向设备控制器发送命令）\n将进程状态改为Waiting\n将进程PCB移入I/O等待队列\n\n3. CPU调度其他进程\n\n从Ready Queue选择其他进程\n进行上下文切换\n其他进程开始执行\n\n4. I/O完成\n\n设备控制器完成I/O操作\n发起I/O中断\n\n5. 中断处理\n\nCPU保存当前进程上下文\n跳转到I/O中断处理程序\n处理I/O数据\n唤醒等待该I/O的进程\n将进程从Waiting改为Ready\n将进程PCB移入Ready Queue\n\n6. 可能的调度\n\n如果被唤醒的进程优先级更高\n可能发生进程切换\n\n进程同步示例\n参考：03.1 进程同步及其工具\n场景：生产者-消费者问题\n基本设置\n\n共享缓冲区（有界）\n信号量机制保护\n\n生产者进程\n\n等待空闲位置（P操作/wait）\n如果缓冲区满，进入Waiting状态\n有空位时被唤醒，进入Ready状态\n获得CPU后向缓冲区写入数据\n通知消费者（V操作/signal）\n可能唤醒等待的消费者\n\n消费者进程\n\n等待可用数据（P操作/wait）\n如果缓冲区空，进入Waiting状态\n有数据时被唤醒，进入Ready状态\n获得CPU后从缓冲区读取数据\n通知生产者（V操作/signal）\n可能唤醒等待的生产者\n\n关键机制的联系\n进程与内存\n\n进程是资源分配的单位：每个进程拥有独立的虚拟地址空间\n内存是进程运行的基础：代码、数据、堆栈都存储在内存中\n页表是进程的”身份证”：建立虚拟地址到物理地址的映射\nPCB是进程的”档案”：记录进程的所有信息，包括内存管理信息\n\n中断驱动系统\n\n硬件中断：Timer、I/O设备产生中断，触发调度\n软中断：系统调用、异常触发中断，进入内核态\n中断处理：内核处理中断，可能改变进程状态，触发调度\n\n调度与切换\n\n调度决策：选择哪个进程运行（软件策略）\n上下文切换：如何切换进程（硬件+软件机制）\n内存隔离：通过页表和MMU保证进程间隔离\n\n性能考虑\n时间开销\n\n上下文切换：约10μs\n系统调用：进入/退出内核态的开销\nTLB miss：需要访问内存中的页表\nPage fault：可能需要磁盘I/O\n\n优化策略\n\n减少上下文切换频率：合理的时间片大小\nTLB优化：使用ASID避免频繁flush\n页面置换：选择合适的算法减少page fault\nCOW机制：延迟复制，节省内存\n\n相关概念\n\n01 系统启动与进程创建 - 系统启动、进程创建机制\n02 内存管理 - 虚拟内存、分页、地址转换\n03 进程调度与切换 - 进程状态、调度、上下文切换\n01 introduction - 操作系统概述、中断、系统调用\n02.1 进程 - 进程概念、PCB\n02.2 调度 - 调度算法、队列管理\n04.1 主存 - 内存管理细节\n04.2 virtual memory - 虚拟内存细节\n"},"课程笔记/操作系统/进程与内存流程总览":{"slug":"课程笔记/操作系统/进程与内存流程总览","filePath":"课程笔记/操作系统/进程与内存流程总览.md","title":"进程与内存流程总览","links":["课程笔记/操作系统/01-introduction","课程笔记/操作系统/04.1-主存","课程笔记/操作系统/02.2-调度","课程笔记/操作系统/02.1-进程","课程笔记/操作系统/04.2-virtual-memory"],"tags":[],"content":"进程与内存流程总览\n本文档从系统上电开始，完整梳理操作系统如何启动、创建第一个用户进程、管理内存，以及如何进行进程切换的整个流程。\n一、系统启动：从硬件到内核\n1.1 上电与引导\n计算机上电后，CPU首先执行存储在**ROM（只读存储器）**中的引导加载器（bootstrap loader）。这个程序是开机后执行的第一个软件，位置固定且已知。\n引导加载器的任务：\n\n进行硬件自检（POST）\n定位磁盘上的操作系统内核镜像\n将内核加载到**主内存（RAM）**中\n切换CPU模式为内核态，开始执行内核代码\n\n1.2 内核初始化\n内核被加载到内存后，开始初始化工作：\n\n初始化中断系统\n\n设置中断向量表（interrupt vector table），建立中断号到中断处理程序的映射\n配置中断请求线（interrupt-request line）\n初始化计时器（timer），用于时间片管理\n\n\n初始化内存管理\n\n建立物理内存的帧表（frame table），记录每个物理帧的使用情况\n初始化内核的页表结构\n设置内存保护机制（base和limit寄存器，或页表保护位）\n\n\n初始化进程管理\n\n创建初始的内核数据结构\n准备就绪队列（ready queue）和等待队列（wait queue）\n\n\n\n二、第一个用户进程的创建\n2.1 内核态到用户态的转换\n内核初始化完成后，需要创建第一个用户进程。在Linux系统中，这个进程通常是init（旧版）或systemd（新版），其进程ID（PID）为1。\n创建第一个用户进程的步骤：\n\n分配进程控制块（PCB）\n\n操作系统为每个进程维护一个PCB，包含进程状态、程序计数器、CPU寄存器、内存管理信息等\n第一个进程的PCB被初始化为初始状态\n\n\n建立虚拟地址空间\n\n每个进程拥有独立的虚拟地址空间\n虚拟地址空间分为两部分：\n\n用户部分：包含text（代码）、data（全局变量）、heap（堆）、stack（栈）\n内核部分：存储PCB等内核数据结构\n\n\n\n\n建立页表映射\n\n为进程创建页表，建立虚拟地址到物理地址的映射\n初始时，只有必要的页面被映射到物理内存\n页表基地址存储在PTBR（Page-Table Base Register）中\n\n\n加载可执行文件\n\n通过加载器（loader）将可执行文件从磁盘加载到内存\n可执行文件经历了编译（.c → .o）、链接（.o → .exe）、加载的过程\n加载器将逻辑地址通过地址绑定（Address Binding）转换为物理地址\n\n\n切换到用户态\n\n通过上下文切换（context switch），将CPU从内核态切换到用户态\n设置CPU的mode bit为1（用户态）\n跳转到用户程序的入口点开始执行\n\n\n\n2.2 地址绑定过程\n程序从源代码到内存中的完整过程：\n\n编译阶段：编译器将符号地址转换为可重定位地址（relocatable address）\n链接阶段：链接器将多个目标文件合并，生成可执行文件，地址相对于整个程序\n加载阶段：加载器将可执行文件加载到内存，完成地址绑定，得到绝对地址\n\n三、内存管理机制\n3.1 虚拟内存的基本原理\n每个进程拥有独立的虚拟地址空间，CPU使用虚拟地址，由MMU（内存管理单元）自动转换为物理地址。\n虚拟地址空间的结构：\n\n用户空间（User Portion）：0 ~ 3GB（32位系统）\n内核空间（Kernel Portion）：3GB ~ 4GB（32位系统）\n所有进程的内核空间映射到同一块物理内存\n\n3.2 分页机制\n现代操作系统使用分页（Paging）机制管理内存：\n\n物理内存分帧：将物理内存切分为等大小的帧（frame），通常为4KB\n虚拟内存分页：将虚拟地址空间切分为等大小的页（page），大小与帧相同\n页表映射：通过页表建立页到帧的映射关系\n\n地址转换过程：\n\nCPU生成逻辑地址（page number + offset）\nMMU根据页表将page number转换为frame number\n物理地址 = frame number + offset\n\n3.3 页表的硬件实现\n页表存储在内存中，通过PTBR指向页表基地址。为了加速地址转换，使用TLB（Translation Look-aside Buffer）作为页表的高速缓存：\n\nCPU访问虚拟地址时，首先查询TLB\n如果TLB命中，直接获得物理地址（一次内存访问）\n如果TLB未命中，访问内存中的页表（两次内存访问），并将结果存入TLB\n\n3.4 按需分页（Demand Paging）\n操作系统采用延迟分配（Lazy Allocation）策略：\n\n进程申请内存时，操作系统只扩大虚拟地址空间，不立即分配物理内存\n当进程首次访问该虚拟地址时，触发缺页中断（page fault）\n操作系统处理缺页中断：\n\n从空闲帧列表中找到空闲的物理帧\n将页面映射到该物理帧\n更新页表项\n重新执行被中断的指令\n\n\n\n3.5 页面置换\n当物理内存不足时，需要将某些页面换出到磁盘（backing store）：\n\n选择victim frame：使用页面置换算法（如LRU）选择要换出的页面\n写回磁盘：如果页面被修改过（dirty bit=1），将其写回磁盘\n调入新页面：将需要的页面从磁盘调入到victim frame\n更新页表：将页表项的有效位设置为无效，记录页面在磁盘的位置\n\n当再次访问被换出的页面时，会触发page fault，操作系统将其重新调入内存。\n四、进程的创建与执行\n4.1 进程创建（fork）\n进程通过fork()系统调用创建子进程：\n\n系统调用：用户程序调用fork()，触发软中断（trap），切换到内核态\n创建子进程：\n\n分配新的PCB\n复制父进程的地址空间（使用Copy-on-Write（COW）优化）\n子进程获得新的PID，PPID指向父进程\n\n\n返回用户态：\n\n父进程：fork()返回子进程的PID\n子进程：fork()返回0\n两个进程从fork()的下一行代码继续执行\n\n\n\nCopy-on-Write（COW）机制：\n\n父子进程最初共享同一份物理页\n当任一进程尝试写入共享页时，才真正复制该页\n节省内存，提高fork效率\n\n4.2 进程执行（exec）\nexec()系统调用用新程序覆盖当前进程的地址空间：\n\n加载新的可执行文件到内存\n建立新的页表映射\n重置程序计数器，从新程序的入口点开始执行\n\n通常的用法是fork()后立即调用exec()，创建新进程并执行新程序。\n五、进程调度与切换\n5.1 进程状态\n进程在运行过程中会经历以下进程状态：\n\nNew：进程正在创建\nReady：进程已准备好，等待CPU资源\nRunning：进程正在使用CPU执行\nWaiting：进程等待某个事件（如I/O完成）\nTerminated：进程已结束\n\n状态转换规则：\n\nRunning → Ready：时间片用完或被抢占\nRunning → Waiting：主动等待（如系统调用、I/O请求）\nWaiting → Ready：等待的事件发生\nReady → Running：被调度器选中，获得CPU\n\n5.2 调度时机\n非抢占式调度：进程主动释放CPU（进入waiting状态或终止）\n抢占式调度：\n\n时间片用完（timer中断）\n更高优先级的进程变为ready状态\n当前进程被中断打断\n\n5.3 上下文切换的完整过程\n当调度器决定切换到另一个进程时，执行上下文切换：\n\n\n保存当前进程的上下文：\n\n保存CPU寄存器（PC、通用寄存器等）到当前进程的PCB\n保存进程状态\n保存内存管理信息（页表指针等）\n\n\n\n更新进程状态：\n\n将当前进程从running状态改为ready状态（或被抢占）或waiting状态\n将当前进程的PCB移入相应的队列\n\n\n\n选择下一个进程：\n\n调度器从ready queue中选择下一个要运行的进程\n根据调度算法（如RR、优先级调度等）进行选择\n\n\n\n恢复下一个进程的上下文：\n\n加载新进程的PCB中的寄存器值\n更新PTBR指向新进程的页表\n如果使用TLB，需要flush TLB或使用ASID\n更新进程状态为running\n\n\n\n切换到用户态：\n\n设置CPU的mode bit为用户态\n跳转到新进程的PC指向的指令继续执行\n\n\n\n上下文切换的开销：\n\n需要保存和恢复大量寄存器\n需要切换页表（可能flush TLB）\n需要更新各种内核数据结构\n典型的context switch时间约为10μs\n\n5.4 中断驱动的调度\n现代操作系统是中断驱动的：\n\n\nTimer中断：\n\n计时器定期产生中断（如每10ms）\n中断处理程序检查当前进程的时间片是否用完\n如果用完，触发调度，将当前进程切换为ready状态\n\n\n\nI/O中断：\n\n当I/O操作完成时，设备控制器发起中断\n中断处理程序唤醒等待该I/O的进程\n将进程从waiting状态切换为ready状态\n\n\n\n系统调用：\n\n用户程序调用系统调用，触发软中断\n切换到内核态执行系统调用\n如果系统调用需要等待（如read），进程进入waiting状态\n\n\n\n六、内存与进程的协同工作\n6.1 进程切换时的内存管理\n进程切换时，内存管理相关的操作：\n\n\n页表切换：\n\n更新PTBR指向新进程的页表\n不同进程的虚拟地址空间被隔离\n\n\n\nTLB管理：\n\n方法1：flush TLB（清空所有TLB条目）\n方法2：使用ASID（Address-Space Identifier），TLB同时匹配page number和ASID\n\n\n\n内存保护：\n\n每个进程只能访问自己的虚拟地址空间\n通过页表的保护位（valid-invalid bit、读写权限位）实现\n\n\n\n6.2 缺页中断的处理流程\n当进程访问的虚拟地址对应的页面不在物理内存中时：\n\n触发page fault：\n\nMMU在页表中查找，发现valid bit为invalid\nCPU触发page fault异常，切换到内核态\n\n\n检查页面合法性：\n\n检查虚拟地址是否在进程的合法地址空间内\n检查访问权限（读/写/执行）\n\n\n分配物理帧：\n\n如果有空闲帧，直接使用\n如果没有空闲帧，执行页面置换算法选择victim frame\n\n\n从磁盘调入页面：\n\n如果页面在磁盘上（被swap out），从backing store读取\n如果页面是首次访问（lazy allocation），分配新的零页\n\n\n更新页表：\n\n建立虚拟页到物理帧的映射\n设置valid bit为有效\n更新TLB\n\n\n重新执行指令：\n\n返回到用户态\n重新执行触发page fault的指令\n\n\n\n6.3 进程间内存共享\n多个进程可以共享同一块物理内存：\n\n共享代码：\n\n多个进程执行同一程序时，可以共享text段\n页表中不同的虚拟页映射到同一物理帧\n代码必须是可重入的（reentrant code）\n\n\n共享内存（IPC）：\n\n通过系统调用建立共享内存区域\n多个进程的虚拟地址空间映射到同一物理内存\n需要同步机制（如信号量）保护共享数据\n\n\n\n七、完整流程示例：从fork到exec到调度\n7.1 创建新进程并执行新程序\n\n\n父进程调用fork()：\n\n触发系统调用，切换到内核态\n内核创建子进程的PCB\n使用COW机制共享父进程的地址空间\n返回用户态，父子进程并发执行\n\n\n\n子进程调用exec()：\n\n触发系统调用，切换到内核态\n内核加载新的可执行文件\n建立新的页表映射\n覆盖原有的地址空间\n返回用户态，从新程序的入口点开始执行\n\n\n\n7.2 进程切换的完整场景\n假设进程A正在运行，时间片用完：\n\nTimer中断：\n\n硬件计时器产生中断\nCPU保存当前指令的上下文，跳转到中断处理程序\n\n\n中断处理：\n\n内核的中断处理程序执行\n检查发现进程A的时间片已用完\n将进程A的状态改为ready，移入ready queue\n\n\n调度决策：\n\n调度器从ready queue中选择进程B（根据调度算法）\n进程B可能是：\n\n之前被抢占的进程\n等待I/O完成的进程\n新创建的进程\n\n\n\n\n上下文切换：\n\n保存进程A的寄存器到PCB\n加载进程B的寄存器从PCB\n切换页表（更新PTBR）\nFlush TLB或使用ASID\n\n\n恢复执行：\n\n切换到用户态\n跳转到进程B的PC指向的指令\n进程B开始执行\n\n\n\n7.3 内存不足时的处理\n当系统内存不足，新进程需要内存时：\n\n\n触发page fault：\n\n进程访问未映射的虚拟地址\nMMU发现页表项无效\n\n\n\n检查空闲帧：\n\n如果没有空闲帧，执行页面置换\n\n\n\n页面置换：\n\n使用LRU等算法选择victim frame\n如果victim page被修改，写回磁盘\n将victim page的页表项标记为无效\n\n\n\n调入新页面：\n\n从磁盘读取需要的页面到victim frame\n更新页表，建立映射\n更新TLB\n\n\n\n继续执行：\n\n重新执行触发page fault的指令\n进程继续正常运行\n\n\n\n八、总结：关键机制的联系\n8.1 进程与内存的紧密关系\n\n进程是资源分配的单位：每个进程拥有独立的虚拟地址空间\n内存是进程运行的基础：进程的代码、数据、堆栈都存储在内存中\n页表是进程的”身份证”：通过页表实现虚拟地址到物理地址的映射\nPCB是进程的”档案”：记录进程的所有信息，包括内存管理信息\n\n8.2 中断驱动的系统\n\n硬件中断：Timer、I/O设备等硬件产生中断，触发调度\n软中断：系统调用、异常等软件事件触发中断，进入内核态\n中断处理：内核处理中断，可能改变进程状态，触发调度\n\n8.3 虚拟内存的优势\n\n隔离性：每个进程拥有独立的虚拟地址空间，互不干扰\n灵活性：进程可以使用比物理内存更大的虚拟地址空间\n效率：通过按需分页和页面置换，提高内存利用率\n共享性：多个进程可以共享同一块物理内存（代码、数据）\n\n8.4 进程切换的本质\n进程切换本质上是：\n\n保存当前执行环境：寄存器、状态、内存映射\n恢复另一个执行环境：加载另一个进程的上下文\n继续执行：从另一个进程的断点继续\n这一切都依赖于：\n\n\n中断机制：提供切换的时机\n内存管理：保证进程间的隔离和正确映射\n调度算法：决定切换哪个进程\n\n\n相关概念索引\n\n01 introduction - 操作系统概述、中断、特权模式\n02.1 进程 - 进程概念、PCB、进程创建与终止\n02.2 调度 - 进程状态、调度算法、上下文切换\n04.1 主存 - 内存分配、分页、页表、TLB\n04.2 virtual memory - 虚拟内存、按需分页、页面置换\n"},"课程笔记/计算机组成/02-Instructions":{"slug":"课程笔记/计算机组成/02-Instructions","filePath":"课程笔记/计算机组成/02 Instructions.md","title":"02 Instructions","links":["tags/flashcard","ABI-(Application-Binary-Interface)"],"tags":["flashcard"],"content":"DECK: CS::CO\nsummary\n\n\n寄存器 registers flashcard\n\nRISC-V architecture 提供 32 个数据寄存器，分别命名为 x0 ~ x31 ，每个寄存器的大小是 64 位。\n\nx0 的值恒为 0\nPreserved on call 意为是否保证调用前后这些寄存器的值不变。\n\n\n也提供一系列浮点数寄存器 f0 ~ f31。\n之所以寄存器的个数不多，是因为过多的寄存器会增加电子信号的传播距离，从而导致时钟周期的延长。\n将不常用的（或之后用到的）变量存入内存的过程被称为溢出寄存器 (Spilling Register)\n寄存器存储空间小，内存存储空间大 因此小规模的数据会放在寄存器内，而更大规模的数据则会存储在计算机的内存(memory) 中\n各种操作与运算都只能在寄存器内完成\n寄存器有着更快的运行速度和更高的吞吐量，使得访问寄存器内的数据更加迅速和方便，且访问寄存器的能耗更低；而访问内存需要 load 和 store 指令，那么就需要执行更多的指令\n\n\n字节地址 flashcard\n\n\n==在 RISC-V architecture 中，一个 word 为 32 位（4Bytes ），一个 doubleword 为 64 位（8Bytes ）。==\nRISC-V architecture 的地址是 64 位的，地址为字节地址，因此总共可以寻址2的64次方个字节，即2的61次方个 dword ，因为一个 dword 占3位（8Bytes用3个字节地址位表示）\n\n如果想操作某一个 bit（比如把第 3 个 bit 从 0 改成 1 ），CPU 必须：\n\n读取 (Read)：先把这个 bit 所在的整个字节（整个房间）的数据（8个 bits）全部取到 CPU 寄存器中。\n修改 (Modify)：在 CPU 内部，使用位运算（比如 OR 运算）来单独修改那 1 个 bit，而其他 7 个 bit 保持不变。\n写回 (Write)：把修改后的整个字节（8个 bits）再存回到原来的内存地址\n\n\n\n\n\n\n寻址 flashcard\n\n在一些 architecture 中，word 的起始地址必须是 word 大小的整倍数，dword 也一样，这种要求称为 alignment restriction。\n\nRISC-V 允许不对齐的寻址，但是效率会低。\n一次只能读出4字节内存中的一行\n\n\nRISC-V 支持\n\n立即数寻址 ( lui )\n间接寻址 ( jalr )\n基址寻址 ( 8(sp) )：\nPC relative 寻址：分支地址为PC和分支偏移量（立即数的2倍）之和\n\n因为所有合法的指令必须存放在偶数内存地址【指令：16bit（压缩指令）/32bit 】因此最低位始终为0，因此为了优化，指令中会略去最后一个0\n把存储的 immediate 还原成真正的 Branch offset\n\n\n\n\n\n\n\n大小端 flashcard\n\nRISC-V 使用 little endian 小端编址。也就是说，当我们从 0x1000 这个地址读出一个 dword 时，我们读到的实际上是 0x1000~0x1007 这 8 个字节，并将 0x1000 存入寄存器低位，0x1007 存入高位。\n\n存储字节 0x88 就是 bit：10001000\n大小端只关心字节的顺序，不关心字节内部bit的顺序\n\n\n\n\n补码 2’s complement flashcard\n\n因此在将不足 64 位的数据载入寄存器时\n\n如果数据是无符号数，只需要使用 0 将寄存器的其他部分填充 (zero extension)\n\n指令中的lwu , lhu , lbu 使用zero extension。\n\n\n而如果是有符号数，则需要用最高位即符号位填充剩余部分，称为符号扩展 (sign extension)。\n\n指令中的 lw , lh , lb 使用sign extension\n\n\n\n\n\n对于补码先看符号位，负数的话就对数字部分做补码还原，还是取反加一。\n1’scomplement是反码，先看符号位，负数就对数字部分做反码还原，取反即可\n\n\n指令\n设计准则\n正则化 simplicity favors regularity 简化规范\n越小越快 smaller is faster 32个通用寄存器 32*64bit\n指令\n\nArithmetic\n\n加法\n\nadd：寄存器 1 + 寄存器 2\n|add reg1, reg2, reg3    // (in C) reg1 = reg2 + reg3|\naddi(Add Immediate)：寄存器 + 常量\n|addi reg1, reg2, const  // (in C) reg1 = reg2 + const|\n\n\n减法\n\nsub：寄存器 1 - 寄存器 2\n|sub reg1, reg2, reg3    // (in C) reg1 = reg2 - reg3|\n==注意：没有subi，但是可以通过addi一个负常数来实现==\n\n\n\nLogical Operations\n\n\nsll/slli，srl/srli 分别为逻辑左移/右移\n\n左移i位相当于乘以2的i次方，右移i位相当于整除2的i次方 \n逻辑右移时最左边补 0\n不带i的指令表示根据寄存器的值确定移动位数，带i的指令表示用立即数确定移动位数\n|slli x11, x19, 4    // reg x11 = reg x19 &lt;&lt; 4 bits|\n\n\nsra/srai 为算术右移，最左边补符号位\n\nBit Operations\n|and reg1, reg2, reg3    // (in C) reg1 = reg2 &amp; reg3`|\n\n|or reg1, reg2, reg3    // (in C) reg1 = reg2 | reg3`|\n\nAND、OR、XOR 也有立即数版本的指令，分别为：andi、ori和xori\n\n|xor reg1, reg2, reg3    `|\n\nRISC-V 中没有 NOT 指令，因为它可以通过异或表示出来：任何数与 111…111 异或的结果即为该数取反后的结果\n\nMaking Decisions\n计算机与计算器的一大不同之处在于计算机具备决策的能力：它能够执行分支（条件）语句、循环语句等。\n在 RISC-V 汇编语言中，关于决策的指令格式均为：inst rs1, rs2, L1\n\n其中rs1、rs2是寄存器\nL1是标签（跳转位置，也可以是立即数 imm，表示跳转到 PC+imm 的指令）\ninst是指令，比较的是补码值。/0\n\n其分类如下：\n\n条件分支(conditional branch)：先检测值，根据检测结果决定是否将控制权转交给新地址上的语句的一类指令\n无条件分支(unconditional branch)：条件恒为真的条件分支，因此该语句一定会执行\n\n有以下几种可用指令：\n\nbeq(Branch If Equal)：如果寄存器rs1和rs2的值相等，那么跳转至带标签L1的语句\nbne(Branch If Not Equal)：如果寄存器rs1和rs2的值不相等，那么跳转至带标签L1的语句\nblt(Branch If Less Than)：如果寄存器rs1的值小于rs2的值，那么跳转至带标签L1的语句\n\nbltu：无符号版本 unsigned 比如存的是地址，就只能用bltu当作无符号数来比较，否则会引入符号位。【如果高位地址用不上也不容易出错，如果地址比较大就一定要bltu】\n\n\nbge(Branch If Greater Than or Equal)：如果寄存器rs1的值大于等于rs2的值，那么跳转至带标签L1的语句\n\nbgeu：无符号版本 unsigned\n\n\n\nif\n\nif-else\n\ncase-switch\n对于case/switch语句，我们可以使用一张放有可选指令序列地址的表格（称为分支地址表，Branch Address Table），这样的话程序就可以根据条件判断的结果，通过表格的索引找到合适的指令序列。\n\n\n\nloops\n\n循环访问数组\nwhile\n\nset on less than\nslt x5, x19, x20\n\n如果 x19&lt;x20，那么将 x5 赋值为 1\n\nData Transfer Instructions\n由于对数据的各种操作只能在寄存器内完成，而无法在内存中实现，因此数据需要再寄存器和内存之间来回传递，来完成这一传递操作的指令被称为数据传输指令\nRISC-V 有以下数据传输指令：\n\nld（Load Doubleword）：加载指令，将数据从内存拷贝到寄存器当中\n|ld reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 一个保存内存基础地址的寄存器（可以理解为能访问到整个内存的头指针）\noffset: 偏移量，是一个常数\n内存数据的实际地址 = mem_base_addr + offset\n\n\nsd（Store Doubleword）：存储指令，将寄存器的数据拷贝到内存中\n|`sd reg, offset(mem_base_addr) |\n\nreg: 寄存器\nmem_base_addr: 内存基础地址寄存器\noffset: 偏移量\n\n\nlbu(Load Byte Unsigned)：加载 1 字节的数据，并看作无符号数\nlb(Load Byte)：lbu的有符号数版本\n\n\n在 RISC 指令集中，只有 load 系列和 store 系列指令能够访问内存。\n\n\n立即数 Constant or Immediate Operands\n\n一般的做法是将常数保存在一个寄存器当中，通过一个地址指针指向这个寄存器，然后通过 add 指令实现加法操作\n|ld x9, AddrConstant4(x3) //x9 = constant 4 add x22, x22, x9|\n实际上我们可以引入一个新的概念：立即数（Immediate），这样就避免了加载指令（即通过操作 addi x22, x22, 4 即可实现）\n\n同步Synchronization in RISC-V\n假设两个处理器在同一片内存空间中工作，并且它们的工作顺序为：P1写入数据后，P2再读取数据。没有同步（Synchoronize）好，那么就会产生数据竞争（Data Race）的问题（结果取决于访问顺序，因此这个结果就是不确定的）。\n避免这一问题的方法是原子读取 / 写入 (Atomic Read/Write) 内存操作，这种操作确保读和写之间不会有任何访问这块内存空间的行为。\n有些处理器有专门实现原子操作的指令，比如原子交换 (Atomic Swap/Exchange)（实现寄存器和内存数据的交换）等。而 RISC-V 提供了一个指令对 (Instruction Pair) lr.d和sc.d：\n\nlr.d（Load-Reserved Doubleword）：\n\nlr.d rd, (rs1) 将存储在寄存器rs1的内存地址上的数据加载到寄存器rd上，同时保留这块内存地址，除sc.d的其他指令不应该访问这块地址\n\n\nsc.d（Store-Conditional Doubleword）：\n\nsc.d rd, rs1, (rs2) 将寄存器rs1上的数据放入存储在寄存器rs2的内存地址上，并且由寄存器rd指示该指令是否成功：若成功，则rd = 0，否则rd为一个非零值（表示有其他指令访问过这块内存空间）\n\n\n\n\n其他\n\n拓展指令集内容：\n\nM：与乘除法相关的指令\nA：原子运算，包括前面提到过的lr.d和sc.d指令，以及它们的 32 位版本lr.w和sc.w等\nF：单精度浮点运算相关指令\nD：双精度浮点运算相关指令\nC：压缩的指令，只有 16 位宽\n\n\n伪指令\n\n过程（Procedure）或函数（Function）\n调用过程Procedure Call Instructions flashcard\n\n\njal与jalr\n\njalr是基于【寄存器地址+12位立即数偏移量】\njal是基于pc相对地址【20位立即数】，jal rd，offset\n\n\n对于调用者：调用某个程序地址后，将返回地址（跳转的下一条地址PC+4）存入x1（ra）中\n对于被调用者，x0无法被写入，表示不保存任何返回地址，仅作跳转。\n\n调用过程中的寄存器Registers for procedure calling\nRISC-V寄存器 flashcard\nLocal Data on the Stack\n栈与栈帧 flashcard\nMemory Layout\nMemory Layout flashcard\nRICV-V指令格式 flashcard\n指令编码32bit, 记其为机器码（Machine Code）。我们可以把每条指令当作一块块二进制数字构成的组合，而这单块的数字被称为字段（Field）。我们为字段赋予了一些名称，每个字段有不同的功能：\n\nopcode：指令要做的运算，可用这个字段区分各种类型的指令格式(instruction format)\nfunct3：额外的opcode字段\nfunct7：额外的opcode字段\nrd：寄存器目标操作数，保存运算的结果\nrs1：第一个寄存器源操作数\nrs2：第二个寄存器源操作数\nimmediate：立即数，即常数\n根据不同的 opcode 我们可以将指令分为 6 种类型，它们的字段构成如下：\n\n\nR 型指令一般用于算术、逻辑运算\nI 型指令一般用于加载操作、涉及立即数的算术逻辑运算、jalr指令\n\n因为寄存器的大小为 64 位，也就是说对于移位操作 slli，srli和srai，它们最多只能移位 64 位，因此移位操作中immediate字段只有后 6 位能实际被用来存储移位的步数，前 6 位用来存储额外的opcode字段（funct6）\n关于 jalr 指令，如果跳转地址（立即数）过大，超过了 20 位，那么可以先用 lui 指令将高 20 位数字放入临时寄存器中，然后再用 jalr 指令跳转到地址剩余的低位数字(临时寄存器)上\n\n\nS 型指令一般用于存储操作\nU 型指令一般用于与高位立即数相关的操作\n\n在大多数情况下，立即数不会很大（），能够直接存在指令中；但如果超过 12 位，RISC-V 会用 lui (load upper immediate) 指令来处理这类较大的立即数。\n它可以加载立即数的高 20 位，将其放入寄存器中间的第 12 位到第 31 位，寄存器的低 12 位用 0 填充，高 32 位用第 31 位上的数字填充。\n例如，要将 32 位立即数赋给寄存器，可以先用lui指令将高 20 位赋给寄存器，之后用addi 指令将剩余的 12 位加到寄存器中。\n\n\nSB 型指令一般用于条件分支语句\n\n可表示的地址范围为 -4096-4094，且都是 2 的倍数（因为立即数第一位恒为 0）\n\n\nUJ 型指令一般用于无条件分支语句（jal）\n\nrd用于存放链接地址（即返回地址）\n\n\n\n\n\n另外，为什么 SB 和 UJ 不存立即数（也就是偏移）的最低位呢？（关注表格，可以发现只包括 i[12:1] 或者 i[20:1]，缺失 i[0]）因为，偏移的最后一位一定是 0，即地址一定是 2 字节对齐的，因此没有必要保存。\n\n\n数组和指针\n事实上，用指针访问数组元素比用索引访问数组元素更快一些。它们分别具有如下特点：\n\n数组索引\n\n需要根据数组基地址、当前索引和元素大小计算出数组元素的地址，而且每趟循环都需要更新和重新计算，有些麻烦\n虽然从理论上来说效率不高，但实际上编译器已经为我们做了一定的优化，比如用移位运算替代乘法运算，避免在循环内进行数组地址计算等\n\n\n指针\n\n它直接指向内存地址（可以看到，在循环开始前就已经算好了），无需多余的计算步骤\n\n\n\n例子\nRISC-V 汇编语言来翻译一个用 C 语言写的冒泡排序函数\nC 语言翻译成汇编语言步骤\n\n为程序的每个变量分配相应的寄存器\n为过程的主体部分书写代码\n在过程调用期间保留要用的寄存器\n\nswap函数\nvoid swap(long long int v[], size_t k) {\n    long long int temp;\n    temp = v[k];\n    v[k] = v[k+1];\n    v[k+1] = temp;\n}\nswap:\n    slli x6, x11, 3      // reg x6 = k * 8 -》变成byte字节地址\n    add  x6, x10, x6     // reg x6 = v + (k * 8)\n    ld   x5, 0(x6)       // reg x5 (temp) = v[k]\n    ld   x7, 8(x6)       // reg x7 = v[k + 1]\n    sd   x7, 0(x6)       // v[k] = reg x7\n    sd   x5, 8(x6)       // v[k+1] = reg x5 (tmp)\n    jalr x0, 0(x1)       // return to calling routine\nsort函数\nvoid sort(long long int v[], size_t int n) {\n    size_t i, j;\n    for (i = 0; i &lt; n; i++) {\n        for (j = i - 1; j &gt;= 0 &amp;&amp; v[j] &gt; v[j + 1]; j--) {\n            swap(v, j);\n        }\n    }\n}\n// Saving registers\nsort:\n    addi sp, sp, -40      // make room on stack for 5 registers\n    sd   x1, 32(sp)       // save return address on stack\n    sd   x22, 24(sp)      // save x22 on stack\n    sd   x21, 16(sp)      // save x21 on stack\n    sd   x20, 8(sp)       // save x20 on stack\n    sd   x19, 0(sp)       // save x19 on stack\n \n// Procedure body\n// Move parameters\n    mv   x21, x10         // copy parameter x10 into x21\n    mv   x22, x11         // copy parameter x11 into x22\n \n// Outer loop\n    li   x19, 0           // i = 0\nfor1tst: \n    bge  x19, x22, exit1  // go to exit1 if i &gt;= n\n \n// Inner loop\n    addi x20, x19, -1     // j = i - 1\nfor2tst:\n    blt  x20, x0, exit2   // go to exit2 if j &lt; 0\n    slli x5, x20, 3       // x5 = j * 8\n    add  x5, x21, x5      // x5 = v + (j * 8)\n    ld   x6, 0(x5)        // x6 = v[j]\n    ld   x7, 8(x5)        // x7 = v[j + 1]\n    ble  x6, x7, exit2    // go to exit2 if x6 &lt; x7\n \n// Pass parameters and call\n    mv   x10, x21         // first swap parameter is v\n    mv   x11, x20         // second swap parameter is j\n    jal  x1, swap         // call swap\n \n// Inner loop\n    addi x20, x20, -1     // j for2tst\n    j for2tst             // go to for2tst\n \n// Outer loop\nexit2: \n    addi x19, x19, 1      // i++\n    j for1tst             // go to for1tst\n \n// Restoring registers\nexit1:\n    ld   x19, 0(sp)       // restore x19 from stack\n    ld   x20, 8(sp)       // restore x20 from stack\n    ld   x21, 16(sp)      // restore x21 from stack\n    ld   x22, 24(sp)      // restore x22 from stack\n    ld   x1, 32(sp)       // restore return address from stack\n    addi sp, sp, 40       // restore stack pointer\n \n// Procedure return\n    jalr x0, 0(x1)        // return to calling routine\n指令集架构\n谬误\n\n更多强大的指令会带来更高的性能\n\n虽然更强大的指令意味着执行相同功能所需指令数更少，但同时也意味着这些指令会更加复杂，难以实现，这样反而影响所有指令的效率\n\n\n直接用汇编语言编写的程序性能更高\n\n在现代的处理器中，编译器可能比人脑更擅长将高级语言代码转换为性能更优的汇编语言代码\n而且，对于人类来说，因为汇编代码量较大，所以会带来更多犯错的机会，且编写效率实在不高\n\n\n指令集的向后兼容意味着无需改变现有的指令集\n\n以 x86 为例，虽然它做到了向后兼容，但它的指令数还是呈上升趋势\n\n\n用字节表示地址的机器内，连续的字地址的间距不是 1 而是 4（字节）\n\n一个地址只能放一个字节\n双字地址间距就是8字节\n\n\n使用指向在定义过程外的自动变量的指针\n\n典型例子：某个过程返回一个指向局部数组的指针，但这个过程在返回后就没了，包括这个局部数组，因此这个指针指向一个没有任何意义的地方，如果动用这个指针，很可能会让整个程序崩溃\n\n\n\n指令集架构 instruction set architecture flashcard\n目前世界上主流的 ISA 主要分为两大类：\n\nCISC (复杂指令集)：一条指令可以完成很复杂的操作。\n\nx86 电脑、笔记本、服务器\n\n\nRISC (精简指令集)：指令都很简单、统一，通过组合简单指令来完成复杂任务。\n\nRISC-V\nARM  手机 平板 嵌入式设备 苹果电脑\nMIPS\n当下计算机建立在两个关键原则（即存储程序概念，Stored-Program Concept）：\n\n\n指令用数字来表示\n程序就像数字一样存储在内存中，可用来被读取或写入\n\n\nMIPS\n\n32 位指令\n32 个通用寄存器，其中一个寄存器的值始终为 0\n只能通过加载和存储指令来访问内存数据\n没有能够批量加载 / 存储多个寄存器的指令\n寻址模式适用于各种大小的数据\n\nRISC-V 和 MIPS 的不同之处有：\n\n条件分支（除了相等和不等）：\n\nRISC-V 仅仅比较两个寄存器的大小，而 MIPS 还会用一个寄存器存储比较结果（1 或 0，对应真值）\nMIPS 只有“小于”分支指令，该指令有符号数（slt）和无符号数（sltu）版本\n\n\n\n指令格式的区别\n\nx86\n8086 指令集仅支持字节（8 位）和字（16 位，注意 RISC-V 的字是 32 位）类型的数据，而 80386 增加了 32 位地址和数据（双字，注意 RISC-V 的双字是 64 位）。\nx86 指令与 RISC-V 的不同之处在于：\n\nx86 指令的算术和逻辑指令中，有一个操作数同时充当源和目标；而 RISC-V（以及 MIPS）会将源寄存器和目标寄存器区分开来\nx86 指令的其中一个操作数可以是内存，下面的表格展示了 x86 中所有可能的操作数搭配\n\n寄存器\n80386 指令集有 14 个寄存器，如下图所示：\n\n寻址模式\n80386 的寻址模式如下图所示：\n\n指令格式\n下图为典型 x86 指令格式- 每条指令的开头（左侧）指明了指令要做的操作\n\n有些指令存在一个 Postbyte 字段，它用来指明寻址模式\nx86 的整数指令有以下几类：\n数据传送指令\n算术和逻辑指令\n控制流\n字符串指令\n分别对应的常见指令有：\n\n\nTranslating and starting a program\n一个 C 语言的程序（源代码）转化为存储在内存中的一个文件的过程\n\n\n编译器 (Compiler)：高级编程语言 → 汇编语言\n\n有的编译器兼具汇编器的功能\n\n\n汇编器 (Assembler)：\n\n伪指令 → 指令\n\n伪指令(Pseudo Instruction)：可以理解为汇编指令的扩展（或者缩写），形式上看似指令，而实际上并不存在这种指令，但汇编器会将其自动转化为实际存在的指令\n\n\n可接受各种进制的数\n用符号表(symbol table) 存储标签名称和内存地址的对应关系，便于将标签转化为实际的地址\n基本的功能：汇编语言 → 机器码，即汇编程序 → 目标文件(Object File)。在 UNIX 系统中，目标文件包含以下内容：\n\n目标文件头 (Object File Header)：描述目标文件中其他区域的大小和位置\n文本段 (Text Segment)：包含机器码\n静态数据段 (Static Data Segment)：包含程序生命周期中分配的数据（在 UNIX 中这个区域同时存放静态和动态数据）\n重定位信息 (Relocation Information)：根据程序被加载至内存的绝对地址来区分指令和数据\n符号表 (Symbol Table)\n调试信息 (Debugging Information)：简要描述模块的编译情况，使调试器能够将机器指令和 C 源文件关联起来，且能够读取其中的数据结构\n\n\n\n\n链接器 (Linker)\n\n对于多文件的编译，采取的做法是先编译、汇编单个的文件，然后将这些机器语言程序链接起来，这样可以尽可能减少重编译和重汇编的情况\n工作流程：\n\n将代码和数据模块以符号化的形式存在内存中\n弄清数据和指令标志对应的地址\n补充好内部和外部的引用\n\n\n经链接器加工后，最终生成一个可执行文件 (Executable File)，它与目标文件的区别在于后者存在不确定 (Unresolved) 的引用\n\n\n加载器 (Loader)：将可执行文件放入内存或磁盘中，工作流程为：\n\n读取可执行文件头，得到文本段和数据段的大小\n创建一个指向足够容纳文本和数据的空间的地址\n将可执行文件的指令和数据拷贝到内存中\n将主程序的参数（如果有的话）放入栈中\n对寄存器进行初始化操作，并将栈指针指向第一个空闲的位置上\n跳转到启动例程，将参数拷贝到参数寄存器中，并调用程序的主例程。让主例程返回时，启动例程中止整个程序，附带exit系统调用\n\n\n\nDynamic Linking\n前面介绍的链接方法属于静态链接，虽然它能快速调用库函数，但它具有以下缺陷：不能及时更新库函数，会一次性加载所有库函数（即使很多库函数没被用到）。因此我们更多地会用到动态链接库(Dynamically Linked Libraries, DLL) 来克服这些缺陷——这种库可以在程序运行时被链接到程序里。\n动态链接库有如下特征：\n\n需要可重定位的过程代码\n能够避免由静态链接获取所有库函数带来的占用存储空间过大的问题\n能够自动获取最新版本的库\n\nLazy Linkage\n在原始版本的 DLL 中，程序和库都需要保留额外的信息，用于定位非局部的过程；加载器会运行一个动态的链接器，使用这些额外的信息找到合适的库并更新所有的外部引用。这种 DLL 的缺点是它仍然会一次性加载所有库函数。一种改进方法是使用懒过程链接(Lazy Procedure Linkage) 版本的 DLL，它能保证只有当程序调用库函数时，对应的库才会被链接到程序里。下图展示了这种版本的 DLL：\n\n数据类型\ngo\n\nc\n\n无论是 32 位还是 64 位系统，long long 类型的大小都是 8 字节\nlong 在 32 位系统上是 4 字节，在 64 位系统上是 8 字节\n"},"课程笔记/计算机网络/lab相关/lab7-网络应用协议-and-Socket编程接口":{"slug":"课程笔记/计算机网络/lab相关/lab7-网络应用协议-and-Socket编程接口","filePath":"课程笔记/计算机网络/lab相关/lab7 网络应用协议&Socket编程接口.md","title":"lab7 网络应用协议&Socket编程接口","links":[],"tags":[],"content":"基本的网络应用软件\n自定义的协议规范\nSocket编程接口\n客户端\n服务端\n程序界面：命令行或者最简单的窗体\n\nIP 地址：IPv4 (32 bits) or IPv6 (128 bits) 地址，一台计算机可以拥有一个独立的IP 地址；一个局域网也可以拥有一个独立的IP 地址（对外就好像只有一台计算机）。\nMAC 地址(48 bits)：每个网卡的MAC 地址在全世界都是独一无二的。多数现实的情况是，一个局域网往往才能拥有一个独立的IP地址；换句话说，IP 地址只能定位到一个局域网，无法定位到具体的一台计算机。\n\n数据包中除了会附带对方的IP 地址，还会附带对方的MAC 地址，当数据包达到局域网以后，路由器/交换机会根据数据包中的MAC 地址找到对应的计算机，然后把数据包转交给它，这样就完成了数据的传递。\n\n\n端口号(16 bits)：一台计算机可以同时提供多种网络服务，例如Web 服务（网站）、FTP 服务（文件传输服务）、SMTP 服务（邮箱服务）等，仅有IP 地址和MAC 地址，计算机虽然可以正确接收到数据包，但是却不知道要将数据包交给哪个网络应用程序来处理。为了区分不同的网络应用程序，计算机会为每个网络程序分配一个独一无二的端口号（Port Number）。端口（Port）是一个虚拟的、逻辑上的概念。可以将某台计算机看成是一个居民楼，而每个网络应用程序是居住在这个楼的居民，为了能把信件投送到家，必须在投送地址上写明房间号。\n\n注意一般0-1023端口是分配给一些特定的网络应用服务，如\n\nhttp (TCP) 服务的端口号是80，https(TCP)服务的端口号是443\nDNS(UDP)服务的端口号是53\nFTP 服务的端口号是21\nSMTP 服务的端口号是25 (POP3 101)\n\n\n我们实验中端口号请选择1024-65535之间的数值（以自己学号的后四位作为服务器端的监听端口号，如果后四位中的第一位为零，则采用1XXXX）。\n\n\n\nsocket\nsocket 的原意是“插座”，在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。\n\n\n                  \n                  UNIX/Linux 中的socket 是什么？ \n                  \n                \n\n\n在UNIX/Linux 系统中，为了统一对各种硬件的操作，简化接口，不同的硬件设备也都被看成一个文件。对这些文件的操作，等同于对磁盘上普通文件的操作。\n\n通常用0 来表示标准输入文件（stdin），它对应的硬件设备就是键盘；\n通常用1 来表示标准输出文件（stdout），它对应的硬件设备就是显示器。\n\n\n为了表示和区分已经打开的文件，UNIX/Linux 会给每个文件分配一个ID，这个ID 就是一个整数，被称为文件描述符（File Descriptor）。\n网络连接也是一个文件，它也有文件描述符！\n我们可以通过socket() 函数来创建一个网络连接，或者说打开一个网络文件，socket() 的返回值就是文件描述符。\n\n有了文件描述符，我们就可以使用普通的文件操作函数来传输数据了\n用read() 读取从远程计算机传来的数据；\n用write() 向远程计算机写入数据。\n\n\n\n\n\n\n\n                  \n                  Window 系统中的socket 是什么？ \n                  \n                \n\n\nWindows 也有类似“文件描述符”的概念，但通常被称为“文件句柄”。\n与UNIX/Linux 不同的是，Windows 会区分socket 和文件，Windows 就把socket 当做一个网络连接来对待，因此需要调用专门针对socket 而设计的数据传输函数，针对普通文件的输入输出函数就无效了。\n\n\n\nsocket的种类\n流格式套接字（SOCK_STREAM）\n\n数据在传输过程中不会消失；\n数据是按照顺序传输的；\n数据的发送和接收不是同步的(流格式套接字的内部有一个缓冲区（是一个字符数组），通过socket 传输的数据将保存到这个缓冲区。接收端在收到数据后并不一定立即读取，只要数据不超过缓冲区的容量，接收端有可能在缓冲区被填满以后一次性地读取，也可能分成好几次读取。)\nExample: HTTP (TCP)\n\n\n数据报格式套接字（SOCK_DGRAM）\n计算机只管传输数据，不作数据校验，如果数据在传输中损坏，或者没有到达另一台计算机，是没有办法补救的。也就是说，数据错了就错了，无法重传。\n\n强调快速传输而非传输顺序；\n传输的数据可能丢失也可能损毁；\n限制每次传输的数据大小；\n数据的发送和接收是同步的\nExample: QQ视频和语音聊天(UDP)\n\n我们所说的socket编程，是在传输层的基础上，所以可以使用TCP/UDP 协议。但是实验要求TCP\nConstructing Message\nByte Ordering\n\nDifferent machines / OS’s use different word orderings\n\nLittle-endian: lower bytes first\nBig-endian: higher bytes first\n\n\n\n注意不同类型的主机字节顺序不同（但是网络传输过程中都是大端的顺序）为了可移植性，需要使用四个函数：\n\ns：16bits的port numbers\nl：32bits的port numbers\nAlignment &amp; Padding\n对齐和置零\nAlignment：把数据放置在内存中地址等于字节倍数的位置，这样可以提高系统性能\nPadding：填充插入额外字节\n\nFraming &amp; Parsing\nFraming\nParsing\n具体的编程\nMany network applications consists of a pair programs ——a client program and a server program ——residing in two different end systems（web or ftp）\n程序执行时会创建一个客户端进程和一个服务器进程，这些进程通过从套接字读取和向套接字写入来相互通信。\n\n决定哪种传输层协议 TCP/UDP\n\n\nTCP是面向链接的，提供一个可靠的字节流信道（TCP是内驻在操作系统里面，我们要写的是网络层的协议）\n\n\nUDP是面向无链接的，将独立的数据包从一个端系统发送到另一个端系统，不保证任何交付性\n\n\n\n\nTCP数据报结构\n• 1) 序号：Seq（Sequence Number）序号占32位，用来标识从计算机A发送到计算机B的数据包的序号，计算机发送数据时对此进行标记。每发一个字节都有一个独立的序号\n• 2) 确认号：Ack（Acknowledge Number）确认号占32位，客户端和服务器端都可以发送，Ack = Seq + 1。确认被接收\n• 3) 标志位：每个标志位占用1Bit，共有6个，分别为 URG、ACK、PSH、RST、SYN、FIN，具体含义如下：\n– URG 紧急指针（urgent pointer）有效。\n– ACK 确认序号有效（1 ）。\n– PSH 接收方应该尽快将这个报文交给应用层。\n– RST 重置连接。\n– SYN 建立一个新连接（1 ）。\n– FIN 断开一个连接。\n\n\nTCP三次握手建立连接\n\n数据在传输前要建立连接 （connect() 函数，为了保证ip地址、端口、物理链路正确），传输完毕后还要断开连接。\nTCP建立连接时要传输三个数据包，俗称三次握手（Three-wayHandshaking）。可以形象的比喻为下面的对话：\n\n[Shake1] 套接字A：“你好，套接字B，我这里有数据要传送给你，建立连接吧。”\n[Shake2] 套接字B：“好的，我这边已准备就绪。”\n[Shake3] 套接字A：“谢谢你受理我的请求。”\n\n\n\n建立连接时需要进行三次握手\n\n建立链接成功后进行数据传输\n\n当数据包在传输的过程中发生丢失的时候，会进行重传。如何发现丢失的呢？RTT：round trip time\nTCP四次握手断开连接\n建立连接非常重要，它是数据正确传输的前提；断开连接同样重要，它让计算机释放不再使用的资源。如果连接不能正常断开，不仅会造成数据传输错误，还会导致套接字不能关闭，持续占用资源，如果并发量高，服务器压力堪忧。\n建立连接需要三次握手，断开连接需要四次握手，可以形象的比喻为下面的对话：\n\n\n[Shake 1] 套接字A：“任务处理完毕，我希望断开连接。”\n\n\n[Shake 2] 套接字B：“哦，是吗？请稍等，我准备一下。”\n\n\n等待片刻后……\n\n\n[Shake 3] 套接字B：“我准备好了，可以断开连接了。”\n\n\n[Shake 4] 套接字A：“好的，谢谢合作。”\n\n5000和7000没关联\n第二个fin包：seq值+1了，但是ack值没有进行变化。因为客户端在ack和fin包之间没有发出新的数据包给服务器端。在这个包里fin会置1。\n第二个ack包：在上一个fin包的seq基础上7001+1\n\n\n客户端最后一次发送 ACK包后进入 TIME_WAIT 状态，而不是直接进入 CLOSED 状态关闭连接，这是为什么呢？\n\nTCP 是面向连接的传输方式，必须保证数据能够正确到达目标机器，不能丢失或出错，而网络是动态、不稳定的，数据随时可能被会毁坏或丢弃，所以机器A每次向机器B发送数据包后，都要求机器B“确认” ，回传ACK包，告诉机器A我收到了，这样机器A才能知道数据传送成功了。如果机器B没有回传ACK包，机器A会重新发送，直到机器B回传ACK包。\n\n\n\n客户端最后一次向服务器回传ACK包时，有可能会因为网络问题导致服务器收不到，服务器会再次发送 FIN 包，如果这时客户端完全关闭了连接，那么服务器无论如何也收不到ACK包了，所以客户端需要等待片刻、确认对方收到ACK包后才能进入CLOSED状态。那么，要等待多久呢？（就是说经过一段时间没发出有问题的信号，才能确认没问题）\n\n数据包在网络中是有生存时间的，超过这个时间还未到达目标主机就会被丢弃，并通知源主机。这称为报文最大生存时间（MSL，Maximum Segment Lifetime）。TIME_WAIT 要等待 2MSL才会进入 CLOSED 状态。ACK 包到达服务器需要 MSL 时间，服务器重传 FIN 包也需要 MSL 时间，2MSL 是数据包往返的最大时间，如果 2MSL 后还未收到服务器重传的 FIN 包，就说明服务器已经收到了 ACK 包。\n\n如果fin包也没送到呢？实际上，ack没达到服务器端的话，会通知客户端重发的，也就不会有服务器发送fin包的问题了。\n\n\n\n\n\n\nlinux的socket例子\n\n函数名和我们用的可能有所不同\nsocket：开洞\nbind：给门洞安门牌号，才能正常收发邮件\nlisten：服务器端使用的\naccept：服务器使用的\nconnect：客户端使用的\nsend：都有的\nreceive：都有的\nclose：都有的\n\n\n在 Linux 下使用 &lt;sys/socket.h&gt; 头文件中 socket() 函数来创建套接字\n\n\n原型为：int socket(int af, int type, int protocol);【因为linux把网络连接当成文件来处理】\n\naf为地址族（Address Family），也就是 IP 地址类型。\n\nAF_INET表示IPv4 地址 (INET是“Internet”的简写)\nAF_INET6表示IPv6地址\nAF_UNIX (local channel, similar to pipes)\nAF_ISO (ISO protocols)\n\n\ntype 为数据传输方式/套接字类型\n\nSOCK_STREAM（流格式套接字/面向连接的套接字 ~ TCP）\nSOCK_DGRAM（数据报套接字/无连接的套接字 ~ UDP）\n\n\nprotocol 表示传输协议，常用的有IPPROTO_TCP 和 IPPROTO_UDP，分别表示 TCP 传输协议和 UDP 传输协议。Usually set to 0 (i.e., use default protocol). 有可能多种协议使用同一种数据传输方式，所以在socket编程中，需要同时指明数据传输方式和协议。（ 提供面向连接的服务，但是有多个协议来支撑面向连接的服务)\n\n\n\n像 connect()、accept() 和 bind() 这样的套接字函数需要使用专门定义的地址结构来保存 IP 地址、端口号和协议类型。\n\n\n困难在于你可以使用套接字用不同的协议来编写网络应用程序。例如，我们可以使用 IPv4、IPv6、本地 Unix 等。问题在于：每种不同的协议都使用不同的地址结构来保存其寻址信息，但它们都使用相同的函数 connect()、accept() 和 bind() 等。\n\n\n因此改成一个通用的地址结构再给这些函数用\n\n\n\nstruct sockaddr\nstruct sockaddr{\nsa_family_t sin_family; //地址族(Address Family)，也就是地址类型\nchar sa_data[14]; //IP地址和端口号\n};\n\n必须传递给所有需要地址结构的 socket 函数的地址结构。\n强制地址转换\n\nIPv4 address structure: struct sockaddr_in\nstruct sockaddr_in{\nsa_family_t sin_family; //地址族(Address Family)，也就是地址类型\nuint16_t sin_port; //16位的端口号\nstruct in_addr sin_addr; //32位IP地址\nchar sin_zero[8]; //不使用，一般用0填充\n};\n \nstruct in_addr{\nin_addr_t s_addr; //32位的IP地址\n};\n\n\nsockaddr是一种通用的结构体，可以用来保存多种类型的IP地址和端口号，而 sockaddr_in是专门用来保存 IPv4 地址的结构体。\n\nconnect(), bind()和accept()函数中第二个参数的类型为 sockaddr\n\n\nsockaddr和 sockaddr_in的长度相同，都是16字节，sockaddr将IP地址和端口号合并到一起，用一个成员 sa_data表示。要想给 sa_data赋值，必须同时指明IP地址和端口号，例如“127.0.0.1:80”，遗憾的是，没有相关函数将这个字符串转换成需要的形式，也就很难给 sockaddr类型的变量赋值，所以使用 sockaddr_in来代替。这两个结构体的长度相同，强制转换类型时不会丢失字节，也没有多余的字节\n\n在服务器端建立一个socket\n\nsocket（） 创建套接字\nbind（）将套接字绑定到一个地址，对于 Internet 上的服务器套接字，地址由主机上的端口号组成。\nlisten（）调用监听连接\naccept（）接受连接。通常是堵塞地，直到有一个客户端与服务器建立连接\n发送和接受数据\n\n简化版：\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;arpa/inet.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;netinet/in.h&gt;\nint main(){\n//创建套接字，it just creates interface\nint serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); //如果serv_sock&lt; 0, 则创建失败，最好有检查\n//将套接字和IP、端口绑定\nstruct sockaddr_in serv_addr; //IPv4地址结构体\nmemset(&amp;serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充\nserv_addr.sin_family = AF_INET;//使用IPv4地址\nserv_addr.sin_addr.s_addr = inet_addr(“127.0.0.1”);//服务器IP地址(这里使用的是本机地址，【最好用这个因为可能本机有很多个网卡要多个套接字，这个的话一个套接字就可以】INADDR_ANY)\nserv_addr.sin_port = htons(1234); //端口//可移植性比较好\nbind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr)); //这里地址强制转换\n//进入监听状态，等待用户发起请求\nlisten(serv_sock, 20); //20表示服务器端可容纳队列长度，可以有20个clients等待连接\n//接收客户端请求\nstruct sockaddr_in clnt_addr;\nsocklen_t clnt_addr_size = sizeof(clnt_addr);\nint clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size);\n//向客户端发送数据\nchar str[] = “Hello Client!&quot;;\nwrite(clnt_sock, str, sizeof(str));\n//关闭套接字\nclose(clnt_sock); close(serv_sock); return 0;\n}\nserv_sock 一直监听\nclnt_sock 用于接收\n需要在这个模板上增加做一些创建失败的检查\naccept\nint clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size);\n\naccept() 返回一个新的套接字文件描述符，用于与客户端进行读写。原有的文件描述符通常用于监听新的传入连接。\n它从服务器该套接字的队列中出队下一个连接请求。如果队列为空，该函数将阻塞直到有连接请求到达。\n注意该函数的最后一个参数是一个指针。你不是在指定长度，内核会指定并将值返回给你的应用，同样对于 clnt_addr 也是如此。在与客户端建立连接后，必须将客户端的地址提供给你的服务器，否则你如何向客户端发送响应？因此，accept 函数调用会为你填充地址结构和地址结构的长度以供使用。、\n当服务器接收到（接受）客户端的连接请求时 ⇒ 它会派生（forks）出自身的副本并让子进程处理该客户端。（确保你记住这些操作系统概念）因此在服务器机器上，监听套接字与已连接套接字是不同的。\n\nwrite() and read()\nintwrite(int file_descriptor, const void *buf, size_t message_length);\nintread(int file_descriptor, char *buffer, size_t buffer_length);\n\nwrite() 函数的返回值是写入的字节数，失败时返回 −1\n这个函数所做的是将数据从你的应用程序传输到本机内核中的一个缓冲区，它并不直接通过网络发送数据。TCP 完全控制数据的发送，这在内核内部实现。\nread() 函数返回的是读取的字节数，可能小于缓冲区长度。失败时返回 −1。\nread() 仅将数据从内核中的缓冲区传输到你的应用程序，你并不是直接从远程主机读取字节流，而是由 TCP 来控制并为你的应用缓冲数据。\n\n\n\n把ip地址转化为用于网络传输的二进制数值\n\nintinet_aton(constchar cp, structin_addrinp);\ninet_aton() 转换网络主机地址ip(如192.168.1.10)为二进制数值，并存储在structin_addr结构中，即第二个参数*inp, 函数返回非零值表示cp主机地址有效，返回0表示主机地址无效。\n这个转换完后不能用于网络传输，还需要调用htonl函数才能将主机字节顺序转化为网络字节顺序。\n\n\n将网络传输的二进制数值转化为成点分十进制的ip地址\n\nchar *inet_ntoa(structin_addrin);\ninet_ntoa函数转换网络字节排序的地址为标准的ASCII以点分开的地址,该函数返回指向点分开的字符串地址（如192.168.1.10)的指针，该字符串的空间为静态分配的，这意味着在第二次调用该函数时，上一次调用将会被重写（复盖），所以如果需要保存该串最好复制出来自己管理！\n\n\n\n在客户端建立一个套接字\n\n使用 socket() 系统调用创建一个套接字\n使用 connect() 系统调用将套接字连接到服务器地址\n发送和接收数据。有多种方法可以实现，但最简单的是使用 read() 和 write() 系统调用。\n\n\n注意，客户端需要知道服务器的存在以及服务器的地址，但服务器在连接建立之前无需知道客户端的地址（甚至无需知道客户端的存在）。【 因为accept会自动读入与服务端建立连接的客户端地址信息的】\n另请注意，一旦连接建立，双方都可以发送和接收信息。\n\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;arpa/inet.h&gt;\n#include &lt;sys/socket.h&gt;\nint main(){\n//创建套接字\nint sock = socket(AF_INET, SOCK_STREAM, 0);\n//向服务器（特定的IP和端口）发起请求\nstruct sockaddr_in serv_addr;\nmemset(&amp;serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充\nserv_addr.sin_family = AF_INET; //使用IPv4地址\nserv_addr.sin_addr.s_addr = inet_addr(“127.0.0.1”);//服务器IP地址(这里是本机地址)\nserv_addr.sin_port = htons(1234); //端口\n//connect()函数执行TCP三次握手建立联接\nconnect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));\n//读取服务器传回的数据\nchar buffer[40];\nread(sock, buffer, sizeof(buffer)-1);\nprintf(&quot;Message form server: %s\\n&quot;, buffer);\n//关闭套接字\nclose(sock); return 0;\n}\nwindows的socket例子\n//Windows 不把套接字作为普通文件对待，而是返回 SOCKET 类型的句柄。\nSOCKETsocket(int af, int type, int protocol);\n \n//Linux下socket函数\nintsocket(intaf, inttype, intprotocol);\nGeneric:\nstructSOCKADDR{\nunsigned short sa_family;\nchar sa_data[14];\n};\nIPv4 address struct:\nstructsockaddr_in{\nshort sin_family;\nunsigned short sin_port;\nstructin_addrsin_addr;\nchar sin_zero[8];\n};\nstructin_addr{\nunion {\nstruct{unsigned char s_b1, s_b2, s_b3, s_b4;} S_un_b;\nstruct{unsigned short s_w1, s_w2;} S_un_w;\nunsigned long S_addr;\n} S_un;\n};\n//include部分\n//Windows 下的 socket 程序依赖 Winsock.dll 或 ws2_32.dll，必须提前加载。\n#include &lt;stdio.h&gt;\n#include &lt;winsock2.h&gt;\n#pragma comment (lib, &quot;ws2_32.lib&quot;) //加载 ws2_32.dll\n绿色是与linux不同的部分\n\n\n\n全流程回顾\n\n\nCommunication via sockets necessitates existence of the 4-tuple:\n\nLocal IP address\nLocal Port#\nForeign IP address\nForeign Port#\n\n\nServer\n\nPassively waits for and responds to clients\nPassive socket 被动套接字\n\n\nClient\n\nInitiates the communication\nMust know the address and the port of the server\nActive socket 主动套接字\n\n\n\n\n服务器先执行并等待接收\n客户端后执行并且向服务器发送第一个网络数据包\n建立连接之后，客户端或者服务器都可以发送和接收数据\n\n关于实验\n\n每增加一个功能就调试一次\n\n\nzjucomp.net/docs/Coding/toolchain\n不要使用定长的数据报，协议的定界问题要自己思考\n实验报告：一些控制相关的 客户端有菜单选项，服务端没有菜单选项的话需要考虑\n"},"课程笔记/计算机网络/lab相关/lab8":{"slug":"课程笔记/计算机网络/lab相关/lab8","filePath":"课程笔记/计算机网络/lab相关/lab8.md","title":"lab8","links":[],"tags":[],"content":""},"课程笔记/计算机网络/物理层-the-physical-layer":{"slug":"课程笔记/计算机网络/物理层-the-physical-layer","filePath":"课程笔记/计算机网络/物理层 the physical layer.md","title":"物理层 the physical layer","links":["tags/flashcard"],"tags":["flashcard"],"content":"DECK: CS::CN\n物理层的主要任务\n\n网络中硬件设备和传输介质的种类繁多，通信方式也各不相同。物理层应尽可能屏蔽这些差异，让数据链路层感觉不到这些差异。\n\n发送方的数据链路层将需要发送的帧交给物理层\n传输后接收方的物理层将这些帧传递给接收方的数据链路层。\n具体地说，物理层确定与传输媒体接口有关的一些特性：\n\n\n机械特性：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。\n电气特性：指明在接口电缆的各条线上出现的电压的范围。\n功能特性：规定物理接口上各条信号线的功能分配和确切定义（各条线上出现各种电压表示何种意义）。\n规程特性 / 过程特性：定义了各信号线的工作顺序和时序，使得比特流传输得以完成。\n\n2 基本概念\n\n数据是需要传送的信息，信号是数据在传输过程中的存在形式。\n\n2.1 link/channel/data rate/baud rate\n链路和信道 flashcard\n\n(物理) 链路 link；承载信号的 physical path\n一条物理链路可以通通过分时、分频等方式容纳多个 信道 channel (也称为逻辑链路)，每条信道对应着一个发送方和一个接收方。\n\n\n比特率 bit rate flashcard\n\n也可以叫data rate数据率 - 单位时间内传输的信息中 bit 的数目，即 (数据量 / 时间)。\n\n单位是 b/s Kb/s Mb/s Gb/s\n也可以写成 bps Kbps Mbps Gbps\n注意是 bit/s 不是 Byte/s\n就算实际发送的比特比数据多【譬如用1111表示1 】，但是data rate不变.也就是说冗余的比特我们不算在内\n\n\n\n\nsymbol rate flashcard\n\n码元 / 符号 symbol - 用一个数字脉冲表示的一个 k 进制数字。就是一次采样得到的结果，可能包含不同数量的bit。\n\n比如假设电平有4档分别编码00，01，10，11，那么一次采样就是2bit数据。那么分辨8个电压的话一次采样的结果就有3bit。\n\n\nsymbol rate / baud rate - 单位时间内传输的 symbol 数目，即单位时间内可能发生的信号变化次数。就是单位时间采样次数。symbol/second就是baud\n\n\n例如一个四进制码元（0123，四个）可以携带2bit（log24）信息，那么如果数据率是64kb/s，那么symbolrate是32kbaud（因为2bit/symbol）。当然也存在0.5bit/symbol的情况。\n\n\n2.2 带宽\n带宽相关原理/谐波拟合方波 flashcard\n\n\n用一个一倍基频的谐波（傅里叶分量）拟合方波\n用一个一倍基频和一个二倍基频的谐波拟合\n用一个一倍基频和一个二倍基频和一个四倍基频的谐波拟合\n……\n谐波越多，拟合方波越成功。但是物理媒体有限制：截止频率fc，超过这个频率的波会有不同的减弱。所以只能使用0-fc频率【带宽/频带宽度】\n\n周期：b（需要传输b bit信号）/r（data rate）\n频率：r/b 周期的倒数\n那么N*r/b⇐fc N为可以接受的谐波个数，N倍基频不能大于截止频率。可以得到N⇐b*fc/r。\n因为N越大，信号质量越好，所以r过大时信号质量就会不好。因此在信号质量有一定要求的情况下，带宽越大，数据率就越大。因此数据率的最大值也可以称为带宽\n\n\n\n\n带宽的辨析 flashcard\n\n(数字) 带宽 (digital) bandwidth：最大可能的 data rate，用来表示通信线路传输数据的能力，频带宽度越大，数据率越大，因此把数据率最大值也叫做带宽。单位与 data rate 一致。\n(模拟) 带宽 (analog) bandwidth：信道的频带宽度，单位是 Hz。带宽是传输介质的一种物理特性，滤波器可以通过过滤掉某些频率的信号来进一步限制信号的带宽。\n\n带宽指的是一段频率范围，它并不要求这段频率一定从 0 开始；事实上对于无线信道来说，发送低频率的信号也是不可能的，因为波长会很大，天线长度要跟波长一样长。\n\n我们称之前所说的频率为 0∼B Hz 的信号为基带信号 (baseband signal)\n而将其搬移到 S∼S+B Hz 的信号为通带信号 (passband signal)。\n\n\n\n\n\n\n2.3 采样定理\nNyquist’s theorem 奈奎斯特定理 flashcard\n\n条件：在理想 (无噪声) 低通 (带宽有限) 信道中\n\n【有噪声也可以适用】，因为提出的是理论上限，有噪声只会更低\n\n\n极限码元传输速率（采样频率）是 2W Baud，其中 W 是理想低通信道的 (模拟) 带宽，大于这个极限码元速率也采不出更多了就浪费了。\n\n若用 V 表示每个码元离散电平的数目 (即其可以取值的离散值的个数；即其进制数)，则极限数据速率为 2W log₂(V) (b/s)。\n8级电平，用log28个bit可以表示一个symbol，即3bit/symbol\n\n\n\n\nShannon’s theorem 香农定理 flashcard\n\n条件：在受高斯白噪声干扰的信道中\n用 W 表示信道的 (模拟) 带宽，S 表示信号平均功率，N 表示高斯噪声功率，则极限数据速率是 W log₂(1 + S/N) (b/s)。\n\n信噪比 Signal-to-Noise Ratio, SNR：公式中的 S/N 就是信噪比，没有单位；但为了方便表示更大的范围，也用 10lg(S/N) 表示信噪比，单位为分贝 dB（比如用50分贝来表示10的五次方的信噪比）。就是说如果看到分贝单位的信噪比需要进行换算之后还原成普通信噪比代入公式.\n\n\n\n\n\n\n                  \n                  求极限数据速率例题 flashcard\n                  \n                \n\n\n对于给出了 V (信号电平数) 的情况，无论是否说明无噪声都应使用 Nyquist’s theorem 确定 data rate 的一个上界。\n对于给出了 SNR (信噪比) 的情况，也应根据 Shannon’s theorem 确定另一个上界。\n\n示例一：电话系统\n电话系统的典型参数是信道带宽为 3000Hz，信噪比为 30dB，则该系统的最大数据传输速率为： 3k×log2​(1+10^(30/10)) b/s≈30kb/s\n示例二：结合两种定理\n二进制信号在信噪比为 127:1 的 4kHz 信道上传输，求最大数据传输速率。【2进制信号可以理解成2元信号】\n\n根据 Nyquist’s theorem，最大数据速率为2×4k×log2​(2) b/s=8kb/s\n根据 Shannon’s theorem，最大数据速率为4k×log2​(1+127) b/s=28kb/s\n结论： 二者均为上界，应取其中较小的一个，因此该信道的最大数据传输速率为 8kb/s。\n\n示例三 无意义信息\n\n一条无噪声的 8kHz 信道，每个信号包含 8 级，每秒采样 24k 次，那么可以获得的最大传输速率是？\n\n无噪声 - Nyquist, data rate = 2 * 8kHz * log₂(8) bit/symbol = 48kbps\n“题目中给出的每秒采样 24k 次是无意义的，因为超过了波特率的上限 2W = 16 kBaud，所以 72kbps 是错误答案”\n\n\n\n示例四 不乘2的情况\n\n一个信道每 1/8s 采样一次，传输信号共有 16 中变化状态，最大数据传输速率是？【最大采样是带宽的2倍，这里已经告诉我们采样频率了就不乘2了】\n\n8Baud * log₂(16) bit/symbol = 32bps\n\n\n\n\n\n\n\n3 信息交互方式 flashcard\n\n单工链路 simplex link - 1条信道，固定单向通信。【 广播】\n半双工链路 half-duplex link - 2条信道，双向可通信但不能同时。【 对讲机】\n全双工链路 full-duplex link - 2条信道，两边可以同时收发。【 打电话】\n\n注意2条 channel 不一定需要2条物理链路，一条通过一些复用方式或者双向传输也可以实现。\n\n\n\n\n4 传输介质 / 传输媒体 flashcard\nTransmission media，数据传输系统中发送设备和接收设备之间的物理通路。\n\n导向传输介质 Guided trans media\n\n双绞线 twisted pair：绞合以【减少相邻导线的电磁干扰】。\n\n在双绞线外加一层金属丝编织的屏蔽层，可以进一步【提高抗电磁干扰的能力 】，称为屏蔽双绞线 STP, Shielded Twisted Pair\n没有屏蔽层的称为非屏蔽双绞线 UTP, Unshielded Twisted Pair。\n\n\n同轴电缆 coaxial cable\n光纤 fiber optics\n\n\n非导向传输介质 / 无线传输 Wireless transmission\n\n无线电波 Radio：有较强的穿透能力，不需对准某个方向；无线手机通信、WLAN (wireless local area network) 等。\n微波、红外线、激光：有很强的方向性，直线传播。\n\n\n\n\n5 数字调制 / 数字数据到模拟信号\n数据与代表它们的信号之间的转换过程称为数字调制 digital modulation。\n5.1 基带传输 Baseband Transmission flashcard\n\n直接将数据转换为数字信号，数字信号是离散的，占用传输介质上的全部频率，用于有线介质 (光纤不是基带传输) 【编码】\n\n**Non-Return to\n\n\nZero\n- 用正电压 / 有光表示 1，负电压 / 没有光表示 0。\n- 问题是如果 0 和 1 交替，接收端可以在每一次变化时校准；但是如果一直是 0 或者 1 的话过一段时间可能就数错了会失去同步。\n\nManchester (以太网 Ethernet 的编码方式)\n\n用一个高和一个低表示1，一个低一个高表示0 (实际上就是与一个时钟信号做了 XOR，如图)。解决了时钟信号的问题，即每个码元中间一定有电平跳变。\n问题是带宽开销增大了—倍。\n\n\nNRZI NRZ Invert (USB 2.0 的编码方式)：\n\n用信号翻转表示 1，信号不变表示 0。没有带宽开销的增加；\n解决了一长串都是 1 的问题；但是如果一长串都是 0 还是不行。\n\n\n4B/5B mapping：\n\n把4bit的data重新映射到一套新的5bit编码\n经过设计的新编码保证映射结果最多只会出现连续 3 个 0，就能解决NRZI NRZ Invert的问题。虽然增加了 25% 的开销，但是比 Manchester 好一些。\n\n\n扰频/倒频 scrambling：\n\n尝试解决一长串 0 和 1 的问题。发送数据之前，用一个伪随机序列 XOR 数据，接收器用同样的序列 XOR 后得到结果。\n但是其实不太靠谱如果信号和xor数据一模一样的话异或完全是0，而且容易被截获\n\n\n双极编码 bipolar encoding / AMI, Alternate Mark Inversion：\n\n这种编码方式关注信号的平衡性；短时间内正电压和负电压一样多的信号称为平衡信号 balanced signal。这样的信号均值为0，即没有直流分量；由于传输介质的物理性质，没有直流分量是一个优点。\n这种编码方式用 +1 或者 -1 表示 1，每次的 1 与前一次的 1 表示法相反，保证最多只差 1 个；用 0 表示 0。\n\n\n8B/10B 编码模式：\n\n同时考虑这些问题，通过映射保证没有超过 5 个连续的 0 或  1，同时保持 0 和 1 数目相对均等；其额外带宽消耗也只有 25%\n\n\n\n5.2 通带传输 Passband Transmission flashcard\n通过调节载波信号的幅值、相位或频率来运载数据，占据载波信号频率为中心的一段频带，用于无线和光纤信道。【 调制】\n\n\n幅移键控 ASK, Amplitude Shift Keying：\n\n通过两个不同的振幅分别表示 0 和 1；可以用更多的幅值等级表示更多的信息。\n\n\n频移键控 FSK, Frequency Shift Keying：\n\n类似地，通过不同频率表示不同的码元。\n\n\n相移键控 PSK, Phase Shift Keying：\n\n将载波波形偏移—定的相位。\n\n二进制相移键控 BPSK, Binary PSK：将波形偏移 0° 和 180°。\n正交相移键控 QPSK, Quadrature PSK：将波形偏移 45°, 135°, 225° 和 315°。\n\n\n\n\n\n叠加综合\n\n星座图 constellation diagram：为了让每个码元传输更多 bit 的信息，也可以将这些方式综合起来使用。下面的星座图用黑点表示一个合法的振幅和相位的组合，每一个symbol可能是这n个黑点中的一个\n\n其中每个黑点到原点的距离表示振幅，\n和 x 轴正方向所成角度表示相位偏移。\n\n\n正交调幅 QAM, Quadrature Amplitude Modulation：上图 (a) 即为前述 QPSK，而后面两个图是 QAM 【正交相移键控x调幅】的两个实例，它们的每个 symbol 分别携带 4 bit 和 6 bit 的信息。\nGray code：为星座图分配每个黑点代表的 bit 时，需要考虑少量的突发噪音不会导致很多 bit 出错。可以使用 Gray code 解决这一问题（相邻点的 bit 码仅相差一位）。\n\n\n6 多路复用\n频分复用 FDM, Frequency Division Multiplexing flashcard\n经过调制后，要传输的信号所占带宽是有限的；而线路可使用的带宽远大于这一宽度。\n我们可以对多路信号采用不同频率进行调制，使得调制后各路信号频率不同，不会互相干扰；即将信道带宽分割为多种不同频带的子信道，实现多路复用。\n\n每个频带之间保留足够宽的距离，保证相邻的频带不会相互重叠。这一部分保护间隙称为保护频带 guard band。 \n正交频分复用 OFDM, Orthogonal FDM：基本思想是：每个子载波相互正交；即每个子载波在其子载波的中心频率处能量为0。这样在每个子载波中心频率处取样，就不会被其他子载波干扰了。这样的方式不需要 guard band，且频带利用率很高。\n\n\n时分复用 TDM, Time Division Multiplexing flashcard\n每个用户周期性地轮流工作，每次在一个非常短的时间内获得整个带宽。类似于频分复用，时分复用也可能会需要增加保护时间 guard time，保证不重叠\n\n\nTDM 的调度方式是机械的，一种动态按需分配时间片的方式是统计时分复用 STDM, Statistical TDM。但是需要额外的信息来标识可能效率反而会变低\n\n\n码分复用 CDM, Code Division Multiplexing/码分多址CDMA, Code Division Multiple Access#flashcard flashcard\n\n\n若干由 1 或 -1 组成的序列S, Sˉ 表示其反码 (序列中的每个数取其相反数)。\n对于任意两个序列 S 和 T，其归一化内积 (normalized inner product) =内积（对应位置相乘的积相加）/m，其中 m 是序列的长度，此处为 8。\n\n容易理解，有 S⋅S=1，S⋅Sˉ=−1。若 S⋅T=0，我们称这两个序列是正交 (orthogonal) 的； 显然此时 Sˉ⋅T=S⋅Tˉ=Sˉ⋅Tˉ=0。根据这一定义，图中 (a) 的 4 个序列ABCD是两两正交的。\n\n\n现在我们尝试利用这些序列发送信号。每个发送端（ABCD）被分配了一个序列；\n\n每一个周期中，发送端可以选择发送 1 (通过发送这个序列)，或者发送 0 (通过发送这个序列的反码)，或者什么都不发送。当多个站同时发送时，它们发送的信号会叠加起来；\n但是由于序列的正交性，我们可以将每个站发送的信息单独解码出来。假设在某一个周期中，A 和 D 发送了 0，B 发送了 1，C 什么都没有发送，那么叠加出的信号就形如 S=Aˉ+B+Dˉ=(1,−1,3,−1,1,3,−1,−1)。我们将这个信号与 B 作归一化内积：\nS⋅B=8−1+1+3+1+1+3−1+1​=1\n\n\n即 B 发送的是 1。如果与 C 作归一化内积，则结果为 0，表示 C 什么都没有发送。如果与 A 或 D 做归一化内积，则结果为 -1，表示发送的是反码 (即 0)。这是因为，归一化内积满足分配律，S⋅D=(Aˉ+B+Dˉ)⋅D=Aˉ⋅D+B⋅D+Dˉ⋅D，而前两项由于正交性为 0，第三项为 -1，因此最终结果为 -1；其他的情况也是类似的。\n下面回顾我们做了什么。我们==在原本需要发送 1个 bit 的时间发送了 m 个 bit 组成的序列==，这样的序列可以有 m 个且两两正交 (考虑正交矩阵)，==从而满足 m 个发送方同时互不干扰地传输的需要==。同时由于我们在单位时间内传输的 bit 数是原来的 m 倍，因此==所需要的带宽也是原来的 m 倍==。如此我们将一个窄带信号扩展到了一个很宽的频带上，这样更能容忍干扰，同时允许多个用户共享同一个频带。\n\n\n7 公共电话交换网络 The Public Switched Telephone Network, PSTN flashcard\n\n\n7.1 本地回路 Local Loop flashcard\n\n调制解调器 modem: 调制器 modulator 和 解调器 demodulator 的缩写，数字信息和模拟信号流之间的转换。\n非对称用户线 ADSL Asymmetric Digital Subscriber Line: 使用 FDM。在过去，整个电话系统中的传输都是模拟的，实际的语音信号以电压的形式从源端传输到接收方。\n\n\n7.2 中继线 Trunk flashcard\n\n编码解码器 codec: coder-decoder，模拟信号转为数字信号，使用脉冲编码调制 PCM, Pulse Code Modulation。\n波分复用 WDM, Wavelength Division Multiplexing：感觉和频分复用差不多，毕竟频率和波长没啥区别。可能 FDM 用来说电，WDM 用来说光这个样子。\n\n\n7.3 交换 Switching flashcard\n\n\n电路交换 Circuit Switching:\n\n先建立连接，然后直接发，最后释放连接；过程中路径被独占。路径的结点收到就立刻发给下一个结点，不储存。\n\n\n报文交换 Message Switching\n\n不需要建立连接。报文携带目的地址和源地址，途中每个结点在收到整个 message 以后再找下一条路进行传输。\n这样可以动态选择合适空闲的线路，增加线路的可靠性和利用率。但是会引起转发时延，并需要缓存空间。\n\n\n分组交换 / 包交换 Packet Switching\n\n将报文合理分块，增加携带分组编号等信息。\n在报文交换的基础上，缩短了时延，减少了期望的出错重发数据量，同时由于 packet 的长度有所限制，存储管理也方便了很多；动态寻找线路时各个 packet 也可以选择不同路径 (因此，packet 的数据不一定按序到达)。问题是额外信息量进一步增加，且发送前和接收后的工作量也会增加。\n\n\n"}}